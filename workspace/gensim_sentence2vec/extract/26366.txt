
1. OpenCVの機械学習にかかる時間
OpenCVの機械学習は非常に時間がかかり、何もわからない状態から入って一つの学習データ(cascadeファイル)を作るのに相当な時間とトライ&エラーが必要になりました。
その間3〜4ヶ月(爆
まぁ、片手間でやっていたというのもあったのですが、私の実装速度がそこまで速くないため、時間がかかったというのもあります。
2. 導入と検討
早速OpenCVを導入し、学習ツールと方式を検討し始めると・・・・。
HAAR/LBP/HOGが2.4.6の時点では使えることがわかり、
この3つの方法を使って一番どれが良いのか?
ベストプラクティスを探ることにしました。
WEB上で調べてみるとHAAR<LBP<HOGの認識精度のようでした。
しかし、色々と落とし穴があり、
使い分ける必要があることが後々分かりました。
3. 学習画像の収集
まずは学習するデータを集めなければならないと思い、
インターネットから画像ファイルを集め始めました。
ところが、手作業では一向に終わる気配がない・・・・。
1日潰した時点で。。。絶望しました。
WEB上ではゆうすけべーさんや、その他色々な方がcascadeファイルを作ってるのを見かけて、
ぁぁ。簡単そうだから私にも出来るかな?と思っていました。
しかし・・・
それは簡単どころか地獄の始まりだったのです。
4. 如何に素早く的確に画像を集められるか?
今後、様々なものを学習させるにあたって、
ジャンル分けされた画像をどう効率集めるか?が課題だと感じました。
そこで、画像収集ツールを探し始めました。
が、あまり良いツールが見つかりません。orz
探すのに時間を費やすよりもプログラミングした方が早いと感じた私は、
以前、hpricotをRubyに導入してクローラーを作っていたのを思い出し、
簡易版の画像収集ツールを作ったのですが、
思ったより効率が悪く巡回スピードが出ませんでした。
5. ネイティブの画像クローラー
もっと効率を上げるためにはGUI化して、
他の人にタスクを委譲したり、
寝る前に巡回させたりが簡易にできなきゃ時間を短縮出来ない!!
そう思ってMacのGUIアプリにすることにしました。
私にはC/C++のちょっとしたソース財産(SDK)がありまして、
それを使えばパラレル化も非同期通信やらも高速に出来るので
手っ取り早くSDKをベースにhpricot相当のものをC/C++ベースに作って、
画像クローラーGUI版を組み上げました。
このアプリはジャンル指定することで
画像をインターネットから自動的に収集くれるツールで、
その他、様々な設定が出来るようになっています。
寝る前にcpmというクロール予約ファイルを作って、
設定しておくだけであら不思議!
次の朝になると、50〜100GBクラスのデータがごっそり入ってるので、
これらを元にして学習データをチョイスしていきます。
今回は学習認識精度を見ることが目的だったので、
画像は一番収集しやすい、ムフフな画像を中心として収集しました。
これらを使って主にボディパーツを認識させます。
しかし、画像は楽に収集が出来ても、
ローカルディレクトリでTB単位の500〜800万画像のファイルを仕分けするのは、
相当時間がかかるという課題が残りました。
またもや絶望しました。。。。。
OpenCVの機械学習ツールとHAAR/LBP/HOG検出アルゴリズムの比較と検討その1 - リンゴをかじれ
