キャッシュメモリを管理するアルゴリズムは,メインメモリのデータ転送遅延を隠蔽するために重要である.近年では,大容量の LLC(Last Level Cache) が広く使われており,この LLC を管理するアルゴリズムとしてスキャンアクセスに耐性を持つ置き換えアルゴリズムやプリフェッチなどが提案されている.それぞれのアルゴリズムは LLC の性能を向上させるが,組み合わせた場合にお互いのアルゴリズムが悪影響を与え合い,かえってキャッシュの性能が低下することが知られている.我々は,このような衝突を防ぎ,かつプリフェッチと LLC 向けのキャッシュ置き換えアルゴリズムとが協調し合うことでよりキャッシュ性能を高めるプリ・プロモーションを提案している.この手法では,プリフェッチャのアドレス予測に基づいて,アクセスを予測されたキャッシュラインを投機的に MRU 側に移動させ,近い将来にアクセスされるラインを保持する.しかしながら,この手法はプリフェッチャの予測に依存するため,この予測精度によって性能が左右されてしまう.そこで,プリフェッチ精度によりラインを保持するかを決定する適応型プリ・プロモーションを提案し,プリフェッチ精度による性能の変化を調査,評価する.本提案手法を既存のキャッシュライン置き換えアルゴリズム RRIP に適用し,SPEC CPU2006 を用いてシミュレーションにより評価した.この結果,LLC を 1MB の L2 キャッシュとしたシングルコア構成において,RRIP に対して IPC が最大で 25.5%,幾何平均で 6.0%向上した.また,DRRIP に適応したプリ・プロモーションに対しては最大で 19.9%,幾何平均で 1.4%向上した.

