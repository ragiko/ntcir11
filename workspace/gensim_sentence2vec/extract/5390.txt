IBM Model メモ
NLP
有名な翻訳モデルであるところの IBM Model 。翻訳モデルというのは、ある単語(列)がどの単語(列)に翻訳されるかという生成モデルです。Model 1 から 5 まである中の Model 1 についてのメモ。
基本的な式は
j が原言語文 f の長さ、m が目的言語文 e の長さで、j または m が 0 のときは空文字(NULL)です。は e が単語数 m になる確率。
は f_1 から f_j を表す。f_j が e_k に対応するとき、アライメントは となる。
(1) 
まで翻訳され、それぞれが目的言語文 e の  番目に対応しているとき、j番目の単語が a_j 番目の単語に対応する確率。
(2) 
e 原言語文 f の j 番目が f_j の確率。
IBM Model の簡略化(Model 1)
上の式はパラメータが多くて大変大変。なので、以下のようにパラメータを簡略化するのが Model 1
(1) は f_j が e の a_j 番目に対応する確率なので、全て等確率に対応すると仮定すると、(1) は となる。ここで l は e の単語数で、NULLに対応することも考えなきゃならないので、+1します。
(2) の f_j は  のみに依存するとして、となります。
は定数とすると
全てのについて合計すると
パラメータ  をEMアルゴリズムで推定する。こんなところで疲れたので E ステップと M ステップについてはまた今度。
(1) が l のみに依存している Model 1 と違い、Model 2 では、やmにも依存する。
Model 3 では、ひとつの単語が何個の単語に対応するのかを考慮する。また、対応先との距離(歪み率)も考慮する。
歪み率は、今いる位置から翻訳されることで、どの位置に移るかをモデル化していて面白い。
Model 4 では単語の位置が相対位置になるらしい。Model 5 は…
Todo:
フレーズ抽出のヒューリスティックスについてまとめる。
Permalink | コメント(0) | トラックバック(0) | 22:08
IBM Model メモ - ガーデンパス/迷子の記録
