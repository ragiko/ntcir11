
« 読了:Cayla & Eckhardt (2008) ブランドによる「想像のアジア共同体」の構築 |
メイン
| 読了:Tziralis & Tatsiopoulos (2007) 予測市場研究レビュー in 2007 »
2014年4月 5日 (土)
Prelec, D. (2004) A bayesian truth serum for subjective data. Science, 306(15).
Bayesian Truth Serum (ベイジアン自白剤) を最初に提案した、有名な論文。以前頑張って読んだんだけど、途中で理解できなくなって放り出してしまった。このたび仕事の都合で再挑戦。
客観的真実がわからない状況で、調査対象者から真実に近い情報を引き出す手法を提案します。
先行研究:従来のBayesian elicitation メカニズム: d'Aspremont & Gerard-Varet (1979, "Incentives and incomplete information", J.Public Econ.)Johnson, Pratt, & Zeckhauser (1990, Efficiency Despite Mutually Payoff-Relevant Private Information: The Finite Case", Econometrica)McAfee & Reny (1992, "Correlated Information and Mechanism Design", Econometrica)調査者側が異なる反応の間の確率的関係を知っている必要がある。Batchelder & Romney (1988, "Test Theory without an answer key", Psychometrica). コンセンサスが真理性の規準とされている。集団全体が歪んでいると結果も歪む。デルファイ法. Linstone & Turoff, "The Delphi Method" (1975) という本が引用されている。上と同じく、コンセンサスが真理性の規準とされている。 著者の基本的なアイデアは、個々の回答にその真実らしさを示す「情報スコア」を与える、というもの。たとえば、まず「過去1年の間にあなたは20人以上とセックスしましたか?」と聴取する。さらに、Yesと答える人は何割いると思いますか、と尋ねる。二問の集計を比較する。たとえば、一問目のYesの集計(Yes率の実態) が10%、このYes回答についての二問目の集計(Yes率の予測)が5%だったとしよう。こういう風に予測より実態のほうが高い回答、つまり"surprisingly common"な回答に、高い情報スコアが与えられる。
なにいってんだ、という感じですが、著者の説明は以下の通り。surprisingly common基準は、母集団頻度についてのベイズ推論が持っているこれまで注目されてこなかった含意を利用するものである。[...] ある意見ないし特性の母集団における頻度について、それをもっとも高く予測する人とは、その意見ないし特性を持っている人である。なぜなら、その意見を持っているということ自体が、その意見が一般にポピュラリティを持っているということの、妥当かつ好まれるシグナルになるからだ。[...] もう少しフォーマルな説明。
回答者の正直な答えのことを個人的意見と呼ぶ(実際の回答と一致するとは限らない)。対象者 r にm個の選択肢のなかからひとつ選ばせる課題で、個人的意見が選択肢 k であるとき t^r_k = 1, そうでないとき t^r_k = 0 とする。これらm個の値からなるベクトルを t^rと略記する。同様に、一問目への回答のベクトルを x^r とする。要素は0か1, 合計は1である。二問目についての予測のベクトルを y^r とする。要素は0以上、合計は1である。 対象者は二問目の回答に際して母集団分布を推測する。未知の母集団パラメータを \omega = (\omega_1, ..., \omega_m) と略記するとして、対象者は事前分布 p(\omega) を持っていると考える。これは全員で共通だと仮定し、共通事前分布と呼ぶ。さて、回答者は自分の個人的意見を「非個人的に情報的な」シグナルとして扱い、信念を p(\omega | t^r) にベイズ更新する。個人的意見が同じ時、そのときに限り、2人の人の事後分布は等しくなると仮定する。事前分布・事後分布の形状について全く仮定をおかないところがポイント。
以下のようにスコアリングする。標本サイズは十分に大きいものとする。
まず、それぞれの回答カテゴリについて回答を集計する。
\bar{x}_k = \lim_{n\rightarrow\infty} (1/n) \sum_r x^r_k
log \bar{y}_k = \lim_{n\rightarrow\infty} (1/n) \sum_r log y^r_k
二問目のほうにlogがついているのは幾何平均をとりたいからである。式を何度も見直したが、一問目になんと答えたかは無視して、全員について単純に集計するのである。(ここでどれだけ考え込んだことか...)
次に、各カテゴリについての情報スコアを求める。
log (\bar{x}_k / \bar{y}_k)
k 番目のカテゴリを回答した人にはこのスコアを渡す。つまり、
\sum_k x^r_k log (\bar{x}_k / \bar{y}_k)
えーと、「みんなマイナーだと思っているけど実はメジャーな意見」に組した人は高くなるわけか。
さらに、その人の予測の正確さについてのスコアも求める。
\alpha \sum_k \bar{x}_k log (y^r_k / \bar{x}_k}
\alphaは調整用の正の定数。えーと、カテゴリに対する回答率のその人の予想と実態との比の対数を、実態で重みづけて足しあげた値だ。これ、経験分布とその予測のずれの相対エントロピー(KLダイバージェンス)と比例している由。どうも納得できなくて、いろいろ値を入れて試したんだけど、要するに、ぴったり当てて0, 予測をしくじるほど負の方向に大きくなる。要は適当に予測している人へのペナルティであろう。で、その期待値を最大化するのは y^r = E(\bar{x}_k | t^r} とすることである由。真面目にやるのが一番だってことですね。
各対象者にはこの2種類のスコアの和を与える。みんなが正直に答えているという想定のもとで、正直な回答はこのスコアの期待値を最大化する(ベイジアン・ナッシュ均衡となる)。また、どの対象者においても、情報スコアの期待値をそれ以上に高くする他の均衡解は存在しない。
この手法を実際に用いる際には、対象者にスコアリングの数理や均衡の概念を説明しなくてもよい。ただ、正直な回答が得点を最大化するということ、個人的な真の回答について考える際には他の対象者がなにをいうかは無視して良いということ、を伝えればよい。ある条件の下でこの主張が誠実であることは均衡分析によって確認されている。云々。
限界。前提が満たされていないとうまくいかない。すなわち:(1)公的情報が利用可能で、個人的意見が情報的でないとき。たとえば、母集団における女性の割合についての判断には、本人の性別は効かないだろう。フォーマルにいえば、ふたりの t は異なるのに、ふたりのp(\omega | t)がほぼ等しい、という場合である。(2)好みや性質のちがう人が混じっていて、違う理由で同じ答えを示し、しかし母集団についての事後分布は同じ、という場合。つまり、ふたりの t は同じなのに、ふたりのp(\omega | t)が異なる、という場合である。
その他、alphaの意義、数値例、他の手法との関係、など。
うーん... 二回読んだけど、疑問点や理解できない点が山のように出てきた。やっぱり、この論文は難しい。別のを読んでから考え直した方がよさそうだ。
一番不思議なのは次の点。表面的にいえば、ベイジアン自白剤は「自分の意見と同じ意見を他人も持っている」という認知バイアスを活用する手法だと思う。で、この認知バイアスを説明するために、母集団での意見の分布について全員が同じ事前分布を持っており、自分の意見だけを入力としたベイズ更新を行う、というモデルをつくる。著者が提案するスコアリングはこのモデルに依拠している。そこで疑問なのだけれど、第一に、「自分の意見と同じ意見を他人も持っている」という認知バイアスを説明する方法はほかにないのだろうか。もしもっと優れた説明が可能なら、全然別のスコアの最大化が均衡解になるのではないか。第二に、著者らのモデルを正当化する証拠はあるのか。直感的には、全員が同じ事前分布を持つという想定も、自分の個人的意見だけが入力だという想定も、相当に無理があるような気がするんだけど。
もっと素朴な疑問もある。この論文では、このスコアを最大化するためには正直に答えることがナッシュ均衡だ、ということが売りになっているのだけれど、それはなにを意味しているのだろう。そのスコアを最大化することを参加者が目指したくなるようなメカニズムを設計すれば、きっとみんな正直に答えてくれますよ、でもそんなメカニズムをどうやってつくるのかは知りませんけどね、ということなのだろうか。
最後の疑問は、正直なところここに書き留めるのがちょっと恥ずかしいようなナイーブな疑問なのだけれど... この論文に限らないのだけれど、ゲーム理論の概念を使って、この状況下ではこの行動が合理的です、だからこういう風に設計しましょう、という説明を聞くと、いつも狐につままれたような気分になってしまう。人が利用可能な情報を全て使って合理的に行動するとは限らないんじゃない?だって俺はもっと頭悪いよ? と思うからである。この論文についていえば、スコアをインセンティブに直結させるメカニズムをうまく設計したら、本当に人は正直に答えるようになるのか、という疑念がある。
読書日記: 読了: Prelec (2004) ベイジアン自白剤
