
人工神経回路網 (通称、ニューラル ネットワーク) とは、生物学上のニューロン (神経細胞) とシナプス (神経細胞接合部とその構造) を大まかにモデル化する抽象概念です。ニューラル ネットワークは何十年も研究されてきましたが、インターネット上に公開されているニューラル ネットワークの多くのコード実装は、私の考えでは、あまりうまく説明されていません。今月のコラムでは、ニューラル ネットワークについて説明し、ニューラル ネットワークを実装する C# コードを紹介します。
何をしようとしているかは、図 1 と図 2 をご覧ください。ニューラル ネットワークについての 1 つの見方は、ニューラル ネットワークを、ある数値入力から別の数値出力に変換するメカニズムと考えることです。図 1 のニューラル ネットワークには、x0、x1、x2 というラベルが付き、値をそれぞれ 1.0、2.0、3.0 とする入力があり、y0 と y1 というラベルが付き、値がそれぞれ 0.72 と -0.88 となる出力があります。図 1 のニューラル ネットワークは、いわゆる非表示ニューロンという 1 つの層があり、3 つの入力、2 つの出力、および 4 つの非表示ニューロンを備えた、3 層完全接続フィードフォワード ネットワークと表すことができます。残念ながら、ニューラル ネットワークには多種多様な専門用語が使われます。今回は、ニューラル ネットワークに関する優れた FAQ (bit.ly/wfikTI、英語) に記載されている用語を使用するようにしていますが、必ずではありません。
図 2 ニューラル ネットワークのデモ プログラム
図 2 は、今回紹介するデモ プログラムからの出力です。ニューラル ネットワークはアクティブ化関数として、シグモイド関数とハイパーボリック タンジェント (tanh: 双曲線正接) 関数の両方を使用します。図 1 では、これらの関数を、ギリシャ文字のファイ (Φ) を使用した 2 つの式で示しています。ニューラル ネットワークは、数値による重みとバイアスのセットを使用して出力を生成します。今回の例では、合計 26 セット (0.10、0.20、～-5.00 と続く値) の重みとバイアスがあります。重みとバイアスをニューラル ネットワークに読み込んだら、デモ プログラムは 3 つの入力値 (1.0、2.0、3.0) を読み込み、一連の計算を実行します。この計算は、出力例の "入力ニューロンから非表示ニューロンへの合計" (input-to-hidden sums) と "非表示ニューロンから出力ニューロンへの合計" (hidden-to-output sums) というメッセージに示すような過程で行います。デモ プログラムは、2 つの出力値 (0.72、-0.88) を表示して終了します。
ここからは、図 2 に示す出力を生成したプログラムを見ていきます。今回は、プログラミングについては中級程度のスキルが必要ですが、ニューラル ネットワークの知識はなくてもかまいません。デモ プログラムは C# 言語でコーディングしていますが、Visual Basic .NET や Python など別の言語にリファクタリングしても問題はありません。ここで紹介するプログラムは、基本的に、機能を試すためのチュートリアルおよびプラットフォームです。実際の問題を直接解決するのではなく、重要な問題を解決するためにコードを拡張する方法を説明します。ここに記載する情報に興味を持ち、価値を見出したら、そのプログラミング技法をコーディング スキルのセットに加えていただければさいわいです。
ニューラル ネットワークをモデル化する
概念的には、実際の生物学上の神経回路網の動作を基に、ニューラル ネットワークをモデル化します。図 1 の青い円は処理が行われるニューロンを表し、矢印は情報の流れと重みの数値を表します。多くの状況では、入力値は重みを加えることなく入力ニューロンに直接コピーされます。また、出力ニューロンからは処理することなく直接出力されます。したがって、最初の実際のアクションは非表示層のニューロンで行われます。ここで、入力値 1.0、2.0、3.0 が入力ニューロンから取り出されるとします。図 1 を見てみると、3 つの入力ニューロンと 4 つの非表示ニューロンの間に、重みの値を表す矢印があります。1 番上の非表示ニューロンに向かっている 3 つの重みの矢印にそれぞれ、w00、w10、w20 という名前を付けます。この命名法では、1 桁目のインデックスが入力元の入力ニューロンを、2 桁目のインデックスが出力先の非表示ニューロンを表します。ニューロンの処理は 3 手順で行います。まず、重みの合計を計算します。ここでは w00 = 0.1、w10 = 0.5、w20 = 0.9 となり、1 番上の非表示ニューロンの重みの合計は、(1.0)(0.1) + (2.0)(0.5) + (3.0)(0.9) = 3.8 になります。次に、バイアス値を加算します。バイアス値が -2.0 であれば、調整後の重みの合計は 3.8 + (-2.0) = 1.8 になります。最後に、調整後の重みの合計にアクティブ化関数を適用します。アクティブ化関数が、1.0 / (1.0 * Exp(-x)) で定義されるシグモイド関数 (Exp は自然指数関数を表します) だとすると、非表示ニューロンからの出力は、1.0 / (1.0 * Exp(-1.8)) = 0.86 になります。この出力が重みの合計の一部となり、出力層の各ニューロンに入力されます。図 1 では、この 3 手順をギリシャ文字ファイを使用した式で示しています。つまり、重みの合計 (xw) を計算し、バイアス (b) を加算して、アクティブ化関数 (phi) を適用します。
すべての非表示ニューロン値を計算したら、出力層のニューロン値を同じ方法で計算します。出力ニューロン値の計算に使用するアクティブ化関数は、非表示ニューロン値の計算に使用するのと同じ関数を指定することも、異なるアクティブ化関数を使用することもできます。図 2 に実行結果を示したデモ プログラムは、ハイパーボリック タンジェント関数を、非表示ニューロンから出力ニューロンへのアクティブ化関数として使用しています。出力層のすべてのニューロン値を計算したら、大半は、これらの値に重みを加えたり、処理したりしないで、ニューラル ネットワークの最終値として出力します。
内部構造
今回紹介するニューラル ネットワークの実装を理解する鍵は、図 3 を詳しく調べることです。一見、非常に複雑に見えるかもしれません。しかし、我慢して付き合ってください。じっくり見てみるとそれほど複雑ではありません。図 3 には、合計 8 つの配列と 2 つの行列があります。this.inputs というラベルを付けた最初の配列は、ニューラル ネットワークの入力値 (この例では、1.0、2.0、3.0) を保持します。その隣は、非表示層の値の計算に使用する重み値のセットです。重みの値は、i-h weights というラベルを付けた 3 x 4 の行列に格納します。i-h は input-to-hidden (入力ニューロンから非表示ニューロンへ) を表します。図 1 のデモ ニューラル ネットワークには 4 つの非表示ニューロンがあります。i-h weights 行列では、行数が入力数、列数が非表示ニューロン数に等しくなります。
i-h sums というラベルを付けた配列は、計算に使用する初期状態の配列です。i-h sums 配列の長さは、常に、非表示ニューロン数と同じです (この例では 4)。次が、i-h biases というラベルを付けた配列です。ニューラル ネットワークのバイアスは、非表示層ニューロンと出力層ニューロンの計算に使用する重みです。i-h biases 配列の長さは、i-h sums 配列の長さと同じで、非表示ニューロン数です。
i-h outputs というラベルを付けた配列は中間結果で、次の層の入力として使用します。i-h sums 配列の長さも非表示ニューロン数に等しくなります。
次は、h-o weights というラベルを付けた行列です。h-o は hidden-to-output (非表示ニューロンから出力ニューロンへ) を表します。h-o weights 行列のサイズは 4 x 2 で、4 つの非表示ニューロンと 2 つの出力ニューロンがあることを表しています。h-o sums 配列、h-o biases 配列、および this.outputs 配列の長さはすべて、出力ニューロン数 (この例では 2) と等しくなります。
図 3 の一番下の weights というラベルを付けた配列は、input-to-hidden (入力ニューロンから非表示ニューロンへ) および hidden-to-output (非表示ニューロンから出力ニューロンへ) のすべての重みとバイアスを保持します。今回の例では、重みの配列の長さは (3 * 4) + 4 + (4 * 2) + 2 = 26 です。一般に、Ni を入力値数、Nh を非表示ニューロン数、No を出力数とすると、重みの配列の長さは Nw = (Ni * Nh) + Nh + (Nh * No) + No になります。
出力を計算する
前述の 8 つの配列と 2 つの行列を作成したら、ニューラル ネットワークはその入力、重み、およびバイアスに基づいて、出力を計算します。まず、入力値を this.inputs 配列にコピーします。次に、重みの配列に値を代入します。このデモでは、好みの重み値を使用できます。次に、重み配列の値を i-h weights 行列、i-h biases 配列、h-o weights 行列、および h-o biases 配列にコピーします。図 3 がわかれば、この関係が明確になります。
i-h sums 配列の値は、2 手順で計算します。まず、入力配列値に、i-h weights 行列の列値を乗算し、重みの合計を計算します。たとえば、非表示ニューロン [3] (ここではゼロから始まるインデックスを使用しています) の重みの合計は、各入力値と、i-h weights 行列の列 [3] の値から、(1.0)(0.4) + (2.0)(0.8) + (3.0)(1.2) = 5.6 になります。次に、i-h sum 値を計算します。この計算では、各バイアス値を、現在の i-h sum 値に加算します。たとえば、i-h biases [3] の値は -7.0 なので、i-h sums [3] の値は、5.6 + (-7.0) = -1.4 になります。
i-h sums 配列のすべての値を計算したら、それらの合計に入力ニューロンから非表示ニューロンへのアクティブ化関数を適用して、出力値を生成します。使用できるアクティブ化関数は多数あります。最もシンプルなアクティブ化関数は、ステップ関数です。この関数は、ゼロを超えるすべての入力値には 1.0 を返し、ゼロ以下のすべての入力値には 0.0 を返します。よく使用するもう 1 つのアクティブ化関数が今回使用しているシグモイド関数で、f(x) = 1.0 / (1.0 * Exp(-x)) と定義されます。図 4 に、シグモイド関数のグラフを示します。
シグモイド関数は、0 ～ 1 の範囲で値を返すことがわかります。今回の例では、バイアス値を加算後の i-h sums [3] の値が -1.4 なので、i-h outputs [3] の値は 1.0 / (1.0 * Exp(-(-1.4))) = 0.20 になります。
入力ニューロンから非表示ニューロンに出力されるニューロン値をすべて計算したら、それらの値を非表示ニューロン層から出力ニューロン層への入力に使用します。これらの計算は、入力ニューロンから非表示ニューロンで行った計算と同じです。暫定的な重みの合計を計算し、バイアスを加算してから、アクティブ化関数を適用します。今回は、非表示ニューロンから出力ニューロンへのアクティブ化関数に、ハイパーボリック タンジェント (tanh) 関数を使用しています。tanh 関数は、シグモイド関数と密接に関係しています。tanh 関数のグラフもシグモイド関数に似た S 字型のカーブを出力しますが、tanh 関数は、0～1 の範囲ではなく、-1～1 の範囲で値を返します。
重みとバイアスを組み合わせる
インターネット上で公開されているニューラル ネットワークの実装の多くは、重みとバイアスの配列を別に管理するのではなく、重みとバイアスを weights 行列に組み合わせています。どうしてこのようなことが可能なのでしょう。入力ニューロンから非表示ニューロンへのニューロン [3] の値の計算は、(i0 * w03) + (i1 * w13) + (i2 * w23) + b3 のようになります。i0 は入力値 [0]、w03 は入力 [0] からニューロン [3] への重み、b3 は非表示ニューロン [3] のバイアス値です。ここで新たに入力 [4] を作成し、この入力に、ダミー値 1.0 と、バイアス値を保持する重み用に行を追加する場合、上記の計算は、(i0 * w03) + (i1 * w13) + (i2 * w23) + (i3 * w33) になります。i3 はダミーの 1.0 という入力値で、w33 はバイアスを表します。つまり、この手法を使用すればニューラル ネットワークのモデルが簡潔になると考えられています。私はそうは思いません。私の意見では、重みとバイアスを組み合わせると、ニューラル ネットワーク モデルが理解しにくくなり、実装時にエラーが発生しやすくなります。ただし、この意見を持っているのが私だけかもしれないので、読者ご自身でこの設計上の決定を下すことをお勧めします。
実装
ここでは、Visual Studio 2010 を使用して、図 1、図 2、および図 3 に示すニューラル ネットワークを実装する、NeuralNetworks という C# コンソール アプリケーションを作成しました。ソリューション エクスプローラーで、Program.cs ファイルを右クリックして、NeuralNetworksProgram.cs という名前に変更します。これにより、テンプレートが生成するクラス名も NeuralNetworksProgram に変更されます。ほとんどの WriteLine ステートメントを取り除いた状態の、プログラム構造全体を図 5 に示します。
using System;
namespace NeuralNetworks
{
class NeuralNetworksProgram
{
static void Main(string[] args)
{
try
{
Console.WriteLine("\nBegin Neural Network demo\n");
NeuralNetwork nn = new NeuralNetwork(3, 4, 2);
double[] weights = new double[] {
0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2,
-2.0, -6.0, -1.0, -7.0,
1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0,
-2.5, -5.0 };
nn.SetWeights(weights);
double[] xValues = new double[] { 1.0, 2.0, 3.0 };
double[] yValues = nn.ComputeOutputs(xValues);
Helpers.ShowVector(yValues);
Console.WriteLine("End Neural Network demo\n");
}
catch (Exception ex)
{
Console.WriteLine("Fatal: " + ex.Message);
}
}
}
class NeuralNetwork
{
// Class members here
public NeuralNetwork(int numInput, int numHidden, int numOutput) { ... }
public void SetWeights(double[] weights) { ... }
public double[] ComputeOutputs(double[] xValues) { ... }
private static double SigmoidFunction(double x) { ... }
private static double HyperTanFunction(double x) { ... }
}
public class Helpers
{
public static double[][] MakeMatrix(int rows, int cols) { ... }
public static void ShowVector(double[] vector) { ... }
public static void ShowMatrix(double[][] matrix, int numRows) { ... }
}
} // ns
テンプレートが生成するすべての using ステートメントを削除します (ただし、System 名前空間への参照は除きます)。Main 関数では、開始メッセージ表示後に、3 つの入力ニューロン、4 つの非表示ニューロン、および 2 つの出力ニューロンから成る、nn という NeuralNetwork オブジェクトのインスタンスを作成します。次に、26 個の任意の重みとバイアスを、weights 配列に代入します。SetWeights メソッドを使用して、weights をニューラル ネットワーク オブジェクトに読み込みます。値 1.0、2.0、3.0 を、xValues 配列に代入します。ComputeOutputs メソッドを使用して、入力値をニューラル ネットワークに読み込み、結果の出力を確定します。この結果を yValues 配列にフェッチします。このデモは、出力値を表示して終了します。
NeuralNetwork クラス
NeuralNetwork クラス定義は、次の定義から始まります。
テストの実行 - ニューラル ネットワークについての紹介
