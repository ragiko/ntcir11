 事例:教師無し学習
マイクロアレイデータのクラスタリング
ラベルなしのデータ構造における教師無しクラスタリングの有効性を、以下に示します。マイクロアレイデータを、次の図に示します。
81 サンプルのラベルを削除したとします。もし自然な固まりがあったなら、それをクラスターに分けます。通常の方法では、4681 の変数についてサンプル同士の距離を計算します。RandomForests はそれとは異なる方法をとります。
labeltr=0 に設定します。さらに 4681 変数 81 サンプル、変数はすべて独立している合成データを作ります。オリジナルのデータにはクラス1、合成データにはクラス2のラベルを付けます。
2 つのクラスがうまく分類できた場合、すなわち誤差率が低い場合、オリジナルデータとは何か知ることができます。nprox=1 および iscale=D-1 に設定します。そして、オリジナルデータの近似性が計算され、スケーリングされた座標を使ってプロットされます。以下に、スケーリングされた座標を使ってプロットした図を示します。
教師無しモードでは、クラスのレベルによってまだ 3 つのクラスターがあることがわかります。2つのクラス間の oob エラーは 16.0% です。2つのクラスに対して mdim2nd=15 を使った場合、誤差率は 2.5% まで落ち、教師無しのクラスターはより厳密になります。
DNA データのクラスタリング
教師付および教師無しの DNA データのスケーリングは、以下の図のようにたいへん興味深いものです。 
回転しており軸スケールも異なりますが、教師付のスケール構造は保持されます。2つのクラス間の誤差は 33% です、強い依存性は見られません,。 
ガラスデータのクラスタリング 
構造が保持されるより劇的な例として、古典的な機械学習のサンプルであるガラスデータが挙げられます。それには 214 サンプル、9 変数、6 クラスがあります。ラベル付のスケールを、次に示します。 
HULINKS | サポート | RandomForests | 事例:教師無し学習
