・言語モデル(9:00～11:00)SLP-4  述語項構造を介したWebテキストからの文選択に基づく言語モデルの評価
吉野幸一郎・森信介・河原達也(京大)対話システムのためのドメイン依存言語モデルの作成.ドメイン依存のコーパス(Yahoo!知恵袋)からのテキスト選択に基づくが,従来のパープレキシティ基準ではなく,述語項構造を使って意味的な良さに基づいてテキストを選択する.述語項の内容・格・述語の組を1つの単位として,そのドメイン内外文書に対する出現確率に基づいてNaive Bayesまたはロジスティック回帰による分類を行う.単語3-gramのPPをベースに文選択を行った場合よりも高性能.述語項構造を使った文選択は発話スタイルの部分を無視するので,その効果が主に出ているのか,それとも意味的な整合性を重視した結果が強く出ているのか,どちらなのかが気になった.SLP-5  生成型アプローチによるLatent Words Language ModelのN-gram近似
増村亮・政瀧浩和・大庭隆伸・吉岡理・高橋敏(NTT)言語モデルを複雑にするとデコーダでの利用が難しいので,複雑な言語モデルを使って文を生成し,そこから単純なN-gramを学習する枠組み.生成に使うのはLatent Words LMで,N種類の単語がN種類のクラス(Latent Word)から確率的に生成されるというモデル.Latent Wordの生成は階層Pitman-Yor過程,Latent Wordから単語の生成はディリクレ事前分布に基づく.LWLMの確率算出のための総和を求めるのは非常に計算量が多いので,LWLMを生成に使い,生成された文から普通のN-gramを求める.単独で使ても通常のN-gramよりもやや良く,通常のN-gramと組み合わせるとさらに性能が上がる.SLP-6  統計的言語モデルにおける確率的潜在意味解析の学習初期化手法の一検討
大島寛史・川端豪(関西学院大)PLSAの学習についての考察.初期値として,スパースな初期値を用いた場合(ランダムに少数の文書を選び,そのunigram確率をそのまま初期値とする)と,それをフロアリングした場合(一定値およびunigram確率に比例)の比較を行った.フロアリングしないほうが高性能.フロアリングすると性能の変動が少ないが,フロアリングのやり方には性能はあまり依存しない.SP-5   重みベクトルの適応的正則化に基づく発音推定
久保慶伍・サクティ サクリアニ・グラム ニュービッグ・戸田智基・中村 哲(奈良先端大)Grapheme-to-phonemeタスク.系列学習法のMIRA(Margin Infused Relaxed Algorithm)に対し,過学習に強い重みベクトル正則化法AROW(Adaptive Regularization of Weight vectors)を適用し,性能を改善する.特に学習にノイズデータがある場合などに頑健.重みベクトルの各次元に正規分布を仮定し,これまでの更新頻度に基づいて分散を推定し,分散が小さい場合は更新が起こりにくいような制約を入れる.これにより,誤った学習データを与えたときに悪影響が起きることを抑圧する.・音声対話・検索(11:20～12:20)SP-6   質問応答データベースに基づくマルチタスク音声対話システムのタスク作成実験
三宅真司・伊藤彰則(東北大)私が発表.音声対話システムのコンテンツを素人に開発させたら使い物になるのかどうか.QAデータベースに基づくシステムで,データベースの部分を5人の素人に開発させて,経験者と比較.また,経験者と素人が開発したシステムを使って実際に対話をしてみて,その結果を比較.素人でもそれほど問題なくタスクの作成ができるが,素人が開発したタスクのほうがタスク達成率が低い.UI開発のきちんとした方法論を踏まえて開発してるのかどうか下平先生に質問されたが,うまく答えられなかった(きちんとしていないからね).SLP-7  ベイズリスク最小化音声認識の複数仮説を用いた音声検索
南條浩輝・古谷遼(龍谷大)かねてより開発してきたベイズリスク最小化音声認識と単語重要度推定の枠組みを使って,音声検索の精度を上げようという研究.検索はベクトル空間モデルで,N-bestからクエリベクトルを構成する方法(3通り)と,単語グラフからクエリベクトルを構成する方法(3通り)を比較評価.結果として,MBR音声認識と単語グラフからのベクトルを組み合わせたものが高性能.MBR音声認識は通常認識よりもN-best上位の認識性能が高いので,N-bestの組み合わせの性能向上が現れやすい.認識性能がもともと低い場合に提案法が有効.・オーガナイズドセッション(13:20～15:20)SP-7   ［招待講演］再訪:ニューラルネットワークによる音声処理
中川聖一(豊橋技科大)NNによる音声処理の歴史.- 1990年前後と2010年前後との比較: コンピュータ速度とメモリ量は1000倍,音声の学習データ量は100倍 学習アルゴリズム:BPRBM+BP- NNとパターン分類器の対応- 多層パーセプトロンの表すもの 事後確率を直接学習することができる- 多層パーセプトロンの万能性 任意の非線形関数の近似 実用上どんな性質がよいかは考える必要がある  構造を導入する必要- ニューラルネットによる特徴抽出 5層ボトルネットワーク- TDNN (A. Weibel)- Convolution network 時間方法:TDNN 周波数方向: 時間周波数:コグニトロン(福島)- リカレントネットワーク リカレントネットワークによる有限オートマトンの実現 Viterbiネットワークの実現- ボルツマンマシンとDPマッチング パターン間の最適照合パス- リカレントネットワークによる音素認識- CRF/SCRF/HCRF/HCNF- HMM/HCRF/HCNFの比較- NCNFによる音声認識  Deep-HCNFへ- DNN-HMMによる音声認識 DNNでの言語重み GMM-HMMよりも最適値が小さい(2倍ぐらい)- NNによる言語モデル- 音響モデル,言語モデル,デコーダ,翻訳などがすべてNNで実現できるか?最後に「人間の脳処理とニューラルネットワークは関係あるか?」というアンケート ほとんど関係ない/深い関係がある/関係があると思うが関係ないかも/関係ないと思うが関係あるかもの4択.時間いっぱい使って終了.SP-8   ［招待講演］確率的ディープラーニング入門
安田宗樹(山形大)ディープラーニングとボルツマンマシンについて,わかりやすい入門.- 統計的機械学習理論とは- ベイズ則による確率推論- ボルツマンマシン 無向グラフによる生成モデル,節点が確率変数 可視変数だけのものと隠れ変数のあるもの 学習アルゴリズム  FVBM(Fully-Visible Boltzmann Machine)の最尤推定  隠れ変数がある場合の最尤推定  隠れ変数の意味:エネルギー関数を複雑化してモデルの表現能力を上げる- ボルツマンマシンの学習にはノード数の指数時間を必要とする 近似学習法 constractive divergence (Hinton 02)- Resticted Boltzmann Machine (RBM) 完全2部グラフ上に定義された2層構造のボルツマンマシン  片方は可視層,もう片方は隠れ層 条件付き独立性 : 片方の変数値が固定されると,もう片方の変数はそれぞれ統計的に独立  サンプリングが単純にできる 隠れ変数を周辺化した分布が解析的に表現できる Contrastive divergence  繰り返し推定回数を1回に(経験分布を初期値とする)- Deep Boltzmann Machine 隠れ層が多層になったボルツマンマシン 事前学習(RBMの学習を多層に)・オーガナイズドセッション(15:40～16:40)SLP-8  Deep Neural Networkに基づく日本語音声認識の基礎評価
神田直之・武田龍・大淵康成(日立製作所)DNNによるCSJの認識評価実験.RBMによる事前学習でなく,SeideらによるDiscriminative Pre-trainingを利用.学習にはDropout学習を使う.GMMベースで約80%のものが87%以上に向上.特徴量はMFCCよりメルフィルタバンクのほうがよい.Dropout学習により1ポイント程度向上するが,学習時間は10倍程度.DNNの良さとして,「複数ある特徴量のどれかが発火すればよい」という情報を扱うのが得意なことがよかったのではないかという考察.その他に特徴抽出との最適化など.もう一つの話題として,「スペクトル伸縮歪みによる疑似データ生成」を紹介.少量のデータを時間・周波数方向に歪ませて,それを疑似的な学習データとして追加する.すべてのひずみを導入した場合に,約2ポイント改善.SLP-9  CSJを用いた日本語講演音声認識のためのDNN-HMMの評価
三村正人・河原達也(京大)こちらもDNNによるCSJの認識評価.事前学習はRBM.GPGPUを使うと学習時間が約100倍になる.プログラムはPythonのライブラリCUDAMatを利用.GMM-HMMとの比較では言語重みと挿入ペナルティだけをそれぞれの手法に合わせて最適化.評価データは,CSJに加えて京都大のオープンコースウェアの音声を利用.平均で5ポイント強改善.DNNは隠れ層を増やすほど性能が上がる.また,認識時間はDNNの方が2倍以上速い.学習もGPGPUを使えばGMMの識別学習と同程度.また,教師なし話者適応手法として,適応データに似た学習話者を学習コーパスから選び,その話者を使って追加学習をする(学習データを使えば正解ラベルがあるので,学習が容易).選択基準は,MLLR変換行列の類似性と,HMMの平均ベクトルの類似性の2つ(どちらの基準でも同じ話者が選ばれた).効果は認識結果を直接学習に使う場合と同じ程度で,両方使うとさらに性能が向上.最終の適応済みモデルの認識結果は,GMM-HMMのMLLR適応よりちょっと悪かった.・オーガナイズドセッション(17:00～18:00)SP-9   ［招待講演］音声認識の為のディープニューラルネットワーク学習
松田繁樹(NICT)会議をやってたせいで聞けなかった.どなたか聞いた方まとめを・・・・夕食後SLP企画「DNNに関する世界の研究動向:ICASSPの発表より」
河原達也、神田直之、篠田浩一、篠原雄介、松田繁 (予定)最初に河原先生がお話.今回のICASSPではニューラルネット関連の発表が爆発的に増加.ここ25年で最大のブレークスルー.全部聞くのは無理だったそうで,その内容を持ち寄って発表.- HintonのPlenary Talk. 成功のカギ:  学習データ,計算機パワー,過学習を避けるテクニック(RBM, CNN, Dropout methid) 音声認識で,さまざまなタスクで一貫して高性能 画像検索でもぶっちぎり高性能- ICASSPでの発表:音声認識全体の4割ぐらいがDNN関連- Language Modeling DNNではないがNN系の言語モデル Feedforward/Recurrent ネットワーク規模を落とすために,クラスタリングや通常の言語モデルとの併用 + RWTH&LIMSIの論文:さまざまなNNLMの組合わせ,Backoff N-gramとの組み合わせが有用,Recurrentのほうが高性能 + AT&Tの論文:Recurrent NNLM + IBM: Feedforward, アラビア語,Deep structure,素性を増やす(あまり効果なし) + IBM: Feedforward NNLMを通常のN-gramに変換次に篠田先生:CVPRでのDeep Learningの扱いなど.ICASSPよりは冷めた感じのようだ.- Acoustic Modeling with Neural Networks + JHU: 多言語で学習したDNNをある言語の初期モデルに用いる(Resource-deficient Language用) + AT&T: HDA+MLLTとMLPによる前処理を比較.MLPでいい + RWTH Aachen: RNNにLSTM(Long-Short Term Memory)を組み合わせる,RNNとDNNのスタッキング + IDIAP: 5層NNの真ん中のボトルネックをPhone factor とSpeaker factorに分けて学習 + Google: minibatch SGDの改良 + Aalto U: MFTによる耐雑音認識でバイナリマスクをRBM+SVMで推定神田さん: + Toronto U: Hintonの論文.隠れ層の活性化関数としてLSTMを利用.Bidirectional RNN, 隠れ層をDeepに  LSTMは手書き文字認識に使われていたモデル.  RNN Decoder (音響モデルと言語モデルの同時最適) TIMITでの音素エラー率17.7% + IBM: Deep Convolutional NNを音声認識に適用 + Microsoft: Convolutional NNでのpoolingサイズを自動調整(heterogeneous pooling) + Google: 特徴抽出層を言語非依存に + Cambridge:  Noise-aware training + Tronto U: 非線形としてRectified Linear Unitを使って学習を速くし,遅いDropout学習と組あわせる + Google: RNNをVADに使う篠原さん: + Microsoft: マイクロソフトの最近の研究動向.MFCCFBANK, CNN, マルチタスク学習,耐雑音,RNNLM, 音声対話の状態トラッキング + Microsoft: DNNの話者適応 過学習しやすいので,SI-DNNから離れすぎないよう正則化 + Google: 多言語対応(上と同じもの)DistBeliefで高速並列学習 + Google: フレームを飛ばしながら計算.4フレームごとぐらいで計算しても性能低下なし松田さん:- 話者適応 + Microsoft: KL-divergenceを使う話者適応(上と同じもの) + Google: SIモデルとSAモデルのパラメータの差を正則化に使う + York U: パラメータ数が少ないほど話者適応が効く.話者適応のためのレイヤーを作る- マルチタスクラーニング + Microsoft: DNN-HMMによる音素認識と,状態コンテキスト・音素コンテキストのタスクを併用して学習- 多言語音声認識 + Microsoft, NICT, Google: 言語独立なネットワークに言語依存のネットワークをつなぐ(一部上の発表と同じ) +Edinburgh U: トランスファーラーニング的アプローチ
7月26日 SP・SLP研究会@遠刈田温泉 まとめ | aitoの日記 | スラッシュドット・ジャパン
