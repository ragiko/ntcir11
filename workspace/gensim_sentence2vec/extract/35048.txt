今までPRMLを読んで実装を続けてきましたが、10章からは難しくて歯が立たなくなってきたのでここらで少し具体的な応用に目を向けてみようと思います。機械学習の応用先としては画像の方が結果を見ていて面白いんですが、当面は自然言語処理を取り上げます。そんなわけで一番始めの応用は機械学習と自然言語処理の接点として非常に重要なテキスト分類(Text Classification, Text Categorization)の技法たちを試していきたいと思います。テキスト分類は文書分類(Document Classification)という呼び方もあります。テキストと文書は同じ意味です。最初なので自分の知識の整理と入門者への紹介のためにちょっと丁寧にまとめてみました。
テキスト分類とは
テキスト分類とは、与えられた文書(Webページとか)をあらかじめ与えられたいくつかのカテゴリ(クラス)に自動分類するタスクです。テキスト分類は対象とするテキストによって幅広い応用が可能です。たとえば、すでに実用化されて身近でお世話になっている機能としては、
電子メールを「スパム」と「それ以外」というカテゴリへ自動分類して「スパム」をゴミ箱へ捨てる(スパムフィルタ)
Webページを「政治・経済」「科学・学問」「コンピュータ・IT」「ゲーム・アニメ」などのカテゴリへ自動分類(はてなブックマーク)
ニュース記事を「興味あり」「興味なし」というカテゴリへ自動分類して「興味あり」のニュース記事だけおすすめ(情報推薦・情報フィルタリング)
などがあります。それぞれ、電子メール、Webページ、ニュース記事がテキストに当たります。たとえば、私も愛用しているはてなブックマークですが、人間がWebページの内容を読んで、このページは「コンピュータ・IT」だなとか分類しているわけではなく、機械学習の手法を用いた分類プログラム(分類器と呼ぶ)が自動的に分類しています。
新はてなブックマークでも使われてるComplement Naive Bayesを解説するよ
大量のWebページが毎日毎日出てくるのにこんなの人手でできるはずないですよねー(Yahoo!は昔これを人手でやってましたが今はどうなんでしょうね?)。
教師あり学習
仕組みはこうです。まず、人間が教師となって分類器を訓練します。こんな感じ。
Webページ1は「IT」
Webページ2は「科学」
Webページ3は「IT」
Webページ4は「政治」
Webページ5は「ゲーム」
・・・このような(テキスト,人間が与えた正解カテゴリ)を組としたデータを訓練データと呼びます。分類器はこの訓練データをもとに各カテゴリの文書の特徴を自動学習します。たとえば、
「iPhone」「Apple」「Twitter」などの単語が含まれるテキストは「IT」カテゴリである確率が高い
「民主党」「菅直人」などの単語が含まれるテキストは「政治」カテゴリである確率が高い
「研究」「JAXA」「遺伝子」などの単語が含まれるテキストは「科学」カテゴリである確率が高い
などです。このように訓練した分類器を用いて、カテゴリがわからない新しい文書、たとえば、「Apple」「iPhone」が含まれる文書のカテゴリは?と分類器に聞くと「IT」である確率が高いと返してくれます。一般的に訓練データは多ければ多いほど分類器は正確なテキスト分類ができるようになります。このように、人間が正解カテゴリを訓練データとして与える機械学習手法は教師あり学習と呼びます。
Bag-of-words
一般的にテキストは単語の集合として与えます。集合なので並び順は無視されます。つまり、単語が文書内にどこに出てくるかは考慮しません。このようなテキスト表現はbag-of-wordsと呼ばれます。単語をバッグの中にぐちゃぐちゃ詰め込むイメージでしょうか。たとえば、
テキスト分類とは、与えられたテキストをあらかじめ与えられているカテゴリに「自動で」分類するタスクです。という文書は、bag-of-wordsで表すと
テキスト テキスト カテゴリ タスク 自動 分類 分類 みたいに単語の集合で表されます。タスクにもよりますが、形態素解析(2009/4/15)で名詞だけ抽出して使うことが多いんじゃないかと思います。話はそれますが、Visual Wordsを用いた類似画像検索(2010/2/27)で取り上げたbag-of-visual wordsはbag-of-wordsの画像版です。bag-of-visual wordsもbag-of-wordsと似ていて画像における単語(局所特徴量のセントロイド)が画像上のどこにあるかは考慮しません。このような単純化のおかげで学習アルゴリズムがシンプルになります。
テキスト分類の技法
テキスト分類は非常に多くの研究があり、そのアルゴリズムも大量にあります。ちょっと思いつくだけでも、ナイーブベイズ、決定木、Rocchio分類法、k-最近傍法、ロジスティック回帰、ニューラルネットワーク、サポートベクトルマシン、ブースティングなどなど。それぞれやり方はだいぶ違っています。また、テキストをベクトルへ変換する手法(TF-IDFとか)や次元削減の方法(LSIとか)もたくさん提案されており、その組み合わせを考えると結局どれ使えばいいの?って感じです。一般的には、サポートベクトルマシンやブースティングが他の手法と比べて高精度な分類ができると言われています。これから実際に試していきます。今回取り上げるのは、よく使われていて実装も簡単、しかも高速というナイーブベイズです。精度評価のベースラインとしてよく使われてます。
ナイーブベイズを用いたテキスト分類 - 人工知能に関する断創録
