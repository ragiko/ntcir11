【要約書】【課題】第1の言語の音声をより高い信頼性をもって第2の言語の正しいテキストに翻訳する機械翻訳システムを提供する。【解決手段】音声認識および機械翻訳装置20は、Nベストの仮説を出力するための自動音声認識(ASR)モジュール80と、Nベスト仮説の各々に対しK個の訳文候補を引出すための統計的機械翻訳(SMT)モジュール84と、ASRモジュール80とSMTモジュール84とから得られる特徴量を組合せて訳文候補の各々にスコアを割当てる再スコアリングモジュール56とを含む。
【発明の詳細な説明】【技術分野】【0001】  この発明は機械翻訳に関し、特に、音声認識と機械翻訳のカスケード構造を含むシステムに関する。【背景技術】【0002】  グローバルなセルラー電話およびいわゆるIP(インターネットプロトコル)電話等の現代の通信システムが発展するにつれて、さらに現代の交通手段の発達につれて、より多くの人々が様々な国の同僚や、友人や仕事相手と直接会って、またはオーディオビジュアルな通信を介して、話す機会が増してくるであろう。残念ながら、多くの人にとって母国語以外の言語を話したり聴いたりすることは困難である。このため、スピーチ・ツー・スピーチ機械翻訳の重要性が増している。【0003】  このようなスピーチ・ツー・スピーチ機械翻訳の2つの重要な要素は、音声認識と機械翻訳である。現在の翻訳システムでは通常、音声認識に続いて機械翻訳が行なわれる。【非特許文献1】ハーマン  ネイ、「音声翻訳:認識と翻訳との結合」、ICASSP1999予稿集、第1巻、517−520ページ、フェニックス、AR、1999年(Hermann  Ney.  1999.  Speech  translation: Coupling  of  recognition  and  translation.  In  Proc.  of  ICASSP'1999,  volume  1,  pages  517-520,  Phoenix,  AR,  March)【非特許文献2】ゲンイチロウ  キクイ、エイイチロウ  スミタ、トシユキ  タケザワ、およびセイイチ  ヤマモト、「スピーチ・ツー・スピーチ翻訳のためのコーパスの作成」、ユーロスピーチ2003予稿集、381−384ページ、ジュネーブ、2003年(Genichiro  Kikui,  Eiichiro  Sumita,  Toshiyuki  Takezawa,  and  Seiichi  Yamamoto.  2003.  Creating  corpora  for  speech-to-speech  translation.  In  Proc.  of  EUROSPEECH'2003,  pages  381-384,  Geneva.)【非特許文献3】ピーター  F.ブラウン、ビンセント  J.デラ  ピエトラ、スティーブン  A.デラ  ピエトラ、およびロバート  L.マーサー、「統計的機械翻訳の数学:パラメータ推定」、コンピュータ言語学、19(2):263−311、1993年(Peter  F.  Brown,  Vincent  J.  Della  Pietra,  Stephen  A.  Della  Pietra,  and  Robert  L.  Mercer.  1993.  The  mathematics  of  statistical  machine  translation:  Parameter  estimation.  Computational  Linguistics,  19(2):263-311.)【非特許文献4】ダニエル  マルク  およびウィリアム  ウォン、「統計的機械翻訳のための句ベースの結合確率モデル」、EMNLP−2002予稿集、フィラデルフィア、PA、2002年(Daniel  Marcu  and  William  Wong.  2002.  A  phrase-based,  joint  probability  model  for  statistical  machine  translation.  In  Proc.  of  EMNLP-2002,  Philadelphia,  PA,  July.)【非特許文献5】タロウ  ワタナベおよびエイイチロウ  スミタ、「統計的機械翻訳のための用例ベースのデコーディング」、機械翻訳サミットIX、410−417ページ、ニューオリンズ、ルイジアナ、2003年(Taro  Watanabe  and  Eiichiro  Sumita.  2003.  Example-based  decoding  for  statistical  machine  translation.  In   Machine  Translation  Summit  IX,  pages 410-417,  New Orleans,  Louisiana.)【非特許文献6】ウィリアム  H.プレス、ソール  A.トイコロスキー、ウィリアム  T.ヴェタリングおよびブライアン  P.フラネリー、「C++におけるニューメリカルレシピ」、ケンブリッジ大学出版局、ケンブリッジ、UK、2000年(William  H.  Press,  Saul  A.  Teukolsky,  William  T.  Vetterling,  and  Brian  P.  Flannery.  2000.  Numerical  Recipes  in  C++.  Cambridge  University  Press,  Cambridge,  UK.)【非特許文献7】キショーレ  A.パピネニ、サリム  ロウコス、トッド  ウォードおよびウェイ−ジン  シュー、「Bleu:機械翻訳の自動評価方法」、ACL2002予稿集、311−318ページ、フィラデルフィア、PA、2002年(Kishore  A.  Papineni,  Salim  Roukos,  Todd  Ward,  and  Wei-Jing  Zhu.  2002.  Bleu:  A  method  for  automatic  evaluation  of  machine  translation.  In  Proc.  of  ACL'2002,  pages  311-318,  Philadelphia,  PA,  July.)【非特許文献8】ソニア  ニーセン、フランツ  J.オク、グレゴール  ロイシュおよびヘルマン  ネイ、「機械翻訳の評価ツール:機械翻訳研究の高速評価」、LREC(2000)予稿集、39−45ページ、アテネ、ギリシャ、2000年(Sonja  Niessen,  Franz  J.  Och,  Gregor  Leusch,  and  Hermann  Ney.  2000.  An  evaluation  tool  for  machine  translation:  Fast  evaluation  for  machine  translation   research.  In Proc.  of  the  LREC  (2000),  pages  39-45,  Athens,  Greece,  May.)【非特許文献9】フランツ  ジョセフ  オク、「統計的機械翻訳における最小誤り率トレーニング」、ACL2003予稿集、160−167ページ、2003年(Franz  Josef  Och.  2003.  Minimum  error  rate  training  in  statistical  machine  translation.  In Proc.  of  ACL'2003,  pages  160-167.)【非特許文献10】ニコラ  エッフィング、フランツ  ジョセフ  オクおよびヘルマン  ネイ、「統計的機械翻訳におけ単語グラフの生成」、自然言語処理のための経験的方法会議(EMNLP02)予稿集、156−163ページ、フィラデルフィア、PA、2002年(Nicola  Ueffing,  Franz  Josef  Och,  and  Hermann  Ney.  2002.  Generation  of  word  graphs  in  statistical  machine  translation.  In  Proc.  of  the  Conference  on  Empirical  Methods  for  Natural  Language  Processing  (EMNLP02),  pages  156-163,  Philadelphia,  PA,  July.)【非特許文献11】フランツ  ジョセフ  オクおよびヘルマン  ネイ、「さまざまな統計的アライメントモデルの系統的比較」、コンピュータ言語学、29(1):19−51、2003年(Franz  Josef  Och  and  Hermann  Ney.  2003.  A  systematic  comparison  of  various  statistical  alignment  models.  Computational  Linguistics,  29(1):19-51.)【発明の開示】【発明が解決しようとする課題】【0004】  現在の音声認識および機械翻訳システムはかなり理解できる訳文を生成するが、依然改良の余地がある。音声認識と機械翻訳とがカスケードされているので、システムの精度は音声認識の精度とともに機械翻訳の性能にも依存する。認識されたテキストが正確でなければ、認識したテキストを翻訳しようとする機械翻訳も入力された発話の正しい訳文を生成することはできないであろう。【0005】  したがって、この発明の目的の一つは、第1の言語の音声をより高い信頼性をもって第2の言語の正しいテキストに翻訳する機械翻訳システムを提供することである。【0006】  この発明の別の目的は、音声認識の結果が信頼できない場合にも、第1の言語の音声をより高い信頼性をもって第2の言語の正しいテキストに翻訳する機械翻訳システムを提供することである。【0007】  この発明のさらに別の目的は、信頼できる認識されたテキストを生成する音声認識システムを提供することである。【課題を解決するための手段】【0008】  この発明にしたがった音声認識および機械翻訳装置は、第1の統計的モデルを利用して第1の言語の入力された音声の観測量を認識し、最も高い尤度を有するNベスト(Nは1より大きい整数)仮説を、Nベスト仮説の各々についてそれぞれの第1の尤度情報とともに出力するための音声認識手段と、第2の統計的モデルを利用してNベスト仮説の各々から複数個の訳文候補とそれぞれの第2の尤度情報とを導出するための統計的機械翻訳手段と、訳文候補が導出された仮説の第1の尤度情報と、訳文候補の第2の尤度情報とを予め定められた関数で組合せることによって、訳文候補の各々にスコアを割当てるための再スコアリング手段と、再スコアリング手段によって、予め定められた条件を満足するスコアを割当てられた訳文候補を選択するための選択手段とを含む。【0009】  音声認識で得られる第1の尤度情報と統計的機械翻訳で得られる第2の尤度情報とが組合されて、訳文候補を再スコアする。訳文候補の各々に対し再スコアリング手段によって計算されたスコアは、音声認識と機械翻訳との精度を反映する。音声認識および機械翻訳の使用と、尤度情報の組合せとが統合されバランスをとられて、信頼性のある最適な訳を出力する。【0010】  好ましくは、再スコアリング手段は、音声認識および機械翻訳から訳文候補が導出された仮説を組合せることにより、第1の尤度情報の対数線形モデルにしたがって、訳文候補の各々のスコアを計算する手段を含む。【0011】  より好ましくは、第1の統計的モデルは、第1の言語の音響モデルを含み、第1の尤度情報は、音響モデルにしたがって計算された入力音声観測量の音響モデル尤度を含む。【0012】  さらに好ましくは、第1の統計的モデルはさらに、第1の言語の言語モデルを含み、第1の尤度情報はさらに、仮説の言語モデル尤度を含む。【0013】  第2の統計的モデルは複数のサブモデルを含み、第2の尤度情報はそれぞれのサブモデルにしたがって計算された訳文候補の複数のサブモデル尤度を含んでもよい。【0014】  複数のサブモデル尤度は、訳文候補の品詞言語モデル確率と、訳文候補の長さモデルと、訳文候補および訳文がそこから導出された仮説のセプトのジャンプ重みと、訳文候補の用例一致スコアと、訳文候補の動的用例一致スコアとの組合せを含んでもよい。【0015】  好ましくは、第1の尤度情報と第2の尤度情報とが、合計でM個(Mは整数)の特徴量を含み、計算するための手段は、各訳文候補のスコアPΛ(E｜X)を以下の式にしたがって計算し、【0016】【数1】ここでXは音響的観測量を示し、fi(X,E)はi番目の特徴量の対数値を示し、Eは訳文候補を示し、λi(1≦i≦M)はi番目の特徴量の重みを示し、Λはλi(1≦i≦M)の組を示し、Eはいずれかの訳文候補を示す。【0017】  より好ましくは、音声認識および機械翻訳装置は第1の言語の既知の発話の開発用音響観測量の組と、各発話の参照訳文の組とを利用して、重みλi(1≦i≦M)を最適化するための手段をさらに含み、それによって再スコアリング手段が参照訳文にしたがった適切なスコアを開発用音響観測量の組から導出された訳文候補に割当てる。この動作において、訳文候補は音声認識手段および統計的機械翻訳手段により開発用音響観測量から導出される。【発明を実施するための最良の形態】【0018】  1  はじめに  現在の翻訳システムは通常、カスケード構造である。すなわち、音声認識に機械翻訳が続く。この構造は分かりやすいものの、その性能には組合せに関する最適化が不足している。というのも、音声認識モジュールと機械翻訳モジュールとが、どちらかというと別々に動くからである。さらに、音声翻訳システムの翻訳モジュールは、テキスト入力ベースの翻訳システムをそのまま利用したものであるため、通常はシングルベストの認識仮説をテキスト化したものに対し標準的なテキストベースの翻訳を行なう。音声認識から得られる大量の補足的情報、例えば、Nベスト認識仮説、音響および言語モデルの尤度等は、翻訳プロセスで有効に利用されてはいない。この実施の形態は、この種の情報を用いて、翻訳の品質を効果的に改良するものである。【0019】  補足的情報は、音声認識と機械翻訳とを緊密に結合することによって(ネイ、1999:非特許文献1)、またはカスケード構造は不変のまま、統合モデル、対数線形モデル、を用いて訳文仮説を再スコアすることによって活用できる。この実施の形態では、明瞭さのために、最後で述べたアプローチを用いる。【0020】  この実施の形態は、音声認識プロセスで得られた上述の情報を活用することにより、音声翻訳を改良しようとするものである。さらに、モデルには、機械翻訳モジュールから得た新しい特徴が幾つか付加される。音声認識モジュールおよび機械翻訳モジュールからの全ての特徴量が、対数線形モデルによってシームレスに組合される。【0021】  この実施の形態の結果を概略的に試験するために、4つの自動翻訳評価指標、すなわちBLEU、NIST、複数単語誤り率、および位置独立な単語誤り率を用いて、訳文の改良を測定した。【0022】  以下のセクション2では、音声翻訳システム、その全体構造、そこで用いられるモデル、およびシステム全体の動作を説明する。セクション3では、対数線形モデルにおける重みパラメータを見出すために用いられる最適化アルゴリズムを説明する。セクション4では、音声翻訳実験でのこの実施の形態の効果を例示する。最後の2つのセクションでは結果と現時点での結論を述べる。【0023】  2  音声翻訳における特徴量を用いた対数線形モデル  2.1  実施の形態の構造と対数線形モデル  この実施の形態にしたがった音声翻訳システムを図1に示す。その一般性を失うことなく、この発明を日本語—英語翻訳システム20を例として記載し、包括的な音声翻訳プロセスを説明する。このシステムは典型的な統計ベースのシステムである。図1を参照して、この実施の形態の音声翻訳システム20は日本語の音声から英語のテキストへの翻訳システムであって、入力音声30(日本語)を受けて入力音声30の複数の英訳文を生成する音声認識および翻訳モジュール42と;音声認識および翻訳モジュール42によって用いられる日本語の発話に対する音響モデル62、日本語言語モデル63、英語言語モデル72、および英語−日本語(J｜E)翻訳モデル76を記憶するモデル記憶部40と;学習データ36から、音響モデル62、言語モデル63および72、ならびに翻訳モデル76を準備するためのモデル準備モジュール38と;音声認識および翻訳モジュール42が出力する複数の訳文を再スコアリングし、それらの内から最良の訳文58を選択するための再スコアリングモジュール56と;訳文の再スコアリングに用いられるパラメータΛ=｛λ1M｝を記憶するための記憶部とを含む。【0024】  音声翻訳システム20はさらに、パラメータΛ=｛λ1M｝を最適化するのに用いられる開発データ32を記憶する記憶部と;開発データ32から人手による翻訳44により準備された参照訳文を記憶するための記憶部50と;パラメータΛ=｛λ1M｝を最適化し、後に導入される対数線形等式が音声認識および翻訳モジュール42によって翻訳された開発データ32の音声訳文を参照訳文に対し適切に再スコアできるようにするパラメータ最適化モジュール52とを含む。【0025】  動作の前に、開発データ32を用いてパラメータΛ=｛λ1M｝を最適化しなければならない。この目的で、音声翻訳システム20はさらに、入力音声30又は開発データ32をモード選択信号22に応答して音声認識および翻訳モジュール42に選択的に与えるためのマルチプレクサ34と;音声認識および翻訳モジュール42から出力された訳文をモード選択信号22に応答してパラメータ最適化モジュール52または再スコアリングモジュール56に与えるためのデマルチプレクサ46とを含む。【0026】  モード選択信号22は、パラメータを最適化するときにはハイレベル(Hレベル)となり、入力音声を認識し翻訳するときにはローレベル(Lレベル)となる。モード選択信号22がHレベルのとき、マルチプレクサ34は開発データ32を音声認識および翻訳モジュール42に与え、デマルチプレクサ46は音声認識および翻訳モジュール42からの訳文をパラメータ最適化モジュール52に与える。【0027】  モード選択信号22がLレベルのとき、マルチプレクサ34は入力音声30を音声認識および翻訳モジュール42に与え、デマルチプレクサ46は音声認識および翻訳モジュール42からの訳文を再スコアリングモジュール56に与える。【0028】  モデル準備モジュール38は、学習データ36中の音声データによって音響モデル62をトレーニングするための音響モデルトレーニングモジュール60と;日本語言語モデル63をトレーニングするための日本語言語モデルトレーニングモジュール61と;英語言語モデル72をトレーニングするための英語言語モデルトレーニングモジュール70と;翻訳モデル76をトレーニングするための翻訳モデルトレーニングモジュール74とを含む。【0029】  基本旅行者表現コーパス(The  Basic  Travel  Expression  Corpus:BTEC)(キクイら、2003、非特許文献2)を開発データ32および学習データ36として用いる。このコーパスは旅行ガイドブックおよび旅行会話で一般に用いられる文章を含む。このコーパスは、多言語スピーチ・ツー・スピーチ翻訳システムを開発するために設計されたものである。これは4つの異なる言語を含む。中国語、日本語、韓国語および英語である。この実施の形態では日本語−英語のパラレルデータのみを用いる。【0030】  音声データは多くの話者によって録音されたもので、音響モデル62をトレーニングするのに用いられ、テキストデータベースは言語モデル72および翻訳モデル76をトレーニングするのに用いられる。【0031】  標準的なBTECトレーニングコーパス、BTEC標準テストコーパス#01の第1のファイルおよび第2のファイルが、それぞれ、トレーニング、開発およびテストに用いられる。コーパスの統計は表1に示すとおりである。【0032】【表1】  図1に示すように、音声認識および翻訳モジュール42はカスケードされた2つの主たる構成要素を含む。入力音声を認識して入力音声の各々に対しNベストの仮説を出力するための自動音声認識(Automatic  Speech  Recognition:ASR)モジュール80と;入力された仮説を翻訳し入力された仮説の各々に対しK個の訳文候補を出力するための統計的機械翻訳(Statistical  Machine  Translation:SMT)モジュール84とである。ASRモジュール80は音響モデル62と言語モデル63とを用いて入力音声を認識し、最も高い確率を有するNベストの仮説を、認識プロセスで得られた付随する情報と共に出力する。同様に、SMTモジュール84は、各仮説に対し、言語モデル72および翻訳モデル76を用いて計算した最も高い確率のK個の訳文候補と付随する情報とを出力する。【0033】  音声認識および翻訳モジュール42はさらに、ASRモジュール80からのNベスト仮説を記憶するための記憶部82と、SMTモジュール84から出力される訳文候補を記憶するための記憶部86とを含む。Nベスト仮説82はSMTモジュール84に与えられる。訳文候補86はデマルチプレクサ46に与えられる。【0034】  再スコアリングモジュール56はシステム20の鍵となる構成要素である。このモジュール56は、ASRモジュール80とSMTモジュール84とから得られる特徴量組合せ、訳文候補を再スコアリングするとともに、最も高いスコアの候補を選択する。【0035】  上述の通り、一般性を失うことなく、この実施の形態は日本語−英語翻訳システム20について記載し、一般的な音声翻訳システムを説明する。Xは日本語の発話の音響的観測量を示すものとする。典型的には、10ミリ秒ごとのフレームレートで受取られる短時間スペクトルのシーケンスである。これはまず、日本語の文Jとして認識される。認識された文はその後、SMTモジュール84で対応の英語文Eに翻訳される。【0036】  XからJへの変換はASRモジュール80内で行なわれる。ベイズの定理に基づき、音響的観測量Xが与えられたときの文Jの確率、P(J｜X)は次のように書ける。P(J｜X)=Pam(X｜J)Plm(J)/P(X)ここでPam(X｜J)は認識された文Jが与えられたときの観測量の音響モデル尤度であり、Plm(J)は日本語言語モデル確率であり、P(X)は全ての音響観測量の確率である。【0037】  ASRモジュール80はNベスト仮説の組J1N=｛J1,J2,…JN｝を生成し、Jiの各々は次のように決定される。【0038】【数2】  ここでΩiはより高いランクのJkを全て(すなわち1≦k≦i−1)除いた、可能な全てのソース文の組でである。【0039】  図1のJからEへの変換は機械翻訳プロセスである。統計的機械翻訳の定式化(ブラウンら、1993、非特許文献3)によれば、この翻訳プロセスは以下のようなベストの文＾E(記号「＾」は式中ではその直後の文字の直上に記載される。)を探索することであり、【0040】【数3】ただしP(J｜E)はEとJとの対応を特徴づける翻訳モデルであり、P(E)は英語の言語モデル確率である。【0041】  IBMモデル4では、翻訳モデルP(J｜E)はさらに4個のサブモデルに分解される。−レキシコンモデル−t(j｜e):日本語の単語jが英語の単語eに翻訳される確率−ファーティリティーモデル−t(j｜e):英語の単語eがφの単語を生成する確率−ディストーションモデル−d:ディストーションの確率であって、先頭単語と先頭でない単語とのディストーション確率に分解される。−NULL翻訳モデル−p1:各英語の単語を決定した後にNULL単語を挿入する固定された確率【0042】  上記のうち、この実施の形態では7個の特徴量を用いる。ASRから2個(Pam(X｜J)、Plm(J))、SMTから5個(P(E)、t(j｜e)、n(φ｜e)、d、p1)である。【0043】  図1の再スコアリングモジュール56は、特徴量に基づく対数線形モデルを用いて、SMTモジュール86からの訳文仮説を再スコアリングするものである。音声認識および翻訳モジュール42から出力される全ての訳文候補は、関連の全特徴量を用いて再評価され、最も高いスコアのベスト訳文候補が探索される。【0044】  再スコアリングモジュール56で用いられる対数線形モデル、P(E｜X)は以下で与えられる。【0045】【数4】  式(1)で、fi(X,E)はi番目の特徴量の対数値である。λiはi番目の特徴量の重みである。等式中に異なる特徴量を統合すると異なるモデルが結果として得られる。セクション4で行なわれる実験では、特徴量の数を順次増加させることによって4個の異なるモデルをトレーニングし、異なる特徴量が音声翻訳の改良にどのような効果を及ぼすかを調査した。【0046】  上述の7個の特徴量に加えて、以下の特徴量もまた組込んだ。−品詞言語モデル:英語の品詞言語モデルが用いられた。翻訳された英語文のPOS依存性は英語文候補の刈込みにおいて有効な制約である。以下で説明する実験では、81個のPOSタグと5グラムのPOS言語モデルが用いられる。−長さモデルP(l｜E;J):lは翻訳された英語文の長さ(単語数)である。−ジャンプ重み:モデル4における近接したセプト(単語チャンク)間のジャンプ幅(マルクおよびウォン、2002、非特許文献4)。−用例一致スコア:翻訳された英語文を句翻訳用例とマッチングさせる。一致の数に基づきスコアが導出される(ワタナベおよびスミタ、2003、非特許文献5)。−ダイナミック用例一致スコア:用例一致スコアに類似するが、句は文の用例からダイナミックに抽出される(ワタナベおよびスミタ、2003、非特許文献5)。【0047】  この実施の形態では、全部でM(=12)個の異なる特徴量を用いる。セクション3では、種々の客観的な翻訳指標に基づき、モデルパラメータλ1Mを最適化するツールとして、パウエルのアルゴリズム(プレスら、2000、非特許文献6)を検討する。【0048】  2.2  音声翻訳システム20の全体動作  音声翻訳システム20は3つの動作段階を持つ。モデルトレーニング段階、パラメータ最適化段階、および音声認識および翻訳段階である。音声翻訳システム20の、これら3段階の各々における動作を以下で説明する。【0049】  始めに、学習データ36が準備される。この実施の形態では、標準BTECトレーニングコーパスをトレーニングに用いる。音響モデルトレーニングモジュール60が学習データ36中の音声データを用いて、HMMベースの音響モデル62をトレーニングする。学習データ36中のテキストデータベースが、言語モデルトレーニングモジュール61および70ならびに翻訳モデルトレーニングモジュール74による言語モデル63および72ならびに翻訳モデル76のトレーニングにそれぞれ用いられる。モデル62、63、72および76が準備されると、対数線形モデルのためのパラメータΛ=｛λ1M｝が最適化される。【0050】  最適化に先だって、BTEC標準テストコーパス#01の第1ファイルが開発データ32として準備される。人間の翻訳者が開発データ32中の各発話について参照文を言換え、複数個の文にする。この実施の形態では、文は16通りに言換えられる。【0051】  開発段階では、モード選択信号22はHレベルに設定される。マルチプレクサ34は開発データ32中の発話を選択し、その発話をASRモジュール80に与える。ASRモジュール80は各発話についてNベスト仮説の組を生成する。L個の音声発話があると仮定する。この場合ASRモジュール80はL×N個の仮説を生成し、これらは記憶部82に記憶される。【0052】  認識仮説の各々に対し、SMTモジュール84はK個の英語言語翻訳仮説を生成する。l(エル)番目の入力音声発話には、この場合Cl1=｛＾E1,…,ElN×K}個の訳文ができることになる。全部でL個の音声発話で、合計L×N×K個の訳文候補が生成される。【0053】  デマルチプレクサ46はL×N×K個の訳文候補を選択し、パラメータ最適化モジュール52に与える。パラメータ最適化モジュール52はパラメータΛ=｛λ1M｝を最適化する。パラメータ最適化モジュール52がパラメータを最適化する方法はセクション3で述べる。最適化されたパラメータは記憶部54に記憶される。【0054】  パラメータΛ=｛λ1M｝が最適化されると、音声翻訳システム20は第3の段階で動作する準備が整う。すなわち、入力音声を英語テキストに翻訳する準備が整う。この第3の段階では、モード選択信号22はLレベルに設定される。マルチプレクサ34は入力音声30を選択し、これをASRモジュール80に与える。ASRモジュール80は入力音声30の音響モデル62を利用して、Nベスト仮説を生成する。Nベスト仮説の各々について、SMTモジュール84はKベスト訳文候補を生成する。したがって、SMTモジュールは合計N×K個の訳文候補を生成する。【0055】  デマルチプレクサ46はN×K個の訳文候補とそれらに付随する情報を再スコアリングモジュール56に与える。【0056】  N×K個の訳文候補と、翻訳プロセス中に得られたそれらに付随する情報と、Nベスト仮説と、ASRプロセス中に得られたそれらの情報とを与えられ、再スコアリングモジュール56はN×K個の訳文候補の各々を再スコアする。最も高いスコアを達成する訳文がベスト訳文58として再スコアリングモジュール56から出力される。【0057】  3  翻訳指標に基づくパラメータの最適化  このセクションでは、パラメータがパラメータ最適化モジュール52でどのように最適化されるかを説明する。全ての仮説に等しく正規化が適用されるので、式(1)の分母は無視できる。したがって、可能な全ての訳文Eからベストの訳文＾Eを選択することは、分母に依存しない。【0058】【数5】ここでは、特徴量fi(X,E)を対数logPi(X,E)と明示的に書いている。【0059】  式(2)のモデルの有効性は、客観的に測定可能であり、かつ主観的に妥当な何らかの指標に対する、パラメータセットλ1Mのパラメータ最適化に依存する。【0060】  L個の音声発話があり、発話の各々に対しNベストの音声認識仮説を生成すると仮定する。認識仮説の各々について、K個の英文言語翻訳仮説が生成される。l(エル)番目の入力音声発話には、Cl1=｛＾E1,…,ElN×K}個の訳文がある。全部でL個の音声発話からは合計L×N×K個の訳文が生成される。【0061】  目標とされるのは、参照訳文Rと翻訳された文＾εとの翻訳のひずみ(ディストーション)を最小にすることである。【0062】【数6】ここで＾ε=｛＾E1,…,＾EL｝は全ての発話の訳文の組である。l(エル)番目の発話の訳文＾Elは式(2)から生成され、ここでE∈Clである。【0063】  R=｛＾E1,…,＾EL｝を全ての発話の参照訳の組とする。人間の翻訳者が各発話について16の参照文を言換えた。すなわちRlは、l(エル)番目の発話について16個の参照候補を含む。【0064】  D(＾ε、R)は客観的な訳文評価、翻訳ひずみ(ディストーション)である。この実施の形態では以下の4個の指標を特に用いる。−BLEU(パピネニら、2002、非特許文献7):テスト文と参照文とのnグラム一致の加重幾何平均に短文ペナルティを乗じたもの。これは短い訳文にペナルティを課す。−NIST:テスト文と参照文とのnグラム一致の算術平均に長さによる係数を乗じたもの。これも短い訳文にペナルティを課す。−mWER:(ニーセンら、2000、非特許文献8):複数参照単語誤り率、テスト文と参照文との間の編集距離(挿入、削除および置換の最小数)を計算するもの。−mPER:複数参照位置独立単語誤り率、単語の順序を考慮せずに編集距離を計算するもの。【0065】  BLEUスコアとNISTスコアとはインターネット上で入手可能なツールを用いて計算される。【0066】  モデル(式(3))の目的関数は滑らかな関数ではないので、この実施の形態では、解を見出すためにパウエルの探索方法を用いた。この実施の形態で用いるパウエルのアルゴリズムは(プレスら、2000、非特許文献6)で用いられるものと類似しているが、ここではパウエルのアルゴリズムのサブルーチンである線最適化コードを(オク、2003、非特許文献9)を参照して修正した。【0067】  通常、高次元のベクトル空間では、グローバルな最適条件を見出すのは困難である。良好な局所的最適条件を確実に見出すために、さまざまな初期化を用いてアルゴリズムをリスタートし、最良の局所最適条件を最終解に用いた。【0068】  4  実験  4.1  コーパス&システム  実験に用いた音声認識エンジンはHMMベースの大語彙連続音声認識装置である。音響HMMは合計で2,100の状態を持つトライフォンモデルであり、25次元の短時間スペクトル特徴量を用いた。デコーディングの1回目と2回目のパスでは、37,000語辞書のマルチクラス単語バイグラムに加えて10,000個の複合語を用いた。単語トライグラムを用いて結果を再スコアした。【0069】  機械翻訳システムはグラフベースのデコーダである(エッフィングら、2002、非特許文献10)。デコーダの1回目のパスで単語グラフが生成されるが、これは択一的な訳文候補を簡潔に表したものであって、辞書と言語モデルとのスコアに基づくビーム探索を用いている。【0070】  2回目のパスでは、A*探索によりグラフを横断的に探す。単語グラフのエッジ、すなわち句訳文候補が逆辞書モデルから得られる単語訳のリストから生成される。トレーニングコーパスのビタビアライメントから抽出される句訳文もまた、エッジを構成する。同様に、対訳文からダイナミックに抽出された句訳文からもエッジが作られる(ワタナベおよびスミタ、2003、非特許文献5)。デコーダは、トライグラム言語モデルと5グラム品詞言語モデルで、IBMモデル4を用いた。IBMモデル4のトレーニングはGIZA++パッケージ(オクおよびネイ、2003、非特許文献11)で実現した。【0071】  4.2  モデルトレーニング  音声認識および機械翻訳のそれぞれの特徴量から訳文の改良を定量化するために、特徴量を順次増加させることによって4個の対数線形モデルを構築した。4個のモデルは、以下のとおりである。−標準翻訳モデル(stm):対数線形モデルで、セクション2で説明したIBMモデル4(M=5)の特徴量のみを用いた。このモデルではパラメータ最適化を行なわなかった。これはλ1Mを全て1に設定することと等しい。このモデルはほとんどの統計的機械翻訳システムで用いられる標準的なモデルである。これをベースラインモデルと呼ぶ。−最適化標準翻訳モデル(ostm):このモデルは上述のモデル「stm」と同様の特徴量からなるが、パラメータはパウエルのアルゴリズムによって最適化される。このモデルをベースライン「stm」と比較することにより、パラメータ最適化の効果を示す。−最適化改善翻訳モデル(oetm):モデル「ostm」を充実させるために、セクション2で説明した付加的な翻訳特徴量を組入れた。このモデルでは特徴量の合計数Mは10である。モデルパラメータは最適化した。これらの改善特徴量で翻訳の品質をどの程度上げられるかを示す。−最適化改善音声翻訳モデル(oestm):モデル「oetm」に音声認識からの特徴量と、音響モデルおよび言語モデルの尤度スコアとをさらに組入れた。セクション2で説明した12の特徴量全てを用いた。モデルパラメータは最適化した。【0072】  対数線形モデルのλパラメータを最適化するために、510の音声発話の開発データ92を用いた。λをトレーニングするために、Nベスト仮説アプローチ(オク、2003、非特許文献9)を採用した。入力音声発話の各々につき、N×M個の候補訳文が生成され、ここでNは生成された認識仮説の数であり、Kは訳文仮説の数である。翻訳モデルで用いられる多数の特徴量に対応する次元Mのベクトルが、訳文候補の各々について生成された。パラメータを最適化するために、パウエルのアルゴリズムを用いた。有望な訳文候補が刈込まれることがないように、大きなKを用いた。トレーニングでは、N=100、K=1,000に設定した。【0073】  セクション3で説明した種々の客観的翻訳評価指標を用いて,モデルの各々についてそれぞれBLEU、NIST、mWER、mPER指標に関連して4組の最適化パラメータを得た。【0074】  4.3  付加的特徴量による訳文の改善  テストデータ中の508個の発話全てをモデルの評価に用いた。開発データの処理と同様に、ASRモジュール80は各テスト音声発話につきNベスト(N=100)の認識仮説を生成した。表2はシングルベストおよびNベスト仮説でのテストデータセットの音声認識結果を示す。【0075】【表2】  シングルベストの認識仮説に対し、Nベストの認識仮説では文精度の8%以上の改善が観察された。その後認識された文を対応する英文に翻訳した。認識仮説の各々に対しこのような訳文候補1,000個が生成された。その後訳文候補を、それぞれトレーニングで得られた最適化されたパラメータの4個のセットで4個のモデルの各々について再スコアした。最良のスコアの候補を選択した。【0076】  モデルによって生成された最良の訳文を、開発の際にモデルパラメータを最適化するのに用いた訳文評価指標で評価した。実験結果を表3に示す。【0077】  実験では、Nが変わるにつれて翻訳性能がどのように変化するかを見るため、仮説の数Nを変えた。比較的小さな仮説数、N=5を用いたときに、最良の翻訳がなされることがわかった。したがって、表3の値はNを5に設定したときのものである。【0078】【表3】  各モデルを、シングルベスト認識仮説翻訳と、Nベスト認識仮説翻訳とを用いてテストした。シングルベスト翻訳は、音声認識のシングルベスト仮説の翻訳からであり、Nベスト仮説翻訳はASRモジュール80によって生成された仮説全ての翻訳からのものである。【0079】  表3において、ベースラインモデル「stm」から最終モデル「oestm」までで、大きな改善が観察される。BLEU、NIST、mWER、およびmPERスコアはそれぞれ7.9%、2.7%、6.1%、5.4%改善された。BLEUおよびNISTスコアの高い値は良好な翻訳を示し、一方mWERおよびmPERでは悪い翻訳を示すことに注意されたい。シングルベストおよびNベスト認識仮説翻訳において一貫した性能の改良が達成された。【0080】  改良の理由は以下の通りであろうと考えられる。−最適化  パラメータを最適化したモデルではパラメータを最適化しなかったモデルよりも良好な訳文が得られた。これは、シングルベストおよびNベストともに、モデル「stm」とモデル「ostm」とを比較することでわかる。−Nベスト認識仮説  表3の大部分の項目で、Nベスト認識の翻訳性能はシングルベスト認識の対応のものより良好である。「ostm」のNベストBLEUスコアは、「ostm」のシングルベストより2.1%改善されている。しかしながら、NISTスコアはこの変更には無関係である。NISTスコアはわずかな訳文の変更を検出する感度が低いように思われる。【0081】−改善された特徴量  対数線形モデルにより多くの特徴量を組入れるにつれて、翻訳性能は着々と改良された。モデル「oetm」の翻訳性能は、モデル「ostm」の性能よりも良好であるが、これはより多くの効果的な特徴量を用いたからである。モデル「oestm」は音声認識特徴量が改善されているため、モデル「oetm」より良好である。これによって、音声認識からの特徴量と翻訳の特徴量とを統合するこの発明の実施の形態のアプローチが非常にうまく働いたことが確認できた。【0082】  4.4  不正確に認識された文の認識改良  これまでの実験では、本提案に係る改善された音声翻訳モデル「oestm」によって音声翻訳の性能が改良されることを示した。このセクションでは、この改善が、Nベスト認識仮説を用いることで不正確に認識された文がかなり改良されたことによりもたらされたことを示す。【0083】  以下の実験を行なった。不正確に認識された文のみを翻訳用に抽出し、シングルベストの場合はモデル「oetm」により、Nベストの場合はモデル「oestm」により再スコアリングを行なった。翻訳結果を表4に示す。不正確に認識された文の翻訳が、この表に示すとおり大きく改善されている。【0084】【表4】  Nベスト認識仮説を用いたので、対数線形モデルはN個の仮説のうち最良の訳文を生成する認識仮説を選択した。この結果、翻訳により高い精度の認識仮説を選択すれば、音声認識を改善することができる。不正確に認識された文の選択された認識仮説を抽出すれば、この効果を明らかに観察することができる。【0085】  表5は翻訳モジュールによって選択された認識仮説の単語精度と文精度とを示す。不正確に認識された文の文精度は7.5%改善された。単語精度も改善された。【0086】【表5】  5  議論  この実施の形態のアプローチはかなり一般的なものであり、実施が容易で柔軟に拡張できる。実験では音響モデルと言語モデルとから特徴量を組入れた。しかしながらこのフレームワークは柔軟であって、より効果的な特徴量を含めることができる。実際、提案された対数線形モデルの音声翻訳パラダイムは、多くの応用で有効であることが示されている。【0087】  音声認識の特徴を用いるためには、Nベスト音声認識仮説が必要である。Nベストを用いることは計算の負荷を増大させ得る。しかし、実験では、Nが小さくても、計算量をさほど増加させることなく訳文改良のほとんどを達成するのに適当であることが示されている。【0088】  6  結論  この明細書では、音声認識および機械翻訳の特徴量を共に対数線形モデルに組入れて音声翻訳を改良するという発明のアプローチの一実施の形態を呈示した。【0089】  この新しいアプローチのもとでは、翻訳性能が著しく改良される。性能の改良は、一貫した実験結果で確認され、さまざまな客観的指標を用いて測定された。特に、BLEUスコアは絶対値で7.9%改善した。【0090】  音声認識から導出される特徴量:音響モデルおよび言語モデルの尤度は音声翻訳の改善に有効であった。Nベスト認識仮説は翻訳に用いられる際にはシングルベストのものより良好である。Nベスト認識仮説の翻訳は、不正確に認識された文の音声認識精度を改善できる。【0091】  実験の成功は統計的機械翻訳と対数線形モデルとによるものであり、このためさまざまな効果的特徴量を合わせてバランスをとり、最適な翻訳結果を出力することができる。【0092】  今回開示された実施の形態は単に例示であって、本発明が上記した実施の形態のみに制限されるわけではない。本発明の範囲は、発明の詳細な説明の記載を参酌した上で、特許請求の範囲の各請求項によって示され、そこに記載された文言と均等の意味および範囲内でのすべての変更を含む。【図面の簡単な説明】【0093】【図1】この発明の実施の形態にしたがった音声翻訳システム20のブロック図である。【符号の説明】【0094】20  音声翻訳システム、22  モード選択信号、30  入力音声、32  開発データ、34  マルチプレクサ、36  学習データ、38  モデル準備モジュール、42  音声認識および翻訳モジュール、46  デマルチプレクサ、50  参照訳文、52  パラメータ最適化モジュール、56  再スコアリングモジュール、58  ベスト訳文、62  音響モデル、63  日本語言語モデル、72  英語言語モデル、76  翻訳モデル、80  ASRモジュール、84  SMTモジュール
【特許請求の範囲】【請求項1】音声認識および機械翻訳装置であって、  第1の統計的モデルを利用して第1の言語の入力音声の観測量を認識し、最も高い尤度を有するNベスト(Nは1より大きい整数)仮説を、前記Nベスト仮説の各々についてそれぞれの第1の尤度情報とともに出力するための音声認識手段と、  第2の統計的モデルを利用して前記Nベスト仮説の各々から複数個の訳文候補とそれぞれの第2の尤度情報とを導出するための統計的機械翻訳手段と、  訳文候補が導出された仮説の第1の尤度情報と、訳文候補の第2の尤度情報とを予め定められた関数で組合せることによって、訳文候補の各々にスコアを割当てるための再スコアリング手段と、  前記再スコアリング手段によって、予め定められた条件を満足するスコアを割当てられた訳文候補を選択するための選択手段とを含む、音声認識および機械翻訳装置。【請求項2】前記再スコアリング手段が、音声認識および機械翻訳から訳文候補が導出された仮説の第1の尤度情報と組合せることにより、対数線形モデルにしたがって、訳文候補の各々のスコアを計算するための手段を含む、請求項1に記載の音声認識および機械翻訳装置。【請求項3】前記第1の統計的モデルが、前記第1の言語の音響モデルを含み、前記第1の尤度情報が、前記音響モデルにしたがって計算された入力音声観測量の音響モデル尤度を含む、請求項2に記載の音声認識および機械翻訳装置。【請求項4】前記第1の統計的モデルがさらに、前記第1の言語の言語モデルを含み、前記第1の尤度情報がさらに、仮説の言語モデル尤度を含む、請求項3に記載の音声認識および機械翻訳装置。【請求項5】前記第2の統計的モデルが複数のサブモデルを含み、前記第2の尤度情報がそれぞれのサブモデルにしたがって計算された訳文候補の複数のサブモデル尤度を含む、請求項3又は請求項4に記載の音声認識および機械翻訳装置。【請求項6】前記複数のサブモデル尤度が、訳文候補の品詞言語モデル確率と、訳文候補の長さモデルと、訳文候補および訳文がそこから導出された仮説のセプトのジャンプ重みと、訳文候補の用例一致スコアと、訳文候補の動的用例一致スコアとの組合せを含む、請求項5に記載の音声認識および機械翻訳装置。【請求項7】前記第1の尤度情報と前記第2の尤度情報とが、合計でM個(Mは整数)の特徴量を含み、前記計算するための手段が、各訳文候補のスコアPΛ(E｜X)を以下の式にしたがって計算し、【数1】ここでXは音響的観測量を示し、fi(X,E)はi番目の特徴量の対数値を示し、Eは訳文候補を示し、λi(1≦i≦M)はi番目の特徴量の重みを示し、Λはλi(1≦i≦M)の組を示し、Eはいずれかの訳文候補を示す、請求項2に記載の音声認識および機械翻訳装置。【請求項8】前記第1の言語の既知の発話の開発用音響観測量の組と、各発話の参照訳文の組とを利用して、重みλi(1≦i≦M)を最適化するための手段をさらに含み、それによって前記再スコアリング手段が参照訳文にしたがった適切なスコアを前記開発用音響観測量の組から導出された訳文候補に割当て、訳文候補は前記音声認識手段および統計的機械翻訳手段により前記開発用音響観測量から導出される、請求項7に記載の音声認識および機械翻訳装置。
音声認識および機械翻訳装置
