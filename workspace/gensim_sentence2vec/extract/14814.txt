
【前へ】
3.2 音声処理応用システム・音声インタフェース
3.2.1 音声処理技術の応用領域
この1、2年の間にパソコン搭載の音声認識ソフトの発売、カーナビや携帯電話に音声認識機能が搭載されるなど音声インタフェースが民生品として広がりを見せており、世間的にも注目を集めている。これはおよそ、この30年間につぎ込まれた研究開発努力が実用品としてようやく実りつつあるということでもある。音声インタフェースは、システムの構成要素としては多くの場合マンマシンインタフェースの一部でしかないが、その技術要素は人間のもつ音声言語生成・知覚・認識理解と不可分であり、音声メディアのもつ内容をマンマシン間で交換する知的機能である。したがって、この意味では音声インタフェースという呼称は必ずしも適当ではないが、ここでは慣例的に使用する。
本章では、音声処理応用システムとしての音声インタフェースを取り上げ、1)その代表的な応用用途、2)応用面から観た技術展開の方向・技術課題、3)技術や応用システムを進展させるためのインフラ整備や標準化の問題点、について日米欧などの研究開発動向を踏まえて述べる。
音声情報処理技術には、音声符号化、音声加工、音声合成、音声認識、話者認識、音声対話処理などの分野が含まれる。これらの要素技術を内包する応用システムのうち、現在、もっとも市場が大きいのは携帯電話などに用いられている音声符号化技術である。また、音声加工(たとえば話速変換、話者のマスク化など)や音声合成技術も比較的単純な方式でも応用が可能であることから実用化が進んでいる。これに比べると、認識機能を伴う音声認識理解システムは誤りの少ないロバストなシステムの構築が難しく、実用的な応用は少なかった。とくに計算機の大容量化と高速処理が進むと生データを活かした抽象度の低い処理が採用されることが多くなり、高度な抽象化が必要な音声合成方式(音声規則合成)や音声認識は敬遠される傾向にある。たとえば、録音した文章例を符号化して大量に蓄積でき且つ高速な検索が可能であれば、規則合成音声を利用しなくてもかなりの範囲の音声出力機能をカバーできる。しかし、一方では、現代社会においては膨大なデータが何らかの文書的な形式で蓄積されており、また知識が言語的メディアを用いて表現されることが多い。これらの事実を考慮すると、有用なデータや知識を効率よく利用するためには規則合成技術や認識技術も必要不可欠な重要要素技術となる。ここでは、こうした抽象化度合の高い音声認識機能を核とした音声インタフェースに焦点を当てる。
3.2.2 代表的な音声インタフェース応用システム
音声インタフェースを普及する原動力の1つが現在、急速に普及しつつある携帯性と移動性である。具体的には、インターネット、CTI(Computer-Telephony Integration)、高度交通情報システムなどに代表されるシステムに組み込まれていくと予測される。また、音声インタフェースには他のモーダリティと比較して、入力と並行して手足の自由を確保できる点、数百を超える多項目からの選択も可能であることなどの利点がある。しかし、一方では、安定でロバストな動作が難しいこと、機械側の状態がユーザに見え難く何が認識できるかなどの点でユーザが戸惑うこと、などユーザインタフェースとしての問題点がある。これらの問題も使用の蓄積によって徐々に解決されていくであろう。
音声インタフェースの具体的な用途としては、次のようなものが考えられる。すなわち、携帯電話・携帯端末、カーナビ、音声ワープロ(ディクテーション)、放送音声字幕化、情報検索・要約、音声案内・予約、コンサルテーション、ゲーム・教育システム、自動通訳、老人・障害者支援、セキュリティなどであり、その一部は既に実用化されている。これらをより基本的な機能システムとして捉えると、下記のようなシステムとなる。以下に現状を概説する。
音声コマンド
音声応用システムとしては最も早くからある形態であり、物流制御などの産業用、音声ダイアルなどの民生用に使用されてきた。今後も携帯端末・ネットワーク端末、家電製品など広い用途が期待される。基本形は、単語を単独で発声した音声、ないしは簡単な構文をもつ単語連鎖からなる音声である。語彙は、個々の用途に依存するので、数十語〜数千語のシステムが存在する。しかし、ユーザインタフェースを向上させるには、さまざまな環境ノイズ、老人、子供など広範囲なユーザ、繋ぎ語や非音声的発話などに対処できる技術が要求され、必ずしも簡単ではない。多くの企業において製品開発が行われている。製品は、LSIチップ、ボード、PC搭載ソフトなどの形で多数発売されている。
大語彙ディクテーション、音声ワープロ、放送音声字幕化
音声の文書化技術であり、現在、数万語の語彙を持つシステムが製品化され、(IBM、NECなどから)発売されている。概ね単語(形態素)を単位としてスコアリングした認識率で、良質の発話音声について90%前後の性能を示す。ディクテーションは、いうまでもなく文書(たとえば日本語のテキスト)としての正確さが必要とされるので、音声を音声記号へ変換する技術とは異なる。米国のIBMやドラゴンシステムズで早くから研究開発が行われていたが、DARPAが1992年頃から経済紙ウォールストリートジャーナルを対象にディクテーションのプロジェクトを実施し、参加機関の競争を促し、技術開発が急速に進んだ[1]。ディクテーションシステムの開発には、大量のテキスト言語データを統計処理する必要があり、日本ではこの部分の整備が遅れたため研究開発の遅れに繋がった。日本でも、1997年度より大学・国立研究機関などが主体となり、2万語規模の語彙をもつディクテーションのプロジェクトがIPA(情報処理振興事業協会)の下で実施されている[2]。その成果は一般に公開されている。最近では、 放送音声を対象としたディクテーションのプロジェクトが米国[3]、日本などで実施されている。
音声要約・検索
用途としては期待されるが、現在のところ、研究レベルの段階である。キーワードスポッティング技術と自然言語処理との結合により、音声メディアで記録されているデータの要約や検索が可能になると期待される。必ずしも音声認識を伴わなくても、音声自体の縮約処理ができれば、ユーザがその縮約された音声をチェックすることで、要約・検索を効率的に行うことができ、こうした観点からの音声信号処理技術も提案されている。
音声対話システム
ごく単純には、コマンド入力システムも音声対話システムと見ることもできるが、これらは、入力音声が単語発声ないしは非常に制約のきつい文であり、発話は前後の文脈と独立、ないしは、システム内部がもつ木構造で表わされた選択肢を選ぶという形式で対話が制御されていて、対話性の低いものであった。1980年代終盤から始まった音声対話システムは、発話者にある程度の言い回しの自由度を認めていて、また、その言語的意味構造の抽出に重点をおいており、オートマトンなどで対話が制御されている。具体的に扱われているタスクには、地理案内、フライト情報サービス・予約、内線電話案内、国際会議支援などがある。これらのタスクに含まれる語彙規模は、数百〜3000語程度である。ユーザ(話者)がこれらの語彙を使用してできる会話は、文法的にも制限されているし、おおむね1文に相当する発話ごとにシステムが受け付けて、応答してくる。システムの多くは、音声入力に対して音声応答や文字、画像表示などで応答する。フライト情報サービスをタスクとする音声対話プロジェクト(ATIS:Air Travel Information Service)がDARPAの下で1990〜1995頃に実施された[1]。その後、MITなどではこれを発展させた実用に近いシステムを発表している。国内でも内線電話取り次ぎなどのタスクを扱う実用システムが発売されている。ただし、いずれも広範囲に利用されているとは言い難い。
自動通訳システム
日本では外国語によるコミュニケーションを苦手とする人が多いので、自動通訳システムへの期待は高いものがある。むろん、音声認識、自動翻訳、音声合成というどの1つをとっても困難な技術を結合したもので、しかも実時間処理が必要となるので、現状では研究開発段階である。タスクはかなり限定されたものである。国内では、ATRにおいて自動通訳(音声翻訳)のプロジェクトが1987年より開始され、国際会議参加・ホテル予約をタスクとしており、最近のシステムの語彙は約7000語程度である[4]。また、EUでもVerbmobilと呼ぶ多言語間音声翻訳プロジェクトが実施されている[5]。
3.2.3 応用面からみた技術展開の方向
今後の社会情勢を考えると、音声インタフェースが組込まれた情報機器の将来形態としては次のような方向が重要要素となろう。
パーソナル性
携帯性
グローバル性
公共性
弱者・老人・障害者支援
パーソナル化には個人あるいは家庭内で使用されるPC、あるいは家電、自動車、携帯端末などへ組込みが考えられ、機能としては個人へのカスタマイズ(個人への適応、音声による感情・感性情報処理、個人認証)や耐環境性能向上(ソフト的かつハード的頑健性)などが必要な技術となる。個人への適応技術では統計的な手法が有効性を発揮しているが、これはとりもなおさず、適応のために大量の学習データが必要ということであり、効率的な方式が望まれる。
携帯化は、いわゆるウェアラブルコンピュータの概念に通じるものであるが、音声インタフェースはこのような状況ではもっとも有力なマンマシンインタフェースとして期待される。現在、既に携帯電話器に音声認識機能が搭載されているように、ハード的には小型携帯化も可能である。ただし、ウェアラブルという概念を実現するにはマイクロホンやスピーカを含むハードウエアや音響的信号処理がかなり難しくなる。(電話器は音声入出力に関してはその形態からこの問題を回避できている。)
グローバル化の方向性には、インターネットの普及により多言語、他人種(方言)などへの対応、また、蓄積されているデータベースへの音声でアクセスにする検索や要約、逆に入力された音声の要約蓄積などが考えられる。多言語や方言への適応においても、現時点では、統計的な手法のため大量の生データの収集が必要である。この結果、(高性能な)システム構築は事実上、先進国において多数を占める民族の言語に限られている。
公共性には、駅構内や劇場での券売機、病院や公的施設における補助装置、その他にも各種の情報案内や予約システムなどが考えられる。基本的に、特定の人へのチューニングはできず、また高い耐環境性能がハード的にもソフト的にも要求される。たとえば、システムに不慣れな人々を想定して未知語や非音声、非文法的発話への対処が重要となるし、ハード的にも壊れにくい装置である必要がある。
老人・障害者支援という用途は必要性からくる要求度は高いが、これまでのディジタル補聴器や食道発声補助装置などの開発に関与した筆者の経験からすると、難しい問題を多く含んでいる。安定な動作、連続的な変化、違和感のない操作性が望まれるので、時間遅れや非連続性のあるディジタル処理はなじまない部分がある。しかし、現時点では、データの収集解析もほとんど進んでいないので、まずは実際のデータを収集するところから始めるべきであろう。
以上をまとめると、およそ重要な技術課題は、(ノイズ、話者、発声などに対する)ロバストなシステムの構築、多言語処理や環境変化に対して大量の適応用実サンプルを必要としない認識方式の開発、熟成されたヒューマンインタフェース、などであろう。もちろん、これらはプログラミング技術、ハードウエア性能、センサや無線通信など周辺技術の進歩にも大きく依存している。
3.2.4 技術開発を促進するには
技術開発を促進する最大の要因は一般的にはニーズの高まりであり、これによって資金、人などの資源が集中投入されることによる進歩が大きいであろう。ここでは、こうした一般論よりはむしろシーズ側からみた技術開発の促進について述べる。
(1)研究開発プロジェクト
米国などでも音声インタフェースは必ずしも世の中のメジャーになるような利用のされ方はしていない。しかし、いわゆるベンチャー的企業は相当数あり、またIBM、AT&T、TI、マイクロソフト、アップルコンピュータなどの企業も開発に積極的である。音声認識応用システムの普及や関連技術のレベルは日本に比べ数年先を行っている。これは、必ずしも基本技術レベルに大差があるというわけではなく、むしろ音声・言語データの整備とこれらに基づいて性能評価を行った(つぶしの効いた)ソフトウエア蓄積の違いによるところが大きい。そしてこのような状況が生まれる原動力の1つが3.2.2節でも挙げたDARPA(Defense, Advanced 
Research Projects Agency)の下で行われた音声言語プロジェクト(1987〜1994)であった。国の予算で先導されるプロジェクトが全体的な技術レベルの向上に貢献した例といえよう。
このプロジェクトにはAT&T、TI、SRI、BBN、MIT、CMU、NISTなど産学官が参加し、共通データベースの構築、性能評価法の確立、ソフトウエア流通などのベースを固めつつ、毎年ワークショップを開催し相互が競争的に性能比較を行った。(ワークショップには、IBMなども参加している。)このプロジェクトが採用した方式は、ロジスティックスを重視する米国的な戦略の特徴をしめすもので、大量の音声・言語データベースとそれらのハンドリングが重要な役割を果たす音声認識システム研究開発にとっては強力なものであった。(もちろんこの方式にも批判はあり、評価は一長一短である。また音声情報処理研究の一部を扱っているに過ぎないともいえる。)ほぼ同時期にEU(/EC)においてもESPRIT 
(I,II,III)プロジェクトの中で音声言語処理プロジェクトが実施された。
日本では1987年からのATRプロジェクトなどがあるが、多数の企業、大学、研究機関などが共同の研究体制をとることはなかった。したがって、共通のデータベースの整備、評価法の確立などが遅れ、研究開発の共通基盤が弱かった。電子協、JIPDEC、音響学会、情報処理学会などの下を利用したボランティア的活動はあったが、予算措置は殆ど無かった。このため新規手法の提案はあっても、その評価が定まらず、汎用ツールに発展するというような蓄積に欠けた。最近になって、こうした遅れを取り戻そうとするディクテーション関連のプロジェクトがIPAの下で実施されている[3]。ここでは、開発したソフトウエアを公開するという立場であり、国内の音声認識技術レベルの全体的な向上を目指している。音声処理は言語依存の部分がかなり大きいので、その面では日本語音声を扱っているこのプロジェクトでも研究開発要素やノウハウの蓄積は大きいが、基本的指針は上記のDARPAプロジェクトの後塵を拝している。
国の予算などを使用するプロジェクトを進めるに当たっては、開発ソフトウエアやデータベース、ノウハウをオープンにし、参加機関はもちろん、外部機関もこれを使用できるような体制をとることが望ましい。特にソフトウエアについてはこの点が重要である。
(2) 研究基盤整備
繰り返しになるが、音声認識システムは、標準パターンや文法知識などを知識ベースとして組込んでいて、これらを処理するモジュールを幾つか組み合わせた構成になるので、単純なシステムとは言えない。高性能化を達成しようとすると、研究開発には相当な資源(資金・人)を必要とする。したがって、研究の基盤となるデータベースや知識ベース、ソフトウエアツールが整備され、容易に入手可能であることが、多くの研究開発機関やベンチャー企業などが音声インタフェース研究に参入するための基本的要件である。
音声言語データベースを有料配布する機関として、米国にはLDC(Linguistic Data Consortium)という組織があり、またEUにはELRA(European 
Language Resources Association)がある。日本にもこうした組織を作ろうとする動きはあるものの現在のところは実体のあるところまでは行っていない。また、新聞や放送関係が所有する著作物・音声データ等に関して、公開利用することにきわめて防御的であり、問題を一層困難にしている。国内にも、ATRやRWCP(新情報処理開発機構)などが刊行したものや先に述べたようなボランティア活動的な作業に依存したデータベースはあるが[6]、誰でもが入手可能なデータベースが相対的に少ない。
上記の組織やアジア・豪州などのメンバーを中心に、データベースや性能評価法の標準化に関する国際的な研究会(COCOSDA)も組織されている。ただし、この活動は毎年国際会議に付随してワークショップが開催されているが、現在のところあまり実効性はない。標準化の問題は、むしろマイクロソフト社のSAPI(Speech Application Interface)に代表されるデファクトスタンダードに対する日本(の企業など)の対応にある。日本側が日本語音声言語対応APIをどの程度主張できるかも今後の課題である。
3.2.5 あとがき
4年ほど前(1995年)に、音声研究者の間でなぜ音声認識応用システムが一般に普及しないのかという議論をメーリングリストならびに研究会で行ったことがある[7]。このときの議論で多くを占めた意見を列挙すると、認識性能が低い(技術的に)、発話がきつく制限されている、ロバストネスが不足、システムの透明性が低い、ヒューマンインタフェースが未熟、工夫が足りない、などであった。
当時と比べて、基本性能の向上、チップ性能の向上などによりカーナビ、携帯電話器などの民生用製品への装着も出てきた。また、PC搭載ソフトも認識誤りがさして重要でない用途への応用に使用され始めている。しかし、上記の問題は大幅に改善されたわけではなく、応用装置自体も音声がメインのインタフェースとなっているいるわけではない。需要的にみれば、おそらくゲームなどいわゆるエンターテイメントシステムに用いられたりする部分も大きいかもしれない。しかし、3.2.2節では敢えてこうした応用には触れなかった。爆発的な需要は、予測できないところから生まれることも多いので、本章ではある程度、論理的に予測できる話に絞った。
<参考文献>
[1] Proceedings Speech and Natural Language Workshop, Morgan Kaufman Publishers(1989〜 93).および Human Language Technology, Morgan Kaufman Publishers(93, 94).
[2] 河原達也他:「日本語ディクテーション基本ソフトウエア(97年度版)」、日本音響学会誌55巻3号、pp.175-180(1999-3).
[3] Proc. DARPA broadcast news transcription and understanding workshop, 
http://www.nist.gov/speech/proc/darpa98/index
[4] Y. Yamazaki, Toward cross-language global communications-challenging research 
for spontaneous speech translation, Proceedings of Telecom 95 Forum, pp.3-7 (1995).
[5] T. Bub, W. Wahlster, A. Waibel, Verbmobil: The combination of deep and shallow 
processing for spontaneous speech translation, Proc. ICASSP97, pp.71-74 (Apr. 1997).
[6] 人文学と情報処理 No.12 「音声データベース」、勉誠社 (1996-12)。
[7] 嵯峨山茂樹:「音声認識技術実用への課題」、情報処理36巻11号、pp.27-33(1995-11).
技術動向、製品化動向など:
B1)「音声の知的処理に関する調査研究」、日本情報処理開発協会刊(92年3月、93年3月)。
B2)「OA機器の標準化に関する調査研究報告」、日本電子工業振興協会(92年〜98年)。
学会、研究会等の論文誌、学術誌など:
日本音響学会誌。電子情報通信学会論文誌 A、DII分冊
IEEE Trans. Speech and Audio Processing, および Signal Processing Magazine.
電子情報通信学会音声研究会および情報処理学会音声言語情報処理研究会など。
Proceedings of 
ICASSP(毎年)、Proceedings of 
ICSLP- 90, 92, 94, 96, 98. 
Proceedings of EUROSPEECH- 89, 91, 93, 95, 97
【次へ】
音声対話システム研究開発の現状と将来
