  
　ところが、前掲の特許文献１に記載の技術は、前記のとおり、不正解の音素と正解の音素との対を２値分類することで音素と調音的属性を推測するものであることから、音素と調音的属性の認識は設定した音素対に依存した任意の属性に関するものに限定されていた。また、上記技術における音素認識手法が２値分類であることから、音素認識の精度に問題があり、その認識結果に基づいて抽出される調音的属性に良い影響を与えるものではなかった。さらに、この技術は、抽出した音素および調音的属性から動画アニメーションを生成するものではなかった。
　他方、前掲の非特許文献１に記載の研究は、前記のとおり、調音器官ごとにアニメーション表現し、これを合成することによるものであることから、学習者が単語を入力すると、その単語に含まれる音素系列が単語辞書により抽出され、当該単語に対する正しい発音動作のＣＧアニメーションが自動的に生成されるものであった。従って、音声から調音運動を直接抽出し、その発音動作を可視化するものではなかった。また、学習者の音声からアニメーションを生成することがなく、調音器官の誤りや矯正方法を指導する機能を有するものではなかった。
　なお、発音診断用のソフトウエアも存在しているが（非特許文献２および３参照）、これらは、学習者の音声を単語単位または注目音素のみに対して誤りを提示するものであり、誤りの内容や、矯正方法については、テキストや静止画によって指示しているものであって、学習者は発音器官の動きや具体的な矯正方法を理解することは困難であった。
　さらには、本願の出願人は、音声合成に関する技術（特許文献２参照）を開発したが、この音声合成技術は、入力音声から直接抽出した調音特徴系列データを声道パラメータ系列に変換し、音声合成する技術であることから、学習者が発した音声から検出される調音特徴の相違、すなわち、調音様式（母音、子音、破裂、摩擦など）や調音位置（前舌、半狭、半広など）の諸属性の相違を合成された音声により把握できるものであって、これらの相違点を視覚により認識することができるものではなかった。そこで、上記技術を発展させることによって、すなわち調音特徴系列を利用して、調音器官の動作を可視化することができる技術が切望されていた。
　本発明は、上記諸点にかんがみてなされたものであって、その目的とするところは、学習者の発音誤りを矯正することを容易にするため、学習者の音声から発音動作を可視化することができる装置を提供することであり、また、当該可視化装置を使用した学習装置を提供することである。
　そこで、発音動作可視化装置にかかる本発明は、入力音声を取得する音声取得手段と、前記音声取得手段により取得した音声データを声道パラメータ系列に変換する声道パラメータ変換手段と、前記声道パラメータ系列を調音器官の輪郭を示す座標ベクトル系列に変換する座標ベクトル系列変換手段と、前記座標ベクトル系列から調音器官の動作の画像を生成する画像生成手段と、前記画像生成手段により生成された画像を表示する画像表示手段とを含むことを特徴とするものである。
　ここで、座標ベクトルとは、口腔形状（舌、口蓋、口唇、下顎など）の初期状態に付与した特徴点の位置から所定時間ごとの移動量を計算したものである。
　上記構成によれば、取得された入力音声から調音器官の座標ベクトルを得ることができ、上記座標ベクトルに従って調音器官の動作を画像化することにより学習者の発音器官の動作を再現させることが可能となる。なお、現実の発音器官の動作状況には個人差がある（つまり口腔および各器官の大きさが異なる）が、座標ベクトルを使用することにより、画像化された口腔形状の動作に変換することが容易となるのである。
　また、本発明は、上記構成において、さらに、前記音声取得手段により取得した音声から調音特徴系列を抽出する調音特徴抽出手段と、予め複数話者の音声について、前記調音特徴抽出手段により抽出した調音特徴系列から計算した調音運動の状態遷移モデルを記憶する調音運動記憶手段と、前記調音特徴抽出手段により抽出された入力音声に関する調音特徴系列と前記状態遷移モデルとを比較しつつ調音特徴系列を生成する調音特徴系列生成手段とを備え、前記声道パラメータ変換手段は、前記調音特徴系列を声道パラメータ系列に変換するものであることを特徴とするものである。
　上記構成によれば、声道パラメータは、話者による音声から取得される調音特徴系列に基づいて生成されることとなり、話者が発音した音声の調音様式（母音、子音、破裂、摩擦など）および調音位置（前舌、半狭、半広など）の諸属性を検出することができる。
　また、本発明は、上記両発明において、さらに、前記声道パラメータに基づき音声を合成する音声合成手段を備え、前記画像表示手段は、生成された画像を表示するとともに前記音声合成手段により合成された音声を出力するものであることを特徴とするものである。
　上記構成によれば、取得された入力音声がどのように聞こえるかを学習者が確認することができる。従って、学習者が発した音声を聞くことができ、調音器官の動作とともに発音を聞くことによって、調音器官をどのように作動させることにより発音が変化するかを、学習者自らが聞いて把握することができる。
　また、上記各発明において、前記座標ベクトル系列変換手段は、予め複数話者の音声から抽出した声道パラメータを入力データとし、かつ、同時に発話状態の透視画像から前記声道パラメータに対応する透視画像中の調音器官の輪郭を示す座標ベクトル系列を教師データとするものであることを特徴とするものである。
　ここで、透視画像とは、調音器官の動作をあらわすことができる口腔内部の画像であって、代表的には、声道部分を透視した状態で表現し得る画像を意味する。このような画像としては、例えば、磁気共鳴画像装置（Ｍａｇｎｅｔｉｃ　Ｒｅｓｏｎａｎｃｅ　Ｉｍａｇｉｎｇ　ｓｙｓｔｅｍ：ＭＲＩ）を使用したＭＲＩ画像、コンピュータ断層撮影（Ｃｏｍｐｕｔｅｄ　Ｔｏｍｏｇｒａｐｈｙ：ＣＴ）による画像、または、Ｘ線撮影による画像を使用することができるが、これらに限定されるものではない。
　上記構成によれば、人間が発話したときの口腔形状の状態を表示する透視画像に基づき、座標ベクトルを算出することから、調音器官の詳細な動作を分析することができ、また、透視画像から変形したＣＧアニメーション上で座標ベクトルに基づき、調音器官の動作状態を再現することにより、実際の人間に発音動作に近い画像を生成することができる。このとき、声道パラメータと座標ベクトルをリンクすることにより、各発音時における調音器官の状態を一致させることができる。
　さらに、上記各発明において、前記画像生成手段は、座標ベクトルの時系列を非線形に平滑化する手段と、調音器官の輪郭を示す座標値を曲線補完する手段とを備えていることを特徴とするものである。
　上記構成により、所定時間ごとに口腔形状（舌、口蓋、口唇、下顎など）の特徴点の位置の移動量を平均化するとともに、各特徴点の移動状態を滑らかにすることができる。
　また、上記各発明において、前記画像生成手段は、調音器官のうち音源部位を特徴ある状態の画像を生成するものであることを特徴とするものである。
　ここで、特徴ある状態とは、当該部分を明確に視認できる状態とすることを意味するものであって、例えば、当該部分のみを着色し、もしくは、他の色彩と異なる色彩を使用し、または、部分的に明るさを変化させる（ハイライト表示）などにより、画像が表示されるとき、その画像中の一部を際立たせるようにするものである。さらに、これらに限定されることなく、当該部分を囲むように図形を表示させる方法でもよい。
　上記構成によれば、生成されて表示される口腔形状のうち、特に重要な音源部位を強調させることができ、学習者による確認のポイントを明確に表示できることとなる。
　発音学習装置にかかる本発明は、上記各発音動作可視化装置を使用するものであって、理想とすべき発音動作における座標ベクトル系列から目標画像を生成する目標画像生成手段を備え、前記画像生成手段により生成された学習者画像とともに画像表示手段に表示してなることを特徴とするものである。
　上記構成によれば、目標画像生成手段は、学習者が学習しようとする単語やフレーズについて、本来あるべき理想の発音動作と、学習者が発音した音声により生成された学習者画像とを比較することができる。これにより、調音器官の動作の相違を明確に把握することができることから、誤りのある発音を矯正する方法の提示を受けることができる。
　また、上記発明において、前記画像生成手段は、前記学習者画像のうち、前記目標画像との間で調音器官の異なる部位を特徴ある状態で生成するものであることを特徴とするものである。
　上記構成により、調音器官の動作のうち、学習者画像が目標画像と異なる部位を強調することができ、学習者が自ら発見できない調音器官の相違部分や、僅かに異なる相違点を学習者に知らせることができる。
　さらに、上記各発明において、前記画像表示手段は、再生速度を可変としたものであることを特徴とするものである。
　上記構成によれば、画像表示手段の再生速度を遅くする場合には、高速で動く調音器官の動作の状態を確認することができ、また、同じ単語やフレーズをゆっくり発音した後、再生速度を速くすることにより、例えばナチュラルスピードによる調音器官の動作を確認することも可能となる。
　発音動作可視化装置にかかる本発明によれば、話者の調音運動を調音特徴として直接抽出しているため、音素認識結果に依存せずに音素ごとに正確な調音特徴を取得することができる。そして、話者に依存する音響的特徴量ではなく話者不変の調音特徴を用いることから頑健な音素認識を実現することができる。これにより、話者の調音特徴を口腔形状の座標ベクトルに変換することが可能になり、話者の発音状態を画像により確認することが可能となる。
　また、複数話者による発音から入手した声道パラメータと、透視画像における座標ベクトルとを使用することから、学習者の入力音声を声道パラメータに変換したとき、同じ声道パラメータによる座標ベクトルによって画像生成することができる。これにより、学習者の音声特性に依存することなく調音器官の動作を視覚的に把握することができる。
　さらに、入力音声を声道パラメータに基づき合成し、これを画像表示とともに出力する場合には、話者の音声を耳で確認するとともに、調音器官の状態を目で確認することができることから、発音の誤りを視覚および聴覚の双方で把握することができる。そして、同じ語について発音を繰り返すことにより、調音器官を変化させた際の音声の変化を知ることも可能となる。
　他方、発音学習装置にかかる本発明によれば、目標画像と学習者画像とを比較することができることから、学習者の発音の誤りが、どの調音器官の動きによるものであるかを把握することができる。このとき、画像生成手段が音声合成された音声を出力する機能を有する場合には、発音の誤りの程度の大小を聴覚的に把握することができる。
　また、目標画像と学習者画像とが異なる部位を特徴ある状態で表示する場合には、調音器官の微妙な相違についても把握でき、発音学習における矯正の方法を知ることができる。
発音動作可視化装置の電気的構成を示す模式図である。 発音動作可視化装置の構成例を示す説明図である。 ＭＲＩ画像と座標ベクトルの関係を示す説明図である。 調音抽出手段のブロック図である。 声道パラメータから画像を生成する手段のブロック図である。 アニメーション画像とＭＲＩ画像との特徴点の相関係数結果を示すグラフである。 アニメーション画像とＭＲＩ画像との特徴点の相関係数結果を示すグラフである。 アンカーポイントを設定した場合のアニメーション画像とＭＲＩ画像との特徴点の相関係数結果を示すグラフである。 
　以下、本発明の実施の形態を図面に基づいて説明する。図１は、発音可視化装置にかかる本発明の電気的構成を示す図である。この図に示すように、本実施形態は、サーバと端末機とを通信回線で接続可能とするものである。サーバは、中央演算処理装置１１、記憶装置１２、外部記憶装置１３および通信インターフェース１４を備えており、これらがバス１０を介して電気的に接続されている。また、端末機は、通信インターフェース１５、入力装置１６および出力装置１７のほかに、記憶装置１８および操作部１９を備えており、これらがバス２０を介して電気的に接続されている。従って、端末機の入力装置１６から入力されたデータは、端末機側の通信インターフェース１５、通信回線およびサーバ側の通信インターフェース１４を介してサーバ側に送信され、サーバ内において処理され、再び端末機に送信されて、当該端末機の出力部から出力できるようになっている。端末機におけるデータの送受信は操作部１９により行うことができるようになっている。
　ここで、中央演算処理装置１１は、数値演算・制御などの処理を行うために設けられており、本実施の形態において説明する処理手順に従って演算・処理を行う。例えばプロセッサー等が使用可能である。入力装置１６は、マイクロホンやキーボード等で構成され、利用者が発声した音声やキー入力された文字列が入力される。出力装置１７は、ディスプレーやスピーカ等で構成され、画像生成された調音器官の動作画像の情報、あるいは音声合成結果を処理することによって得られた情報が出力される。サーバ側の記憶装置１２は、中央演算処理装置１１によって実行される処理手順（音声認識プログラム）や、その処理に必要な一時データが格納され、端末機側の記憶装置１８は、送信された画像データや音声データを一時的に格納される。これらの記憶装置には、例えば、ＲＯＭ（リード・オンリー・メモリ）やＲＡＭ（ランダム・アクセス・メモリ）装置が使用可能である。
　また、外部記憶装置１３は、音声認識・音声合成処理に使用される各種情報を記憶するために設けられている。例えば、ハードディスクドライブ（ＨＤＤ）が使用可能である。そして、これらは、互いにデータの送受信が可能なように、バス１０を介して電気的に接続されている。
　なお、本発明のハードウエア構成は、図１に示す構成に限定されるものではない。従って、必要に応じてサーバ側または端末機側に各種機能を備える構成としてもよく、全ての装置を一つにまとめた構成としてもよい。
　次に、発音動作可視化装置の詳細を説明する。図２は、本実施形態の構成例を示す図である。音声取得手段（マイクロホンなど）２１により取得した入力音声は、調音特徴抽出手段２２により調音特徴系列が抽出され、調音運動記憶手段２４に記憶される状態遷移モデルとの比較により識別された音声単位系列に基づき、調音特徴系列生成手段において調音特徴系列が生成される。
　ここで、調音運動記憶手段２４には、複数話者の音声を予め調音特徴抽出手段２２によって抽出した調音特徴系列から調音運動の状態遷移モデルが計算され、その結果が記憶されている。音声取得手段２１から入力される入力音声の調音特徴系列は、上記調音運動記憶手段２４に記憶されている状態遷移モデルとの比較により、音声単位系列の状態が識別されるのである。このようにして識別された音声単位系列は調音特徴系列生成手段２５によって調音特徴系列が生成され、さらに、声道パラメータ変換部（声道パラメータ変換手段）２６に出力されるのである。
　声道パラメータ変換手段２６では、調音特徴系列のデータが、声道パラメータ系列に変換される。声道パラメータへの変換は、記憶手段２７に記憶されている声道モデルに基づいて規則的に変換される。また、音声パラメータの系列ごとに、調音器官に重要な口腔形状（舌、口蓋、口唇、下顎など）の座標ベクトルが予め計算され記憶手段２８に記憶されており、この座標ベクトルを参照しつつ上記音声パラメータ系列は、座標ベクトル変換手段２９によって座標ベクトル系列に変換される。変換された座標ベクトル系列は、当該系列に従って画像化（アニメーション化）され、表示手段によって表示可能となる。
　なお、図２は、同時に音声合成を可能にするものであり、声道パラメータ変換手段２６により声道パラメータ系列に変換されたデータは、音源パラメータとともに音声合成部（音声合成手段）３０に送られ、音声合成された音声を出力手段（スピーカなど）３１から出力することができるものである。
　また、声道パラメータ変換手段２６に入力すべき音声データは、調音特徴抽出手段２２などを経由せず、音声取得手段２１によって取得された音声データとしてもよく、調音特徴系列が生成されていない音声データを声道パラメータ変換手段２６によって声道パラメータに変換することも可能である。
　次に、座標ベクトルについて説明する。座標ベクトルは、透視画像を用いて算出されるが、ここでは、ＭＲＩ画像を用いて算出する場合について説明する。図３は、ＭＲＩ画像をモデル化した口腔形状（右図）と座標ベクトル（左図）の関係を示す図である。座標ベクトルとは、ＭＲＩ画像の口腔形状（舌、口蓋、口唇、下顎など）の初期状態に付与した特徴点の位置から所定時間ごとに移動量を計算したものである。その際には、例えば、ＭＲＩ画像をデジタル画像に変換するが、このとき、ＭＲＩ画像は所定のサイズ（２５６#65298;５６ピクセル）を使用する。また、画像変化（特徴点の移動量）を計算するための所定時間は、０．０１秒（１０ｍｓ）を１フレームとして画像を取り込む。そして、取り込んだ各画像において、特徴点の座標データを取得し、各画像間における各特徴点の移動量を計算するのである。
　ここで、特徴点としては、変化量の大きい部位を中心として選定するものであり、図３中の右図に示されているように舌、口蓋、上唇、下唇について、それぞれ複数箇所を特徴点とすることができる。ここでは、舌の表面について５点（図中第１～第５の点）、上唇について１点（図中第６の点）、口蓋（軟口蓋）の鼻腔側について１点（図中第７の点）、および、下唇について１点（図中第８の点）の合計８点を特徴点としている。このような特徴点の選定は、調音方法や調音位置の違いを全般的に表現するうえで重要である。そこで、上記８点の特徴点は、かつ、変形の激しい舌を中心に、破裂音の調音方法や口の高低による調音位置に大きく関与する上唇および下唇、ならびに、鼻音を発する際に大きく変化する軟口蓋をそれぞれ選定した。なお、口蓋には、硬口蓋と軟口蓋があり、硬口蓋は口腔の入り口側に、軟口蓋が口腔の奥側に位置し、また、硬口蓋は発音時においてもほとんど変化しないが、軟口蓋は鼻音を発する際に変化する。
　なお、上記特徴点の選定は、当然に上記８点に限定されるものではない。すなわち、多数の位置を特徴点とすることができ、特徴点が多ければそれだけ調音器官の動作を詳細に分析することができる。この場合、特徴点の位置や数は、分析すべき各国言語の特徴に応じて異ならせてもよい。
　このような特徴点の移動量を計算する際には、座標の原点を任意に設定し、Ｘ方向（Ｘ座標）とＹ方向（Ｙ座標）のそれぞれについて計算することとなる。この場合、図３中の左図に示されているように、調音器官の部位から離れた位置を原点とすることができ、図中横方向をＸ座標とし、図中縦方向をＹ座標として計算することができる。ただし、前述のように、硬口蓋は発音時にほとんど変化しないことから、硬口蓋の位置を基準に各特徴点の移動量を計算することもできる。その際、各特徴点のみの移動量を把握するため、例えば、舌の移動量については、口蓋の移動量と舌の移動量との差によって舌のみの移動量を計算することができる。また、各特徴点の移動方向が一方向のみに著しい場合、例えば、舌の動きは、Ｘ方向に比較してＹ方向の移動が僅少である場合のように、調音方法に関与しない移動量を無視して座標データを求めてもよい。
　また、調音器官の動作を明確化するために、上記特徴点の選定に付加して、アンカーポイントを設定してもよい。アンカーポイントとは、調音に際して変化する調音器官の重要な部位を意味し、調音器官の部位が特定の状態で定まる特定音素について、その音素を発音する際の調音器官の部位の座標を固定（アンカー）させるために設定するのである。例えば、「ｐ、ｂ、ｍ」を発音する場合には、唇を閉じるように両唇（上唇および下唇）を密着させることから、当該音素について両唇をアンカーポイントと定めるのである。このようなアンカーポイントは、上記「ｂ、ｐ、ｍ」以外の音素を調音する場合においても設定され得る。すなわち、特定の音素を調音する場合、両唇のほかに舌と口蓋により声道中に狭めや閉鎖を生じさせる特徴があるものについて、調音器官の部位を選択することができるのである。そこで、声道を部分的に閉鎖するように調音部位が動作する音素についてアンカーポイントを設定することにより、声道の部分的閉鎖を伴う特徴のある特定の音素について、調音動作を明確にすることができる。そして、そのような種類の音素については、各国言語の特徴に応じて異なることとなるが、その概略は次の表に記載のとおりである。なお、アンカーポイントの設定は声道の部分的閉鎖を伴う音素に限定されるものではなく、各種言語における特徴ある音素について、アンカーポイントを設定してもよい。
　なお、設定されたアンカーポイントの座標値は、調音器官の部位が所定の状態となるように特定される。例えば、上記において例示した特定音素「ｐ、ｂ、ｍ」について、アンカーポイントを設定した場合には、上唇の特徴点の座標値に対し、下唇の特徴点の座標値を一致させることによって、両唇が閉鎖した状態の座標とすることができるのである。アンカーポイントにおける座標値の特定は、表１に例示した音素について、それぞれの調音部位について座標値を特定することとなる。
　また、上記Ｘ方向（Ｘ座標）とＹ方向（Ｙ座標）に加えてＺ方向（Ｚ座標）についても特徴点の移動量を計算することにより、三次元画像の生成を可能にすることとなる。このように、特徴点および座標の選定は生成すべき画像の種類等に応じて適宜増減させることができるものである。
　上記特徴点についてのフレームごとの座標データと、当該口腔形状における音声データとの整合は、ＭＲＩ画像とともに取得可能な音声データから調音特徴を得ることによって行われる。すなわち、ＭＲＩ画像とともに取得された音声データは、図４に示すように、分析処理された後に局所特徴が抽出され、多層ニューラルネットワークなどの識別器に通されて調音特徴が抽出されるものである。
　入力音声は、調音特徴が抽出される前の段階において分析処理されるものである。本実施形態の分析処理としては、１６ｋＨｚでサンプリングされた後、２５ｍｓのハミング窓で１０ｍｓごとに、５１２点の高速フーリエ変換（Ｆａｓｔ　Ｆｏｕｒｉｅｒ　Ｔｒａｎｓｆｏｒｍ：ＦＦＴ）処理を受ける。この結果はパワースペクトルの形で積分され、中心周波数をメル尺度間隔で設計した２４－ｃｈの帯域通過フィルタ（Ｂａｎｄ　Ｐａｓｓ　Ｆｉｌｔｅｒ：ＢＰＦ）出力にまとめられる。ここまでが分析処理である。
　続いて、パワースペクトル系列上の音響特徴抽出が行われる。パワースペクトル系列が構成する曲面は、多様体として見ると時間と周波数方向の局所的な微分要素で表現できる（微分多様体）。そこで、ＢＰＦ出力を時間方向および周波数方向について数点の微分成分に変換する（例えば、時間方向に３つの微分成分と、周波数方向の３つの微分成分に変換する）ことにより、局所的な要素によって特定（変換）することができる。そのため、時間軸と周波数軸上でそれぞれ数点（例えば３点）の線形回帰演算を行うのである。これらの演算結果によって、前記パワースペクトルが微分特徴としての局所特徴として抽出されるのである。なお、局所特徴は、音声スペクトル系列の時間微分と周波数微分から求めたベクトルであるが、これらの局所特徴のデータが膨大であるため離散余弦変換処理によって圧縮することができる。
　調音特徴は、単音分類に用いられる調音様式（母音、子音、破裂、摩擦など）と、調音位置（前舌、半狭、半広など）の諸属性を指す。調音特徴では、あらゆる音素が調音特徴の有無（＋／－）を示すベクトルで表現される。調音特徴を音声認識で利用する際の利点は、調音的に近い音素同士を距離の近いベクトルとして表現できることである。そこで、本実施形態では、各調音器官の位置や動作方法の特徴量である調音特徴を各調音器官のベクトル座標にマッピングすることで発音動作を可視化するものである。すなわち調音特徴と調音器官の座標ベクトルとを関連づけることにより、調音特徴の系列に対応した座標ベクトルを選択することができるのである。また、調音特徴系列は、上述した声道パラメータ系列に変換され、この声道パラメータ系列に基づいて、座標ベクトル系列を生成することができるのである。
　なお、調音特徴は、局所特徴を識別器に通すことによって得られる。識別器としては、例えば、多層ニューラルネットワークを使用することができる。多層ニューラルネットワークは、高精度な調音特徴を抽出させるため２段構成とし、二つの多層ニューラルネットワークにより、識別器を構成することができる。なお、識別器としては、これに限定されるものではなく、ＳＶＭ（Ｓｕｐｐｏｒｔ　Ｖｅｃｔｏｒ　Ｍａｃｈｉｎｅ）等を使用することも可能である。
　ところで、話者の音声データ（入力音声）から発話動作の画像を生成するためには、音声パラメータ系列を入力とし、座標ベクトルを教師データとして、識別器により画像データを生成することとなる。図５は、その手法を示すブロック図である。
　この図に示すように、記憶手段４１には、透視画像（ＭＲＩ画像）から計算された座標ベクトルが調音特徴とともに記憶され、声道パラメータ系列が識別器（多層ニューラルネットワークなど）４２に出力される際、座標ベクトルが教師データとして処理される。識別器４２を通過したデータは、声道パラメータ系列に沿って座標ベクトル系列が生成され、この座標ベクトル系列に基づいて、調音器官（口腔形状の各特徴点）の移動量を再現するように画像を構築するのである。
　すなわち、フレームごとに抽出された座標データをもとに、フレームごとにｘ、ｙ座標の移動量を算出し、これを座標ベクトル（Δｘ，Δｙ）とする。識別器４２の学習データとして使う座標ベクトルは前記複数の特徴点におけるものである。なお、入力するフレームは、注目フレームと前後３点離れたフレーム（図中に示されているように、例えば、Ｘ座標については、Ｘ（ｔ－３）、Ｘ（ｔ）、Ｘ（ｔ＋３）の３つのフレーム）を用い、識別器として使用する多層ニューラルネットワーク４２は入力層８４次元、隠れ層１６８次元、出力層１０８次元とした。これにより、話者（学習者）が発話を行うことにより、その音声から変換された調音特徴を多層ニューラルネットワーク（識別器）４２に通すことで、調音特徴にマッピングした座標ベクトルを抽出し、画像生成が可能となるのである。
　上記のように、ＭＲＩ画像から座標ベクトルを計算する場合、数十枚の画像を同期加算することがあるため、調音器官の部位が明確とならないことがあり得る。このような場合には、調音のアンカーポイントを設定することによって、そのアンカーポイントに応じた座標値の修正を可能とするのである。アンカーポイントは、上述のように、特定音素について、明確に画像表示するために設定されるものであり、両唇や舌と口蓋などにより声道中に狭めや閉鎖を生じさせて発音する特徴がある音素の場合の調音器官の部位が選択されるものである。
　アンカーポイントに応じた座標値の修正は、アンカーポイントが設定されている音素について、特定の座標値となるように座標の修正値を多層ニューラルネットワーク（識別器）４２の教師データに含めることによる。追加される教師データは、アンカーポイントが設定された音素の音声データと修正値である。修正値としては、特定音素の場合の調音部位に対する所定の座標値であり、具体的には、例えば、「ｂ、ｐ、」の場合には下唇の座標値を上唇の座標値と同じとなるように、また、「ｔ、ｄ、ｚ」などの場合には舌の尖端を歯茎に接地させるような座標値となるように、当該座標値を教師データとして付与するのである。そして、修正するか否かは入力される音素ごとに決定されるものとする。具体的には、音声に対するラベリング情報（音素情報）を教師データに付加し、そのラベリング情報の音素に一致するアンカーポイントについて修正するのである。このように、修正値を教師データに付加することにより、多層ニューラルネットワーク（識別器）４２から出力される座標ベクトルは修正され、当該修正された座標ベクトルに基づく画像データが生成されることとなる。従って、表示される画像（アニメーション）は、アンカーポイントが設定された音素について明確になり、画像（アニメーション）全体の可視化精度が向上することとなるのである。
　なお、上記画像は、フレームごとの静止画として作製され、これを連続させることにより動画像とすることができる。この動画像の生成プログラムはＡｃｔｉｏｎＳｃｒｉｐｔ（登録商標）３．０に実装されており、Ｆｌａｓｈ　Ｐｌａｙｅｒ（登録商標）１０またはＦｌａｓｈ　Ｐｌａｙｅｒ（登録商標）プラグインが有効なブラウザで動作させることができる。
　また、口蓋、上唇、下顎の動きを各フレームの座標ベクトルで平均することで滑らかにすることができる。その方法としては、例えば、いわゆる移動平均法がある。また、曲線補完により画像の動きを滑らかにすることができる。その方法としては、例えば、いわゆるスプライン曲線補完法がある。
　以上のとおり、発音動作可視化装置にかかる上記実施形態によれば、予め調音特徴にマッピングした座標ベクトルを抽出することにより、話者（学習者）の音声データに従った調音器官の動作を画像により表示させることができる。
　従って、上記発音動作可視化装置を使用することにより、話者（学習者）の発音方法に誤りがあるか否かを視覚によって確認することができる。特に、話者（学習者）の調音器官の画像とともに、目標画像（理想とすべき発音状態の画像）とを比較することによって、その調音器官の動作の誤りを発見することができ、発音の誤りを矯正するための指針を得ることができる。このように学習者画像と目標画像とを同時に表示させることにより発音学習装置として機能することとなるのである。このとき、調音特徴が抽出された調音特徴系列を声道パラメータに変更する形態の場合には、この声道パラメータに音源パラメータを付与して合成した音声を出力すれば、学習者自身が発音した音声を聴覚的に把握することも可能となる。なお、目標画像は、話者（学習者）が学習しようとする単語またはフレーズ等についての発音動作を、上述の座標ベクトル系列から生成したものである。画像を動画像として表示する際の速度は、話者（学習者）の発音速度に合わせることにより音素ごとの発音動作を確認することができる。
　ここで、上記両画像が生成された時点で、画像を比較し、相違点をプロットすることにより、両画像の相違点を把握することができる。このとき、プロットされた相違点については、画像表示の際に強調して表示させることにより、学習者が相違点を明確に把握することが可能となる。また、これと同時にまたはこれとは別に、調音器官のうちの音源部位を強調することにより、どの部位に注意しながら発音矯正を行えばよいかを把握することも可能となる。なお、上記のような映像上の強調方法は、ハイライト表示によることのほか、色彩を明確に変化させることによって、学習者に知らせることができる。このような強調方法は、これらに限定されることはなく、表示部位の特徴点部分を四角形などの図形で囲む映像を生成させてもよい。
　さらには、表示される際の再生速度を可変とすることにより、学習者が再現したい速度での発音画像を確認することができ、特に矯正困難な音の発音において、再生速度を遅くして確認するような使用方法も可能となる。
　前記実施形態に基づきアニメーション化した動画像を作製し、その調音器官の輪郭の特徴点と、現実の発音動作にかかるＭＲＩ画像中の調音器官の輪郭の特徴点とを比較した。上記の特徴点は、それぞれ前述した特徴点選定例の場合と同様に、舌に５点、上唇に１点、口蓋（軟口蓋）の鼻腔側に１点、および、下唇に１点の合計８点とした。作製したアニメーション動画像は、音声取得手段により取得された音声データを、（調音特徴系列を生成することなく）声道パラメータに変換し、この音声パラメータを入力とし、座標ベクトルを教師データとして、多層ニューラルネットワークにより画像データを生成したものである。画像生成のフレームは１０ｍｓ間隔とした。ＭＲＩ画像中の特徴点は、英語を母国語とする女性話者により、４７個の英単語を発話する状況を撮影したものを使用した。
　上記の条件下で「ｂａｔ」を発音する場合の両画像についての各調音器官の輪郭の特徴点を比較した。その結果を図６に示す。この図から明らかなとおり、１１０フレームから「ｂ」の発音が開始されるが、この１２０フレームから高い相関が見られる。現実のＭＲＩ画像の声道断面積と、アニメーション画像の声道断面積が極めて高い相関関係を有していることが判明した。
　また、上記と同様の条件下において、音素ごとの各調音器官の輪郭の特徴点を比較した。その結果を図７に示す。この図から明らかなとおり、全体的に高い相関関係を示している。音素の種類によっては相関係数の多少の高低はあるものの、極端に低い相関を示すものはなく、各音素について発音する際の調音器官をアニメーション画像としたとしても、全体的には現実の画像に類似したものとなり得ることが判明した。
　さらに、アンカーポイントを設定し、特徴的な特定音素について座標値を修正した場合の音素ごとの各調音器官の輪郭の特徴点を比較した。その結果を図８に示す。なお、図８（ａ）は英語を母国語とする話者における相関係数のグラフであり、図８（ｂ）は日本語を母国語とする話者における相関係数のグラフである。また、両図ともアンカーポイントを設定しない場合の特徴点の相関係数を対比のため並べて表示している。この図から明らかなとおり、アンカーポイントを設定した場合の相関係数は、設定しない場合に比べて高い相関を示している。特に、アンカーポイントが設定された特定音素の相関が特に高いことから、可視化精度が向上していることがわかる。さらには、アンカーポイントを設定していない他の音素についても、少なからず相関係数が高くなっており、特定音素における特徴点の相関の向上に伴い全体的な相関係数が上昇していることを示している。従って、全体的な可視化精度を向上させる結果となった。
１　発音動作可視化装置
１１　中央演算処理装置
１２　記憶装置
１３　外部記憶装置
１４，１５　通信インターフェース
１６　入力装置
１７　出力装置
１８　記憶装置
１９　操作部
２１　音声取得手段
２２　調音特徴抽出手段
２４　調音運動記憶手段
２５　調音特徴系列生成手段
２６　声道パラメータ変換手段
２７　声道モデル記憶部
２８　座標ベクトル記憶部
２９　座標ベクトル変換手段
３０　音声合成部
３１　音声出力手段
４２　識別器（多層ニューラルネットワーク）
Patent WO2013031677A1 - 発音動作可視化装置および発音学習装置 - Google Patents
