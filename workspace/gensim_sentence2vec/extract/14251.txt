予測のためには、実世界をモデル化しなければなり ません。モデル化することさえできれば、あとはそのモデルに数値を突っ込むだけで勝手に予測が出来てしまいます。
前回(単回帰)は説明変数が一つだけでした。要するに、一つの値からまた別の値を予測すると言うだけだったので、どのモデルにすればいいのか、どの変数を使って予測すればいいのか、ということを考えなくても済んだ訳です。
しかし、実際に予測をする場合は多くの変数を用いたほうが当てはまりもよくなるし、実用的でしょう。
どの変数を用いて、どの変数を使わないのか、それを決めるための色々な方法(検定とAIC)とRによる計算方法を紹介します。
特に最後の方に紹介するパッケージMuMInはお 勧めです。簡単にモデル選択ができます。
目次
1.なぜモデル選択をするか
2.検定によるモデル選択
3.検定の方法
4.AICによるモデル選択
5.AICの使い方
6.AICの計算方法
7.AICでモデル選択してみる
8.AICの正しい使い方
9.正しそうなモデルを列挙した後は……
10.パッケージMuMInをもっと活用する
1.なぜモデル選択をするか
たとえば、魚の資源量を、「卵の数」と「水温」から予測したとします。これをモデルαとします。
このモデルαに、私の家で飼っている「猫の体重」という変数を加えて、合計3つの変数で魚の資源量を予測したとします。これをモデ ルβとします。
モデルαとモデルβ、どちらの方が「今手持ちのデータへの」当てはまりがよくなるのでしょうか。
答えはモデルβ。なんの関係もなさそうな猫の体重データを入れ込んだ方が、当てはまりはよくなるのです。
じゃあ、猫の体重も入れたほうがうまく魚の資源量を予測できるかと言うと、そうではない。当たり前ですね。うちの猫がダイエットし始めたら資源量が激減するな んてことが本当にあったら、大変です。
ようするに、やみくもに予測のための説明変数を増やしたところで、予測の精度はよくなるどころか下がっていってしまう訳です。
なるべく少ない変数で、本当に必要な変数だけで、予測した方がいい。
その「本当に必要な変数」を探すためにモデル選択と言うのがあるわけです。
モデル選択は、よりよい予測モデルを作るためには必須の行為と言えます。
また、目的としている変数が、どんな変数から影響を受けているのか、と言うことが分かります。
例えば。ビールの売り上げは、安売り券を配った時には増えるが、ただのチラシを配った時には増えない、なんてこともモデル選択では分かるようになりま す。意思決定の際にも役立ちそうです。
予測における縁の下の力持ち的な存在であるモデル選択の方法論を、以下で簡単に示します。
2.検定によるモデル選択
検定とは、単純に言うと「マグレかマグレで無いか」を確率を用いて判断する方法です。
具体的には「マグレだと仮定した際にこの現象が起こる可能性は5%未満である」ときに「これはマグ レではない」と判断します(別に5%でなくても1%でも何でもいいのですが、慣習として5%がよくつかわれます)。
こ れをモデル選択に応用すると、こうなります。
①ある変数が 入っているモデル(A) と 入っていないモデル(B) とで当てはまりを比較する
②—1 当てはまりの差が「誤差の範囲内」であるならば、変数が少ない方のモデルBを採択
②—2 誤差の範囲内とはいえない(この差がマグレで生じたと仮定したら、この差は5%未満の確率でしか生じえない)のならば、変数 が多い方のモデルAを採択
と言う感じです。
検定を行えば、「あっても無駄」な変数をなくすことができます。
3.検定の方法
model1
model2
の 二つのモデルがあるとします。
model2 が複雑なモデル。model1 が単純なモデルだったとします。
ここで、
anova(model1,model2)
をすれば、二つのモデルの当てはまりが本当に異なっているのか(「まぐれで当てはまりがほんのちょっとよくなっただけ」ではないと証明できるか)が分かり ます。
マグレじゃない=本当にmodel2 の方が優れている のならば、model2 を採用。そうでなければ、単純なモデル=model1 の方がよいということになります。
また、複雑な方のモデルにおいて
summary(model2)
としてやると、変数が役に立っているかどうかが一発で分かります。
「変数が役に立っているように見えても、実はそれはマグレだ」という確率が全部求まります。詳しい実例については次のページで説明します。
複雑・単純というと、どうしても複雑なモデルの方がよさそうな気がしてしまいます。けれども、違うんですね。株価の予測モデルに猫の体重を入れて、むりやり複雑なモデルを作ったって無駄なわけです。こんな変数を入れたら、余計に当たらくなるのは明らかです。
複雑であればいいと言う訳ではない。
データとの当てはまりがよければそれでいいと言う訳ではない。
このこと、是非ご銘記ください。
4.AICによるモデル選択
検定以外にも変数選択をする方法があります。
それが「赤池情報量基準:AIC」
これは、予測をやる側としてはもってこいの指標です。と言うのも、「将来をできるだけよく予測できるモデルがもっともよいモデルだ」という判断基準におい てモデル選択ができるからです。
「実世界をよく表す真のモデルを見つけよう」とするのではなく、「よく予測できるモデルを作ろう」と考えたところがミソ。
というのも、観測データの数が限られている時は、無理に真のモデル(実世界をよく表したモデル)を選ぶよりも、もっと単純なモデルのほうが、より予測精 度が高まることが分かっているからです。
要するに、今持っているデータだけでどれだけ上手く予測できるか? と言うことを勘案しつつ、モデル選択をすることができるのです。
5.AICの使い方
AIC とは、ものすごく単純に言ってしまうと、もっともよいモデルとの距離を表しています。
良いモデルとより近いモデルの方を採用したいですよね。というわけで、AICは小さければ小さいほどよいということになります。
6.AICの計算方法
model1
model2
の 二つのモデルがあるとします。
model2 が複雑なモデル。model1 が単純なモデルだったとします。
AICの計算方法はとても単純
AIC(model1,model2)
と してやれば、各々のモデルのAICが計算できます。これを考えられる全てのモデルで計算してやって、もっともAICが小さなモデルを採用すればいいという ことになります。
7.AICでモデル選択してみる
いちいち全部のモデルでAIC(～～)って計算するのは面倒なので、それを勝手にやってくれるプログラムがあります。
よくつかわれるのが、余りお勧めはしませんが、次のプログラム。
step(model2)
複雑なモデルの方を step( ) の中に入れます。逆はだめです。
これだと、簡単にもっともAICが小さなモデルを選択してくれるのですが、その計算方法が結構怪しい。はっきり言って、あまりお勧めしません。いろんな本に載ってる関数ですが……。
お 勧めは、CRANからダ ウンロードできるパッケージMuMInです。
パッケージのダウンロードは簡単です。
まず、Rを起動させるときにアイコンを右クリックして「管理者として実行」してください。そのうえで以下のコードを実行します。
install.packages(“MuMIn”)
すると国の名前なんかがずらずら出てくると思います。Japan(tokyo)などJapanだけで3つくらいあるのですが、Japanならばどれでも構いません。それをダブルクリックしたらパッケージのインストールは完成します。
そしたら
library(MuMIn)
と してやって、読み込みます。これで準備完了。
dredge(model2,rank=”AIC”)
としてやれば、AICが小さいモデルから順番にずらずらと表示されます。これの一番上にあるモデルがもっともよいモデルと言うことになります。
これも、複雑なモデルを入れてやらないといけません。
この関数は、一覧が表示されるだけで、よいモデルを「ポン」と選んで持ってきてくれるわけではありません。
そこで、
all.model <- get.models(dredge(model2,rank=”AIC”))
best.model<-all.model[1]
これで、best.modelにAICが最も小さい=もっともよいモデルが格納されたことになります。
この best.model を用いて予測をすれば良い訳です。
ちなみに、all.model には全てのモデルのパターンが「モデルとして」全部入っています。それの一番目がもっともよいモデルなので、  all.model[1] がbest になったわけです。[1] とは一番目のみを引用すると言う意味です。
8.AICの正しい使い方
AICはとても便利な基準なのですが、「完璧」ではありません。
例えば、モデル1 と モデル2 で AICが0.001だけ違っていたとします。そんなときでもAIC最小モデルの方が絶対に良いのだと盲目的に信じるのは、普通に考えてダメでしょう。
統計解析っていうものは、その結果を盲目的に信じれば良いというものでは、多分ないと思います。やはり機械任せ数学任せではなく、人間が頭を使って吟味しないと正しい予測はできないのでしょう。
dredge(model2,rank=”AIC”)を計算してやると、もっともAICが小さいものから順番にずらずらと表示されます。 また、AICの差も表示されます。その差を見て「割と近そう」と思ったものを全部ピックアップして吟味するのがお勧めです。具体的にはAICの差が2未満であるモデルはすべて候補として残しておくのがセオリーです。
また、この関数は Akaike Weight という値も算出してくれます。これが大きいモデルの方が、より確からしいと言うことになります。この値を参考にして選ぶのも有りです。
9.正しそうなモデルを列挙した後は……
AICがどうとか、検定の結果がどうとか理屈をこねても、やはり予測結果がうまく実際と当てはまっていなければ意味がありません。
じっさいにモデルがうまく当てはまっているかどうかを見るためにも、一回予測をして見て、そして95%信頼区間なりを求めてそれが本 当に正しい信頼区間を表しているか確認する必要があります。
また、
plot(model)
としてやれば、そのモデルの特徴何かが一発で分かります。良いモデルかどうかの判断材料として重要です。
10.パッケージ MuMIn をもっと活用する
このパッケージには、もっと色々な関数が含まれています。
まずはAICcを計算する関数が入っています。
AICc(model1)
AICc(model2)
で 簡単に計算可能です。
AICc とは、サンプル数が小さい時などにAICにかかるバイアスを補正したものです。ただし、応答変数が正規分布していないと使えません。割と良くつかわれている指標で、水産分野でもちらほら散 見されます。
また、Akaike Weight を用いた Model Averaging も可能です。
これは、
AIC が一番小さいモデルだからと言って絶対正しいとは限らない
⇒だから、いくつかのモデルを重みづけして、全部ごっちゃにしたモデルにした方が、一つだけのモデルを「えいやっ」と定めるよりも良いのではないか?
という考えに基づいたものですが、これは本当に予測精度向上につながるかは微妙らしいです(文献[2])とはいえ、簡単に計算できて便利なので、載せてお きます。
avg.model<-model.avg(get.models(dredge(model2,rank=”AIC”), subset = delta < 4))
で計算できます。 subset=delta<4 というのは、 「AICが最も小さいモデルからAICの値が4までしか離れていない⇒あるていど正しそうなモデルだけで重みづけをして平均しなさい」と言う指示です。必須ではありません。
summary(avg.model)
を してやれば、各説明変数の持つ重みなんかも一発で見れます。
最後の方はちょっと怪しげな世界へ突入してしまいましたが、色々工夫してみたい人は、自己責任で試してみるのも面白いかもしれません。
参 考文献[1]
甘利俊一 : 赤池情報量基準 AIC 、第Ⅱ編 1 赤池情報量基準 AICーその思想と新展開
参 考文献[2]
生態学のデータ解析−FAQ モデル選択
http://hosho.ees.hokudai.ac.jp/~kubo/ce/FaqModelSelection.html#toc9
参 考文献[3]
山田作太郎・北田修一:生物統計学入門、第7章 回帰分析
参考文献[4]
Package manual in PDF
前のページへ ⇒ 単回帰分析
次のページへ ⇒ モデル選択_実践編
モデル選択_理論編 | 回帰分析 | Logics of Blue
