
Sorry, this page is only in Japanese.
これは、文部省重点領域研究「脳の高次情報処理」成果報告書を兼ねて出版された「脳と計算論」(外山敬介・杉江昇編、朝倉書店)に掲載した解説論文で、1997年までに得られた研究成果の一部をなるべく易しく述べたものです。無断で転載したり配布したりしないで下さい。
時系列パターンの学習・記憶の計算論
1. はじめに
脳の学習・記憶機構を神経回路モデルを用いて研究する際,二つのアプローチが考えられる.一つは,学習や記憶に関係する脳の部分,例えば海馬の神経回路をモデル化し,その情報処理能力を検討する方法である.不明な部分に関しては適当な仮定を行い,それにより目的の機能が達成されるならば,モデルはその機能を実現するための一つの十分条件を示すことになる.
もう一つは,計算論的なアプローチ,すなわち適当な前提の下で,ある機能の実現に必要な原理は何かを検討する方法である.そして,そのような原理に基づく最も簡明な神経回路モデルを構成する.ここで言う原理とは,神経回路網の基本構造,回路網の動作(ダイナミクス),情報表現(コーディング),学習アルゴリズムの4つを合わせたものを指す.最初の前提が現実の脳にも当てはまるならば,脳の神経回路も同様な原理に基づいているはずであり,モデルは目的の機能の必要条件を示すことになる.
脳の記憶機構を解明するためには,前者だけではなく後者のようなアプローチをとることが不可欠だと考えられる.しかし,これまでなされてきた脳の記憶機構に関する理論的研究のほとんどは,天下り的に与えられたモデルを扱っており,原理的な必然性や生理学的な妥当性に乏しいものであった.
記憶の計算論的研究が困難なのは,一つには記憶系に関する生理学的知見が基本的な部分で不足していたからである.もう一つの大きな原因は,従来の理論的研究の対象が学習アルゴリズムの面に偏っており,ダイナミクスに関する理解が不十分だったことにあると思われる.しかし,最近の実験と理論双方における研究の進展により,これらの困難さも解消されつつある.そこで,ここでは時系列パターンの学習と記憶の問題に対して計算論的アプローチを試みた結果について述べる.
脳内では,運動系列や一連のエピソード,メロディなどの情報は,あるニューロン群の興奮パターンの時系列によって表現されていると考えられる.これらの時系列パターンの一部は,脳のある領域に長期記憶として保持され,必要に応じて再生される.長期記憶が保持される領域は記憶の種類によって異なり,特に陳述記憶(認知性記憶)と手続き記憶(運動性記憶)とは,全く別の記憶システムに属するとされている.つまり,これらの記憶のメカニズムは異なっている.
しかしながら,神経回路網による時系列パターンの記憶という観点から見たとき,それぞれが全く別の原理に従っているとは考えにくい.その基礎には何らかの共通な原理があるものと思われる.しかし,そのような原理は不明であり,その有力な候補となり得るものも知られていない.そこで,従来のモデルの問題点を足がかりに,脳における時系列パターンの記憶原理を探ることにする.
2. 従来のモデルの問題
まず,情報表現について考えよう.簡単のため各神経素子が1(興奮状態)か0(静止状態)の2値を取るものとすれば,時系列を素子の活動パターンによって表現する方法として図1のようなものが考えられる.
(a)は,おばあさん細胞型の表現の例である.ある瞬間に興奮している素子が1つだけではノイズに弱すぎるので,興奮している期間に重なりを持たせているが,各素子は特定の系列の特定の部分のみをコードしているため分散表現とは言えない.このようなコーディングをすれば,時系列の記憶や想起は容易である.
しかしながら,この表現では記憶する系列の数と同じだけの素子群が必要であるから,非常に効率が悪い.また,ノイズに対する耐性も低く,それを高めようとすると記憶効率が更に低下する.それ以外にも,コードに時間以外の情報構造を持たせる(情報間の関係をパターン間の関係に反映させる)ことができないといった問題がある.
一方,(b)と(c)では,一つの素子は複数の異なる部分をコードしており,共に分散表現(集団コーディング)に属する.但し,(c)は素子の状態変化が同期している特別な場合であり,従来のモデルではほとんどこちらが採用されている.以下にその理由を簡単に述べる.
図2は従来の典型的な記憶モデルのダイナミクスを示したものである.横軸は回路網の取り得る状態(興奮パターン),縦軸はポテンシャルエネルギーを表す.各状態でのエネルギーを結ぶことにより,仮想的な地形が描ける.回路網の状態は,外部からの入力がなければ常にエネルギーが減少するように変化するから,エネルギー地形の谷底が安定状態(アトラクタ)に対応する.
記憶は目的のパターンをエネルギーの深い谷(図2のS0とS1)にすることによって行う.このとき一般に,エネルギーの地形は谷底に近いところほど急な傾斜を持ち,パターンが記憶されている地点では下向きにとがっている.そのため,記憶パターンはお互いにある程度離れていなければならず,その間にはエネルギーの高台が存在することになる.
従って,ある記憶パターンを想起してから,連続的な状態遷移によって別のパターンを想起することができない.パターン系列を想起するためには,回路網の状態が離れた地点に飛び移る必要がある.状態が飛び移るとは,多数の素子が同時に状態変化することであるから,このことは素子の動作に同期が必要なことを意味している.
このような理由で図1(c)のようなコーディングが多く用いられてきたのだが,これにはいくつかの問題点がある.まず,素子間の同期のために特別なメカニズムが必要である.また,同じパターンがある期間続くので,(b)に比べて時間の表現能力が劣る.更に,時間的な近さとパターンの近さとの対応関係が不自然である.例えば,S0とS1が同じ系列中の隣接する部分をコードしているとき,S0とS1の中間的なパターンはその中間部分をコードしていないし,そのようなパターンから系列を想起することもできない.
以上のように,図1の中では(b)のような表現が最も合理的だと考えられるが,それを用いた記憶原理は知られていなかった.拡張した逆伝播学習アルゴリズムなどを用いる方法も,極めて複雑な計算を要するにもかかわらず,実際にはうまくいかない場合がほとんどである(森田, 1995).なぜならば,問題の本質は図2のようなダイナミクスにあるのであって,それは学習アルゴリズムの改良では解決されないからである.
3. 原理的モデル
前節で述べたように,非同期的集団コーディングされた時系列パターンを記憶するためには,ダイナミクスの改良が必要である.逆にある改良したダイナミクスを用いれば,記憶は容易であることが明らかになっている.本節では,その原理をわかりやすく示すために,生理学的な妥当性にはあまりこだわらずに構成したモデルについて述べる.なお,このモデルの詳細についてはMorita (1996a)を参照されたい.
3.1 構造とダイナミクス
モデルの全体構造を図3に示す.時系列パターンS(t)がn個の素子からなる回路網N1に入力され,そこに記憶される.N1の素子間には相互結合があるため,N1は自身からの再帰的入力を受ける.また,学習時には回路網N2から送られた学習信号Rも入力される.
学習信号Rは,入力パターンSを回路網N1のどの状態にコードするかを指定するものであるが,ここでは最も単純にR=Sとする.この場合,N2は単なる中継器であり,N1からN2への信号も不要である.
このモデルの最大の特徴は,回路網N1を構成する各素子が,図4に示すような非単調入出力特性を持つことである.それ以外は,従来の連続型ダイナミクスと同じである.このような素子の非単調特性により,回路網の記憶容量が大幅に増加することなどが知られている(Morita, 1993)が,ここでそれ以上に重要な性質は,図2に示したダイナミクスの性質が変化し,仮想的なエネルギーの地形が記憶パターンの周辺でなだらかになることである(図5を参照).これは,強いアトラクタに近づくにつれて多数の素子が大きな入力を受け,それらの出力強度が非単調特性によって低下するからである.
3.2 コーディング
前述のように,このモデルでは非同期的な集団コーディングを用いる.すなわち,学習信号R(t)は時間と共に成分が少しずつ反転するようなn次元のパターンである.但し,ここでは簡単のため,コードの各成分が±1を等確率で取るものとする.また,R=Sを仮定したので,入力パターンS(t)もそのようなパターンでなければならない.
3.3 学習アルゴリズム
学習アルゴリズムは非常に単純であり,時系列パターンを連続的に入力しながら,学習信号Rと回路網N1の出力パターンXとの間のコバリアンス学習(具体的には,i番目の素子への入力シナプス荷重wijをその素子への学習信号riと他の素子からの入力信号xjの積に応じて修正する)を実行するだけである.
学習の過程を模式的に示したのが図5である.回路網の状態空間(実際にはn次元である)における仮想的なエネルギーの地形が3次元的に描かれている.図中の小球は回路網の現在状態X,矢印は現在の学習信号Rを表す.
まず最初,ある静止パターンが入力され,学習信号Rが変化せずに一定に保たれたと仮定しよう.そうすると,まもなくXはRと一致する.このとき,Xを中心とする領域におけるエネルギーは学習によって低下し,入力したパターンは安定な状態として記憶される(a).
この状態から入力パターンが変化し,Rが少し動いたとする.XはRに追従しようとするが,エネルギーの傾斜に逆らって動かなければならないので,すぐには追いつくことができない.その間,上記の学習則は,XとRの間のエネルギーを低下させるだけでなく,両者の食い違いのためXをRの方向に動かそうとする流れを作り出す(b).
同様に,入力パターンが変化し続けRが連続的に動くと,Xは常にRの少し後方を追従する.その結果,Xの軌跡に沿って溝が刻み込まれ(c,d),その底にはXの進行方向に沿った緩やかな流れができることになる.この「エネルギーの溝」は,ちょうど心理学で言うところの記憶痕跡に相当するものだと言える.
更に同じ時系列パターンを繰り返し学習することにより,エネルギーの溝がより深く明瞭なものとなると共に,Xの動きが次第に外部からの学習信号に依存しなくなる(この際,学習の進行につれて学習信号の入力強度を弱めると,学習がよりうまくいく).そして数回の学習の後には,外部からの信号なしに学習時と同じ軌道上を移動できるようになる.このことは,時系列パターンが回路網に記憶されたことを意味している.
学習が完了した後は,適当な初期状態を与えるだけで,刻み込まれたエネルギーの溝の中を回路網の状態Xが動いていき,記憶した時系列パターンが自動的に想起される.外乱を加えても回路網の状態が溝から飛び出さない限り想起は続くから,この過程は非常に安定である.
4. 現実的モデル
前節のモデルは,脳内でも実現可能と思われる単純な原理に基づいているが,脳のモデルとして見るといくつかの問題点がある.
第一に,現実のニューロンは一般に単調な入出力特性を持っており,図4のような特性は備えていない.その意味で,前節のダイナミクスは非現実的である.第二に,上記のモデルのコーディングでは記憶回路網の約半数の素子が興奮しているが,これも現実と合わない.脳における情報表現には不明な部分も多いが,最近の生理実験によれば,記憶系ではスパースコーディングが用いられているという考えが有力である.少なくとも興奮しているニューロンは興奮していないものよりずっと少数であることは間違いない.そのほか上記のモデルには,数学的表現の単純化のために,信号が正負両方の値を取るなどやや不自然な点がある.
これらの問題を解消し,モデルと実際の記憶系との比較検討を行いやすくするために,より現実的なモデルを構成した(Morita, 1996b).以下では,このモデルについて述べる.
4.1 構造とダイナミクス
モデル全体の構造は図3と同じであるが,回路網N1の内部は,図6に示すように2種類の細胞の対をユニットとして構成されている.この図で,Ci+は興奮性の出力細胞であり,その出力xiがユニットの出力となる.Ci-は抑制細胞で,その出力yiはCi+を強力に抑制する.ユニットの出力xiは,他のユニットの出力細胞および抑制細胞の両方に入力される.数式で示すと,
となる.ここで,wij+とwij-はそれぞれj番目のユニットからCi+およびCi-へのシナプス荷重,wi*はCi-からCi+への抑制性シナプスの効率,uiは平均膜電位,ziは外部からの入力信号を表す.また,f(u)は0から1の値を取るシグモイド関数,τとθは正の定数である.
解説論文(1997)
