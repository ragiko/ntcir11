
【異文化言語習得論】2006.02.20
担当者: Y. O.
Ney, H. (2005). One decade of statistical machine translation:
1996-2005. MT Summit X, Phuket, Thailand, September 13-15, 2005,
Conference Proceedings: the tenth Machine Translation Summit:
invited
paper; pp.i-12-17.One Decade of Statistical
Machine Translation:1996-2005
この10年で、機械翻訳(研究)の、統計的手法というものが普及した。
統計的機械翻訳の原則を説明して、この10年で作られた進歩や、今後進歩させていくことについてまとめる。
本論文のゴールは、統計機械翻訳(machine translation : MT)において、最高水準の技術をカバーすることになっている
2.1 The Baseline Approach to Statistical MT
原言語(S)から目的言語(T)へ翻訳するとき、人間の翻訳者は以下を考慮に入れなければならない
・ 語彙の選択(Lexical choice) : SはTの中に幾つか翻訳候補がある。適当である訳語の選択は前後関係に依存する
・ 単語の並べ替え(Position re-ordering) : SとT文中で対応する単語の位置が異なるので
・ 構文と意味(Syntax and semantics) : T文を生成するために統語論的意味的制約を考慮に入れなければならない
従来の非統計的なMTでは、人間の手で(翻訳)規則や辞書を作成していた。これには判明している二つの問題(two open problems)がある。
1. 我々はどうやって全ての規則を把握すれば良いのか、そして、システムが必要とする規則を全て持っていることを確認できるのか
2. Tを生成する際に、どのようにしてこれら全ての規則を一貫して、矛盾無く相互作用させられるのか
両方の問題に、統計的手法はすっきりと対処することができる。堅いルールの代わりに、確率に基づく知識源として、確率分布を用いる。
IBMのグループによって紹介されるように、統計アプローチのベースライン版において、翻訳作業は次のように表すことができる。
原言語で文Fを与えられる、そして、対応する目的言語文Eを生成したい。そのために我々は全ての可能な(翻訳)ペア(F,E)の後部の分布p(F|E)を考慮して、確率最大の目標文E
'(F)を選ぶ。これはベイズ決定則(Bayes decision rule):と呼ばれる。
第二の方程式では、経験的確率p(F|E)は、言語モデルp(E)と翻訳モデルp(F|E)の積として書かれる同時確率p(E,F)と取り替えられた。
文Fと文E全体にわたって確率分布を記述するので、翻訳モデルは複雑である。この複雑さを軽減するために、我々はSとTの対応を捉え、文レベル単語レベルの移動を考慮に入れるalignments
(A)の概念を利用する
これらの対応は一意に定まらず決定的で無いので、翻訳確率を得るときと同様に、確率分布によって記述される。
IBMグループが設計した、順番に複雑になっていく5種類のalignment-語彙モデルは、今日でも用いられている。
確率分布を使うことの利点
・ 可能性が得点として直接使われる
・ 計算方法が明白である
・ 弱くて漠然として依存関係も簡単にモデル化できる
・ 確率の自動学習をする強力なアルゴリズムの中に、人間の干渉が無い
2.2 The Tasks in Statistical MT
一般的な見解から、図2で示されるように、統計アプローチには4つの作業がある:
・(error measure and decision rule):
統計的機械翻訳システムや音声認識の、従来のエラー指標は、文誤り率を最小化する0/1-loss functionで、必ずしもBLEU、WERのようなエラー指標では無かった。
・(probability models):
確率モデルの究極のゴールは、翻訳システムに入力と出力の関係を提供すること
・(training criterion):
training criterionはトレーニングデータから、確率モデルのパラメータを学習するのに用いられる
・(decision rule):
全く莫大な数から最も適当なTを選ぶのは非常に複雑なので、効果的な方法が必要である
つまり、統計的アプローチは、決定規則、確率モデル、トレーニング基準や生成アルゴリズムなどの問題を解決しなければならない
3. Statistical MT in 1996-2005
3.1 Projects
機械翻訳のための今日の統計システムが基礎的な原則は、1990年に出来た。それから、書き言葉や話し言葉の翻訳はかなり進歩した。
話し言葉翻訳は、国家レベル、ヨーロッパレベル、そして国際的レベルといった多くの共同プロジェクトにおいて研究されている。
最近始まったばかりのTC-Star(TC-STAR is a European integrated project focusing
on Speech-to-Speech Translation)を別にすれば、これら全ては限られた領域(旅行中だとか)や、中語彙(およそ1万単語)での翻訳作業を対象にしていた。
現在最もよく機能している翻訳システムは、統計的手法にexample-basedなどの他手法を併せたものである。
書き言葉翻訳でも同様の進歩があった。
米Tidesプログラムで、中国語から英語、アラビア語から英語の、ほぼ無制限ともいえる大語彙(八万単語以上)のニュース記事翻訳評価で、従来の翻訳システムと同等か、優れているという結果となった。
これら言語ペアのための統計システムが2、3年だけの短い期間以内で開発されたというのは注目に値する。
3.2 Major Improvements
この10年にわたって成し遂げられる進歩は、いくつかの要因による
・(automatic error measures):
IBMグループが機械翻訳に統計的手法を導入したときはまだ、どのように出力結果を(自動)評価すべきか明らかでなかった。
そのうち、実験的にBLEUやWER、PERなどが提案、吟味された。
これらの指標はどれも完璧でないことが知られているが、適切性となだらかさ(?? fluency)を測定するとき、MT品質と相関するようである。
現在のMTのレベルなら、これで十分と考えられている。このような自動指標は速い訓練テストのサイクルを考慮に入れる際に有用である。
・(efficient algorithms for training):
alignment-語彙モデルは、S-Tの大きなセットについて訓練する。この方法は1993年に既に紹介されたのだが、訓練手順が複雑であった。これは公共のソフトウェアパッケージであるGIZA++によって解決した。
・(context dependent or phrase-based lexicon models):
本来のalignment-語彙モデルは、SとTに出現する単語の前後関係を考慮しない。一つの単語だけよ、り多くの前後関係依存を、例えば単語グループやフレーズに導入する必要がある。一つの単語だけから離れて、SとT両方の単語グループを扱った研究で、多くの成功があった。
・(efficient algorithms for generation):
目標文を生成するためにA*探索やdynamic programming beam searchのような、様々な方略が研究された。実験でdynamic
programming beam searchが(純粋な)A*探索より非常に有用だと言うことが判った。
・(log-linear model combinations and rescoring):
統計翻訳の中のベースライン・モデルは、語彙モデル、Alignmentモデルと言語モデルである。モデルと訓練の欠点のため、log-linear法でそれらを結合することで'relevance'
factorsをこれらのモデルに割り当てるのは便利である。
・(more powerful computers and more parallel corpora):
統計的機械翻訳の生成アルゴリズムと訓練は大きな計算能力を必要とする、さらに(訓練に用いる)バイリンガルコーパスは着実に大きくなっているので非常に大きなメモリが必要である。
3.3 Additional Research Directions
・Syntax-based Translation Models.
明確な統語上の構造を統計翻訳モデルに導入する試みがあった。
このような方法では、TとS文の間の語順の違いがより考慮に入れられると予想される。現在、これら構文ベースの機能拡張は(まだ)成果をあげていない
・Speech Translation.
話し言葉翻訳は、口頭からのS文認識とTへの翻訳という二つの操作が必要になるので、認識と翻訳の適切な統合という問題になる。この統合には大部分のシステムがN-bestを利用しているが性能は向上していないようだ。
・Interactive MT.
我々がこれまで述べたのはfully automatic MTと呼ばれるもの。Interactive MTでは、Tを生成するとき、ユーザはシステムと対話する。能率的にこのシステムを扱うために、ベイズ決定則が拡張できることがわかる。
4. Conclusion
話し言葉と言語処理に接した過去の経験から、発展が、データの依存関係をモデル化する方法や、システムがよりよくデータから学ぶ方法と、純粋にアルゴリズムの概念の改良によって、常に成し遂げられたことを示した。
我々は、これらの線に沿った将来の仕事が統計的機械翻訳のための重要な進歩に帰着すると予想する。
大塚 悠平
