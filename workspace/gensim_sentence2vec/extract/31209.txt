
概要
これまでに経験のない仕事をする場合、その仕事において必要となる知識を持っていないことが多い。そのようなとき、必要な情報を効率よく取得するためには、まず何が必要な情報であるかを知ることが重要である。この問題は、ある分野における辞書を作成することにより解決することができる。辞書を作る際には見出し語や索引語を決めなければならないが、その作業を人手で行うことは労力が大きい。そこで、できるだけ人手による作業を少なくし、見出し語や索引語を抽出できる手法が必要となる。
そこで、そういった語の抽出を機械的に行う手法を考える。語の抽出は筆者の所属する研究室で行われるゼミを記録した議事録集合を対象として行う。見出し語となるような特徴的な語(特徴語)にはある共通の性質があると考えられる。たとえば、主語や目的語になりやすかったり、発表の資料に出現しやすい傾向にあると考えられる。本研究では、特徴語を抽出するために特徴語となり得るような語(特徴語候補)の選出とSupport Vector Machine(SVM)と呼ばれる識別器を用いた分類を行う。識別器による分類を行うためには、一つ一つのデータに対してベクトルを付与する必要がある。このベクトルを特徴ベクトルと呼び、特徴ベクトルには先に挙げた特徴語の性質、主語や目的語になる、資料に出現する、といった異なる観点からなる特徴を定量化し、ベクトルの要素として設定する。特徴語抽出は次のような流れにより行う。まず議事録集合に含まれるテキストを形態素解析によって形態素に分割する。次に、複合語などの連接する形態素を連結し、特徴語の元となる語の集合を生成する。さらにいくつかの制約に基づいてフィルタリングし、特徴語候補を決定する。この特徴語候補のそれぞれに特徴ベクトルを設定し、SVMによる分類の結果、特徴語の集合を抽出する。本論文では、その特徴ベクトルの設定とSVMによる分類とその評価、及び抽出された特徴語の応用について述べる。分類の評価は、分類により抽出された語中に含まれる、実際の特徴語の割合により評価する。本研究における特徴語は、議事録に出現している語のため、時間情報と密接に結びついている。その情報を利用することで、話題の推移状況を知ることができる。
1 はじめに
今や世の中には大量の情報が溢れかえっている。人口の増加と通信手段の発達に伴い、一日あたりにやり取りされる情報量は近年、増加の一途をたどっている。
実際に、米国VeriSignの調査リポートでは、2008年第1四半期でのドメイン登録数が全世界で1億6,200万件であった。これは、前年同期比で26%増、前の四半期(2007年10月-12月期)に比べ6%増に当たるとのことだった。1つのドメインに複数のコンテンツが含まれることは自然であり、Web上から情報を取得するためには1億6,200万以上のコンテンツを相手にしなければならないのである。そういった情報の洪水に飲まれないためには、必要な情報を取捨選択し、効率的な情報収集に努めなければいけない。
ユーザが情報を収集しようと考えたとき、いったい何をするのだろうか。先ほども述べたように、Web上には大量の情報があふれている。これらすべてに目を通し、必要かどうかを判断することは現実的には不可能である。したがって、その時ユーザは検索という手段を取り、必要な情報に関係するWebページを探し出すのである。検索により得られたWebページは、ランク付けもされているため、ユーザは順に目を通していき、望みの情報を手に入れることができるのである。一般的に検索はクエリによって行われる。すなわち、ユーザは自らが調べたいことを理解し、調べたい事柄を検索のクエリとして設定しなければいけないのである。検索を行うことは、情報を選別することであり、必要な情報へと素早くたどりつくことに役立つ。しかし欠点として、ユーザが必要とする情報にたどり着くためのクエリを知っていなければいけない点がある。
多くの場合、ユーザは必要な情報を検索するためのクエリを知っている。しかし、研究室や会社の異動など、活動の場が変わった場合はその限りではない。知らなければいけないことがあるが、何を知ればいいのかがわからないという状態になるのだ。そうなると、検索により情報を集めることができなくなってしまう。なぜなら、検索のためのクエリを設定することができないからである。検索ができないとなると、人に聞くか、大量の情報を前に一つずつ要不要を確認して見ていかなければならなくなる。人に聞くことは、ある意味では最も確実で迅速な手段ではある。しかし、その情報が記憶に頼ったものである以上、忘れたり、思い込みによる齟齬があると考えられる。こういったときに、整理されたマニュアルの存在や、必要な知識が既にまとめられてあれば何も問題はない。ユーザは知っておかなければいけないと感じる部分に目を通せばよいのである。だが、それらの作成にはコストがかかり、また、真に必要な情報であるかを事前に知ることが困難である。たとえば、携帯電話の説明書などは、近年の多機能化により、非常にページ数が多くなっている。しかし、ユーザが説明書の情報をすべて必要としているのは稀で、多くのユーザは自分に必要な部分、あるいは有用であると判断する部分だけを読むのである。
ユーザは大量の情報を前に、何かを知りたいという欲求がある。しかし、情報を集めるための検索を行うためのクエリを知らないとする。そうした場合、ユーザの欲求を叶えるためには、どのようなサポートが必要であるのか。当然のことながら、ユーザが知りたいと考えているのは、未知の情報についてである。では、未知の情報かどうかは誰が判断できるのか。無論それはユーザ自身に他ならない。ある情報がユーザにとって未知の情報であるかどうかを機械が判断することはできない。したがって、システムとしてサポートできるのは、ユーザに対して、どういった種類の情報があるのかを提示することである。そのためには、コンテンツの集合をいくつかの小さい集合に分類することが効果的である。ある情報がどのような内容であるかは、その情報中において特徴的な語を知ることで類推することができる。たとえば以下のような文書があったとする。
「関係者が集まり、討論・相談や決議をする会議という場において、スムーズに議論が進むということ、さらに、過去の議事内容を検索などの手段により参照して、再利用できるということは非常に有益である。「議事録」という形で議論内容を保存しておかないと、過去の議論は容易に忘れ去られ、何度も同じ議論を繰り返す恐れがある。さらに、過去の議論内容を参照したい場合も、あやふやな記憶から間違った内容を新たな議論の場に出してしまうと考えられる。これは、現在進行中の会議においても同様のことが言える。議論の途中で、現在までの議論の内容を確認できるということも同様に有益である。今までの議論を一度振り返ることで、人間の創造性を刺激することができる。しかしながら、オンラインの掲示板などによる会議とは異なり、オフラインの会議においては議論を再利用可能な形にするのは一般に困難である。」
この文書が何を意味しているのか、一見しただけで把握することは難しい。しかし、この文書中には「会議」「議事録」「オンライン」「オフライン」「再利用可能」などの、特徴的な語が含まれている。これらの語を見ることにより、この文書が「議事録」に関係していたり、「再利用可能」という話題についての話をしていることが類推できる。このように特徴的な語を抽出し、それらをまとめた辞書を作成することができれば、ユーザがこの辞書を調べることで、必要な情報にたどり着くことができると考えられる。
このようにして得られた特徴語は、分類を行う上でも役立つ。たとえば図1.1のようなコンテンツ集合を分類することを考える。
図1.1は、二次元空間にコンテンツを配置した図であり、各点はひとつのコンテンツを表している。空間上の距離はコンテンツ間の類似度を表し、近いものほど類似しているとする。手がかりを用いない空間上の分布によるクラスタリングでは、距離の近いものを同じクラスとして分類するので、図1.2のようにクラス分けされる。
図1.2のクラス分けは一見正しいように見える。しかし、いくつかの問題点がある。一つは、この方法では、一つのコンテンツは一つのクラスにしか分類されないことである。しかし、ひとつのコンテンツが持つ情報は必ずしも一つとは限らない。そのため、さまざまな観点での分類ができなければ、コンテンツの分類手法としては効果的と言えない。もう一つは、クラスタリングによる分類が正しいかどうかをユーザが判断することが難しい点である。「類似している」という考え方は、必ずしも推移的とは限らない。すなわち、AとBが似ていいるからと言って、BとCが似ているとは限らない。そのため、類似しているものを集めたクラスが、本当に正しいかを確かめるためには、クラス中のすべてのコンテンツ間の類似度を見なければいけない。
このように、何の手がかりも用いずに、コンテンツ同士を比較するやり方では分類に効果的とは言えない。これに対して、特徴語による分類を行った場合を考える。
特徴語を利用した分類では、どの特徴語に着目するかにより分類結果が変わる。そして一つのコンテンツは複数の特徴語を含むことができる。そのため、特徴語ごとのクラス、例えば「議事録」クラスや「再利用可能」クラスなど、を作れば一つのコンテンツが複数のクラスに分類されることになる。また、その特徴語で分類するべきかどうかの判断は、そのコンテンツと特徴語に関連があるか見ればよい。これは、そのクラス中のすべてのコンテンツ間の類似度を見るよりは手間が少なくて済む。
このように、特徴語を抽出することができれば、情報の収集に大きく役立つ。そこで、機械的な特徴語抽出の手法に関して考えてみる。機械的な処理がもっとも容易なコンテンツは、テキストである。画像や動画などでは、語を抽出するためには特別な処理が必要となるからである。そこで、本研究ではテキストから特徴語を抽出する。
筆者の所属する研究室では、毎週行われているゼミ中の発言を記録した議事録が存在する。この議事録は、ゼミ中の発言を書記が記録したもので、キータイプによりリアルタイムに計算機へと保存されている。発言の際には、発言者が専用の機器を用いて、発言の開始と終了を宣言する。そのため、発言間の明確な区切りが存在する。この一つの発言を一つのテキストとして考え、本研究ではこのテキスト中から特徴語抽出を行う。
特徴語を抽出するためには、特徴語に共通する性質を手掛かりとして用いる。特徴語は話題の中心となることが多く、発言の中では主語や目的語として使われるのではないかと考えられる。それは前後の語の品詞として助詞が出現しやすいと言い換えることができる。
また、筆者の所属する研究室のゼミでは、必ずPowerPointによるスライドを資料として用いる。このスライド中には、発表に関する説明などが書かれているため、特徴語が多く出現することが考えられる。これは、特徴語であるならばスライドに多く出現するということでもある。
このような特徴語の性質を用いて、特徴語の抽出を行う。そこで、まず特徴語になりそうな語を特徴語候補として選び出し、その候補を二つに分類することを行う。候補の中から、前述の特徴語としての性質を持っている語、持っていない語の二つに分類し、特徴語の性質を持っている語を特徴語として抽出する。このような性質による分類を行うために、各性質を定量化し特徴ベクトルというものとして考える。
この特徴ベクトルには、前後の品詞による要素と、スライド中への出現数という要素の二つの観点からなる情報が含まれている。このように、全く別の観点からなる情報を組み合わせることで、特徴語としての性質がより顕著に表れるのではないかと期待される。特徴ベクトルを用いた分類には、Support Vector Machine(SVM)と呼ばれる識別器を用いる。SVMは高次元の特徴ベクトルを分類するのに適した識別器である。このSVMにより、特徴語候補を特徴語と非特徴語に分類することで、特徴語抽出を行う。
では、そもそも特徴語とは何であろうか。特徴語と対になる言葉は一般語である。したがって、特徴語であるということは一般語ではないということである。そして、一般語とはその言葉通り、一般に使用され特別な説明を必要としない語である。ある分野において特徴語であるということは、その分野に関係の浅い人間に対して説明を要するということである。このことから、ある分野における特徴語とは、その分野における辞書の見出し語に相当するものと考えることができる。
本研究の目的は、議事録のテキストから特徴語候補を選出し、特徴ベクトルを用いることにより特徴語を抽出することである。このように議事録の発言テキストから特徴語を抽出することには大きな意義がある。それは、議論の最中に特徴的な語を入力することができないからである。一般に、何かを記録しながら議論を行うことは難しいとされている。したがって、その発表や発表中に行われた発言の特徴語を設定するのは、発表後となる。しかし、発表後に議事録を見直し、特徴語を選択し設定することはあまり効率的とは言えない。例えば、発表終了後に、各自自分の発言を見直し特徴語を設定することを考えると、発表中に多く発言するほど後の手間が増えることになる。このことにより、発言に対する負担が増えることは望ましくない。よって、発表後に機械的な手法により議事録から特徴語を抽出する必要がある。
また、議事録の発表はいくつかのプロジェクトに分けることができる。筆者の所属する研究室では、複数のプロジェクトが活動を行っているためである。各プロジェクトは全くの無関係ではないが、扱う対象が大きく異なり、それぞれのプロジェクトごとに特徴語となる語が違う。そこで本研究では、特徴語候補には各プロジェクトごとに別々の特徴ベクトルを設定し、そのプロジェクトごとに分類を行い特徴語を抽出する。
本論文では、議事録からの特徴語抽出の手法とその応用について述べる。本論文の構成は、第二章で特徴語候補の定義や特徴語の抽出方法について説明する。第三章では、実際に行った特徴語抽出とその応用について述べる。第四章では、議事録から得られた特徴語の評価と考察について述べる。第五章では、いくつかの関連研究について述べる。第六章では、まとめと今後の課題について述べる。
2 特徴ベクトルを利用した特徴語抽出
2.1 特徴語抽出の流れ
一般的な特徴語抽出にはTF-IDFが用いられる。TF-IDFは文書に対する語の重要度を数値化したものである。その算出式は以下のとおりである。
TF-IDF = tf・idf
tfとはTerm Frequencyの略であり、その語の出現頻度を表す。一般的にはその語の文書中への出現回数を用いる。idfはInverse Document Frequencyの略で逆出現頻度と呼ばれ、一般には次の式を用いる。
idf = \log\left(\frac{D}{d}\right)
Dは全文書数を表し、dは語の出現する文書数を表す。TF-IDFが大きいほど、その文書に対してその語が強く結び付いていると考えられ、特徴語であると言える。しかし、TF-IDFによる手法では、文書から得られる特徴語の数が、文書量に大きく依存してしまう。長い文書であればそれだけ多くの特徴語が抽出でき、短い文書なら少ない特徴語しか抽出できない。だが、文書量と特徴語の数は必ずしも比例の関係であるとは限らない。短い文書に多くの話題が含まれている場合は特徴語の数は多くなるし、長い文書でも、同じことを繰り返し論じている場合では特徴語の数は少なくなる。そこで、文書単位ではなく、文書集合全体の中での語の特徴により特徴語を抽出する手法を考える。
そのために、ある語がどのように使われているのかということに着目した。特徴語となるような語は、ある文書中においての話題となるようなものが多い。それは、主語や目的語といったものとして出現しやすいということである。主語となる場合は、その語の後ろに「は」「が」といった助詞が来ることになり、目的語となる場合はその前に「を」「に」といった助詞が来ることになる。
また、本研究で対象としている議事録に記録されている発表では、資料としてPowerPointのスライドを利用している。特徴語となるような語は、こういった資料中に頻繁に出現することが予想される。スライド中に載せることのできる情報には限りがあるため、発表者は重要と思われる情報を選出し、資料に載せるからである。したがって、資料中への出現回数によっても、特徴語であるかどうかの判断ができると考えられる。
そこで、このような特徴語が持つと考えられる性質を定量化し、特徴語抽出に利用する。本研究では、定量化した値をまとめて、ひとつのベクトルとして考える。このベクトルを、語の特徴を表すベクトルと考え、特徴ベクトルと呼ぶ。この特徴ベクトルを利用し、特徴語抽出を行う。特徴語を抽出するということは、特徴語とそうでない語の二つに分類することと同じである。本研究では、この分類のためにSupport Vector Machine(SVM)と呼ばれる識別器を利用する。
また、こういった特徴語抽出を行う際には、まず文書中から特徴語の候補となる語を抽出する必要がある。そのためには文書を形態素解析し、語を取り出す必要がある。
本研究で提案する特徴語抽出は、図2.1のように行う。
本研究では議事録の集合を対象としている。その中に含まれるテキストを形態素解析する。分割された形態素は、複合語として連結できるものもあるため、これらを連結する。こうして特徴語候補の元となる語の集合から、いくつかの制約によるフィルタリングを行い、特徴語候補を抽出する。抽出された特徴語候補のそれぞれ特徴ベクトルを設定し、SVMによる分類を行い、特徴語を抽出する。
以下では、特徴語候補の抽出と特徴語候補からの特徴語抽出とに分けて説明をする。
2.2 特徴語候補の抽出
2.2.1 形態素解析
日本語文は、英文と違い単語間の明確な区切りが存在しない。そのため、文書中から語を取り出すためには、形態素解析と呼ばれる処理を施さなければいけない。
形態素解析とは、テキストを形態素と呼ばれる単位に分割することを指す。この形態素は、厳密にいえば単語とは違った分割の単位ではあるが、おおよそ単語と同じようなものになる。そのため、形態素は品詞の情報を持つ。例えば以下のような文を形態素解析した場合、表2.1のような形態素に分割される。
「形態素解析により文書を分割する」
表2.1:
表2.1. 形態素解析の結果
このように、形態素解析による文書解析により、日本語文の中から語を取り出すことができる。
形態素解析のプログラムとして、JumanやChaSenといったものがある。表2.1の形態素解析の結果は、ChaSenによる解析の結果である。JumanとChaSenでは、形態素の品詞体系が異なるため、解析の結果が大きく変わる。本研究では、品詞の情報を多く用いるため、より詳細な品詞の分類が可能なChaSenを用いて形態素解析を行う。
2.2.2 連結処理
形態素解析により得られた形態素は、語を構成する最小単位と考えることができる。したがって、この形態素の連結により語となることがある。
そこで、特徴語候補の元になる語の集合を作るために、形態素の連結処理を行う。連結して新たな語となるかどうかは、その形態素の品詞により判別する。表2.1の形態素の中から連接することができるものを考えると「形態素」と「解析」は連結により「形態素解析」になると考えられる。また「分割」と「する」を連結し「分割する」とすることもできると考えられる。この場合「形態素解析」は連結によリ語とする意味はあるが「分割する」に関してはその意味は薄いと考える。「形態素」「解析」はともに名詞である。このように名詞が連続する場合は、連結することにより新たな語となることがある。しかし「分類」と「する」は名詞と動詞の連接である。この場合は「分類」の動詞化であるため、特徴語として抽出する意義は薄い。
また、形態素解析は常に正確な分割を行うとは限らない。例えば、「議事録」という単語は「議事」と「録」に分割されてしまい、この二つの品詞も名詞となる。
そこで、本研究では連結処理を行うのは名詞が連接している場合とする。これにより、複合語などの二つ以上の形態素からなる語を特徴語の候補として選ぶことができるようになる。
2.2.3 フィルタリング
連結処理により、特徴語候補の元となる集合を取得した。この集合の中からいくつかの制約によるフィルタリングを行い、特徴語候補を抽出する。
まず、品詞の情報により語をふるい落とす。動詞や形容詞は、一般的な動作や形容を表すための語である。特徴的な動作や形容などは、名詞に対して「する」や「的」などを付け加えることで表す。このことから、動詞や形容詞などは特徴語として扱わないこととし、名詞を特徴語の対象とする。また、形態素解析により未知語として判別される形態素はカタカナやアルファベットからなる語であり、実際の文中で名詞として使われることもある。そのため、本研究では特徴語として抽出するのは名詞と未知語からなる語とし、特徴語候補の元となる集合から名詞、未知語以外の品詞を持つ形態素を除去する。
このようにして得られた集合にも、特徴語となりえない語は含まれている。形態素の品詞は、名詞にもいくつかの小分類が存在する。この小分類の中で、特徴語の先頭に来ることのないような項目が存在する。それは「接尾」「非自立」「代名詞」である。接尾の品詞情報を持つ形態素としては「的」や「化」といったものである。これらの形態素が語頭に来る語は、そもそも語としての条件を満たせていないと考えられる。非自立の品詞情報を持つ形態素は「こと」「もの」のように単独では意味をなさない語である。これらの形態素も、語頭に来ることはないと考えられる。代名詞に関しては、語頭となることはあり得る。しかし、代名詞を関する語は、「この事実」「あの分類」などのように、何かを指し示すときに使うものである。したがって、これらの語を特徴語と考えることはできない。こういった事実から、先頭の形態素として「接尾」「非自立」「代名詞」が来ている語は、特徴語候補には含めない。
最後に、ある語の一部である語を除去する。例えば「議事録」という語は形態素解析により「議事」と「録」に分割されるが、それぞれ単体で使用されることはほとんどない。そういった場合、「議事」や「録」が特徴語とはならず「議事録」が特徴語となるはずである。このように、特定の語と連結することが多い語は、単独で特徴語となることはないと考える。そこで、ある語sの出現数の90%以上の割合でwを含む語xの出現があった場合、wはxの一部であると考える。この場合wは特徴語候補から除外する。
したがって、本研究で特徴語候補となるのは以下の制約条件を満たす語である。
構成する形態素は名詞か未知語である
先頭の形態素は「接尾」「非自立」「代名詞」の形態素情報を持たない
特定の語に頻繁に(90\%以上の割合で)含まれることがない語
2.3 特徴語候補からの特徴語抽出
2.3.1 特徴ベクトルの設定
特徴ベクトルは、特徴語とそうでないものがそれぞれ判別できるようなものを設定しなければいけない。そこで、特徴語の言語的性質を考える。特徴語となるような語は、その文書中での話題となり、主語や目的語になることが多い。これは、説明や解説を行うためには主語や目的語になる必要があるからである。主語となる場合はその後ろに「が」「は」といった助詞が出現し、目的語となる場合はその前後に「を」「に」といった助詞が来ることが多い。
そこで、特徴ベクトルの要素として前後の品詞の出現割合を利用する。特に着目するべきは助詞の出現割合である。既に述べたとおり、助詞が前後に来る場合は特徴語となることが期待されるからである。そこで、特徴語候補の前後に助詞が出現する割合とそれ以外の割合を、特徴ベクトルの要素として考える。しかし、助詞の中にもさらに細かい品詞分けがなされている。特徴語が助詞と連接することが多いことは経験的に理解できるが、そもそも助詞と連接することが多いのは、特徴語以外の名詞でも同じである。そこで、助詞以下の細かい情報を別の特徴ベクトルの要素として考え、より詳細な情報を利用する。助詞はさらに、格助詞, 引用, 連語, 係助詞, 終助詞, 接続助詞, 特殊, 副詞化, 副助詞, 副助詞/並立助詞/終助詞, 並立助詞, 連体化の10個に分類されている。しかしこの中で、「特殊」の出現数は非常に少ないので要素からは除外する。また、前後に記号が来る場合のことを考えてみる。ここでいう記号とは句点や読点、各種括弧などのことである。これが前後に来るということは、そこで意味的な切れ目になるということである。よって、前後に記号が来る割合も特徴ベクトルの要素として考える。
しかし、前後の品詞による要素だけでは、文書に出現する回数に大きく依存してしまう。文書量に依存しない分類を行うために、別の観点からなる要素を用いる必要がある。本研究においては、議事録という特殊な文書から特徴語を抽出する。そこで、議事録から得られる特徴を特徴ベクトルの要素として取り入れる。本研究において対象としている議事録は、ゼミの発表を記録したものである。筆者の所属するの研究室では、ゼミの発表にはすべてPowerPointの資料を用意する。そこで、このPowerPointのスライドを利用して特徴ベクトルの要素を設定する。
スライドに載せることのできる情報には限りがある。そのため、発表者は必要となる情報だけをスライド中に記述するはずである。したがって、スライド中に出現する語は特徴語となりやすいと考えられる。そこで、特徴ベクトルとして、スライド中に出現するかどうかを要素として与える。さらに、出現する位置にも注目する。一般的に、スライドの一枚目には発表のタイトルを記述する。すなわち、一枚目のスライド中に出現する語は発表のタイトルに出現することになる。発表のタイトルは文章量的には少ないが、そこに出現するということは特徴語としての性質として重要と考えることができる。また、一枚一枚のスライドには、タイトルが付けられている。スライドのタイトルは、そのスライドの内容を端的に表すものをつけるため、ここに出現する語も、重要な語であると考えられる。そこで、特徴ベクトルとして、発表のタイトル、スライドのタイトル、それ以外、の三つに出現する回数を別の要素として利用する。さらに、出現する場所の文章量と重要度を考え、発表のタイトルは100倍、スライドのタイトルは10倍する。
このようにして各特徴語候補に対して特徴ベクトルを設定していく。
2.3.2 SVMによる分類
各特徴語候補が持つ特徴ベクトルを、利用して特徴語を抽出する。そのために、特徴語候補を特徴語クラスと非特徴語クラスに分類することを考える。このようなクラス分類のために、SVMと呼ばれる識別器を利用する。
分類を行うための識別器には様々な種類がある。K-means法やウォード法、多層パーセプトロンなどがある。これの識別器には、大きく分けて二つの種類がある。教師なしクラスタリングと教師ありクラスタリングである。
教師なしクラスタリングは、特徴ベクトルの分布からクラス分けを行う手法である。K-means法やウォード法などがこれにあたる。この手法では、それぞれのクラスの分布が偏っている場合はうまくいくが、そうではない場合はうまくいかない。今回の特徴ベクトルで、その分布が偏っている保証がないため、この手法を適用することは難しい。
もう一つの教師ありクラスタリングは、分類を行う前に学習データを与える手法である。この手法は学習データを参考に、分離のためのパラメータを決定し分類を行う。しかし、教師ありクラスタリングにはいくつかの既知の問題がある。一つは次元の呪いと呼ばれる問題であり、もう一つは認識率の問題である。次元の呪いとは、高次元の特徴ベクトルを用いたときにおこる問題で、次元数の増加に伴い識別に時間がかかったり、どの特徴ベクトルも「似ていない」となってしまうことである。すなわち、望ましい分類の結果が得られなくなってしまうのである。認識率に関しては、多くの識別器では分離のためのパラメータに対して初期値を設定しなければならない。この初期値をどのように取るかにより、認識率に差が出てしまのである。
しかし、SVMでは高次元のベクトルに対応し、高い識別率による分類が可能となっている。SVMは教師データから最適分離超平面を求め、未知データの分類を行う。SVMの識別関数は以下の式により表わされる。
\[f\left(x\right)=sign\left(g\left(x\right)\right)\\g\left(x\right)=w^{t}x+b\]

