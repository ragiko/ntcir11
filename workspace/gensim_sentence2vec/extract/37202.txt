
by 望月
場所,日時:東京工業大学 ベンチャービジネスラボラトリ,1999年12月9日
参加者一覧(15名):
(敬称略,順不同)
豊橋技科大 増山
リコー 亀田,望主
国文学研究資料館 野本
沖電気 桝井
富士ゼロックス 岡
NTTデータ 平尾
NEC 中澤
松下電器 野口
学術情報センター 神門,江口
通信・放送機構 福島
北陸先端大 奥村,望月,難波
========================================================
1.原案の提示および説明
今回は,前回の話し合いから,これまでの間にML等で議論され,
まとまっている点を踏まえて,原案の提示および説明があった.
原案: 3つのタスクからなる
1.人間の被験者にテキストから要約を作成してもらう.
(1)要約の作成
a. 被験者へのinstruction
a-1.重要文抽出,重要部分抽出(および,その書き換え)に基づく要約
a-2.自由作成による要約
(2)作成した要約によるシステムの評価
2.タスクベースの評価
IRタスク
3.Q & A
この内,まず,タスク1,2について,原案を元に議論がすすめられた.
また,タスク3(Q&A)については,神門先生よりTRECの状況を伺った.
================================
2.議論
2-1 タスク1について,
要約作成の対象データについて
・具体的にどのデータを利用するかは,まだ決定していない.
・現実に利用できるデータについての情報が少ないので,今後も著作権等の問題
も含めて,データについての提案や情報を集めていく.
・現在までに利用可能/利用を検討しているデータ,また今回の議論で参加者か
ら問い合わせのあったデータは以下のものがある.
利用可能なデータ:
・論文の抄録,科研費の報告書,新聞記事
・「TAOの字幕制作に関する国際ワークショップ(1999年11月20日開催)」
の要約筆記と書き起こし全文(利用可能になる見込み)
現在検討中のデータ:
・論文のフルペーパー
・Webドキュメント
・特許 
需要が大きければ,考えていきたい
参加者から問い合わせのあったデータ:
・JICSTのデータ
人工知能学会のフルペーパーは,データが学情にあるので可能性がある.
要約作成基準について
・要約の長さをどのくらいにするか.
・長さの単位は文だけでなく文字も考えられる.
・要約として妥当な長さは,テキストのジャンルによる.
・使用する素材が決まってからでないと見当がつかない.
いくつかの長さに関する候補を決め,ドライランで探っていく.
・a-2について,「...参考にしたテキスト中の文を列挙して下さい..」
というような記述があると重要文抽出と同じようになってしまう恐れがある.
・分析者が,被験者の要約の根拠となる箇所を知りやすくするために入れた文
であり,重要文抽出的な意味はない.
・根拠となる部分をマーキングできるのであればその方が良い.
・経験的に,元の文と要約とのアライメントは自動で結構できる(7割くらい).
この一文を外し,根拠となる部分を(半)自動的に決定する方向で進める.
・1つの要約を作成する人数および,テキスト数はどのくらいが良いか?
どのくらい可能か?
・1つのテキストに対して複数の人間でやった方がよい,
(ある程度コントロールしても人によるゆれは生じると思われるため)
・人数,テキスト数は,予算と費用によって変わってくるので,現時点では決
定できない.
2-2 タスク2について,
・IRタスクベースでは評価実験に,参加した要約システム間だけの比較でなく,
タイトルやキーワードなどの手法による要約も含める必要がある.
2-3.今後のスケジュールについて
・NTCIR全体のスケジュールは以下のようになる.
4月 CFP
5月 訓練データ配布
8月 IR評価用データ配布
9月中ごろ
結果を提出してもらう
その後,評価し,
2000年2月 成果報告.
ただし,tscでは,4月の時点で全て決まっている必要はない.
・ドライランを年度が変わって早々に実施したい.
・今年度中に,ドライランができるように必要事項を決定する.
・1の要約作成もドライランの時期に予備的にやる.
・ドライランの前では,その時点までに決まった方針でアナウンスし,ドライラ
ンの結果によって,修正があれば,本番用のアナウンスではその点を変更する.
===========================================
3.タスク3.Q & Aについて,
神門先生からTREC-8のQ&Aについて伺った.
TREC-8のQ & Aでは,
・Q: 200種(基本的に What-, Which-などの形が多い).
・対象ドキュメント:ad hoc検索と同じ物を使用(disk 4と5の内,長いものは除
き,平均では500ワードより少ない).
・A: 長さが,50bytesまで/250bytesまでの 2とおりを設定.
参加者がどちらも選べる(両方参加してもよい).
参加したそれぞれの長さで,順位付けした5つの答を提出する.
・判定:人間が行なう.答が問題に答えていると思えば,そうでなれば×.
上位5つの内,最初に正解した位置で得点をつける.
1位1点,2位0.5点,3位0.33点,4位0.25点,5位0.2点.正解数は関係ない.
・参加者のアプローチは大きく2つに分かれる(参加20チームくらい)
・IRのpassageグループ:「250bytesで良い成績」の傾向
・IEのグループ:「50bytesで良い成績」の傾向
・Workshop:参加者のシステムについての発表はほとんどない.主に来年どのよ
うに行なうか,という議論に時間を割く.
・Q & A は,聴講者が大く大盛況だった.
今回議論になった点は以下のことだった,
・何がQuestionか?
・50/250bytesという単位は良いのか? 答そのものの方が良いのでは?
結局,何がQuestionで,何がAnswerなのかという議論になる.
来年	
・2年目も答は長さ 50/250bytesの2通りで実施する
(1年目のデータを生かすために,ドラスティックにやり方を変えない).
・Questionを500にし,Yes/NoのタイプのQuestionも設定する.
・Q & Aでは,評価をするところに非常にパワーがいる.
・IRによってドキュメントを発見するということの次は,答そのものの検索だと
いうのが,業界の共通認識のようである.
・(質問)50/250bytesの違いの元々の狙いは?
(回答)50が望ましいが,IRの人々には高すぎるハードルなので,
250も入れたというような話だと思う.
・"contest"は使用に要注意の言葉,順位が一人歩きする恐れあり.
・TRECでは,結果を営業等に利用してはいけないと決まっている.
============================================================================
4.今後の話
・タスク1は,実施することで決定.
・ジャンルについては,利用可能性も含めて引き続き検討する.
・テキストの長さは,ドライランで候補を決めておいて,最終的に決める.
・重要文抽出,自由作成のどちらについても,評価できる部分は評価する
(要約の新しい評価方法の提案や評価方法の蓄積という点も視野に入れる).
・タスク2と3は,参加者次第で開催するかどうかを決定する.
・2については,参加者がどのくらいいるか,アンケートを取る.
参加者がいるようであれば実施の方向で検討する.
・3については,アンケートと共に,organizeしていいと思っている人がいるか
どうかも聞く.
参加者,organizeしてくれる人がいれば,実施可能になる.
・参加者は日本人だけに限らず,外国人でも参加できるようにした方が良い.
・要約作成ツールについて,
1のa-1用のツールは現在JAISTにて作成中.
1のa-2用は特にいらない.
===========================================================================
publicity:
・情報処理最前線(既刊),
・情報処理特集(「評価ワークショップ」4月頃原稿),
・HICSS(招待講演),
・RIAO(招待講演の推薦状態),
・CLEF(招待講演,ヨーロッパのcross-language NISTが協力)
・情報学シンポジウムで報告(井佐原さん)
===========================================================================
Text Summarization Contest Home Page
