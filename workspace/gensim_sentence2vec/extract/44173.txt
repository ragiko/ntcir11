
ランダムサンプリング(random sampling: 無作為標本抽出)とは被験者をある母集団からランダム(無作為)に抽出(サンプリング)するということを意味しており、ランダム割付とは被験者を各要因・各水準に割り当てる操作である。たとえば、宮教大の学生(母集団)の生活実態を調べたいときに、全員を調べ上げる(全数調査)ことは大変なので、宮教大の学生の中から無作為に被調査者を選ぶような手法(標本調査)がランダムサンプリングとなっている。ただし、調査目的が日本の大学生(母集団)の生活実態調査であるならば、上記の標本データより示された結果には一般的妥当性の問題が生じる可能性もある(キーワード:世界、母集団、標本)。
このような場合は、ランダムサンプリングではなく便宜的なサンプリングと呼ぶべきである。
近代統計学の基本的な考えは、
母集団と標本を区別することにあるといわれている。
標本にもとづいて計算された量(統計量)から、
母集団の数理的特性(母数)を推定することになる。
たとえば、国とか県とか、母集団が大きい場合には、そこから抽出される標本の平均の分散も大きくなってしまうが、
逆にクラスとか班といった具合に母集団が小さいときには、そこから抽出される標本の平均の分散は小さくなる。
また、母分散(母集団の真の分散)の大きな母集団の平均値を調べる場合には、多くの標本が必要とされるが、
母分散が小さい母集団だったら標本数は少なくてすむ。
つまり、当然だが、母集団の母分散を小さくするような工夫ができるのであれば、調査の精度は向上することになるということである。
上記の関係を数式的に模擬的に表すと、(全体の分散)=(層内の分散)+(層間の分散)といった感じになる。
これを具体的に言うと、サンプリングをする層をあらかじめ細かくけて調査すると、各層内の分散が小さく抑えることが可能になり、
調査の精度(全体の分散の推定)が向上するかもしれないということである。
たとえば、宮教大全体を調査するのではなく、1年生、2年生、3年生、4年生といった具合に分けそれぞれサンプリングして調査をすると、
各学年内の分散と学年間の分散に分けられるのが分かるであろう。
ちなみに、このような工夫を層別抽出とよぶ
(このあたりの考え方は分散分析と感じが似ているかもしれない)。
コスト面の問題から、学力調査では抽出調査によるテスト実施が望まれるが、
都市部における学校数と郡部における学校数は異なっているし、そして、
それぞれの区分においてどれぐらいの規模の学校に揃えたらよいか判断するかはなかなか難しい問題である。
たとえば、標本調査の方針として、1学年4クラスといった大規模校を対象として
「ランダムに」学力調査を行うと決めたとしても、
郡部と都市部ではそういった大規模校の数が異なる。
したがって、大規模校を対象とすることは放棄した方が無難…
といった思考実験が必要とされるわけだ。
いずれにしても、ほとんどの心理学実験では上述した便宜的なサンプリングとならざるを得ないが、その辺りの限界を認識した上で、実験から得られた結果がどれだけ実質的な意味を持っているかを考えるべきであろう。
次に、割付に関する問題について少し考えてみよう。
たとえば、Aという教授方法とBという教授方法とがあったとき、どちらの教授方法が有効であるかを調べたいと仮定する。
ここで被験者をランダムに割り付けるとは、実験者が被験者をいずれかの教授方法へ強制的に割り振ることを意味している。直感的に分かるように、教授方法の効果を検証する場合には生徒の自主的な選択に任せてはいけない。
つまり、教授方法の違い以外にも、Aのスタイルの授業を好む学生、Bを好む学生といった「実験で見たい要因以外の別の変数(交絡変数)」の影響が問題となることが分かるであろう。その他にも、性差や年齢、ベースラインとなる学力なども考慮すべきかもしれない。
こういった交絡(confounding errors)を生じそうな要因の影響を取り除くために被験者の無作為割付を実施することを、実験計画法では「カウンターバランスをとる」とよぶことがある。
天候や気温、照明の明るさ、身長、体重、性差など、どの要因が実験結果に影響を及ぼすかは、個々の研究領域の中で経験的合意が形成されているのが普通である。したがって、どの要因に注意してカウンターバランスをとるかは、研究領域に応じて考えていくことになる。
たとえば、利き手と学力とのあいだには何か関連性があるのかもしれないが、一般的には、無視しても構わないであろう。
しかし、小学一年生が漢字を学習するスピードを調べたいときなどは、
運筆の仕方が利き手によって微妙に違うため、どちらが利き手かは重要な要因になるのかもしれない(もちろん、重要ではないカモしれない)。
この辺りの話は、心理学論文の典型例でも少しふれたが、モデルや仮説と密接な関係がある。
更に一歩進んでこのカウンターバランスについて考察してみよう。
被験者の割り当てをできるだけ均質なものにするためには、原則としてある程度の被験者数を用意すべきである。
これは被験者をランダムに割り振ったとしても偏りが生じる可能性があるからだ。
しかし、これは全ての実験条件で被験者が異なるような実験計画(被験者間計画:between subject)で特に注意すべき問題であり、被験者が全ての条件を経験するような実験計画(被験者内計画:within subject)の場合には、その制約が少し緩やかになる(混合計画というのもある)。
被験者内計画の実験デザインでは、個人差によるデータの変動を分析から除外できるというメリットがあるが、分野によってはそのような実験計画を立てること自体に無理があることもある。
たとえば、AとBという二つの教授方法の違いを調べたいときには、それぞれの効果をなにがしかの試験で確認する必要があるだろう。
しかし、同じ先生が同じ単元を繰り返し教えることは不自然だし、同じ試験問題を使い回すのも同様に不自然だろう。
もちろん、この場合には、順序効果を抑制するために生徒を二群(AB、BA)に分けて実験すればよいわけだが(cf. カウンターバランスをとる)、
一つのクラスを半分に分けて実験させてくれるような奇特な学校など存在しない。
また、単元に応じて教え方も切り替えるべきなのだから、
単元の特性をカウンターバランスによって潰してしまう発想自体が問題視されるかもしれない。
いずれにしても、実験によって得られた結果というものは、これらの制約の下に得られた結果であることを意識して本来は解釈すべきである。
なお、1つのセル(要因と水準)にどれだけの人数を割り当てればよいかは、実は非常に悩ましい問題である。
この手の問題は効果サイズ(effect size)に関する考察の中で議論されることが多い。
たとえば、悉皆調査(全数調査)でない限り、調査した結果である標本は母集団の一部を観察したものに過ぎない。
このような場合に母集団の母数(たとえば母平均)を推定するときには常に標本誤差(sampling error)がつきまとう。
つまり個々の標本からの推定値にも何らかのバラツキが生じるわけだが、そのような推定量(統計量)のバラツキを
標準誤差(standard error)とよぶ
(=標本抽出分布の標準偏差)。
そして、この誤差がどれくらいなのかは、直感から分かるとおりサンプリングされる被験者の数によって決定されてしまう。
標本サイズが大きくなれば標本誤差は小さくなり、標本サイズが小さくなれば標本誤差が大きくなるということである。
実際に平均値の標準誤差は「母標準偏差/n^1/2」となることが知られている。
たとえば、標本の大きさが4倍になると、平均値の標準誤差は1/2になる。
つまり、標本の大きさが4倍になると検定量の効果測定の精度が2倍になることが分かるであろう。
ちなみに、母集団の分布がどんな形でも
標本平均の分布は正規分布の形に近づくという中心極限定理という定理があり、
これをもとにして様々な統計的な推定が行われている。
<関連キーワード:大数の法則>
しかし、このことから分かることは、もの凄く小さい差でも、被験者を千人以上集めることができれば、たいていは統計的に有意な差となるだろうということでもある。
つまり、統計的に有意な差であることと、それが実質的にどういう意味を持っているかは全く別の話であるということもである。
重回帰分析などを行うと、そのモデルが統計的に有意かどうかを判定できるが、
偏回帰係数やR-squareなどを見たら実は大したことがなかったり…とか。
経験論的には、相関係数を元にした調査では100+α人くらいを目処に、分散分析を元にしたような実験計画では1つのセルに20+α名程度を目処にという一応の目安があるような気がする。
ただ、効果サイズが小さくても(条件間の差が小さい)、その差が重要な意味を持つような研究文脈もあるだろう。
効果サイズを真面目に考えたい人は、『検定力表』とか『サンプルサイズ表』をキーワードにして検索するとよいだろう。
統計的仮説の検定の基本的考え方
ある学校のあるクラスの漢字のテストの普段の得点が69点で標準偏差が5.2だったとする。
それに対して、担任の教師が少人数のクラス(5人)の宿題として特別に漢字ドリルを課したところ、
得点が84点へと向上したとする。
この得点の向上をどのように解釈するのか?
統計学からの仮説は単純で、15点の差は、単に母集団から抽出された
標本平均の標準誤差に過ぎないと考えることになる。
つまり、一般の教師の研究仮説は、少人数指導の効果による成績の向上がある(かもしれない)
というものだが、その逆の差がないという仮説を立てるわけである。
このような統計法上の仮説を、帰無仮説
(Null hypothesis)とよんでいる。
標本平均や標本SDなどの統計量は、
標本変動により値が分布している。
この仮想の分布が標本分布とよばれているものであり、
その標準偏差が上記の標準誤差である。
そして、この標準誤差は標本変動によりどれくらい標準的に変動するかの指標となる。
このとき、別の表現をすると、帰無仮説は
「平均84点は平均69点の母集団から得られた標本である」と考えることになる。
それに対する対立仮説(Alternative hypothesis)とは、
「平均84点は、平均84点の母集団から選ばれた標本である」と表現することになる。
言い換えれば、少人数クラスの値は平均69点の母集団から得られたものではな
いと考え、教育効果があったと判断する。
この場合は、z得点へ変換する公式によって得られたz値を見て、
そのz値が5%水準よりも大きければ帰無仮説を棄却することになる。
このように、帰無仮説が本当に偽であるとき、それを正しく棄却する確率を
検定力とよぶ。
母集団に差があるとき、
サンプルにおいて有意な結果が得られる確率とも言い換えることができる。
このとき、帰無仮説が正しいのに棄却してしまったエラーは、
第1種の誤り(Type I error)とよび、
逆に帰無仮説が間違っていたのに棄却できなかったエラーは、
第2種の誤り(Type II error)とよぶ。
※ z=(84-69)/(5.2/5^1/2)=6.45 は、
両側検定の5%の棄却域(=2.5%)の臨界値である1.96よりも有意に大きいので、
帰無仮説(平均84点は平均69点の母集団から得られた標本である)を却下することになる。
疫学的な考え方
ある病気の患者に対して薬Xを投与したと仮定する。
そして、たとえば、その薬Xを100人が飲んだら、その内の約80名が3日の内に完治した!!!・・・
といった話を聞いたら、どう考えるだろうか?おそらく、その薬の有効性を信じる人が多いかもしれない。
しかし、その「ある病気」というのが単なる普通の下痢であった場合にはどうだろうか?
なんとなく自然治癒する可能性も高いと思われるだろう。
極端な話として表にまとめると、このように示すことができる
ここまで大げさに示すと逆に薬Xの有効性が疑わしくなってしまうが、しかし、疫学的に有効性を検証するためには、単に薬が効いたがどうかを調べるだけでは不十分であることが分かるだろう。
つまり、条件群(薬を投与する群)と統制群(薬を投与されない群)、この2つの被験者集団が必要とされるということである。
他にも、
「インド人は日本人と比べてガンで死ぬ割合が非常に少ない。この事実はインドの人たちの生活様式の中にガンの予防に有効な要因があることを示している by 豊村先生
」
といった言説があったと仮定しよう。
こういった言説を主張されたとき、どのように反論するのか?
このように、交絡(confounding errors)するような要因がなにか考えるのも、
疫学的な推論、統計学的な推論の第一歩といえるだろう。
このインド人の例では、
インドにおける死亡事故率や
ガン以外の重篤な病気の疾患率(脳梗塞等)などの
要因を考慮するような反論が可能だと思う。
相関関係と因果関係の違いについて
気圧計を読むことができないような状況では、直接的に観察しうる指標としてカエルが重要な役割をもつかもしれない。直接調べることができない状況でも使いうる、「ユーザーとして重要な指標」を見つけることも心理学的には十分意味がある。利用の簡便性という観点が重要とされることもありうるわけだ(数理的な解説は平のホームページに掲載されている講義資料「回帰分析」を参照)。
「カエルが鳴くから雨が降る」
= 「気圧が変化するからカエルが鳴く」
「カエルが鳴くから雨が降る」
ただし、因果関係の全体像がすでに明らかにされている場合には、たとえば、「カエルが鳴くから雨が降る」という関係は相関関係であっても、因果関係とはいわない。現代人であるならば、カエルが鳴くこと、雨が降ること、気圧計が変化することは、以下のように平行して生じる現象として理解するべきである。
「気圧が変化するから」  「気圧計が変化する」
「気圧が変化するから」  「カエルが鳴く」
「気圧が変化するから」  「雨が降る」
しかし、大昔のように気圧の変化という概念が存在しない場合には、「カエルが鳴くから雨が降る」というのは、因果関係として認められていたのかもしれない。つまり、カエルが雨を降らせる何らかの霊力を持つ存在と考えられていた可能性もあるわけだ。たとえば、気圧の概念を持ち得なかった江戸時代の人々の場合には、以下のような因果の連鎖と考えても不思議はないだろう。また、気圧計を利用できない状況などでは、江戸時代の人々のようにカエルを気圧計の代わりに使うべきであろう。
「(カエルには雨を降らせる霊力を持つから)」
= 「カエルが鳴く」
「雨が降る」
たとえば、高校生くらいまでは身長と学力や語彙の数とが相関しているが(学齢が上がるから当たり前)、これが因果関係でないのは明白であろう。
しかし、年齢が全く分からないときには、見た目だけで学力の高さを判断しなければならない。
そのような場面では、賢そうな顔とかそういった判断基準も有効かもしれないが、
身長の高さに基づいて判断した方がより妥当性が高いと言えるであろう。
つまり、因果関係を直接把握することが難しいときには、
このような便宜的な指標を使うことにも意味があるということである。
以上のことから分かるように、変数どうしの共変動
を相関関係と呼ぶべきか、因果関係と言って良いかは区別しておく必要がある。
というよりも、因果関係を主張するときには慎重になるべきである。
因果関係が成立する条件としては以下の4つが挙げられている。
時間的先行性
変数間の結びつきの強さ
関連の普遍性
関連の整合性
ちなみに、男性は高校から身長が伸びることもあるが、女性は高校生になると身長が伸びない人が多い。
要するに身体的な成長に性差があるわけだが、このような場合には、男子高校生では身長と学力の相関が高く、女子高生では相関が低いという結果が得られるはずである。
心理学では、このように単に相関関係を確認するだけではなくて、
属性(e.g., 男性・女性)によって相関関係が違うことを調べることも重視される。
たとえば、適性処遇相互作用(ATI: Aptitude Treatment Interaction)
といった概念は教育効果の測定では基本中の基本である。
さて、上記の相関関係の考察からさらに一歩進めて、
「共通する内在変数(潜在変数)」
という概念について少し考えてみよう。
カール・ルイスのように走り幅跳びでも100m走でもメダルを取るような選手がいるし、
最近?でもマリオン・ジョーンズ選手のような女性が存在する。
すなわち、
100m走のタイムと走り幅跳びの距離とは相関関係にあるといえるであろう。
このような場合には、
一方の変数を原因・結果と見なすのは間違いで、
両者のパフォーマンスを支える「脚力の強さ」という2つの現象に共通した変数を考えるべきであろう(図1参照)。
図1.因子分析的なモデル(SEMライク?)
心理学の分野では「脚力」のように抽象的で測定(定義・定式化)することが難しい要因を、実際に目に見ることができる現象の原因と想定して研究を進めることがある。
この場合の因果的予測の方向性は「脚力から100mのタイムや幅跳びの距離をを予想する(脚力=外生的な潜在変数)」ことになるだろうが、実際の方程式の中では逆向きの「100mのタイムや幅跳びの距離から脚力を予想する(脚力=内生的な潜在変数)」となっても構わない。
どちらの方向の方程式を採用するかは研究目的と照らし合わせて決めるべき問題である。
他にも、理科系の学力とか文科系の学力など、直接観測はできないけど想定しておくと便利な潜在変数というのが心理学では沢山ある。
たとえば、受験時の試験科目として5教科が課せられているとして、
その中で、どの教科の得点が入学後の取得単位状況にどのような影響を持つのかを考えるようなときには、
この手の潜在変数を含んだ分析モデルを考える必要があるだろう。
入学試験(センター試験や内申書を含む)の重みづけは、その学部・学科の学力モデルを具現化したものとも言えるので、
受験で課している科目と入学後のカリキュラムとがミスマッチを起こしているかどうかを考察するときにも、
こういった潜在変数を含んだ思考方法は便利である。
更に別の例を挙げるならば、朝食を食べる児童は学力が高いという「相関関係」が存在するらしいが、
朝食を食べたからといって、学力が上がると素直に信じる人は誰もいないと思う
(しかし、マスコミに発表されるときには、
この相関関係が因果関係として提示されるので…ヘンテコな話として流布される)。
裁判官が餓死したり、欠食児童が多数存在していた時代ならイザ知らず、今の日本でこの関係が因果関係でないのは明らかであろう。
この場合には、社会的な階層性とか、家庭の教育力とか、
「隠れた学力 (hidden curriculum)」を共通する潜在変数として想定すべきであろう。
話を整理すると、要するに、心理学では、
観測可能な変数(観測変数:
observed variable)と、
観測することが難しい変数(潜在変数:latent/unobserved variable)
という二つの異なる種類の変数を扱うことがあるといえるだろう。
因子分析などで頻出の因子(factor)が代表的な潜在変数の例であり、
これは正確に書くと、共通因子(common factor)と表現されることもある。
観測された変数(観測変数)どうしの共変動が相関関係であったばあいに、
その相関関係を成立させている原因(潜在変数)を明らかにするための分析が因子分析であると言い換えることができるかもしれない。
調子に乗って少し脱線すると、観測された変数の変動
(説明的に書くと質問紙の中の各項目のバラツキ=分散)は、
共通因子とそれ以外(独自因子:
unique factors)から説明可能と見なすのが、因子分析の基本的な考え方である。
つまり、潜在的で観測できない変数には、系統的にまとめることができる共通因子と、
そうでない独自因子(誤差)の二つが存在するということである。
そして、それぞれがどの程度観測変数に影響を持っているかを分かりやすく?表現したモノが、
因子負荷量(factor loadings)と因子パターン(factor pattern)である。
前者が直交回転(orthogonal rotation)をしたあとの結果、
後者が斜交回転(oblique rotation)をしたあとの結果に相当している
(斜交回転をしたときには、因子間相関係数も忘れずに)。
どちらの回転を選ぶかは、モデル(仮説)と照らし合わせて検討すべきことなので、
分析をする人間が決めてよい。
しかし、
先行研究が沢山おこなわれているような状況でない限り、一般論として、
いきなり直交解を求めるのはあまり好ましくないかもしれない。。。
なぜならば、
互いに独立した因子であるという仮説が必要とされるから。
cf. 心理学論文の典型例
また、知能研究などで典型的に当てはまる話であるが、
こういった潜在変数は、どうしても操作的な定義(operational definition)にならざるをえない。
質問紙の中で全ての観測変数を網羅することは事実上不可能であるため、
その状況で観測可能な項目が、
その潜在変数の実質的な定義になってしまうからである。
つまり、本当は、潜在変数に関わる全ての要素を測定すべきであるが、
それは実行不可能なので、
「知能検査で測っている内容が知能である」といった操作的な定義になってしまうということである。
逆にいうと、心理検査で測っている内容は、一般的に極めて限定されたものであるということである。
そして、後述するような妥当性の問題がでてくるのである
(研究者が独自の理論・モデルにもとづいて知能を定義することは自由だが、
それが妥当かどうかは別の話ということ)。
だから、心理学が占いよりも当たるかどうかというよくある質問も、
当たるときもあるだろうし、当たらないときもあるだろうという回答になるのである。
cf. 講義資料: 知能指数、心理検査・心理テスト
蛇足ながら、分析手法としては、
前者のモデル(潜在変数を元に予測)では因子分析
ないしは共分散構造分析(SEM)を利用するのに対して、
後者(潜在変数を予測)では主成分分析とか
重回帰分析を用いることが多い。
予測(推定)をするときには常に誤差がついてまわるので、
誤差項(独自部分、攪乱変数など)がどこにあるのかに着目すると、それほど混乱しないで済むと思う。
実際に、重回帰は
Y=p1X1+p2X2+qE
といった数式として、主成分分析は
Y=w1X1+w2X2
といった数式として、それに対して因子分析は、
X1=a11F1+a12F2+d1U1
といった数式として表現される。(HTMLで強引に書くのには若干無理があるけど…)
また、ここまでパス図的な思考に慣れてくれば、ニューラルネットワーク的なモデルにあと一歩のところまできたことになる。
意欲的な人は、ぜひそちら方面にも手を出してみて欲しい。
この辺りはすっかり自分のことを棚に上げて書いていますが…。
切断効果と曲線相関
相関関係を考えるときに見逃してはならない効果として切断効果(breakage effect)
、
群合併の効果、
曲線相関(curvilinear correlation )などがあります。
たとえば、国語と英語とは相関があると思われますが、成績上位のクラス、中位のクラス、下位のクラスといった感じにクラス分けをおこなったときには、各クラスにおける相関係数は全てひっくるめた形で計算したときよりも相関が低い値になるでしょう。
また、同様に国語と英語の成績の相関を見ようとしたときに、
入試後の成績データを用いた相関係数と、
入試前の成績データを用いた相関係数を考えてみましょう。
おそらく不合格者のデータがあるため後者の入学前の相関係数の方が高いことが予想されますが、
このような母集団の性質を考えた上で相関係数の高さを考える必要があるということです。
難しい言葉で言い換えると、相関関係を分析するときには、
「等質性をもつと想定できるように区分せよ」となりますが、
このような「外れ値」の混在に気がつかないことによる誤読は、
Simpson's Paradoxともよばれています。
そして、相関係数を求めるときには基本的に直線の相関関係を想定して計算しますが、
必ずしもそのような前提が成り立たない場合もあることに注意が必要とされます。
たとえば、間歇強化のように強化子(renforcer)が毎回必ずしも提供されない状況(ギャンブル場面)において、行動の強化ががもっとも強く働くことが知られていますが、このような状況は直線相関ではなくて曲線相関の状況といえるでしょう。
しっかり朝食の子、6割が「学校楽しい」・千葉大教授ら調査
本当かどうかは分からないけど・・・。こんなニュースが流れていました。
マスコミって恐ろしいですよねえ。
基本的には、階層性の問題(隠れた学力 or 文化的再生産)として論じるべき話であるのに、
いつの間にか「早寝、早起き、朝ご飯」が
学力を高めると論じられるようになってしまっています。
主食と主菜、副菜、一汁の4品がそろった朝食を食べている小学5年生の61.8%
が「学校がとても楽しい」と感じていることが28日、千葉大の明石要一教授(教
育社会学)ら研究者グループが2006年に実施した調査でわかった。朝食が不足し
ている子どもは生活の夜型化の傾向が進んでいることも明らかになった。
食事などが子どもの生活リズムに与える影響などを調べている明石教授らの調
査研究会が実施。06年9月、東京や鳥取など1都2県の小学校4校の5年生計231人を
対象に調べた。  (07:00) 
http://www.nikkei.co.jp/news/main/20070529AT1G2803928052007.html
他にも、たとえば文科省が行っている全国学力調査では、
秋田県、福井県、石川県、富山県といった日本海側の県が上位を占めてます。
このとき、これらの県では、持ち家住宅敷地面積、持ち家率、共働き率、米生産量などが
高いことが知られています。
つまり、学力を目的変数とおいたときに、持ち家住宅敷地面積、持ち家率、共働き率、米生産量などを
説明変数とした重回帰分析を行えば、おそらく高い説明率が得られるでしょう。
しかしながら、はたしてそれらの要因が学力と因果関係として成立しているかというと、
ほとんどの人は違和感を感じるでしょう。
こられの県でどのような教育的取り組みをしているのか考えるのが自然でしょう。
TV shows make you fat
このタイトルはThe Japan Timesの記事で見かけたものですが、
有り得ない因果関係を利用して読者の興味を引きつけている点で、
記事としてよくできていると思います。
は元ネタでしょうか…。
Entertaining TV shows make you eat more
--- Distracted brains don't notice how much you're shoveling into your
mouth
It seems that distracted brains do not notice what the mouth is doing,
said Dr. Alan Hirsch, neurological director of the Smell and Taste
Treatment and Research Foundation in Chicago.
http://www.msnbc.msn.com/id/19014841/
(2007.06.06)
直訳すれば、「テレビ番組があなたを太らせる」というニュースですが、
因果関係の誤謬がいくら一般的でも、
テレビを見ているだけではカロリーを摂取できないのは明らかです。
モニタから発せられるある種の電磁波を受けることで
カロリーの消費が著しく低減すると推論することも可能かもしれませんが、
これも、あまり賛同は受けないでしょう(そもそも不健康ですし)。
この場合には、テレビの視聴時間と肥満度の関連性を成立させているような、
何か別の要因が存在することが容易に分かるでしょう。
要するに、娯楽番組を見ていると(テレビを見ながら)食べていることを忘れてしまうので、
普通の状態よりもより食べてしまい、結果的に太るということです。
おそらく、テレビを見ている時間が長いと運動不足にもなるから、
そういう加算効果もあるでしょう。
つまり、この現象も、
特定の生活スタイルをもつ視聴者層という潜在変数的な考えが有効である事例になっているような気がします。
グラフと表
実はこのセクションは息子@小学6年生の宿題をみていて思い立った箇所です。
ですから、基本的には小学校高学年くらいで身についていなければならない知識であると言えると思いますが、
意外と難しい内容も含んでいるかもしれません。
たとえば、折れ線グラフと棒グラフの使い方の違いや、4次元グラフの作り方など、
他の人に口で説明しようとすると意外と困ることがあります。
ということで、このセクションは息子に説明したときの備忘録という雰囲気があるかもしれませんが、
グラフ作成の基本的事項の整理として読んでいただけると幸いです。
先ずはじめにグラフ作成において重要なポイントは、軸(変数)の性質を定めることにあります。
たとえば、変数が
連続量(continuous quantity)なのか、
離散量(discrete quantity)かでだいぶ扱いが変わります。
連続量の代表例は、時間や重さといった単位が候補として挙げることができるでしょう。
別の言い方をすると、データの順序を変えることができないような順序尺度(Ordinal scale)が相当してるといえます。
それに対して、離散量の代表例は、性別、県名、所属クラブといった、いわゆる質的な変数を挙げることができるでしょう。
これらはいわゆる質的なデータ、名義尺度(Nominal scale)とよばれるもので、
尺度水準(scale levels/levels of measurement)でいうともっとも低いもので、
距離的な情報量が少ない尺度であります。
質的な変数に対する対義語として、量的変数とか数量データといった呼ばれかたもあります。
なお、距離的な情報量がもっとも多い尺度は比率尺度(Ratio measurement)とよばれるもので、
次に間隔尺度(Interval scale)、
順序尺度(Ordinal scale)、
名義尺度(Nominal scale)と続きます。
このうち、平均値を求めてもかまわない尺度は間隔尺度以上の尺度水準とされていますが、
理論的には、5以上の範囲をもつものであれば順序尺度でも(一応)大丈夫であるとされております。
(参考:萩生田・繁枡,1996 順序つきカテゴリカルデータへの因子分析の適用に関するいくつかの注意点 心理学研究, 67, 1-8)3件法と4件法あたりがグレーゾーンと考えられているようですが、
4件法くらいがぎりぎり無難なところ?
順序尺度の場合は、たとえばAさんが1着、Bさんが2着、…Pさんが9着といった具合に9名走ったとしましょう。
そのときに、9名全体の平均タイムを計算することは、直感的におかしいと感じると思います。
それに対して、9名それぞれのタイムをストップウオッチなどで計測した場合には、
9名全体の平均タイムを計算することはきわめて自然なことに感じされるはずです。
ちなみに、離散量=名義尺度の話のときに良く出される冗談として、
食べ物の好みで、「洋食傾向」と「和食傾向」の話がよく出てきます。
そして、その中間点=平均値は???と話を振って・・・中華???となるかどうか、
要するに、平均値を求めて良い尺度はどんな尺度なのかという話につながっているわけですが
…もちろん、爆笑するほど面白い話ではなくて、仕方がないから聞いてやるみたいな感じでしょうか…orz
このあたりの話は、後述する心理尺度作成のときにも関係するので、
少し注意が必要かもしれません。
ひとまず、分布が偏っていたりした場合には、色々とチェックして測定のポイントが一定間隔であることを確かめた上で、
平均値を使うと良いと思います。
場合によっては、中央値や四分位偏差値等を見ておく必要があるかもしれません。
そして、脱線ついでに話をすると、
箱ひげ図(平均値を中点とし、箱の上を平均+1標準偏差、
箱の下を平均−1標準偏差で作り、ヒゲの上を最大値、ヒゲの下を最小値)等を作成すると良いかもしれません。
(※正規分布しているときには、平均値±1標準偏差のあいだに約70%の値が含まれる)
また、一口に平均値といってもいくつか異なるものが含まれています。
ただし、たとえば、普通にいわれている平均値は算術平均と呼ばれているものですが、他にも幾何平均、調和平均、
さらには移動平均などもありますし、
中央値といった概念も重要だと思います
(
算術平均・幾何平均・調和平均の関係
)。
可能であれば、標準偏差の概念とあわせて理解しておいた方がよいと思われます。
たとえば、データの分布が左右称であることを想定しがちですが、
大きい値の方向で見た偏差と、小さい値の方向で見た偏差を
区別して考える必要があります。
つまり分布が歪んでいる場合には、
平均値と標準偏差の代わりに中央値や四分位偏差値を要約統計として
利用する必要があることもあるということです。
次に、その変数が独立変数か、従属変数かも重要なポイントです。
独立変数とは、ひとくちで言うと実験などで操作して変更する要因となるでしょう。
そして従属変数とは、独立変数が変化した結果生じた変化、つまり、
原因結果といった因果関係でいうと結果に当たる部分といえるでしょう。
この2次元の組み合わせでいうと、
(連続量・離散量)×(連続量・離散量)という格好になります。
このとき、離散量×離散量の場合はグラフではなくて表(table)として表現するのが一般的だろうと思います。
データをパーセントで表示するのが多く見受けられますが、表のかたちで示すときにはできれば実人数を使った方が
無難だろうと思います。
そして、独立変数が離散量で従属変数が連続量の場合は棒グラフ、
独立変数が連続量で従属変数が離散量あれば折れ線グラフないしは棒グラフが一般的だろうと思います。
具体的にいうと、勉強スタイル(離散量)とテスト得点(連続量)だと、棒グラフで表現されることが多いと思います。
年齢(連続量)と食事の好み(離散量)だと、複数の線からなる折れ線グラフが使われることが多いと思います。
独立変数、従属変数ともに連続量であれば、散布図になる可能性がでてきます。
たとえば、身長(連続量)と体重(連続量)の関係をグラフで表すときは散布図を使うことが多いでしょう。
ところで、散布図と棒グラフは非常によく似ていると思いまいますが(そうでもない?笑)、
決定的に違うのが棒線グラフの場合にはX軸が階級(離散量)になっているところにあります。
つまり、連続量であるものを無理矢理階級として表現すると棒グラフになるわけですが、
このとき、連続量を離散量的に「美しく」表すテクニックとしてスタージェスの公式というものがあります。
まあ、この公式に頼らなくても、常識的には階級のインターバルはせいぜい5個〜20個くらいになるだろうと思いますが…。
ちなみに、0次元の世界は普通は点だけの世界で、1次元は直線の世界で、
2次元は2つの直線によって構成される面の世界で、3次元は立体の世界といわれています(いわゆる現実世界)。
このとき、次元の基準を構成できる座標軸の数と考えれば、
4次元グラフ!というのを書くことも容易になると思います。
たとえば、身長(連続量)と体重(連続量)の関係をグラフで表すときは散布図になるわけですが、
これを性別(離散量)という軸を導入すれば3次元のグラフができますが、
更にこれに人種(離散量)という軸を導入すれば、
理屈の上では4次元のグラフができるわけです。
しかし、我々人類は3次元の世界に生きている生物なので、
一般的にグラフもやはり3次元ぐらいに留めておく方が望ましいかと…(笑)
グラフ・表作成のTIPS
以下のTIPSは「図表の作り方が身につく本」永山嘉昭著(高橋書店)を参考にまとめました。
※上述した離散量、連続量もあわせて考えた上でグラフや表を作成してください。
その他のTIPSとして
グラフにデータラベルやタイトルを付ける方法があります(日経パソコン)。
円グラフは割合を示す:
棒グラフで割合を示すのは無理がある。
それぞれ異なったグループ間の
(e.g., 県、国、民族など)の特徴を
構成比の異なりとして表すときには、
それぞれレーダーチャート(風配図)のような図形として表現すると分かりやすくなる。
表のどこに注目すべきか分かりづらいときには、思い切って棒グラフなどのグラフにすべき。
折れ線グラフよりも、棒グラフの方が「大きさ」が分かりやすい。
棒グラフの並べ方は、
読み手にも分かる並べ方(メッセージ・意図)を意識すべき。
項目の文字数が多い場合は、横棒の棒グラフにすべき。
例:引きこもりの理由
折れ線グラフは推移を表現するのに適している(棒グラフは量を示すもの)。
折れ線グラフは相対的な変化を把握するためのものなので、
「0」を表示しなくてもかまわない。( 棒グラフは「0」を省略しない)
折れ線グラフにおいて折れ線は4本程度にする:
折れ線が増えすぎたときには、関連のあるものに分けて分割すべき。
グラフは立体的なものよりも平面的に表した方が見やすい。
(パワーポイントなどの)プレゼンテーションでは、
グラフにメッセージや注釈を入れた方が分かりやすい。サンプル
信頼性と妥当性
信頼性(reliance/reliability)とは測定の精度を意味し、
妥当性(validity)とは測定された内容が意図したものとどれだけ一致しているかを意味している。
心理学者は、尺度の標準化(standardization)をおこなうことが好きな人が多いので、
信頼性と妥当性は知っておいた方がいいでしょう。
さて、その尺度が、何のためにあるのか…という素朴な疑問はさておいて、
信頼性の高い尺度では、その尺度の個別的な項目間で一貫性があるはずである。
たとえば、ある質問項目でYesと回答した被験者は、同じ尺度内の別項目でもYesと回答するはずである。このような一貫性をチェックする尺度として、クロンバックのα係数があるが、これ以外にも以下のような様々な分析手法が存在する。
心理尺度を作成するときには、相互に相関が高い項目を選び、
項目数を増やすことによって
尺度の信頼性(一貫性とか内的整合性:internal consistency)を高めるのが基本的な手続きである。
G-P分析(Good−Poor Analysis)
たとえば、合計得点の高低によって被験者を分割する。どの項目についてもその平均値は上位群の方が下位群より高いことが予想される(逆転項目などは適宜変換しておく)が、高低双方のグループの平均値を計算し、グループ間で平均値の差の検定(e.g., t検定)を行えば有意な差が見られるはずである。理想的には、上位軍、下位群で差が見られた項目のみを残して、それ以外は尺度から取り除く操作も考えられ得るが、相対的な差の大きさによって判断するのが普通である。
I-T相関分析(Item-Total Correlation Analysis)
尺度得点の高い被験者は、それぞれの項目でも高いと予想される。項目得点と尺度得点との相関係数を見て、あまりにも低い項目は尺度から取り除く。
たとえば、尺度得点に対する相関係数(の絶対値が)が0.3未満であるような項目は、
尺度の整合性を考えると不良項目と見なされても仕方がないであろう。
そして、この値が0.2未満である場合には、よほどのことがない限り尺度に含めることはないと思う。
S-P表(Student-Problem Table)を用いた分析
S-P表は主に成績評価の関係で用いられることが多いが、
この分析は(Yes/No)で回答するタイプの一般的な心理尺度のチェックにも適用可能である。
被験者を縦軸(尺度得点の高低でソートする)にとり、
横軸に問題の難易度(正解数やYESの数でソートする)にとって、
回答パターンを分析する(もちろん、縦軸・横軸は入れ替えてよい)。
たとえば、中程度の難易度であっても、
高得点群も低得点群も同じように間違っているような変な問題があったりする。
つまり、高得点群・低得点群を識別する力の低い問題(項目)といえるであろう。
このような問題は、S曲線とP曲線のズレとして検出され、
到達度を測る問題として不適切である可能性が高い
(実際には、曲線ではなくて、
ガウス関数のような階段状のラインになり、
ガタガタなラインが大きくずれる部分を集中的に分析することになる)。
関連する概念として、項目反応理論(item response theory)がある。
折半法(Split-half correlations/method)
尺度全体を同等と見なすことのできる2つの尺度に折半し、
それぞれの観測値(尺度得点)間の相関係数を求めれば、
これを信頼性の指標とすることもできるであろう。
同様の発想に基づいた検討方法としては、再検査法(test-retest method)
や平行検査法(parallel test method)がある。
クロンバックのα係数(Cronbach's coefficient alpha)
上記の折半法には、
折半する方法が1通りではないという問題がある。
すなわち、
可能な全ての折半方法を考慮した信頼性の推定値を求めた方が適切であることが分かるであろう。
このような推定値がクロンバックのα係数である(単にα係数と呼ばれることが多い)。
α係数の値が1に近づくほど一貫性が高い尺度といえるので、
一般的な利用上の目安としては、
0.7〜0.8を目指して各下位項目を付けたり外したりしていくことになる。
ただし、本当にα係数が1になる状況というのは、
尺度内の質問項目相互の相関が1になるような状況である。
つまり、同じ質問項目がずらっと並んでいるような状況だから、
基本的にはありえない話である。
理想的な尺度(項目群)とは、それぞれ似たようなことを聞いているんだけど、
微妙に違っているような項目群で、項目間の相関もだいたい.4〜.6
くらいで、項目数も5個くらいの、そんなイメージだと思う。
測定しようとしている対象が曖昧な場合がほとんどであろうから、
複数の項目で幅広い領域をカバーすることが重要であることと関係している。
以上のように、(古典的な)テスト理論(test theory)に基づけば、
尺度の信頼性はある程度自動的にチェックできる。
しかし、尺度の信頼性が高いことと、
測定している内容が妥当であることとは基本的に別の話である。
「信頼性は妥当性に包含される」と言い換えることができるかもしれない。
たとえば、I-T相関分析を行ったり、
尺度内の各下位項目を付けたり外したりしてα係数が高くなる条件を探ることもできるし、
S-P表を作成して識別率の低い問題をテストから除外することもできるようになる。
しかし、
測定しようとしている概念と尺度とが論理的に対応しているかどうかは保証されていない。
つまり、信頼性を高めようと努力した結果、
尺度が特定の内容に偏った質問項目ばかりになってしまうこともあり得るわけである。
このような問題は論理的妥当性の問題、
内容的妥当性(content validity)の問題と呼ばれている。
たとえば、国語のテストを作っていたつもりなのに、
いつのまにか道徳のテストになってしまったという笑えない話はよくあるかもしれない。
また、心理尺度を作成する目的、質問紙を作成する目的を考えると、
更に別の妥当性の問題もでてくることもわかるであろう。
たとえば、何か新しい心理尺度を作成するときには、
普通は既に存在する別の尺度との関連性を調べたい場合がほとんどであろう。
その動機は様々であるが、
ある特殊な集団と別の集団との識別を容易にするために新しい尺度を作成することは、
実用面で重要な意味をもつだろう。
このような研究状況で重視される妥当性として、
基準関連妥当性(criterion-oriented validity)が存在する。
ここから派生する概念としては、
予測的妥当性(predictive validity)と併存的妥当性(concurrent validity)がある。
この妥当性は、
新たに作成した心理尺度と既存の心理テストの相関を調べたり、
何か別の独立変数を設定してG-P分析を行ったりすることによって検証される。
たとえば、学習方略に関する尺度を作成したならば、
学業成績の高低で被験者を分割し、
優秀者と劣等者を独立変数として各項目得点に差が見られるかをチェックする必要もあるだろう。
なお、
上記の妥当性に関するチェック項目(内容的妥当性、
基準関連妥当性)は項目分析以外にも、
尺度得点全体についても検証が必要とされる項目であるのはいうまでもない。
たとえば、探索的な因子分析を行うと、
どんなにいい加減に作った質問紙でも最低一つはもっともらしい因子が発見(捏造?)される。
しかし、
当然のことながらその因子が本当に実在するかどうかの保証は全くない。
また、いくら真面目に作成した質問紙によって測られても、
その因子が本当に実在すると言っても良いかどうかは、
その後の追加研究によって検証をまたなければならない。
そして、その因子の実在性やもっともらしさを検証する方法として、
たとえば、特定の因子得点を従属変数とした分散分析やχ二乗検定などがしばしば実施されるのである。
cf.
χ二乗検定の説明
テキストマイニングとビッグデータ
心理学関係ではあまり馴染みのなかった用語として「テキストマイニング」と「ビッグデータ」があります。
これらはマーケティングの世界や計量言語学で主に使われてきた言葉たちと思われますが、インターネットの普及や検索技術によって、膨大なテキストデータが存在するようになり、心理学の世界でもそれを統計的に分析する必要性が出てきました。つまり、このような膨大なテキストデータという「ビックデータ」をどのように科学的に分析するのかという問題が生じることになったということです。
2012年の時点では未使用のものが多くありますが、
これからは質的調査を量的に可視化させるツールという観点で考えると頻繁に利用される技術となるかもしれません。
ビッグデータの活用とは、個人の属性に基づいた行動データを大量に集め
マーケティング等に活用することを意味することが多いと思います。
たとえばテキストマイニングとは既存の質問紙法のように単純な5件法のような数量データではなく、
アンケートの自由記述データのような文章のような質的データを分析するための手法と言い換えることもできるでしょう。
この場合には記述データを語彙分析(形態素解析Morphological Analysis)して、
しかる後に何らかの統計的な分析をすることが多いと思います。
形態素解析とは、言葉の意味の最小構成要素に分け、それぞれの品詞を判別する
作業を意味します。
もちろん人手によって品詞を判別し、キーワードを抜き書きすることも可能ですが、相手はビックデータ(大量のデータ)であるため普通は何らかの形態素解析プログラムを利用することになります。
形態素解析プログラムを利用して機械的に分析することには、
キーワードを恣意的に取り出さないという副次的なメリットもあるでしょう。
いずれにしても、
これによって、原文を読まずに膨大なテキストからキーワードを切り出すことができるようになるわけです。
入手可能なフリーの形態素解析プログラムとして、
和
布蕪(MeCab) や
茶筌(Chasen) 、
Tofu
などが有名です。
他にも、KH Coderという
内容分析(計量テキスト分析)パッケージや
Tiny TextMiner 
もあります。
ここ最近の流行でいうと(2012年の時点では)フリーの形態素解析プログラムとしては和布蕪がもっとも使われているように思われます。
Tiny TextMiner には解説本がありますので、
こちらの方が取扱いが便利かもしれません。
しかし、個人的な一押しのソフトはKH Coderです。双対尺度法、クラスター分析、共起ネットワーク、多次元尺度などを網羅していて、これ一本でほとんど全てのテキストマイニングができてしまいます。これがフリーであるのが信じられないくらいです。
さて、一般的に形態素解析によって得られる品詞情報の中でキーワード(内容語)となる重要な品詞は、
名詞、動詞、形容詞、形容動詞などが考えられるでしょう。
そして、キーワードの同異義語(thesaurus辞書)をあらかじめ考えておいた方が無難なことが多いかもしれません。しかし、このあたりの対応は研究の文脈によって変わりうるかもしれません。
たとえば、「予習と復習」「復習と予習」「予習・復習」「予習して復習する」
など、予習と復習に関する概念をどのように表現するかは多様です。
何をどこまで同義語と考えるかは、その後の処理に大きな影響を持つので慎重に判断する必要があります。
しかし、このキーワードの同定については、語用論的(pragmatics)な問題とか意味論的(semantics)、な問題など、さまざまな曖昧性が常につきまとっているので、単語を同定しても1つの概念に絞り込めることができにくいという問題があります。
たとえば、用いられている状況・文脈によっては、ことば=意味という一定の定義が成り立たないことがあり得るわけです。
「仙台で大雪」であったとした場合に、それが「大学入試の当日」なのか、「スキーに行く日」なのか、それぞれの文脈によって大雪が意味している概念が語用論的に全く異なります。
他にも、同一の単語に対して同一の意味があるかというと、比喩、暗喩、直喩など様々なバリエーションがありうることから分かるとおり、意味論的な立場でもキーワードの曖昧性の問題は根深いといえるでしょう。
ひとまず、以上のような文脈・意味・構文解析ができていれば表現が違っても同じ意味をもつ文章を同定できるわけですが、現状ではそこまでの形態素解析は簡単にはできないようです(これは自動翻訳の世界?)。
上記の意味同定に関する問題を含みながらも、
形態素解析の手続きにしたがって、
ようやく客観的にそのキーワードの重要性を統計的に証明する準備が整うわけです。
基本的には、数値化されたキーワードの出現頻度情報をもとにして分析を行います。
そして、複数のデータがともに同じデータに出現することを共起と呼びます。
一般的には、単純な頻度分析でなく、単語と単語の共起、データと単語の共起などを調べた分析を行いますが、
このような分析手法をクロス分析または共起分析と呼びます(派生概念として、双対尺度法やクラスター分析を用いた分析を行うこともあります)。
しかし、この点に関しては非常にあっさりしているというか、逆に
数少ない特定の重要な言葉を拠り所にして判断するのではないというのが、意外な落とし穴といえるかもしれません。
つまり、キーワードの出現頻度とは別にした
重要性判断は行われないため、テキストマイニングに関しては人間の直感的な判断が意外と重要視されるということです。
この部分には質的研究ぽいところが残されていると言い換えることができるかもしれません。
さて、その後の統計的な分析としては、
単純な頻度表(ヒストグラム)、クロス表、
相関ルールを分析するもの、
クロス集計分析、時系列分析、コレスポンデンス分析(双対尺度法)、
強い仮説がある場合には、判別分析も適応可能なようです。
他にも、
「アソシエーション分析」(同時に出現する単語間の関連性を見る分析)や、
「クラスター分析」(テキスト間の類似性からグループ化する分析手法)などもあります。
ここでは、データをグループ分けする統計手法としてよく使われる
クラスター分析にしぼって概要を説明します。
一般的に、クラスター分析において入力データとしての非類似度はあまり重要視されておらず、クラスター間の距離をどのように定義するかが分析の中での中心的な問題とされます。そして、クラスター分析では個々のデータの距離は類似度ではなくて原則的に非類似度で計算されます。その手続きを簡単に表すとこのようになります。
(参考文献:言語研究のための統計入門、石川,前田,山崎(編),くろしお出版)
データをそれぞれ1個のクラスターと考える。
全クラスター(個別データ)間でもっとも距離が近い2つのクラスターを、新しいクラスターに融合(agglomeration)する。
新しいクラスターと残りのクラスター間で距離を再計算する。
上記の手順2と手順3を必要な回数だけ反復する。
全クラスターが融合された時点で分析を終了する。
たとえば、ある種の質問紙の自由記述欄があったとして、そこの中でのキーワードの出現頻度がえられたとします。
このとき、ある文章と同じ文章の類似度はS11=1とし、
非類似度はD11=1-S11=0と考えます。
これと同様に、同じキーワードの出現頻度をそれぞれ代入していけば、それぞれの文章の類似度(S)と非類似度(D)が計算できるようになるわけです。
参考:文章AとBの距離
次に、クラスター間の距離を求めるときにもっとも使われているウォード法について簡単に説明します。
たとえばクラスタAとクラスタBを合併して、新たにクラスタCを作るときに、情報の損失量の増加分を計算して決定する方法がウォード法(Ward method)です。
凝集型の手法 (aggregative hierarchical clustering) は、一般的に分類対象の非類似度行列から計算をはじめ、
一番近いクラスター同士を融合します。これによって新たに形成されたクラスターと
他のクラスターとの非類似度を再び計算し、また最も近いクラスター同士を融合する、といった手続きを繰り返します。
ウォード法を数式的に模擬的に表すと、Δ=ScーSaーSbとなるときに情報の損失(Δ)が少なくなるように、クラスタを融合していくことになります。
情報損失量=ユークリッド平方距離が普通は利用されますが、
ウォード法はまとまりの良いクラスタが出来るため利用されることが多いクラスタリング方法となってます。
実際には、凝集型の手法には他にも最長距離法、最短距離法などいくつかの方法が存在しますが、これらはクラスター間の距離の順序しか持っていません。
そのためクラスタリング合併の判断が難しくなります(参照: 前川, 1988; 心理・教育のための多変量解析法入門〈基礎編〉渡部洋 (編著) )。
それに対して、ウォード法ではクラスター間の距離の値(Δ)そのものが判断指針となるうるため、その点で相対的に優れています。
すなわち、ウォード法では偏差平方和の増分Δに注目してクラスターの分け方を考察していくことができるようになります。
分析に利用した変数それぞれについて、クラスターごとの平均値に差があるのか、
一元配置の分散分析をあらためて行うことも可能です
(クラスター=群に分けて、各群の平均と分散を用いて計算するTukey法等の
多重比較を用いて群間の差を比較・検定も可能)。
さて、長々とテキストマイニングに関して話を書き進めてきましたが、
教育関係における具体的な応用方法について少し書いてみたいと思います。
たとえば、単元の前、中盤、最終段階でポートフォリオを構成させたとして、それぞれの記述データを形態素分析をして、そこから出てきたキーワードについてクラスター分析を行うことができるかもしれません。
ポートフォリオや授業評価アンケートにおける記述データなどは質的研究として客観的な考察の対象になりにくかったと思いますが、
これらの質的なデータを量的に可視化させるための方法としてここで説明したようなテキストマイニング(具体的にはクラスター分析等)などを利用できるかもしれません。
テキストマイニングのデータとしては、生徒の主観的な授業感想やポートフォリオの記述データを含むことができるので、
これらをある程度の客観性をもって記述できるようになれればかなり大きな進歩といえるのではないかと思います。
もちろんテキストマイニングの作業によっても、言語の曖昧性を完全には払拭できないし、非定型の自由文から話者の意図やニーズ、認識構造を把握することは困難なので、その部分に関しては質問の仕方を工夫する必要があるかもしれません。
たとえば、完全な自由な形で記述してもらうのではなく、ある程度回答形式を指定したような定型自由文のようなものを要求するのも1つの手だと思います。原因、理由、結果などを分けて質問するのも良いでしょうし、文章を完成させる方法や、言葉に対して連想させる方法、ロールプレイングさせる方法など、半構成式の質問を駆使しても良いかもしれません。
双対尺度法
双対尺度法(dual scaling)には(似たような)別名が沢山存在します。
コレスポンデンス分析(correspondence analysis)、対応分析、数量化理論Ⅲ類(quantification method of the third type)、最適尺度法、等質性分析とも呼ばれることがありますが、いずれもクロス表を分析するときに利用される統計手法となっていて、
クロス分析(共起分析)をするときに利用されます。
【参考資料:「事例で学ぶテキストマイニング」、上田太一郎監修、共立出版】
【サンプルとして、2013年度教育心理学会総会の要旨を載せてみました。】
このクロス表(別名、分割表:Contingency Table/Cross Tabulation)を分析するときには、まずはじめに、似たデータを近くに、似てないデータを遠くに配置するような格好でデータの並べ替えを行います。
このように、行列の項目を移動させて配置を変更すると、対角線上に数値が高いデータが集まるようになります。
続いて、表を構成する行列のそれぞれに変数名を与えてみます。
行X:X1, X2, X3, ... Xn、
列Y:Y1, Y2, Y3, ... Yn
このとき、X(i)とY(i)の相関係数rの2乗ができるだけ1になるように未知の尺度を推定します。
つまり、双対尺度法とは、このrが最大になるように、割り当てる数値X(i)とY(i)とを求めるものであるといえます。
これは結果的に、固有方程式(eigen equation)を計算することになります。
(参照:双対尺度法による分割表(Contingency Table)の分析)
なお、双対尺度によって求められた結果は、以下のようなポイントに注意して解釈した方がよいようです。
参照:コレスポンデンス分析@マクロミル
軸に意味づけをした方が、結果の解釈がしやすい。この場合、意味がつけやすいように軸を回転させてもよい。
関連の強いカテゴリは近くに、弱いカテゴリは遠くにプロットされるが、
これはあくまでカテゴリ間の相対的な関係で、絶対的なボリュームを表わすものではない。
縦軸の目盛りと横軸の目盛りはあわせた方がよい。そうしないと距離を見誤ることがある。
ただしこのとき、縦軸と横軸の選んだ軸の固有値(あるいは寄与率)に注意する必要がある。
クロス集計表から作成しているので、サンプルサイズは結果に反映されない。
サンプルサイズが少ない際には注意が必要。(ブランドイメージを質問するときなど、認知者だけに質問すると、ブランドごとのサンプルサイズが異なるので注意する。例えば、Aブランドは認知者が10人で、5人が「はい」と答えて50%、Bブランドは認知者が100人で、50人が「はい」と答えても50%で、この差は結果に反映されない。)
異なる項目のカテゴリの位置関係は、原点からの方向で判断する。原点から見て同じ方向にあれば、一見距離があっても、同様の意味づけが可能である。
お薦めの図書など
やはり、数式というか数学的知識はある程度必要。
紙と鉛筆を持って自分で証明をしながらじっくりと読まない限り、
統計学を理解するのはたぶん厳しいでしょう。
ただ、
線形代数(固有値と逆行列)くらいまで勉強しておくと色々と楽になるのは事実だけど、
基本的な道具立ては高校の数Ⅱくらいまでで十分でしょう。
高校生の頃の勤勉さを思い出して取り組めば、
それほど大変ではないと思います。
むしろ、
高校で勉強した内容を実際に使うので、
なんで勉強させられていたのかがスッキリするはずです。
自分が収集したデータを自分で分析すると、
具体的に何をやっているのかがよく分かるし、
「辛くて辛くてタマラナイ」といった状況にはなりにくいような気がします。
余談ですが、拙論文に「最大瞬間学力のパラドクス」という論文があります。
そこの中では「勉強すればするほど学力残存度が低くなる」恐るべき傾向が示されていますが、
しかし、学習時に利用目的が明示されると学力残存度が高まる希望も示唆さています。
『心理統計学の基礎』 南風原朝和著、有斐閣、ISBN: 4641121605
2300円
ここ最近わりと評判のよい本のようです。
入門書としてはたぶん一番手堅い本だと思います。
「心理学のためのデータ解析テクニカルブック」 森敏昭・吉田寿夫編、
北大路書房、3000円前後(?)、ISBN:4-7628-0131-3
この本はいわゆるクックブック的なカテゴリに分類されると思うけど、
説明も(比較的)丁寧で、基礎から色々な統計手法まで幅広く網羅されています。
とりあえず、これ一冊でたいていの分析ができる基本書といえるでしょう。
「実践心理データ解析」 田中敏著、新曜社、3000円前後(?)
ISBN:4-7885-0577-6
この本を読んでも分析結果の書き方が分からないという人は、
おそらく何を読んでも分からないと思う。
それくらい物凄く丁寧に分析結果の書き方が示されている。
ただし、統計学の基礎から説明した本ではないので、
純粋に統計学を勉強するのには適さないかも知れない。
「調査法講義」 豊田秀樹著、朝倉書店、3000円
ISBN:4-254-12731-6
質問紙の具体的な作り方から始まっていることも素晴らしいが、
一番お勧めしたいポイントはほとんどの公式に丁寧な証明が示されている点です。
自由度の証明など、重要だけどつい見落としてしまう概念(横においておく?)
もきちんと言及されているので、とてもお勧めです。
あとがきもしっかり読んで、
大学ではどのような勉強をすべきか考えてみてください。
「心理・教育のための多変量解析法入門」基礎編と事例編 
渡部 洋 (著)、福村出版: 基礎編 ISBN 4571200374、事例編 ISBN 4571200463
心理学における多変量解析の教科書として大変よくまとまっていると思います。
この2冊を使って院生の頃に多変量解析を勉強しました。
邪道編?
鳥瞰図を得たうえで個々の統計的概念をマスターすることは悪い手ではありません。
特に各種の統計技法をどのように使うのか、その見通しを立てた上で勉強するのは、
やる気の面でも重要かもしれません。
ということで、あくまでも「分かったつもり」になれるためのマンガとして、
以下の二冊を紹介しておきます。
マンガそのものとしては、もしかしたら非常に微妙かもしれませんが…。
「マンガ統計手法入門」
石村 貞夫 (著), 高橋 達央、
価格: ¥1,365 (税込)
出版社: シーエムシー出版 ; ISBN: 4882310074
「マンガ必殺!統計攻略法—どうしても有意差を出したいあなたに」
鍵和田 京子 (著), 石村 貞夫 (著), さいとう はるき、
価格: ¥1,680 (税込)
出版社: シーエムシー出版 ; ISBN: 4882317621 
Web上の情報
以下のページを見逃すのはとても勿体ないと思う。
統計科学のための電子図書システムのWebページ:
統計学の書籍が丸ごと載っています。
絶版された書籍ばかりですが、ここだけでほとんど全ての情報を入手できるはずです。
それぐらい驚異的な情報量です。
逆に言うと、だから本の格好で持ってないと不便だとも言えるわけで…。
Ths Statistics Homepage
: 基本的にはStatisticaという統計ソフトのマニュアルですが、非常に充実しています。
Statisticaというソフトはグラフ機能がとても優れていて、
院生の頃からずっと使っているソフトです。
おそらくSPSSよりもグラフ機能は優れていると思います
(もちろん、Excelよりも 笑)。
群馬大学社会情報学部青木先生
香川大学経済学部堀先生
心理統計いろいろ
:村山航さんが公開しているページです。
信頼性、妥当性についてよくまとめられていると思います。
簡単だけれどもとっても重要な計学の話
