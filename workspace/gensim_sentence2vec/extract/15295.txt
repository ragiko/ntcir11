【0002】【従来の技術】ニュース番組へのリアルタイム自動字幕付与を目的として、大語彙連続音声認識の研究を行っている。これまで、音響モデルとしては混合正規分布型のHMMを使用してきた［今井他,ニュース番組自動字幕化のための音声認識システム,音声言語情報処理研究会,23−11,pp.59−64(1998.10)］。Tree−based  clustering［S.J.Young,Tree−based  state  tying  for  high  accuracy  acoustics  modeling,Proc.ARPA  Human  Language  Technology  Workshop,pp.307−312(1994)］を使用した混合正規分布型のトライフォンHMMの学習では、モノフォンの初期モデルをトライフォンにし、状態共有化されたトライフォンHMMを作成する［世木他,状態共有トライフォンHMMの学習における決定木とモデル数の検討,音講論集,3−Q−3,pp.123−124(1999.9)］。その後混合数を一つずつ増加していく。
【0003】【発明が解決しようとする課題】この間HMMの構造を変化させるたびに、音響モデルの種となる初期の音響モデルからEMアルゴリズムを数回繰り返して音響モデルの正規分布の数を少しずつ増加させるのが通常である。したがって、最終的なHMMを得るまでにEMアルゴリズムを多数回繰り返す必要があり、音響モデルを生成する場合の学習時間の削減が課題と考えられる。なお、EMアルゴリズムについては「パターン認識と学習のアルゴリズム」、上坂吉則他著、文一総合出版、pp129〜132を参照されたい。【0004】そこで、本発明の目的は、音響モデルの生成時間を低減することが可能な音声認識用音響モデル生成装置および記録媒体を提供することにある。
【0005】【課題を解決するための手段】  このような目的を達成するために、請求項1に記載の発明は、時間区分された音響ラベルファイルおよび該音響ラベルファイルに対応した音声データから音声認識で使用する音響モデルを生成する音響モデル生成装置において、前記時間区分された音響ファイルに基づき同一ラベルに属する音声データを抜き出し、当該抜き出された音声データを分割する分割手段と、当該同一ラベルごとに分割された音声データから音響モデルを生成する手段とを具え、前記分割手段は分割された音声データの数がほぼ等しくなるように分割を行うことを特徴とする。【0006】  請求項2に記載の発明は、請求項1に記載の音声認識用音響モデル生成装置において、前記分割手段は、音声データの特徴が類似するものを集めることにより前記抜き出された音声データを分割することを特徴とする。【0008】  請求項3の発明は、コンピュータに実装されているプログラムであって、時間区分された音響ラベルファイルおよび該音響ラベルファイルに対応した音声データから音声認識で使用する音響モデルを生成するためのプログラムを記録した記録媒体において、前記プログラムは、前記時間区分された音響ファイルに基づき同一ラベルに属する音声データを抜き出し、当該抜き出された音声データを分割する分割ステップと、当該同一ラベルごとに分割された音声データから音響モデルを生成するステップとを具え、前記分割ステップでは分割された音声データの数がほぼ等しくなるように分割を行うことを特徴とする。【0009】  請求項4の発明は、請求項3に記載の記録媒体において、前記分割ステップでは、音声データの特徴が類似するものを集めることにより前記抜き出された音声データを分割することを特徴とする。
【0011】【発明の実施の形態】以下、図面を参照して本発明の実施形態を詳細に説明する。【0012】本実施形態では以下の音響モデル生成手順を用いる。すなわち、1状態共有した後、あらかじめアラインメント付けされた学習データを数個のクラスタに分割する。2分割された学習データを用いてHMMのパラメータを直接計算する。【0013】このような生成手順を使用した実験の結果、本実施形態では従来法よりも学習速度の向上に効果が得られた。【0014】以下に、より詳細な音響モデルの生成方法を説明する。【0015】(1)音響モデルの作成生成1  初期音響モデルを利用し学習データのアラインメントをとり、各学習データとモデル、状態の対応関係を得る。【0016】2  各トライフォンの各状態で学習データの平均と分散を計算し、Tree−based  clusteringを行い、状態共有を行う。【0017】3  共有されている各状態に属する学習データに対し、学習データ数をなるべく等しくするように2分割していく。この操作を3回繰り返し、8分割にする。【0018】4  分割された学習データで平均と分散を計算し、これをHMMの正規分布の平均と分散とする。重みは全て1/8とする。【0019】学習データの分割時に必要となる距離LS(Xt)は対数尤度を使用した。【0020】【数1】【0021】ここで、Xtはtフレーム目の特徴ベクトル、μS、ΣSは状態クラスターSの平均と分散、nは特徴ベクトルの次元数である。【0022】学習データは、2つのクラスターで対数尤度が大きい方に属するとしたが、各クラスターで学習データ数をなるべく等しくするため以下の処理を行った。【0023】片方のクラスターに属する学習データが分割前のデータ数の半分になったときには、残りのデータを暫定的に他方に属することにする。このように2分割したクラスターごとに新しい平均と分散を計算し、これらを使ってデータを再度分割する。このような手順を、対数尤度が小さい方に属した学習データの数の変化がある閾値以下になるまで繰り返す。【0024】(2)従来法との学習時における処理時間の違い今回の行った手法と従来法との学習時における処理時間について考える。それぞれの処理で、主な部分を占めるのが正規分布の出力確率の計算であるので、出力確率の計算回数で比較することにする。【0025】従来のEMアルゴリズムでは連結学習であるため、アクティブになっている状態の数だけ出力確率を計算する必要がある。一方、今回の手法の場合は、あらかじめアラインメントをとり学習データとモデルの状態を対応つけてしまうため、その状態だけで出力確率を計算すればよい。【0026】また、1つの状態で出力確率で計算する時に、従来のEMアルゴリズムでは、その状態の混合数の数だけ正規分布の出力確率を計算する必要がある。一方、今回の手法の場合は、混合数を増加させても2分割であるので、距離の計算は2つのクラスターでしか計算しない。したがって、計算する正規分布の数は絶えず2つである。【0027】以上の理由により、EMアルゴリズムの場合に比べて、本手法では計算時間を大幅に短縮できる。【0028】(3)認識実験上記音響モデル生成方法に従って認識実験を行った結果を以下に示す。(3.1)  音響モデル(3.1.1)  音響パラメータ使用した音響分析パラメータは以下のとおりである。【0029】【表1】【0030】(3.1.2)  学習データ学習データとしては、ニュースデータベース、および24人の男性アナウンサーにより発声されたバランス文20892文、54.6時間を使用した。いずれも発声者は男性のみである。(3.2)  言語モデル言語モデル学習データは91.4.1〜99.10.27までのニュース原稿を使用した。総文章数120万文、総単語数6850万語である。語彙の大きさは20Kで、バックオフスムージングにはGood  Turingを使用している。(3.3)  デコーダー(音声認識装置)2パスのデコーダで、1パス目はbigramで200best文を出力し、2パス目はtrigramでリスコアリングし一番良いスコアの文を出力する。(3.4)  評価データ評価データには99.10.28のニュースの男性アナウンサーによるクリーンスピーチ162文(5889単語)を使用した。第1パスはbigramでパープレキシティ79.26、第2パスではtrigramでパープレキシティ35.69、OOVは0.90パーセントである。【0031】(4)認識結果(4.1)  従来法との比較両手法とも、初期音響モデルとして、アナウンサーが読み上げたバランス文2461文に人手でモデルの区間付けを行ったラベルから作成したモノフォンの音響モデルを使用した。【0032】本手法で作成された音響モデルを使用したときの認識率と、従来法により作成された音響モデルを使用した認識結果を表2に示す。【0033】【表2】【0034】従来法と本手法と認識率の差はほとんどなかった。本手法の学習に必要な計算時間は、従来法の約40%まで、短縮された。【0035】また、本手法で作成した音響モデルから2回EMアルゴリズムで出力確率(平均、分散、重み)と遷移確率を再推定した場合の認識結果を表2の中段に示す。EMアルゴリズムでパラメータの再推定を繰り返すことにより、認識率が上昇することが分かる。(4.2)  アラインメントによる認識結果の比較本手法では初めに区分されたラベルファイルが必要であるが、そのラベルファイルが高精度である方が、生成される音響モデルも高精度になると考えられる。そこで、従来法により作成したトライフォンHMM(認識性能としては表2下段)をアラインメントに使用して音響モデルを作成した。結果を表3に示す。【0036】4.1で述べたモノフォンによるアラインメントで作成した場合と比べ認識率が改善された。さらに2回EMアルゴリズムを繰り返したが、認識率はほとんど改善されなかった。【0037】【表3】【0038】(4.3)  混合数による変化混合数を8から16、32に増やした認識実験を行った。16混合と32混合で認識実験を行った結果を表4に示す。アラインメントには4.1で述べたモノフォンの音響モデルを使用した。8混合の認識実験と同様に、混合数を変えても、本手法で作成した音響モデルと従来法による音響モデルとで認識率はほぼ同じになる。本手法のあとに再推定を繰り返すことにより認識率が上昇するのも、8混合の時と同様である。【0039】学習に必要な計算時間は、32混合の時で従来法の約10%となり、かなり短縮されていることが分かる。【0040】【表4】【0041】(5)結論今回の実験より、本手法が従来の作成方法よりも早く音響モデルを作成することができ、従来とほぼ同等の認識率が得られることを示した。また、本手法でパラメータを推定した後にEMアルゴリズムを2回行うことにより、最初のアラインメントをとる音響モデルによらず従来法と同等の認識率が得られることを示した。【0042】上述の音響モデル生成方法を適用した音響モデル生成装置を次に説明する。【0043】音響モデル生成装置としてはパーソナルコンピュータなどの市販の各種の汎用コンピュータを使用できるのでハード構成の説明は簡単に留める。本実施形態では市販のコンピュータに後述の音響モデル生成用のプログラムを実装することにより、市販のコンピュータが音響モデル生成装置として機能する。【0044】図1は汎用コンピュータの概略構成を示す。図1において、CPU10はシステムメモリにロードされた音響モデル生成プログラムを実行して音響モデルを生成する。【0045】システムメモリ20は、CPU10が実行する音響モデル生成プログラム、このプログラムの実行のために必要なデータ、演算結果等を一時記憶する。【0046】入出力インターフェース(I/O)30はマイクロホンと接続し、音響モデル作成のための音声データ、この場合、音声信号を上記学習データとして入力する。マイクロホンからはアナログの音声信号が出力されるので入出力インターフェース30において、音声信号はCPU10が処理可能なデジタル信号に変換される。【0047】ハードディスク40は、上記音響モデル生成プログラムを保存目的で記憶する。入力装置50の中には、CPU10に対してコマンドを入力したり演算に使用する情報を入力するための以下の機器、すなわち、キーボードおよびマウス、および音響モデル生成プログラムが記録された記録媒体、たとえば、CDROMから音響モデル生成プログラムを読み取るハードディスクドライブが含まれている。【0048】ディスプレイ60は入力装置50から入力された情報等を表示する。なお、本発明にしたがって生成した音響モデルを使用して音声認識を行いたい場合には、ハードディスク40に音声認識プログラムをインストールすればよい。【0049】また、生成した音響モデルを専用の音声認識装置に転送したい場合には、通信インターフェースを用意すればよい。【0050】記録媒体からハードディスク40にインストールされた音響モデル生成プログラムは入力装置50のマウス等の指示に応じてCPU10によりシステムメモリ20にロードされた後、CPU10により実行される。以下、CPU10により実行される音響モデル生成処理を図2を参照して説明する。図2は音響モデル生成プログラムの処理手順を機能表現したフローチャートである。音響モデル生成プログラムは、C言語、C++言語等各種のプログラム言語で記載可能であり、当業者であれば、本願明細書の記載に基づき実際に使用するプログラムを作成可能であろう。【0051】図2において、時間区分されたラベルファイル、すなわち、アナウンサーなどが発話する内容をローマ字読みなどの文字で表現し、音韻の区切りを示す区切り記号を含むラベルファイルは、キーボード、フロッピーディスクなどから入力され、CPU10によりシステムメモリ20の専用領域内に一時記憶される(ステップS10)。【0052】次に、上記ラベルファイルと同じ内容を有するアナウンサーの音声がCPU10の制御によりマイクロホンからI/O30を介してシステムメモリ20の専用領域に一時記憶される(ステップS20)。【0053】CPU10は上述した音声データ分割方法にしたがって、同一のラベルごとに、音声データを抜き出し、その特徴が類似するもの同士を集めることにより同一のラベルの音声データを複数回の分割処理により複数の集合に分割する。分割された音声データはシステムメモリ20の作業領域に一時記憶される(ステップS30)。【0054】最終的に得られた平均と分散の値が音響モデルの値として、システムメモリ20の作業領域上に生成される(ステップs40)。【0055】上述の実施形態の他に次の形態を実施できる。1)上述の実施形態では、クラスタリングと呼ばれるデータ分類方法を使用して特徴が類似する音声データ同士を集めて音声データ全体を複数の集合に分割した。しかしながらクラスタリングに限らず、他の周知の分割方法を使用してもよい。2)上述の実施形態では音響モデル生成プログラムを記録した記録媒体としてCDROMを例示したが、他の携帯用記録媒体でもよい。また、ハードディスク、ICメモリなども本発明の記録媒体の概念の中に含まれる。3)上述の実施形態では、汎用コンピュータにより音響モデル生成装置を実現したが、これに限ることはなく、IC回路やCPU等を搭載したボードの形態で音響生成装置を実現してもよい。4)上述の実施形態では、デジタル音声信号を音声データとして処理したが、デジタル音声信号を音響分析し、その分析結果を音声データとしてもよいこと勿論である。【0056】以上、述べた実施形態に限らず、種々の変形が可能である。しかしながら、このような変形が、本願の特許請求の範囲に記載された技術思想に沿うものである限り、その変形は本発明の技術範囲内となる。
特願2000-283478
