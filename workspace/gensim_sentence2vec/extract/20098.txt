音声中の検索誤検出のための複数の音声認識結果を用いたネットワーク型インデキシング(山梨大)10種類の認識器で音声を認識し、その音素出力を組み合わせてネットワーク型のインデックスを作り、DPベースで検索をする。単一の認識器のN-bestを利用する場合よりも複数の認識器を組み合わせた方が性能が上がる。複数認識器をさらにN-best化しても性能は上がらない。大規模音声ドキュメントからの高速キーワード検索法の提案とその評価(豊橋技科大)新田先生のところ。音声言語シンポジウムで聞いた話のような気がする。サフィックスアレイを使った音素認識結果からの単語検出。そのまま探索すると探索空間がでかいので、検索単語の音素系列を短く切って検索した後、DPで検出結果をつなげる。また、検索をしながら徐々に閾値をゆるめることによって、最初から候補数が爆発するのを防ぐ。転置インデックスを使う方法よりも高速かつ使用メモリも少ない。ホームビデオからのハイライト検出支援のための音声情報の視覚化(KDDI研)古井研との共同研究らしい。携帯端末から手軽に動画投稿するための環境開発が目標のようだ。携帯で動画撮影は簡単だが編集はめんどくさいので、それを手軽にやるために、音声情報を視覚化する事によってハイライトが「見てわかる」ようにする。ハイライトだけ抽出して短いビデオクリップを作るのは「短尺化」というのか。音声やテキストでいえば要約に当たる作業だよね。人間の要約作業結果から、人の声と突発音が重要らしいことがわかった。実際の視覚化についてはこれから検討。音声ドキュメント検索語検索における音響情報を用いた再評価(立命館大)山下先生のところ。音素ベースの単語検出をした後、その部分を音響的に再照合して検証をする。まあ考えるよね。完全に音響マッチングベース(音節列HMMと音節列+キーワードHMMの尤度差)に比べて6倍早い。検出性能は音響ベースよりちょっと低いが、音素ベースよりはかなりよい。音響マッチングによる再評価を発話全体でやっているので、かなり効率は悪いはず。最後に秋葉先生がNTCIRのアナウンス。来年は音声検索タスクが入るらしい。
9/15 音響学会 音声A午後前半まとめ | aitoの日記 | スラッシュドット・ジャパン
