顔認識システム(かおにんしきシステム、Facial Recognition System)は、デジタル画像から人を自動的に識別するためのコンピュータ用アプリケーションである。ライブ画像内の顔と思われる部分を抜き出し、顔面画像データベースと比較することで識別を行う。
一般にセキュリティシステムのために使われ、指紋認証システムや目の虹彩認識システムなどの他の生体認証と対比できる[1]。
セキュリティシステム以外にも様々な利用方法が考案されている。
2001年1月のスーパーボウルで、フロリダ州タンパの警察は FaceIt を使って、入場者に犯罪者やテロリストが混じっていないか探し[2]、逮捕状が執行されていない19人を見つけた[10]。
2000年の大統領選挙で、メキシコ政府は偽者による投票を防ぐため、顔認識ソフトウェアを用意した。一部の個人が複数の名前で登録されていて、複数票を投じようとしていたためである。新たな顔の画像と投票者データベースに既にある画像を比較して、二重投票を大幅に減らした[11][2]。アメリカでは同様の技術が、偽のIDカードや免許証の入手を防ぐのに使われている[12][13]。
他にも顔認識の新たな利用方法がいくつか開発されようとしている。例えば、ATMでのセキュリティに使うことが検討されている。つまり、キャッシュカードと暗証番号の代わりにATMが顔の画像を撮影し、データベース上の顔の画像と照合するのである。同様の考え方は、インターネット上の各種サイトへのログインにも応用できる。[2] また、他には、内蔵したカメラを用いて、撮影した人物が成年か未成年を判別し、成年にのみタバコを販売する自動販売機も実用化されている。
マデリン・マクカーン失踪事件の捜査の一環として、イギリスの警察はポルトガルの Paria da Luz のホテル Ocean Club Resort とその周辺地域を事件のあった2007年5月3日までの2週間以内に訪問した人に対して同地で撮影した写真の提供を呼びかけている。これは顔認識によって誘拐犯が写っていないかを調べるためである[14][15]。
生体認証としての利用以外に、最近のデジタルカメラは被写体の顔を認識し、焦点をそこに合わせたり、露出を合わせたりできるものが多い。さらに表情を認識して笑顔を確認したら自動的に撮影するといった機能もある。
比較研究[編集]
他の生体認証技術と比較すると、顔認識は最も信頼でき効率がよいとは言えないが、対象の協力を必要としないという重要な利点がある。空港などのシステムは群集の中から犯罪者を見分けることができる。指紋、虹彩、音声などによる認証では、このような使い方はできない。しかし、セキュリティという観点での有効性には疑問の声もある。
その他の利点としては、一般的に普及している安価なカメラを使用することができる点(既存の監視カメラ・ウェブカメラなどをそのまま利用できる)、顔画像が証拠として残るため不正利用者等が発覚した場合に記録された顔画像を人が見ることで個人を特定することが容易である点(顔以外の生体情報(例えば指紋など)は、その画像を人が見て個人を特定することは困難)などが挙げられる。
批判[編集]
認識率[編集]
顔認識は完全ではなく、条件が整わないと認識率が低くなる。カーネギーメロン大学ロボット工学研究所の Ralph Gross は顔の撮影された角度について「顔認識は真正面から顔を捉えるのを基本とし、そこから20度までは何とか認識できる。しかしそれ以上横向きになると問題が生じる」と説明している[6]。
他にも画面が暗い場合、サングラスをかけている場合、髪が伸びている場合、何かで顔の一部が隠れている場合、解像度が低い場合などに認識率が極めて低くなる[2]。
また、表情が変わると認識できないことが多い。カナダではパスポートの顔写真は無表情でなければならないとしている[16]。
有効性[編集]
技術評論家たちは、ニューアムに実際にデータベースに登録されている犯罪者がいたにもかかわらず、システムが犯罪者を一人も認識していないことに批判的である[17][18]。これは、顔認識システム導入による 34% の犯罪件数の低下という情報と矛盾しているが、犯罪の予防という観点で、バーミンガムでも同様のシステムが導入された[19]。
フロリダ州タンパでの警察による実験でも、同様の期待外れの結果となった[20]。
ボストンのジェネラル・エドワード・ローレンス・ローガン国際空港でも顔認識システムによるテロリスト識別という大規模な実験が行われたが、失敗に終わった[21]。
プライバシー問題[編集]
この技術の潜在的な利点を考慮したとしても、プライバシー侵害という懸念が残っている。政府が国民1人1人を常に監視し、行動を把握するようになるのではないかと憂慮する者もいる。権力がそのような暴走を引き起こす可能性があることは、歴史が証明している[22]。
日本国内における批判[編集]
主に首都圏所在の商業システムや大規模マンションに設置された顔認識システム搭載カメラのうち29台について、利用者や通行人などに対し断らないまま撮影が行われていることが明らかになっている。視聴者の性別・世代を分析し顧客分析に利用する目的があるとされており、カメラ設置業者側は「個人を特定しておらず問題はない」と主張しているが、有識者の間からは「商業目的では納得の行かない人も多いし、何らかの形でのルール整備が必要だ」などとの批判的な意見が多く聞かれる[23]。
情報通信研究機構は、JR西日本などの協力を得て、大阪駅構内の大阪ステーションシティに多数の顔認証カメラを設置し、構内の通行人の追跡を実施する実証実験を、2014年4月から実施する予定にしていた。ところが、計画が同年1月6日に報じられると共に、市民らから抗議が多数寄せられるようになり、2014年3月現在、実施の目処が立たない状態となっている。同機構やJR西日本などは「防災目的である」としているものの、勝手に顔を撮影された上、商業目的などに利用されることが懸念されているものと見られている[24]。
最近の改良[編集]
2006年、Face Recognition Grand Challenge (FRGC) にて最新の顔認識システムの評価が行われた。その結果、2002年のシステムに比べると10倍、1995年のシステムに比べると100倍の正確さで認識できることが示された。中には人間のもつ顔認識能力を凌ぐアルゴリズムもあり、一卵性双生児を別人として識別できた[6]。
低解像度の顔画像の解像度を強化する技法として face hallucination がある。また、近年ではカメラ自体が高ピクセル化しており、解像度の問題は解消されつつある。
歴史[編集]
自動化された顔認識システムのパイオニアは、Woody Bledsoe、Helen Chan Wolf、Charles Bisson らである。
1964年から1965年にかけて、Bledsoe は Helen Chan と Charles Bisson と共にコンピュータを使った顔認識に取り組んだ。彼はこの仕事に誇りを持っていたが、資金提供したのが匿名の諜報機関であったため、あまり公けにされることはなく、ごく一部の成果が公表されるにとどまった。大規模な画像データベース(顔写真の本のようなもの)と一枚の写真を与えられたとき、データベースから写真にマッチする少数のレコードを抜き出すことが研究課題であった。手法の成功度は抜き出したレコード数のデータベース全体のレコード数に対する比率で表される。Bledsoeは、その困難さを以下のように述べている。
「この認識問題は頭の上下左右の動き、照度や角度、表情や加齢で大きな変化があることで難しくなっている。機械による顔認識に関する他の試みでは、これらの変化をほとんどまたは全く考慮しなかった。光学的に加工を施さない画像データで相関関係(またはパターン照合)を行う手法を使う研究者もいたが、それらは変化が激しい場合には必ず失敗した。特に、頭の左右の向きが違う同一人物の写真では、相関関係が極めて低い。(Woody Bledsoe, 1966)
このプロジェクトは「マン・マシン」と分類された。というのは、人間が写真から特徴を抽出して、それをコンピュータが認識するのに使ったからである。GRAFACONやRAND TABLETといったペンタブレットを使って、オペレーターが瞳孔の中心、目の内側の端と外側の端、額の中心の生え際などといった特徴点を抽出した。これらの座標から、口や目の幅、瞳孔と瞳孔の間隔など20種類の距離が計算される。オペレーターは一時間に約40枚の写真を処理することができた。データベース構築時には、これらのデータと顔写真の人物名が対応付けてコンピュータに格納された。認識フェーズでは、これら距離データ群が対象となる写真から抽出した距離データ群と比較される。そして、最も近いレコードが回答として出てくる。
この説明は非常に単純化しているので、ほとんどの場合このまま実施すると失敗するだろう。何故なら二枚の別々に撮影された写真で顔の上下左右の向きやカメラとの距離といった条件が完全に一致することはないからである。従って、距離データは顔を真正面から見たときの値に正規化される。この正規化を行うために、プログラムは顔の向きや傾きの数値を決定しようとする。そして、それらの値(角度)を使って、コンピュータは向きや傾きの変化を打ち消して真正面から見た場合のデータを計算する。角度を計算するために、コンピュータは頭の三次元の位置を知る必要がある。実際の頭を使うことができないので、Bledsoe は七人の頭について測定を行い、標準的な頭の位置を求めた。
Bledsoe が1966年にこの研究を離れた後に、この作業は Peter Hart らによってスタンフォード研究所で続けられた。2000枚を超える写真のデータベースの上で実行された実験において、コンピュータと人間の顔認識力比較では常にコンピュータが優れていた。
1997年頃、ドイツのルール大学ボーフムとアメリカの南カリフォルニア大学はマサチューセッツ工科大学やメリーランド大学カレッジパーク校のシステムよりさらに優れた顔認識システムを開発した。ボーフムのソフトウェアは ZN-Face として製品化され、ドイツ銀行や空港で採用された。この顔認識システムは不完全な顔画像でも十分認識でき、口ひげ、あごひげ、髪型の違い、眼鏡やサングラスをつけていても認識可能だとされた[25]。
画像検索には一般に画像への何らかのタグ付けが必要である。2007年1月、Polar Rose は顔認識技術を使って写真から人物の頭部の3次元イメージを約1.5秒で作成し、ユーザーにその人物の名を尋ねることで名前と顔を一致させ、画像検索のタグとして利用するサービスを開始した[26]。
脚注[編集]
顔認識システム - Wikipedia
