今回は,前回の最後で説明したナイーブベイズの応用である「ベイジアンフィルタ」をPythonで実装しながら,実際に確率の計算がどのように行われるかをみていきましょう。
ベイジアンフィルタとは
ベイジアンフィルタとは,ナイーブベイズ(Naive Bayes)というアルゴリズムを利用して,テキストの自動分類などに応用することのできるフィルタの総称です。
このベイジアンフィルタは,現在では様々なところで応用されているのをご存知ですか? 有名なところではメールのスパム判定やブログのカテゴリ分類に利用されています。
例えばベイジアンフィルタによるスパム判定では,事前に手動でメールをスパムとハムというカテゴリに分類しておきます。これにより,メールの傾向を学習し出現する単語から自動的に新しく届いたメールが「スパムメールか否か」と分類できるようになります。つまり,スパムメールに含まれている文字集合と通常のメールに含まれる文字集合の確率を計算し,スパムメールか否かを判断しているのです。
ベイジアンフィルタがメールのスパム判定として利用される契機となったのは『ハッカーと画家』(オーム社)の執筆でも有名なPaul Graham氏が2002年に発表した「A Plan for Spam(スパムへの対策)」という論文です。この論文によって,スパム判定に統計的なアプローチが用いられることが注目されるようになりました。
先述のようにベイジアンフィルタは,事前に与えられたパターン(情報)にしたがって未知の文章を分類します。事前に正しいデータを与え学習を行うので,「教師あり学習(Supervised Leaning)」と呼ばれる機械学習の手法の一つになります。
「教師あり学習」があるということは「教師なし学習」もありそうですよね? 今後の連載の中で「教師なし学習」も紹介する機会があると思いますので楽しみにしていてください。
環境構築
本連載では基本的にプログラミング言語にPythonを使って実装していきます。バージョンは2.6.1を利用します。
Pythonでは大規模な多次元配列や行列をサポートしている拡張モジュール「Numpy」の提供する高水準の数学関数ライブラリ,それを基礎として統計や最適化,線形代数などのモジュールを提供する科学技術計算のためのライブラリ「SciPy」などの数値解析モジュールが充実しているため,数値計算をとても簡単に行えます。
また,グラフモジュールとして「Matplotlib」なども存在しているため,可視化も簡単に行うことができます。
bag-of-wordsを利用したテキスト分類
それでは早速,ベイジアンフィルタの実装を始めていきましょう。ベイジアンフィルタを実現するのは,何度も言及しているナイーブベイズというアルゴリズムです。
ナイーブベイズは簡単な計算でよい結果のでる「いいモデル」と前回紹介されていますが,実装も計算と同じようにそう難しくありません。
今回は,ベイジアンフィルタを利用して文章をそれぞれのカテゴリに分類してみたいと思います。ベイジアンフィルタを文章と文章が属するカテゴリで訓練して,受け取った文章がどのカテゴリに分類されるかを見ていきます。
一般的に文章を分類するためには何が必要になるでしょうか。それは文章に含まれている特徴になります。 今回は文章の中に出現する単語を出現する順番を意識せずに特徴として扱います。このように文脈に依存しない,単語が文章内のどこに登場するか考慮しないようなテキスト表現をbag-of-wordsと呼びます。バッグの中にごちゃごちゃと単語が入っているようなイメージです。
例えば,以下の文章を考えてみます。
文章を形態素に分割する
今回は日本語を含む文章から単語の集合を作るにあたって「形態素解析」を用いることにします。
英文の場合は単語がスペースによって分割されているため,スペースで区切られた文字列を抽出することで単語を取得できます。しかし,日本語にはそのような「わかち書き」の習慣がありません。そこで,形態素解析を用いて文脈の解析や単語の分解を行う必要があります。
形態素解析ライブラリとしてはMeCabやChaSenなどが有名ですが,今回はYahoo!デベロッパーズネットワークの日本語形態素解析を利用してみます。利用するにあたって,Yahoo!デベロッパーネットワークのアプリケーションIDを取得する必要があります。Yahoo!のIDさえ持っていれば,こちらから登録するだけで利用できます。
また,今回はXMLの解析にBeautifulSoupというライブラリを利用しています。BeautifulSoupでは特定のタグの抽出やソートを簡単に行え,多少の文法の誤りを修正してくれるなど比較的柔軟に使うことができます。BeautifulSoupはここからダウンロードすることができます。本稿ではBeautifulSoup-3.0.8を使います。
# -*- coding: utf-8 -*-
import urllib
import urllib2
from BeautifulSoup import BeautifulSoup
appid = 'Yahoo!デベロッパーズネットワークのアプリケーションIDを入力して下さい'
pageurl = "http://jlp.yahooapis.jp/MAService/V1/parse";
# Yahoo!形態素解析の結果をリストで返します。
def split(sentence, appid=appid, results="ma", filter="1|2|3|4|5|9|10"):
sentence = sentence.encode("utf-8")
params = urllib.urlencode({'appid':appid, 'results':results, 'filter':filter,'sentence':sentence})
results = urllib2.urlopen(pageurl, params)
soup = BeautifulSoup(results.read())
return [w.surface.string for w in soup.ma_result.word_list]
リスト1のコードをmorphological.pyという名前で保存します。保存時の文字コードにはutf-8を指定してください。このコードではYahoo!JAPANの日本語形態素解析サービスに入力された文章を渡しています。そして,XMLで返される結果をBeautifulSoupでパースしています。
引数のfilterで解析する品詞の種類を指定することができます。filterに指定可能な品詞番号は以下のようになっています(表1)。
第3回 ベイジアンフィルタを実装してみよう:機械学習 はじめよう｜gihyo.jp … 技術評論社
