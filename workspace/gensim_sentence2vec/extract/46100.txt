線回帰分析は、複数の変数における相関関係を直線モデルによって説明しようとする分析手法です。仕組みをご理解いただくために極めて簡潔なデータを利用しますが、データサンプル数が数万件、変数の数が数十に及んでも考え方は同じです。図6 のデータセットにおいて、x は年齢を、そして y は化粧品会社に対する年間支出額を表しているとします。この 2つの変数にはなんらかの関係があるのか、より具体的には、年齢という変数は、年間支出額を説明できるのかを分析によって探っていきます。
そしてこの表から横軸に年齢(x)を、縦軸に年間支出額(y)をとり、プロットしたものが以下のグラフ(図7)となります。さて、このグラフから読み取れる傾向を 1本の直線で表すと、どのような線になるでしょうか。数学の授業で習ったかもしれませんが、グラフ上の直線は y=ax+b と表すことが出来ます。それらしく直線を引いてみろと言われれば、おそらく各点の上、もしくは最も近くを通る直線を引かれるのではないでしょうか。これを論理的にこなすのが、「線形回帰分析」と呼ばれる手法です。
ここでの命題は「年齢によって、化粧品の支出額に違いが現れるか。もしそうだとすれば、どのような影響が現れるのか。また顧客を獲得した場合、その年齢からどのような将来売上価値が予測できるか」ということです。年齢が化粧品の年間支出額をある程度説明していることが分かれば、それぞれの顧客が今現在支出している金額が妥当な金額なのか、それとも圧倒的に少ないのかが分かってくるため、もっと購買を促す活動をすることも想定できます。また、若年層向けの化粧品とアンチエイジングの化粧品の価格設定に関してもベースとなる知識を得ることが可能となります。そして「どのような影響」を説明しているのがこの y=ax+b という数式です。この数式を言い換えれば「年齢に a をかけて b を足した数値が年間支出額の予測値である」という意味です。図7 に戻ると、これら 4つの点から y=ax+b で説明できる線を引くことが命題となりますし、これを説明するための a と b の値を導き出すことがここでの命題となります。
線形回帰分析の考え方
4つの点が 1直線上に並んでくれれば何も難しいことは無いのですが、このようなケースは現実世界において極めて稀な出来事です。まして、仮にこの命題を実際のデータに対して適用するとき、顧客の数(点)は何百万人になることも考えられます。このような場合においてまず、もっともこのデータを説明している理想的な直線を想像してください。この直線と、それぞれの点はどのような関係になるでしょうか。これを導く考え方が「最小2乗法」と呼ばれる考え方です(最小二乗法、または最小自乗法とも呼ばれます)。まず図8 のように、この直線とそれぞれの点の距離を測ります。この距離の総和、つまり全て足した長さが最も短くなる線を導き出すのが、「最小2乗法」であり、線形回帰分析の背後にある考え方です。
ここで y=ax+b の a は直線の傾きを意味し、b は切片、つまり x=0 時における y の値を意味します。a 及び b に入る数字には数限りないバリエーションが存在しますが、これを導き出すのはコンピューターの役目ですので、取り敢えずここでは気にしないこととします。そして実際の各点と、y=ax+b の直線とのギャップは、残差、もしくは誤差と呼ばれます。仮に y=ax+b が理想的な直線であるとし、x に何らかの値を代入した場合、y が本来取るべきと考える値と、実際に発生している値には違いが存在しています。これを残差と呼んでいます。そしてこの場合における 4点における残差の 2乗が最小になる y=ax+b を求めているのが、最小2乗法ということになります。
2乗する理由なのですが、図7、 図8 で示している幾つかの点は最終的に引かれることになる直線 y=ax+b に対してマイナスの残差を発生させることになります。ここで必要とする残差は y=ax+b への垂直な距離ですので、マイナスの記号が含まれ、他の、プラスの残差を差し引いてしまうことは好ましくありません。このため、その残差自身で 2乗することによってマイナスを消しこみ、一方で残差間の大きさの関係は残したままで利用することになります。例えば残差が -2.0 であるとするならば、(-2.0)(*)(-2.0)=4.0 となり、他の点からの残差との関係を維持しつつ絶対数値として取り扱えるようになります。
残差2乗和の最小化
最初に用意した例の場合、4つの残差が存在することになります。4つの残差の 2乗和を最小化させる、a と b の値を求めるのですが、それぞれは傾きと切片であり、一方の値が決定されなければ、もう一方の値が決定されないというジレンマに陥ることになります。このとき反復解法という手法を用い、このような条件下での a と b の値を求めることになります。反復解法は多くのデータマイニングにおける分析手法において用いられます。データマイニングがコンピューター資源を必要とする理由の一つは、この作業をこなすためです。もちろん全くランダムに a と b の値を入力して計算を行なう訳ではありません。あるアルゴリズムに沿って反復的に計算を行なっていくことによって、最短距離で求める値(ここでは残差の 2乗和を最小化させる a と b の組み合わせ)へ到達することになります。反復解法によって得られた a と b、そして最小化された残差 2乗和が、ご覧の図9 の値になります。これによって得られた y=470x+26,650 が、図7 においてプロットされている各値に対してもっとも近い直線となります。ここから例えば、33歳の方がこの企業に対して年間支出する額が (470(*)33)+26,650=42,150円程度であろうと想定することが可能となり、商品コスト、購入数量、ユーザーとしてこの商品を使い続ける年数等を勘案すれば、この顧客に対して支出可能なマーケティング経費、得られる利益等を想定できることになります。ただし、当然ながらこの例ではシンプルさを保つために、年齢という単一の変数を用いて、かなり乱暴な予測を行なっています。通常はより多くのデータサンプルを用い、またより多くの変数(購入した化粧品の種類、職業、購買サイクル...)を用いて予測を行なうことになります。また、当然ながらこの数式の通り 0歳児が 26,650円の年間支出をするはずもなければ、100歳の方が 73,650円の化粧品支出をするとも考えにくいです。いずれも x に 0 と 100 を代入すればこのような値を得られますが、x に代入して適切な値が得られる範囲には現実的な縛りがあり、それらを前提としてこのモデルを利用する必要があります。
モデルの当てはまり具合
さて、モデルはこのように作成されましたが、このモデルはどの程度信頼できるものなのでしょうか。モデルの信頼性を評価するための指標や手法は幾つかありますが、ここでは代表的な指標として「寄与率」を取りあげます。図9 にてこの値は既に算出してあります。この値は 0 から 1 の値をとり、1 に近ければモデルの信頼度が高く、0 に近ければあまり信頼できないということになります。線形回帰分析における寄与率は、(予測値の分散)/(実測値の分散) にて求められます。またおおよそ、(実測値の分散)=(残差の分散)+(予測値の分散) となるため、1-(残差の分散/実測値の分散) によっても求められます。従って、本来この指標は、予測値の分散が実測値の分散の中でどの程度の説明をしているかを意味しており、(実測値の分散)に対して(予測値の分散)が、どの程度の「寄与率」を持っているかを表しています。従って予測値が良く実測値を説明していれば、それぞれの分散も同じ関係にあり、実測値の分散のほとんどを予測値の分散で説明しており(言い換えれば残差、残差の分散は最小化され)、結果この指標が 1 に近づくということになります。
尚、利用する変数が多くなる場合は寄与率が大きく見積もられる傾向にあるため、「自由度調整済み寄与率」を用います。基本的な計算は同じなのですが、寄与率に用いる予測値の分散、及び残差の分散に関しては分散の分母に用いていた (データサンプルの数-1)ではなく、(データサンプルの数-変数の数-1) を分母に用います。詳細は割愛しますが、これが「自由度調整済み」の意です。
このような線形回帰分析の考え方は、2つ以上の変数を持つ場合にも適用できます。x に相当する変数が 1つの場合には「単回帰分析」、複数の変数の場合(例: x1=年齢、x2=利用年数、x3=年収等)には「重回帰分析」という名称で呼ばれています。例えば 2つの説明変数(x1、x2)と、1つの被説明変数(y)を用いて散布図をプロットするとき、それは3次元空間にて表されます。4次元以降を散布図表現するのは難しいですが、それでもデータ上は同じ考え方を適用して分析を行なっていきます。
(2007年9月18日掲載)
Teradata｜マーケターのためのデータマイニング・ヒッチハイクガイド:第9回:線形回帰分析
