
音声認識装置
【要約】従来例に比較して高い音声認識率で音声認識することができ、しかも安定に動作する連続音声認識装置を提供する。  入力された単語列からなる発声音声の音声信号に基づいて、所定の音響モデルを参照して、上記発声音声を音声認識する音声認識装置において、上記音響モデルは、単語の隠れマルコフモデルにおいて、単語のバイグラムを挿入してなる音響モデルである。音声認識処理において、各時刻において各音声認識候補の累積尤度を計算し、計算された各音声認識候補の累積尤度のうち最大の累積尤度を有する音声認識候補を最適な音声認識候補として検出し、検出された最適な音声認識候補が認識すべき単語の最終状態であるか否かを判断し、最終状態であるときに音声認識結果の単語として出力する。
【目的】従来例に比較して高い音声認識率で音声認識することができ、しかも安定に動作する連続音声認識装置を提供する。
【構成】入力された単語列からなる発声音声の音声信号に基づいて、所定の音響モデルを参照して、上記発声音声を音声認識する音声認識装置において、上記音響モデルは、単語の隠れマルコフモデルにおいて、単語のバイグラムを挿入してなる音響モデルである。音声認識処理において、各時刻において各音声認識候補の累積尤度を計算し、計算された各音声認識候補の累積尤度のうち最大の累積尤度を有する音声認識候補を最適な音声認識候補として検出し、検出された最適な音声認識候補が認識すべき単語の最終状態であるか否かを判断し、最終状態であるときに音声認識結果の単語として出力する。
【背景技術】0002従来、ワードスポッティング型連続音声認識のためのアルゴリズムとして連続ビタビ符号化法(Viterbi  decoding)を用いることが、従来技術の文献「岡隆一,部分整合法の出力へのベクトル連続DP適用による文スポッティング型連続音声認識,電子情報通信学会論文誌,D?II,Vol.J76?D?II,No.5,pp.921?931,1993年5月」(以下、従来例という。)において開示されている。ここで、文のスポッティング認識とは、文と文との区切りを指定しないで文を認識するものであり、実際の会話文などにおける、言いよどみ(これは、文頭、文末の言いよどみで、文中の言い直しまでは対象としない。)、タスク以外の文発声や文の区切りが明確でない場合の文認識に都合のよい方式といえる。この音声認識システムにおいては、基本とする認識の単位を「音素片」とし、それを部分整合法で識別する。次に、音素片の識別結果をベクトル連続DP音声認識法を用いて文へ統合して文認識する。音素片識別を行う部分整合法と文認識を行うベクトル連続DP音声認識法はともにフレーム同期を用いるスポッティングのアルゴリズムといえる。0003この従来例のアルゴリズムにおいては、始端及び終端はフリーであってビタビ符号化処理を実行し、累積尤度の絶対値を用いて音声認識処理を制御している。言い換えれば、累積尤度が所定のしきい値以上のものを最適値として検出している。
【解決課題】0004しかしながら、この従来例のアルゴリズムを用いた場合、設定するしきい値によって音声認識の性能が大幅に変化するという問題点があった。本発明の目的は以上の問題点を解決し、従来例に比較して高い音声認識率で音声認識することができ、しかも安定に動作する音声認識装置を提供することにある。
【解決手段】0005本発明に係る請求項1記載の音声認識装置は、入力された単語列からなる発声音声の音声信号に基づいて、所定の音響モデルを参照して、上記発声音声を音声認識する音声認識手段を備えた音声認識装置において、上記音響モデルは、複数の状態を備え各2つの状態間の状態遷移確率と出力確率とを含む単語の隠れマルコフモデルにおいて、単語のバイグラムを挿入してなる音響モデルであって、上記音声認識手段は、各時刻において各音声認識候補の累積尤度を計算する尤度計算手段と、上記尤度計算手段によって計算された各音声認識候補の累積尤度のうち最大の累積尤度を有する音声認識候補を最適な音声認識候補として検出する比較手段と、上記比較手段によって検出された最適な音声認識候補が認識すべき単語の最終状態であるか否かを判断し、最終状態であるときに音声認識結果の単語として出力する判断手段とを備えたことを特徴とする。
0006また、請求項2記載の音声認識装置は、請求項1記載の音声認識装置において、上記尤度計算手段は、1つ前の時刻における尤度と、1つ前の時刻における状態から処理すべき時刻への状態遷移確率と、音声認識候補に対する処理すべき時刻の音声認識候補の出力確率との積について、1つ前の時刻におけるすべての複数の状態において加算することにより累積尤度を計算することを特徴とする。
0007以上のように構成された請求項1記載の音声認識装置においては、上記尤度計算手段は、各時刻において各音声認識候補の累積尤度を計算し、上記比較手段は、上記尤度計算手段によって計算された各音声認識候補の累積尤度のうち最大の累積尤度を有する音声認識候補を最適な音声認識候補として検出する。そして、上記判断手段は、上記比較手段によって検出された最適な音声認識候補が認識すべき単語の最終状態であるか否かを判断し、最終状態であるときに音声認識結果の単語として出力する。
0008また、請求項2記載の音声認識装置においては、上記尤度計算手段は、1つ前の時刻における尤度と、1つ前の時刻における状態から処理すべき時刻への状態遷移確率と、音声認識候補に対する処理すべき時刻の音声認識候補の出力確率との積について、1つ前の時刻におけるすべての複数の状態において加算することにより累積尤度を計算する。
0009以下、図面を参照して本発明に係る実施例の連続音声認識装置について説明する。図1の本実施例の連続音声認識装置は、特に、One  pass  DP音声認識部6の処理において、各フレームにおいて単語の最終状態における各音声認識候補の累積尤度を比較して最大の累積尤度を有する最適な状態遷移系列に対応する音声認識候補の単語を認識結果とするフォーワード(前向き)符号化(Forward  decoding)法を用いることを特徴とする。ここで、この連続音声認識装置は、図1に示すように、マイクロホン1と、特徴抽出部2と、バッファメモリ3と、入力される発声音声データに基づいてHMMメモリ5内の音響モデルである隠れマルコフもモデル(以下、HMMという。)を参照して単語照合処理を実行して単語データを出力する単語照合部4と、単語照合部4からの単語データに基づいて、One  pass  DPアルゴリズムであるがフォーワード(前向き)符号化(Forward  decoding)法である新しいスポッティングアルゴリズムを用いて、単語音声認識処理を実行するOne  pass  DP音声認識部(以下、音声認識部という。)6とを備える。
0010音響モデルとして単語のleft?to?rigth型(前向き型ともいう。)HMMを用いる一方、言語モデルとして単語のバイグラムを考慮して、これらを組み合わせたモデルである音響モデルを用いて単語音声認識処理を実行する。すなわち、この音響モデルは、単語のleft?to?rigth型HMMにおいて、単語のバイグラムを挿入してなる従来のエルゴディック(Ergodic)HMMと類似した音響モデルとなっており、この音響モデルの一例を図2に示す。図2において、W1乃至W4はそれぞれHMMの単語を示し、B1乃至B6は単語バイグラムを示している。この例では、HMMの単語W1には、3つの状態C11,C12,S13が存在し、left?rigth型HMMを構成している。そして、複数のHMMの単語W1乃至W4が各2つの単語の間でともに連結遷移するように、すなわち予め決められた単語のバイグラムで遷移確率が決定されるように構成されている。言い換えれば、単語のバイグラムの値は、1つの単語のHMMの最終状態の遷移確率を別の単語に接続されたときの値の分配率と考えることができる。そして、音響尤度と言語の連鎖確率の結合値αは1と考えることができる。
0011本実施例においては、特徴抽出部2は入力された音声信号をA/D変換した後、例えばLPC分析を実行しているが、A/D変換後の特徴パラメータのデータはA/D変換のサンプリング周波数に対応して決定されるフレーム毎に処理される。このフレームは、本実施例においては、例えば10ミリ秒又は20ミリ秒であり、処理する時刻に対応している。
0012エルゴディックHMMのパラメータと信号系列(テストデータ)が与えられたとき、最適状態遷移系列を検出する問題を考える。この最適状態遷移の検出方法として、従来例のビタビ符号化法と、本実施例の前向き符号化法とが考えられる。従来のビタビ符号化法においては、検出されたHMMのパラメータが観測系列を出力する可能性の高い最適状態遷移系列は、ビタビ符号化法により効率的に求めることができ、単語系列は最適状態遷移系列から直ちに類推できて検出できる。これに対して、本発明に係る実施例の前向き符号化法は、まず始めに、累積尤度を各状態からの総和で計算する。次いで、最適状態遷移系列は、各時刻における最大の尤度を持つ状態とする。
0013図3に、前向き符号化法を用いる単語音声認識処理のフローを示す。この処理は、図1の音声認識部によって実行される。図3に示すように、まず、ステップS1において、フレームに対応する時刻tに1がセットされる。そして、ステップS2において、次の数1と数2を用いて、すべての状態iに対して尤度を表わすグリッドδ1(i)と最大のグリッドとなる最適状態遷移系列s1を求める。
0014δ1(i)=πi&times;bi(o1)0015ここで、πiは初期状態確率であり、bi(o1)は観測された特徴パラメータo1に対する状態iのシンボル出力確率である。すなわち、状態iにおけるグリッドは、初期状態確率πiと、観測された特徴パラメータo1に対する状態iのシンボル出力確率bi(o1)との積で表される。数2におけるargmaxiδ1(i)は、状態iを変化したときにグリッドδ1(i)が最大となる最適状態遷移系列s1である。ここで、状態遷移系列は、特徴パラメータからなる系列であって、音素列からなる音声認識候補の単語に変換される。
0016次いで、ステップS3において、ステップS2において求められた最適状態遷移状態系列s1が認識すべき単語の最終状態であるか否かが判断される。単語の最終状態であるときは、単語の終端までの複数の音素列からなる単語が認識されたと判断して当該処理を終了する。一方、単語の最終状態でなければ、ステップS4において時刻tを1だけインクリメントして、ステップS5において、次の数3と数4を用いて、すべての状態jに対して累積尤度を表わすグリッドδt(j)と、最大のグリッドとなる最適状態遷移系列stを求める。
0017δt(j)=Σi｛δt-1(i)&times;aij&times;bj(ot)｝0018上記数3におけるΣは1つ前の時刻におけるすべての状態iに対する左辺の｛｝内のグリッドの和であり、上記数4におけるargmaxjδt(j)は、状態jを変化したときにグリッドδt(j)が最大となる最適状態遷移系列stである。数3の左辺の｛｝内のグリッドは、1つ前の時刻における状態iのグリッドδt-1(i)と、状態iから状態jへの状態遷移確率aijと、観測された特徴パラメータotに対する状態jのシンボル出力確率bj(ot)との積で表される。
0019次いで、ステップS6において、ステップS5において求められた最適状態遷移状態系列stが認識すべき単語の最終状態であるか否か、すなわち認識すべき単語の状態遷移系列をすべて含むか否かが判断される。単語の最終状態であるときは、単語が認識されたと判断して当該処理を終了する。一方、単語の最終状態でなければ、ステップS7に進み、時刻tが最後の時刻Tであるか否かが判断され、最後の時刻Tであれば、当該処理を終了し、一方、最後の時刻Tでなければ、ステップS8において状態jを1つの前の時刻の状態iに置き換えた後、ステップS4に戻る。そして、ステップS4からステップS6までの処理を最後の時刻Tになるまで処理する。
0020この処理においては、各時刻において、最適状態遷移系列が任意の単語の最終状態であるとき、単語が認識されたと判断する。この前向き復号法は、各時刻において認識している単語がわかるため、一種のワードスポッティング型音声認識法といえる。なお、図3の処理における時刻はすべてフレームに置き換えることができる。
0021次いで、本実施例における連続音声認識装置の構成及び動作について図1を参照して説明する。
0022図1において、単語列からなる話者の発声音声はマイクロホン1に入力されて音声信号に変換された後、特徴抽出部2に入力される。特徴抽出部2は、入力された音声信号をA/D変換した後、例えばLPC分析を実行し、対数パワー、16次ケプストラム係数、Δ対数パワー及び16次Δケプストラム係数を含む34次元の特徴パラメータを抽出する。抽出された特徴パラメータの時系列はバッファメモリ3を介して単語照合部4に入力される。単語照合部4に接続されるHMMメモリ5内の音響HMMモデルである単語HMMは、例えば図2に示すように、1つのHMMの単語において、複数の状態と、各状態間の遷移を示す弧から構成され、各弧には状態間の遷移確率と入力コードに対するシンボル出力確率を有している。そして、HMMの単語とHMM別の単語とは、単語バイグラムの確率情報で連結されている。単語照合部4は、入力されたデータに基づいて単語照合処理を実行して単語データを、音声認識部6に出力する。
0023音声認識部6は、所定のOne  pass  DPアルゴリズムを用いて、図3の単語音声認識処理を実行することにより、各フレームにおいて単語の最終状態における累積尤度を比較することで認識を実行し、決定された音声認識結果データ(文字列データ)を出力する。
0024本発明者は、本実施例の連続音声認識装置を用いて、音声認識のシミュレーションを行なった。認識シミュレーションには、認識単位として音素のHMMを用い、音素モデルを連結して単語のHMMを作成した。音素HMMの学習データは単語発声のデータを利用した。単語バイグラムの連鎖確率値は、本特許出願人であるエイ?ティ?アール音声翻訳通信研究所の対話データ8475文57354単語からdeleted?interpolation法(削除補間法)を用いてスムージングをした値を利用した。また、計算量を削減するために、各フレームごとにビームサーチを行なった。テストデータには、単語バイグラムの学習に使用したテキストデータと同一タスクの会話38文(総単語数259)を用いた。また、学習データにテストデータのテキストを加えたテキストクローズド(text?closed)のシミュレーションも行なった。なお、以下、学習データにテストデータのテキストを加えない場合はテキストオープン(text?closed)という。このシミュレーショにおける評価は、単語正解率(ワードコレクト)及び単語認識率(ワードアキュラシー)で行なった。その他のシミュレーション条件を表1に示す。ここで、単語正解率と、単語認識率はそれぞれ当該技術分野で既に決められているように、数5及び数6で表される。
0025連続音声認識シミュレーションの条件音響モデル      4状態3ループ混合分布型HMM音響パラメータ  logパワー+16次LPケプストラム                +Δlogパワー+16次Δケプストラム学習用          男性アナウンサー1名、2620単語発声テキストデータ言語モデル      単語バイグラム学習データ数    8475文総単語数        57354認識語彙数      435単語ビーム幅        4096テストデータ    同一話者発声  38文(259単語)発話様式        朗読0026単語正解率={(N?D?S)/N}&times;100［%］0027ここで、Nはすべての単語数であり、Dは脱落誤りの数であり、Sは置換誤りの数であり、Iは挿入誤りの数である。
0028次に、表2及び表3にシミュレーションの結果を示す。これらの表から、従来例のビタビ符号化法と比較すると、単語正解率は低いが、単語認識率は高いことが示された。これは挿入誤りが少ないことを意味している。
0029実施例の前向き符号化法を用いた場合              テキストオープン  テキストクローズド単語正解率        34.0%        36.3%単語認識率        25.9%        29.0%0030従来例のビタビ符号化法を用いた場合              テキストオープン  テキストクローズド単語正解率        54.1%        56.8%単語認識率        20.1%        23.6%0031これらのミュレーション結果から、本発明に係る実施例の前向き符号化法を用いた音声認識処理においては、脱落誤りが多いことがわかる。これは、当該認識アルゴリズムにおいて、「各時刻において、累積尤度が最大の状態が、任意の単語の最終状態であるとき、単語が認識されたとする。」の条件を加えたためである。この条件を変えることにより、脱落誤り率を改善することが可能である。ただし、同時に挿入誤り率も増加する。
0032今回のシミュレーションに使用した音響HMMモデルのパラメータは、音声データ及びテキストデータから個別に計算した。しかしながら、大量の音声データがあれば、バーム?ウエルチ(Baum?Welch)の学習アルゴリズムを利用して直接に計算することができる。また、本実施例の前向き符号化法は、音響hmmモデルのパラメータと信号系列(テストデータ)が与えられたとき、各時刻におけるローカルな最適解を与えることができる復号法といえる。そこで、各時刻におけるローカルな最適性を持たせてHMMのパラメータを学習する方法が考えられる。これに対して、従来例のビタビ符号化法は、テストデータに対するグローバルな最適解を与える復号法といえる。
0033本実施例の前向き符号化法は、エルゴディックHMMだけでなく、一般的なフレーム同期型の連続認識アルゴリズムにも組み込むことができる。従って、言語モデルとして例えばCYKのようなleft?right型のパーザを組み込むことも容易である。
0034以上説明したように、本実施例の前向き符号化法を用いた連続音声認識装置においては、各フレームにおいて単語の最終状態における累積尤度の比較で認識を行なうため、従来例のビタビ符号化法と比較すると、より高い音声認識率でかつより安定に動作することが可能である。特に、挿入誤りが少ない。
0035以上の実施例において、特徴抽出部2と、音素照合部4と、音声認識部6とは、例えばディジタル計算機によって構成される。
【発明効果】0036以上詳述したように本発明に係る請求項1記載の音声認識装置によれば、入力された単語列からなる発声音声の音声信号に基づいて、所定の音響モデルを参照して、上記発声音声を音声認識する音声認識手段を備えた音声認識装置において、上記音響モデルは、複数の状態を備え各2つの状態間の状態遷移確率と出力確率とを含む単語の隠れマルコフモデルにおいて、単語のバイグラムを挿入してなる音響モデルであって、上記音声認識手段は、各時刻において各音声認識候補の累積尤度を計算する尤度計算手段と、上記尤度計算手段によって計算された各音声認識候補の累積尤度のうち最大の累積尤度を有する音声認識候補を最適な音声認識候補として検出する比較手段と、上記比較手段によって検出された最適な音声認識候補が認識すべき単語の最終状態であるか否かを判断し、最終状態であるときに音声認識結果の単語として出力する判断手段とを備える。従って、各時刻において単語の最終状態における累積尤度の比較で認識を行なうため、従来例のビタビ符号化法と比較すると、より高い音声認識率でかつより安定に動作することが可能である。特に、挿入誤りが少ない音声認識装置を実現できる。
0037また、請求項2記載の音声認識装置によれば、請求項1記載の音声認識装置において、上記尤度計算手段は、1つ前の時刻における尤度と、1つ前の時刻における状態から処理すべき時刻への状態遷移確率と、音声認識候補に対する処理すべき時刻の音声認識候補の出力確率との積について、1つ前の時刻におけるすべての複数の状態において加算することにより累積尤度を計算する。従って、従来例に比較して累積尤度の計算を簡単に実行することができる。
【図面簡単説明】0038図1   本発明に係る一実施例である連続音声認識装置のブロック図である。図2   図1の連続音声認識装置において用いる音響モデルの一例を示す状態遷移図である。図3   図1の音声認識部によって実行される単語音声認識処理を示すフローチャートである。
【請求項】
※以下の情報は公開日時点(1996年9月17日)のものです。
請求項1
入力された単語列からなる発声音声の音声信号に基づいて、所定の音響モデルを参照して、上記発声音声を音声認識する音声認識手段を備えた音声認識装置において、
請求項2
上記音響モデルは、複数の状態を備え各2つの状態間の状態遷移確率と出力確率とを含む単語の隠れマルコフモデルにおいて、単語のバイグラムを挿入してなる音響モデルであって、
請求項3
上記音声認識手段は、
請求項4
各時刻において各音声認識候補の累積尤度を計算する尤度計算手段と、
請求項5
上記尤度計算手段によって計算された各音声認識候補の累積尤度のうち最大の累積尤度を有する音声認識候補を最適な音声認識候補として検出する比較手段と、
請求項6
上記比較手段によって検出された最適な音声認識候補が認識すべき単語の最終状態であるか否かを判断し、最終状態であるときに音声認識結果の単語として出力する判断手段とを備えたことを特徴とする連続音声認識装置。
請求項7
上記尤度計算手段は、1つ前の時刻における尤度と、1つ前の時刻における状態から処理すべき時刻への状態遷移確率と、音声認識候補に対する処理すべき時刻の音声認識候補の出力確率との積について、1つ前の時刻におけるすべての複数の状態において加算することにより累積尤度を計算することを特徴とする請求項1記載の音声認識装置。
【技術分野】5D015音声認識
【出願人】株式会社エイ?ティ?アール音声翻訳通信研究所
【発明者】村上  仁一
【出願日】1995年3月6日(19年4ヶ月経過)
【出願番号】1995-045386
【公開日】1996年9月17日(17年10ヶ月経過)
【公開番号】1996-241094
【登録日】1999年10月1日(14年9ヶ月経過)
【登録番号】2986703
【特許期限】2015年3月6日(残7ヶ月)
【状態】特許維持
音声認識装置 特開1996241094
