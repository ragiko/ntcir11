この連載についてマルチコア・システムが至るところで使われるようになった今、これまで以上に幅広く並行プログラミングを適用しなければならなくなっています。しかし、並行処理を適切に実装するのは難しい場合があり、並行処理を利用するための新しいツールも必要になってきます。このようなツールは、JVM ベースの多くの言語で開発されていますが、なかでも Scala は、並行処理の分野で特に積極的です。この連載では、Java 言語と Scala 言語での新しい並行プログラミング手法をいくつか取り上げて検討します。
プロセッサーの速度は数十年にわたって急速に進化し続けてきましたが、その進化も世紀の変わり目あたりで終わりを遂げました。それ以降、プロセッサー・メーカーはチップのパフォーマンスを高める手段として、クロック速度を上げるよりもコアの数を増やす方法を採るようになっています。今や、マルチコア・システムは、携帯電話からエンタープライズ・サーバーに至るあらゆる機器で標準的に採用されるようになっています。この傾向は今後も続き、さらに拍車がかかっていくことでしょう。開発者はますます、パフォーマンス要件を満たすために、アプリケーション・コードで複数のコアに対処しなければならなくなってきています。この連載では、Java 言語と Scala 言語での新しい並行プログラミング手法について見ていきます。そのなかでは、Scala や他の JVM ベースの言語で既に掘り下げてある概念を Java がどのように採り入れているかについても説明します。第 1 回となるこの記事では、JVM における並行プログラミングのより広範な全体像を理解するための背景知識として、Java 7 と Scala での最先端の手法をいくつか紹介します。具体的には、Java の ExecutorService クラスと ForkJoinPool クラスを使って並行プログラミングを単純化する方法を学びます。また、プレーン Java に用意されている並行プログラミングのオプションを拡張した、Scala の基本機能もいくつか紹介します。その過程で、異なる手法によって並行プログラミングのパフォーマンスがどのように影響されるかを理解できるはずです。今後の記事では、Java 8 で改善された並行性を取り上げるとともに、Java および Scala でスケーラブルなプログラミングを行うための (Akka ツールキットをはじめとする) 拡張機能についても説明します。Java の並行性サポートJava プラットフォームの初期の頃から、並行性のサポートは Java の特徴の 1 つであり、スレッドと同期化の簡潔な実装が、他の競合する言語よりも Java を優位に立たせていました。Java をベースとする Scala は JVM 上で動作し、Java ランタイムのすべての機能 (すべての並行性サポートを含みます) に直接アクセスします。そこで、Scala の機能を探る前に、Java 言語が現在提供している機能を簡単に説明するところから始めます。Java の基本的なスレッド処理Java プログラミングでは、スレッドを作成して使用するのは簡単です。スレッドは java.lang.Thread クラスで表され、スレッドが実行するコードは java.lang.Runnable インスタンスの形をしています。アプリケーションに多数のスレッドが必要であれば、数千個でもスレッドを作成することができます。複数のコアを使用できる場合、JVM はそれらのコアを使用して複数のスレッドを同時に実行します。スレッドの数がコアの数を超えている場合は、スレッド間でコアが共有されます。
Java 5: 並行処理の転換点Java には当初から、スレッドと同期化のサポートが組み込まれていました。しかし、スレッド間でのデータ共有に関する初期仕様はまだ万全ではなかったため、Java 5 の Java 言語更新 (JSR-133) で大々的な変更が行われました。Java 5 の Java 言語仕様では、synchronized と volatile を指定したときの動作に修正を加えて正式なものにしています。この仕様では、不変オブジェクトでマルチスレッド処理を扱う方法も詳細に規定しています (基本的に、コンストラクターが実行されているときに、参照を変更することが許可されていなければ、不変オブジェクトは常にスレッド・セーフです)。それ以前のスレッド間でのやりとりには、synchronized を指定してブロック化する処理が要求されるのが一般的でしたが、Java 5 での変更により、volatile を指定することで、スレッド間でのブロック化を行わない調整が可能になりました。その結果、ブロック化を行わない処理をサポートする新しい並行コレクション・クラスが Java 5 で追加されました。このことは、それまでの必ずブロック化を使用するスレッド・セーフ手法に比べると大幅な改善です。
スレッドの動作を調整するとなると、事態は複雑になってきます。複雑な事態の 1 つは、Java コンパイラーと JVM は、プログラムの観点で整合性が失われない限り、コードに含まれる処理の実行順序を自由に変更できることから生じます。例えば、異なる変数を使用する 2 つの加算処理があるとすると、両方の処理が完了するまで、これらの処理の結果を使用しないようなプログラムになっていれば、コンパイラーや JVM は、コードに指定されているのとは異なる順序で処理を実行することができます。このように処理の順序を変更できる柔軟性があると、Java のパフォーマンスを向上させる上では有効ですが、整合性が保障されるのは単一スレッド内でのみとなります。また、ハードウェアもスレッドに関する問題を作り出す可能性があります。最近のシステムでは複数のレベルのキャッシュ・メモリーを使用しますが、一般に、キャッシュはシステム内のすべてのコアに同一に映るわけではありません。あるコアがメモリー内の値を変更しても、他のコアにはその変更が即時に可視にならない場合があります。このような問題があるため、あるスレッドが別のスレッドによって変更されたデータを扱っている間は、この 2 つのスレッド間の相互作用を明示的に制御しなければなりません。この制御を可能にするために、Java では特殊な処理を使用して、別のスレッドが認識するデータのビューに順序付けを設定します。基本的な処理は、スレッドが synchronized キーワードを使用してオブジェクトにアクセスするというものです。スレッドは、オブジェクト上で同期をとるときに、そのオブジェクトに固有のロックへの排他アクセスを取得します。そのロックをすでに別のスレッドが保持している場合、ロックを獲得する必要のあるスレッドは、ロックが解放されるまで待機しなければなりません (ブロックされることになります)。スレッドがコードの synchronized ブロック内で実行を再開する時点で、Java はそのスレッドが、同じロックを保持していた他のスレッドによって書き込まれたすべてのデータを「認識」することを保証します。ただし、認識されるデータは、他のスレッドがそれぞれの synchronized ブロックを離れてロックを解放した時点までに書き込んだデータに限られます。この保証は、コンパイラーや JVM が行う処理の順序変更にも、ハードウェア・メモリー・キャッシュにも適用されます。従って、synchronized ブロック内部はコード内で安定性が確保された場所であり、複数のスレッドが順に実行し、相互作用し、情報を安全に共有できる場所です。変数に volatile キーワードを指定すると、やや弱い形でのスレッド・セーフな相互作用が実現されます。
synchronized キーワードが保証するのは、スレッドがロックを取得した時点で他のスレッドのストアを認識すること、そしてこのスレッドのストアを、次にロックを取得した他のスレッドが認識することです。volatile キーワードは、この保証を 2 つの部分に分割します。スレッドが volatile 変数に書き込む場合、最初に、その時点までに書き込まれたすべての値がフラッシュされます。スレッドが変数を読み取る場合は、スレッドはその変数に書き込まれた値だけでなく、その書き込み処理を実行したスレッドが書き込んだ他のすべての値も認識します。従って、volatile 変数の読み取りは、synchronized ブロックに入る場合と同様のメモリー保証となり、volatile 変数の書き込みは、synchronized ブロックから出る場合と同様のメモリー保証となります。ただし、1 つの大きな違いとして、volatile 変数の読み取りにしても、書き込みにしても、ブロックされることは決してありません。Java の並行性の抽象化同期化は有用であり、Java で開発されている多くのマルチスレッド・アプリケーションは、基本的な synchronized ブロックだけを使用しています。その一方、複数のスレッドを調整するという部分が厄介な作業になる可能性があります。特に、多数のスレッドと多数のロックを扱う場合は厄介な作業になりがちです。スレッド・セーフな方法でのみスレッドが相互作用することを確実にするとともに、潜在的なデッドロック (複数のスレッドが、互いにロックが解放されるのを待って、実行を続行できないこと) が回避されることを確実にするのは困難です。スレッドとロックを直接扱うことなく並行性をサポートする抽象化は、開発者が一般的な使用ケースに対処する望ましい方法となります。java.util.concurrent 階層には、同時アクセス、アトミックな処理のラッパー・クラス、同期化プリミティブをサポートするさまざまなコレクションが含まれています。これらのクラスの多くは、ノンブロッキング・アクセスをサポートするように設計されているため、デッドロックの問題が回避され、より効率的なスレッド化が可能になります。これらのクラスを使用すると、スレッド間の相互作用の定義および調整が容易になりますが、基本的なスレッド化モデルの複雑さが完全に排除されるわけではありません。java.util.concurrent パッケージには、並行性を扱うためのより疎結合の手法をサポートする抽象化のペアとして、Future<T> インターフェースと Executor および ExecutorService インターフェースが含まれています。これらの関連するインターフェースは、Java の並行性サポートに対する多くの Scala および Akka の拡張機能の基礎となっているため、この 3 つのインターフェースとそれぞれの実装については詳しく調べる価値があります。Future<T> は T 型の値を格納するホルダーですが、Future が作成された後でないと、通常は値が使用可能にならないように工夫されています。値は、同時に実行される可能性もある非同期処理の結果です。Future を受け取るスレッドは、以下の機能を持つメソッドを呼び出すことができます。値が使用可能であるかどうかを確認する値が使用可能になるまで待機する値が使用可能になった時点で取得する値が不要になった場合、処理をキャンセルするFuture の実装のそれぞれは、非同期処理に対処するための異なる方法をサポートするように構成されています。Executor は、タスクを実行する「もの」をラップする抽象化です。ここで言う「もの」とは、結局のところ、スレッドのことですが、スレッドがタスクを実行する方法の詳細は、このインターフェースによって隠されます。Executor は、単独ではその有用性が限られますが、ExecutorService サブインターフェースを併せて使用することで、タスクの終了を管理したり、タスクの結果として Future を生成したりするなどの拡張メソッドを提供することができます。Executor の標準的な実装では、いずれも ExecutorService を実装するため、実際にはルート・インターフェースを無視することができます。スレッドは比較的重たいリソースなので、スレッドを割り当てて破棄するよりも、再利用する方が賢明です。ExecutorService によって、スレッド間での作業の共有が単純になると同時に、スレッドを自動的に再利用できるようになるため、プログラミングが容易になり、パフォーマンスも向上する結果となります。ExecutorService の ThreadPoolExecutor 実装は、タスクを実行するスレッドのプールを管理します。Java の並行性の適用並行性を備えた実際のアプリケーションには、メインの処理ロジックとは独立した、外部 (ユーザー、ストレージ、他のシステム) との相互作用が必要になるタスクを伴うことがよくあります。そのようなアプリケーションを単純な例に簡略化するのは難しいことから、並行性のデモとしては、数値計算やソートといった、単純なコンピューター処理が集約されたタスクがよく使用されます。この記事でも、同様の例を使用します。ここで取り上げるタスクは、不明な入力に最も近い既知の単語を見つけるというものです。ここで言う「最も近い」とは、「レーベンシュタイン距離」の観点で定義されており、不明な入力を既知の単語に変換するために追加、削除、置換しなければならない文字数が最も少ないことを意味します。使用するコードは、Wikipedia の記事「Levenshtein distance」に記載されているサンプル・コードに基づいています。このコードは、既知の単語ごとにレーベンシュタイン距離を計算して、最もよく一致したものを返します (または、複数の既知の単語が同じ距離である場合には、不定の結果を返します)。リスト 1 に示す Java コードで、レーベンシュタイン距離を計算します。この計算では、比較対象の 2 つのテキストの長さにそれぞれ 1 を加えたサイズと一致する行と列からなる行列を生成します。効率化を図るため、この実装ではターゲット・テキストのサイズに合わせた配列のペアを用いて、行列内の連続する行を表し、繰り返し処理のパスごとにこれらの配列を交換します。このようにするのは、次の行を計算するには、直前の行の値だけが必要なためです。リスト 1. Java でのレーベンシュタイン距離の計算
JVM の並行性: Java と Scala での並行処理の基礎
