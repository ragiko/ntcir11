@suzuvie_reさん
音声認識のためのN-gram言語モデル
参考文献
- 音声認識のしくみ
- Julius プロジェクト
- 大語彙連続音声認識エンジン Julius
- STAR Laboratory: SRI Language Modeling Toolkit
- NAIST Japanese Dictionary Wiki
- HTKによる音響モデル構築 - Miyazawas Pukiwiki 公開版
- 大学共同利用機関法人 人間文化研究機構 国立国語研究所 - 日本語話し言葉コーパス
発表資料
あとでリンクする。
メモ
一番刺激を受けた発表だった。下から積み上げて現実に動くものを作り上げるのは素晴らしい。
途中で「トピック外のコーパス足し合わせて使うと悪影響ありませんか」という質問をした。
「トピック内の語を認識する妨げになる割合」が「一般的な語やトピック外の語を認識する助けになる割合」よりも大きくなることが多そうな気がするのですがどうですか、という意味だった。
日本語は同音異義語が多いし、モーラの短い単語も多いし。
その答えがどうだったのかについて教えていただくためにはしばらく時間が必要そうだった。
音声認識
- 音声データ
- 音声データからの特徴量抽出
- 音声認識エンジンで認識
- 音声認識結果の取得
考慮すべきモデルは2つ
音響モデル
言語モデル
音素とモーラ
ザクっと以下のような関係性
||音素||モーラ||単語||
||a,k,a,i||あ か い||赤い||
音声認識エンジンの例としてJuliusがあげられていた。
Juliusのコーパスを見ると、単語・モーラ・音素の組み合わせがどうなってるのかの例が分かる。
長音や「ん」の扱いは文字列処理のときに真似しどころがあるなと思った。
電話などの特殊な音声データを処理する場合は、専用の音響モデルをつくったりするそうだ。
孤立単語型
発話を単語として認識し、尤度が高い単語を出力する
記述文法型
発話を認識し、言語モデルから尤度の高い単語列を出力する
尤度が低い単語列は出力できない
ディクテーション型
発話の内容をとにかく単語にする
N-gram
count N-gram
単語N-gramの高精度化と0頻度問題
高精度化
王道パターン
トピック中の正式名称を含んだ文法的に正しいコーパスを集める
トピック中のユーザが生成する豊富な表現を集める(ブログ、論文とか)
実用上問題が無くても、研究上は表現を多く集めなければいけない
後方の認識間違いが前方の認識に影響を及ぼす場合もある
なんでも良いからとにかくコーパスを大量にあつめる
小手先系(王道パターンを試したうえで、必要なら試す)
話題適応(例:LDAやPLSAによるトピック適応)
表現適応(例:CRFによる不要語の挿入)
未知N-gramを補完(例:単語クラスタリングによるClass N-gram化する)
0頻度問題に対応するためのスムージング手法
Kneser-Ney
Modified Kneser-Ney
Witten-bell
Good-Turing
Natural
単語N-gramの精度指標
- Word Count, Word Accuracy
- Perplexity
単語認識後に算出する「文(単語列)の尤度」の自乗平均
実験で使ったアプリ
- MeCab(複数の発音情報を後処理で付与する必要がある)
- NAIST Japanese Dictionary
- SRILM
音声認識は品詞とかどうでも良いので、未知語も辞書中の単語も混ぜて扱ったりもする。
実験
レシピコーパスによるレシピの認識
ブログからのレシピとメニューの収集
料理レシピ言語モデル
評価コーパスが料理レシピのときにPerplexity
概ね一番良かったのはModified Kneser-Neyだが、Kneser-Neyとの差はわずか。
2-gramと3-gramのコーパスはperplexityの差が凄い
3-gramと4-gramの間は、2-gramと3-gramの間ほどではない。
4-gramは1* GByteのメモリを使うので、現実的には3-gramかな
料理メニューは、全体に多少数値が悪くなる
料理レシピモデルのクローズテストだとPerplexity 50〜60くらいっぽい
単語N-gramの方がモーラN-gramの方が良い
言語的な制約が必要
音声認識で役に立つレベルはPerplexity60位。
認識すべき単語の属するトピックが広い場合と、狭い場合で、使用すべきコーパスは異なる。
デモ
すばらしい。
音響モデルは学会の音声の認識
SRILM
320000語
前向き2-gram、後ろ向き4-gram
Modified Kneser-Ney
体言止めに弱かったりする場合がある。
固有名詞の前後は弱かったりする。
Burst Detection from Stream
参考文献
- Bursty and Hierarchical Structure in Streams:Jon Kleinberg
- document streamにおけるburstの発見:藤木稔明ら
- 周期的に発生するburstの予測と抑制:藤木稔明ら
- blogeyeの実装に学ぶ、Amazon EC2/S3でのHadoop活用術(1/3):CodeZine
- ブロガーの性別や地域ごとに人気キーワード表示する「blogeye」 - ITmedia News
- yazztter(yet another buzztter)をつくりました - Unchained Life
発表資料
あとで貼る
メモ
論文は藤木さん(@pzy)のを読んでから、Kleinbergのを読むと良いかも。
発表中、奥村研の輪講の時のスライドとか議論の内容とかが浮かびまくった。
あと当時の大倉さんのサービス構築速度はすさまじく、本当に素晴らしい人だなと思ったことを思い出した。
Burst Detection from Stream
発表者
大倉務さん(@ohkura)
Bursty and Hierarchical Structure is Streams
Jon Kleinberg(2002)
アルゴリズムデザインの人
HITSの人
イベント検出入門
イベント:異常のこと
異常とは、平常ではないこと
シンプルな方法の例
過去1年の平均を計算して、その平均の10倍を超えたら異常
もうちょっと賢く
過去1年のデータから値の分布を予測して、例えば正規分布の99.9%点を超えたら(閾値を超えたら)異常とする
イベント検出
- イベントの正確な範囲の認識
- イベントが起きた事実の認識
認識のまとまりの扱い
閾値を超えた回数ごとに区切らず、ある程度まとまって検出したい
時系列ストリームへの適用
時系列ストリームからのイベント検出
Temporal Stream Data
最近流行の時系列データ
時間とともにどんどんやってくるデータ 
アクセスログ、Tweets、Blog記事、ニュース記事、各種センサーからの値
シンプルな方法
時間を区切って数を数える
一日ごとにある単語のTweet回数を数えて比較
このシンプルな方法だと、区切りが来るまでburstを検出できない。
かといって粒度を下げるとノイズに弱くなる
発想の転換
イベントの間隔に着目する
時間辺りのイベント数ではなく、イベントの間隔に注目する
瞬間的にたまたま出た異常値はburstなのだろうか。。
状態としてとらえる
普通の状態
イベントが普通の頻度で起きる
バースト状態
閾値以上の頻度で起きている
Burst Detection
ある時点での状態が平常状態かBurst状態かを推定する
全てのイベントにはBurstとStableの2つの状態が考えられる。
イベントストリームが、平常、Burstのどういう遷移から生成されたものかを考える。
Burst状態のときにはイベントの出現間隔が指数分布に従うと仮定してみよう。
指数分布
単位時間あたり平均λ回起きるイベントの生起間隔は、論文参照。
期待値は1/λ
各状態からの出力
単位時間内のイベント発生数がλ回だとすると、この単語の出現間隔は、論文参照。
注目を浴びているときは、別の確率分布を持っているのではないか
例えば10倍したものとか。
前回との時間間隔によって、平常状態とburst状態を検出できる
状態遷移コスト
状態の遷移にはペナルティを与える
あるものが流行して無ければ、その次も流行していない
あるものが流行していれば、その次も流行している
状態遷移確率
別の状態への遷移確率をpとすると、
組み合わせると
時間感覚のシーケンスをx、書く時点での状態のシーケンスをqとすると、
xを観測したときn遷移がqである確率は、bは状態遷移の回数
p(q|x) = 
1/z:正規化項
p^b(1-p)^(n-b)状態遷移確率
Π^n_(t-1):全ての状態の積
fq_t(xt) : 各時点での状態がqtである確率 
ある瞬間のburstが、次の瞬間の情報を使うとburstではなかった
許容する
限界がある
(周期性を使うのも良さそう?)
2つ以上前を間違うことはない   
実際の計算
各状態jについて最短経路のコストC(t)を以下のような更新式で更新していく
C_j(t) = - ln f_j(x_t) + min(C_t(t-1) + γ(l. j))
ある瞬間までのburst状態、定常状態のそれぞれの最適なシーケンスを覚えておく
b-b b-s s-b s-sの遷移をそれぞれを計算する
viterbi
初期のpは経験的に決める。ことが多い。
例:1年に一回が平均値ならそのようになるpを選ぶ
平均出現頻度を各時点で更新していくことで、各瞬間でのburstからstableに遷移しやすくなる。
burst状態にいくのにコストをあたえるが、stableに行くときにはコストがいらないようにするとburstにとどまりにくくなる
実際には論文では無限のstateを扱う話もかいてある。
平常、バーストの2つの状態でななく、平常、バースト、超バースト、超超バースト、とか。
λ、2λ、4λのように指数関数的に、各指数分布の期待値を増やしていき、各状態の確率を求めてやる。
ありとあらゆる単語について流行度を計算すればOK
いろいろな情報ソースから候補を集めてきて、数千語の単語について
ポワソン過程
λは非一様で良い
オートマトンモデル
フレーズは頻度列を重ね合わせれば良いのかな。
何でburstなのか、と、いまの状態がどうなのか、は別に扱いたいということか。
Confidence WeightedをLearning to Rankに適用してみた
参考文献
- Large Scale Learning to Rank:D. Sculley
- sofia-ml - Project Hosting on Google Code
- Conﬁdence-Weighted Linear Classiﬁcation:Mark Dredzら
Analyzing and Modeling Rank Data[Amazonで詳細を見る]
Learning to Rank for Information Retrieval[Amazonで詳細を見る]
Learning to Rank for Information Retrieval[Amazonで詳細を見る]
発表資料
あとで貼る
メモ
ここらへんの内容はとても興味があるというか、個人的にやりはじめたい分野なのでとても楽しみだった。
よくまとまっていたので、みんなもツッコミやすかったみたいで議論が活発だった。
いろいろ聞けて良かった。
今日簡単に紹介するいろいろ
RankingSVM
このへんがはじまり
RankBoost
Bipatite
KistNet
List
Sofia-ML
サンプリングしても精度はあんまりおちない
どんな素性を使うのか
BM25
クエリに対する文書の適合度を計算する指標
PageRank
文書の重要度を表すあれ
文書長
全体に重要であるかも
タイトル文字列の長さ
など
ランク学習の評価指標
NDCG(Normalized Disciunted Cumulative Gain)
j位のNDCG値
1/n_j Σ^j_i=1 (2^r(i) - 1) / log(1 + i)
MAP
Bipatate Learning
データはGoodとBadの2つの集合で与えられる
学習データを作るのが簡単
学習が拘束なことが多い
Pairwise Learning
データはスコア付きのペアの形で与えられる
クエリに対し、どちらの文書が適切か
データを作るのはそこそこ簡単
しかし、作り方に気をつけないと
3すくみになったりする
Listwise Learning
データはスコア付きのリストの形で与えられる
学習データを作る時点でまず難しい
クエリに対して、適合度の高い文書A,B,Cを全部並べ換えておく
Bipatite, Pairwise, Listwise の順に簡単
ListをPairにすると素性が
RankSVM
ランク学習の分野で最も基本的な学習器のひとつ
オリジナルのアルゴリズムは学習時間が長い
Bipatateなデータの与え方をした場合、全てのサンプルの組み合わせを使う
RankBoost
Boosting のランク学習への適用
基本的にPairwiseだが、Broatiteだと速い
ListNet
並べ替えるんだから、並べ替えたリストから学習すれば良い
ニューラルネットで学習する
Large Scale Learning to Rank
全部のペアを見なくても、ランダムにサンプリングして数%くらいみればいけるよ
Pairwiseをもう少し詳しく
A > Bのとき
(ψ(A) - ψ(B))・w > 0になるように学習する
未知の文書ABCの並べ替え
スコアで並べ替える
Learning to Rank 的にはスコアをつける必要はないが順序付けにスコアを使う。。
Confidence Weighted
オンライン線形学習アルゴリズムの一つ
サンプルを一つ選んでパラメタ更新
自信がある、ない、とか
更新式
Confidence Weighted
学習が速い
ループを1回、回すとほぼ収束する
ノイズに弱い
ARROWやNARROWがでてきた
RankCW
二値分類としての学習にはollを利用
Pair-wizeで学習
リストからサンプリング
実験データ 
LETOR
MSRが作ってるデータセット
文書からあらかじめ素性が抽出されている
自分で素性を作らなくてもいい
Pair-wiseとList-wiseの2種類
逆に新しい素性を作りたくても作りにくい
データが必要だったり
構造を理解たり 
今回はOHSUMEDとMQ2007のデータを使った
実験結果
Confidence Weightedはノイズに低い
CWはSVMにありえないほど負けた。。。
まとめ
手法を選べばむずかしくない
それでいて結構良い性能
どちらかというと、featureを実装するのが大変
Confidence Weightedは高速だがノイズに弱い
BM25の値は、クエリごとに値変わってくる
正規化しても悪さするものは悪さする
Grobal Ranking という概念がある
しかし、Learning to Rankと混ぜないように
あとで調べよう。。。
ランク学習の素性は企業秘密なので論文には書いてない。
自分で実験しろ!ということですね。
統計的機械翻訳入門
参考文献
- 統計的機械翻訳入門
- Wikipedia日英京都関連文書対訳コーパス
- giza-pp - Project Hosting on Google Code
Statistical Machine Translation[Amazonで詳細を見る]
発表資料
あとで貼る
メモ
翻訳モデル 
単語ベース
IBMモデル
単語の翻訳
単語を翻訳するには?辞書を引く
いろいろな翻訳が考えられる
対訳コーパスがあれば、どの単語がどの単語に訳されるのか、の頻度付きリストを獲得できる
頻度が分かると、翻訳されやすさを正規化するして確率が得られる
単語アライメント
原文と翻訳文は、対応する単語の位置が入れ替わっているかも。
アライメント:対応する単語同士を対応付けした情報
単語数が1対1とは限らない
1対多のアライメント、もある
対応しない言葉もある、のでNULLというのもある
IBM Model 1
生成モデル:翻訳プロセスをモデル化
翻訳モデルを学習する
対訳コーパスから学習したい
しかし、アライメントが分からない
アライメント => パラメタはできる
パラメタ => アライメントはできる
EMアルゴリズム
不完全データ 
完全データがあればモデルを推定できる
モデルがあれば欠損データを補完できる
Discovering Concepts from Word Cooccurrences with a Relational Model
発表資料
あとで貼る
メモ
発表が始まる前にぐったりしてました。ごめんなさい。
聴講者から「で、結局現実の問題に対する有効な使い道はあるのか」という主旨の質問をされて、@suzuvie_reさんは「あまり無い」と言う主旨の解答をされてました。
コメント
今日は全体的に、自分が知ってること1/3、知らないこと2/3、みたいな絶妙な発表が多かった。
なので、全く分からなくて困るような発表は無かったのが嬉しかったです。
気になったことは「他の人にしゃべられたら困るネタ」とか「Twitterやブログに残ったらこまるネタ」とか「他の人に深くツッコまれたときに答えられないネタ」は話してもらえるのは嬉しいんだけど、それを僕が流布したときに全く責任が取れないということ。
本当にしゃべられたら困る事は自分で形にし終わるまで発表しちゃ駄目だし、サービスするにしても触れられたら困る話題の側には近づかない方が無難な気もします。
たとえば、テーマの内容とデモは見せるが手法や実験結果の詳細は見せない、とか。
そうじゃなくても他人のネタを取ってしまう人が会場内外に居るかも。
講演会とか懇親会とか面接とか打ち合わせとかで、他人から今まで全く扱っていなかったネタについて聞いた数週間後に「これからはコレだ」と言い出し、全く悪気無く他人の研究を乗っ取ってしまう人は、想像ですが普通にいると思います。
発表された内容はどれも自分では実装してなかったけど、 Burst 検出と Learning to Rank は明日からでもやってみたいと思ったし、音声認識や翻訳も「ここまでできるなら楽しそうだ」と思いました。
「自分もやってみたい」とか「いいテーマだなぁ」と思えるような発表をできる人は素晴らしいと思います。僕も他の人に「やってみたい」と思って貰えるような発表をしたくなりました。
関連リンク
- Togetter - 「第4回 #TokyoNLP」
[O] 『第4回 自然言語処理勉強会@東京』に参加した
