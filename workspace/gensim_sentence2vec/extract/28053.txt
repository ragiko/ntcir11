2項分布の復習
歪んだ硬貨があって,投げると確率 $\theta$ で表(おもて)が出て,確率 $1 - \theta$
で裏が出るとします。この硬貨を $n$ 回投げて,表が $r$ 回出る確率を求めてください。
これが2項分布(binomial distribution)の問題です。答えは
\[ _nC_r \theta^r (1-\theta)^{n-r} \]
です。$_nC_r$ は $n$ 個から $r$ 個を選ぶ組合せ(combination)の数で,英語ではよく
$n$ choose $r$
と読みます。階乗(!)を使えば
\[ _nC_r = \frac{n!}{r!(n-r)!} \]
と表せます。
Rでは,例えば $_{10}C_3$ は choose(10,3)
と打てば求められます。
> choose(10, 3)
[1] 120
投げると確率 0.4 で表が出る硬貨を10回投げて表が3回出る確率
$_{10}C_3 \cdot 0.4^3 \cdot 0.6^7$
は dbinom(3, 10, 0.4) で求められます。
> dbinom(3, 10, 0.4)
[1] 0.2149908
> choose(10,3) * 0.4^3 * 0.6^7
[1] 0.2149908
投げると確率 0.5 で表が出る硬貨を10回投げて表が0〜10枚出る確率を全部出力するには次のようにします。
> dbinom(0:10, 10, 0.5)
[1] 0.0009765625 0.0097656250 0.0439453125 0.1171875000
[5] 0.2050781250 0.2460937500 0.2050781250 0.1171875000
[9] 0.0439453125 0.0097656250 0.0009765625
これをグラフにするには次のように打ち込みます。
barplot(dbinom(0:10,10,0.5), names.arg=0:10)
ただし,デフォルトではy軸の文字が横向きになります。上の図のようにするには,あらかじめ
par(las=1)
と打ち込んでおきます。par() は図を描く際のオプション(parameter)を指定するコマンドです。las は label style の意味です。詳しい説明はRに
?par
と打ち込んで出るヘルプを見てください。
これを順に加えていった累積確率は次のようにして求められます。
> pbinom(0:10, 10, 0.5)
[1] 0.0009765625 0.0107421875 0.0546875000 0.1718750000
[5] 0.3769531250 0.6230468750 0.8281250000 0.9453125000
[9] 0.9892578125 0.9990234375 1.0000000000
統計的検定の考え方
硬貨を10枚投げて表が2枚しか出ませんでした。この硬貨は歪んでいるでしょうか。
ある母集団から10人をランダムに選んで聞いたところ,賛成2人,反対8人でした。母集団全体でも反対のほうが多いと言えるでしょうか。
これらの問いについて考えるために,仮に硬貨は歪んでいない(あるいは母集団全体では賛否が等しい)というモデル(帰無仮説,null hypothesis)を立てます。そして,この帰無仮説が正しかった場合に,実際に観測された以上の外れ方(2:8,1:9,0:10,そして通常はさらにそれをひっくり返した8:2,9:1,10:0)が生じる確率の合計を求めます。この確率の合計を $p$ 値(ピーち,$p$-value)といいます。$p$ 値が非常に小さければ,実際に起きた事象はこのモデルでは説明しにくいので,たぶん硬貨は歪んでいる(あるいは賛否は等しくない)と推測します。$p$ 値が大きければ,これだけのデータでは何も言えないということがわかるだけです。
$p$ 値が大きいか小さいかの境界(有意水準)を仮に 0.05 として,$p \leqq 0.05$ であれば帰無仮説からの外れが「統計的に有意」(statistically significant)である,あるいは「帰無仮説は棄却(reject)される」ということがあります。0.05 という値に特に意味はありませんが,伝統的によく使われています(物理学では通常もっともっと厳しい条件を課します)。
さて,硬貨を投げて表の出る枚数の分布は2項分布と考えられますので,表も裏も 1/2 の確率で出るとすれば,表が $r$ 枚出る確率は $_{10}C_r (1/2)^{10}$ です。表裏が 0:10,1:9,2:8,8:2,9:1,10:0 である確率はそれぞれ
> dbinom(c(0,1,2,8,9,10), 10, 0.5)
[1] 0.0009765625 0.0097656250 0.0439453125 0.0439453125
[5] 0.0097656250 0.0009765625
で,この合計,すなわち $p$ 値は
> sum(dbinom(c(0,1,2,8,9,10), 10, 0.5))
[1] 0.109375
になります。同じことが
> pbinom(2, 10, 0.5) * 2
[1] 0.109375
でも求められます。また,後で詳しく述べますが,binom.test()
という関数でも2項検定ができます。
> binom.test(2, 10, 0.5)
Exact binomial test
data:  2 and 10 
number of successes = 2, number of trials = 10, p-value = 0.1094
...
したがって,有意水準を 0.05 とすれば,表裏の差は統計的に有意ではありませんし,アンケートであればこんなに少人数の結果から「賛成が少ない」という結論を導いてはいけないということになります。
表が1枚(賛成が1人)なら,$p$ 値は 0.02 ほどになり,水準 0.05 で有意になります。
これが,フィッシャー(R. A. Fisher,1890〜1962年)が「有意性の検定」(tests of significance,significance tests)と呼んだ方法の考え方です。
統計的検定をめぐる誤解と議論
帰無仮説は現象の理解を助けるために設定した一つのモデルです。そのモデルと現実のデータとの整合性の度合を確率のことばで表したのが $p$ 値です。$p$ 値が非常に小さければ,モデルとデータは両立しにくいので,より良いモデルを考えなければならないことになります。
$p$ 値は「帰無仮説が正しい確率」ではありません。どんな硬貨でも少しは歪んでいます。母集団でまったく賛否の割合が等しいことなどありえません。したがって,帰無仮説が正しい確率というものがもし定義されるなら,それは 0 であるというのが妥当です。
$p$ 値は,標本の大きさ(調べた個数)によって大きく変化します。例えば歪んだ硬貨を調べる場合,投げた回数が非常に多ければ,検定の「感度」がうんと高くなるので,実用上無視できるほどのちょっとした歪みでも $p$ 値が非常に小さくなることがあります。逆に,かなり違いがありそうでも,投げた回数が少なければ $p$ 値はなかなか小さくなりません。いずれにしても,$p$ 値が十分小さくなければ(帰無仮説が棄却されなければ)表が出やすいとか賛成が多いとか言うことはできません。
$p$ 値が(有意水準より)小さくならなかったとき「帰無仮説を採択(accept)する」ということがありますが,これは誤解しやすい言葉です。「帰無仮説を棄却できない」あるいは「わからない」というほうが正しいでしょう。差がなかったのではなく,測定の感度が悪くて差が見つけられなかっただけなのです。
フィッシャーの「有意性の検定」は,後にネイマン(Jerzy Neyman, 1894〜1981)とピアソン(Egon Pearson, 1895〜1980)の「統計的仮説検定」(statistical hypothesis testing)の数学理論へと発展します。ただ,ネイマンたちの問題の設定のしかたを科学の研究にそのまま適用しようとすると,実験前に有意水準を例えば 0.05 と決めたなら,必ず $p = 0.049$ で帰無仮説を棄却して $p = 0.051$ で棄却しないという杓子定規な判断をすることになり,この点にフィッシャーは非常に違和感を感じました。
科学の歴史の中には,$p$ 値が非常に小さかったことが後でひっくり返ることがいくらでもあります。$p$ 値を求めるのは必要ですが,$p \leqq 0.05$ かどうかで機械的に判断せず,小さい $p$ 値が一貫して再現できることをもって判断するのが科学の態度です。一方で,工場の品質管理の現場では,$p$ 値によって自動判断することが必要とされます。
統計的に有意な差と実質的な差
右の図は,分散がいずれも 1 で平均値が 0.2 だけ離れている二つの正規分布
$N(-0.1,1)$,$N(0.1,1)$
です。これらの群の平均値の違いを検出したければ,各群200個ずつ調べる必要があります。それだけ集めて調べれば統計的に有意な差が得られる公算が高いのですが,逆に,それだけ集めないと違いがわからないほどであれば実質的な差はほとんどないとも言えます。実際,各群からランダムに1個ずつ取り出したとき,左の群のものが右の群のものより大きくなる確率は44%以上もあります。
「実質的な差」がなくても,科学的に意味がないわけではありません。ノイズに埋もれて,非常に大きなサンプルを調べなければ統計的に有意な結果が得られないような現象が,科学的には非常に重要であることは,よくあることです。「どんなに $p$ 値が小さくても,例えば相関係数が 0.1 といった値であれば,実質的な意味はない」はあくまで一般論で,ケースバイケースで考えるべきことです。
例えば,ニュートリノの質量が 0 でないという発見は,その質量がどんなに小さくても,ノーベル賞級の意味があります。また,血液型と性格に関連があることが示されれば,その関連がどんなに小さくても,性格の生理学的起源に関する重要な発見であると思われます(未だに一貫した結果は得られていません)。
なお,平均値の小さな違いでも,極端な値の割合に大きな違いが出ることがあります。さきほどの二つの正規分布で $x \geqq 3$ の確率を求めると,
> pnorm(-3.1)
[1] 0.0009676032
> pnorm(-2.9)
[1] 0.001865813
のように,千個に1個の割合が,千個に2個の割合に増えます。この違いが実質的な意味を持つことは十分考えられます(これらの数値は分布が正確な正規分布であることに強く依存するので,単なる例としての意味しかありません)。
検定と区間推定
