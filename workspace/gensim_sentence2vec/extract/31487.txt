
背景[編集]
確率変数  があるとき、そのエントロピー  は  の値の不確かさを表す。 について、イベント  が発生する確率が  であるとき、 のエントロピーは次のようになる。
もう1つの確率変数  では、イベント  が発生する確率が  であるとする。 のエントロピーは  で表される。
ここで、 と  が相互に関連したイベントを表しているとき、系全体のエントロピーは  にはならない。例えば、1から8までの整数を1つ選ぶとし、それぞれの整数が選ばれる確率が同じとする。 は選んだ整数が奇数かどうかを表し、 は選んだ整数が素数かどうかを表すとする。1から8の整数のうち半分は偶数であり、同じく半分は素数である。したがって  となる。しかし、選んだ整数が偶数であるとわかっている場合、それが素数である場合は4つのうち1つしかない。つまり、2つの確率変数の分布は関連している。従って系全体のエントロピーは2ビットよりも小さくなる。
定義[編集]
ここで、考えられる結果の「対」  を全て考慮する。
それぞれの対の発生確率を  としたとき、結合エントロピーは次のようになる。
上記の例では、1を素数と見なしていない。従って、結合確率分布は次のようになる。
以上から、結合エントロピーは次のようになる。
bits
特性[編集]
部分エントロピーよりも大きい[編集]
結合エントロピーは、常に元の系のエントロピー以上となる。新たな系を追加しても不確かさが減ることはない。
この不等式が等式になるのは、 が  の(決定的)関数になっている場合だけである。
が  の(決定的)関数であるとき、以下も成り立つ。
劣加法性[編集]
2つの系をまとめて考えたとき、それぞれの系のエントロピーの総和より大きなエントロピーには決してならない。これは劣加法性 (subadditivity) の一例である。
この不等式が等式になるのは、 と  に確率論的独立性がある場合だけである。
限界[編集]
他のエントロピーと同様、常に  が成り立つ。
他のエントロピー尺度との関係[編集]
結合エントロピーは、次のように条件付きエントロピーの定義に使われる。
また、次のように相互情報量の定義にも使われる。
参考文献[編集]
Theresa M. Korn; Korn, Granino Arthur. Mathematical Handbook for Scientists and Engineers: Definitions, Theorems, and Formulas for Reference and Review. New York: Dover Publications. pp. 613-614. ISBN 0-486-41147-8. 
結合エントロピー - Wikipedia
