図2は文献「日本人英語の発話様態を考慮した英語音声連続認識の検討」(鈴木忠、阿部芳春、中島邦男、日本音響学会平成10年度秋季研究発表会講演論文集I,p151−152,1998年9月)に示されている、従来の日本人英語の音声認識装置の構成を示すブロック図である。図において、1は音声信号入力端、2は音声信号入力端1より入力される音声信号101に対し音響分析を行い特徴ベクトル時系列102を出力する音響分析手段、3は音響分析手段2において求められた特徴ベクトル時系列102の出力先を切り替える切り替えスイッチである。また、図2において、4は切り替えスイッチ3の出力先の一つであり、音響分析手段2で求められた特徴ベクトル時系列102を入力して、音声信号101の各単語区間に対応する特徴ベクトル時系列を切り出して、単語音声データ103として出力する単語データ切り出し手段、5は外国語の音響モデル104,つまり認識対象となる音声を母国語とする複数の話者が発声した音声データにより学習した音響モデル104を格納している音響モデルメモリ、6は単語データ切り出し手段4が出力した単語音声データ103に対し、音響モデルメモリ5に格納されている外国語の音響モデル104を用いて音素タイプライタ処理(連続音素認識)を行い、音素ラベル系列105を出力する連続音素認識手段である。さらに、図2において、7は連続音素認識手段6が出力した音素ラベル系列105に従い、音響モデルメモリ5に格納されている外国語の音響モデル104を接続して、第1の単語モデル106を生成する単語モデル生成手段であり、8は単語データ切り出し手段4から出力された各単語の単語音声データ103を用いて、単語モデル生成手段7が生成した第1の単語モデル106にネイティブ話者の単語モデル107を加えた単語モデル群108に対して、クラスタリングを行い、このクラスタリングにおけるセントロイド(代表値)として選択したときの平均尤度を最大にする第2の単語モデル109を出力するクラスタリング手段である。さらに、図2において、9はクラスタリング手段8が出力した第2の単語モデル109を格納する単語モデルメモリ、10は切り替えスイッチ3の出力先の一つであり、単語モデルメモリ9に格納されている第2の単語モデル109を用いて、音響分析手段2から出力された認識対象となる音声を母国語としない話者による特徴ベクトル時系列102に対して連続音声認識を行い、認識結果110を出力する連続音声認識手段である。次に動作について説明する。ここでは、外国語として英語を例に取り、音響モデル104として英語の疑似音素単位のHMM(Hidden  Markov  Model,隠れマルコフモデル)を用いた場合を説明する。各音響モデル104は、英語を母国語とする複数の話者が発声した音声データを用いて学習されたものである。最初、英語連続音声認識に用いる第2の単語モデル109を作成するために、切り替えスイッチ3をa側に入れておく。英語を母国語としない話者が発声した発声内容既知の英語連続音声による音声信号101は、音声信号入力端1より入力され、音響分析手段2において分析フレームごとに音響分析処理が施されて特徴ベクトル時系列102が出力される。音響分析手段2が出力した特徴ベクトル時系列102は、切り替えスイッチ3を経由して単語データ切り出し手段4に入力される。単語データ切り出し手段4では、英語連続音声の特徴ベクトル時系列102から、該英語連続音声を構成する各単語音声に対応する特徴ベクトル時系列を抽出し、単語音声データ103として出力する。単語音声データ103は、1つ以上の英語連続音声の特徴ベクトル時系列について求められ、｛Tk(n)｜n=1...Nk｝(ただし、k=1...K)が出力される。ここで、kは単語カテゴリナンバーで、単語カテゴリ数はK個、Nkはカテゴリナンバーkの単語についての単語音声データの数である。音響モデルメモリ5には、英語を母国語とする複数の話者が発声した音声データにより学習した疑似音素単位のHMMが、音響モデル104として格納されており、連続音素認識手段6は、この音響モデル104を用いて、単語データ切り出し手段4が出力した単語音声データ103に対して音素タイプライタ処理(連続音素認識)を行う。すなわち、疑似音素単位のHMMが全接続可能で、かつ1回以上任意の回数接続できるモデルとの照合を行い、単語音声データ103に対し最も尤度が高くなるHMMの系列を求め、このHMMの系列に対応する疑似音素単位の音素ラベル系列105を出力する。単語モデル生成手段7は、音素ラベル系列105を入力して、この音素ラベル系列105に従って、音響モデルメモリ5に格納されている疑似音素単位のHMMを接続し、第1の単語モデル106として出力する。すなわち、Tk(n)で示される、ある単語音声データ103に対する音素ラベル系列105が、s−i−b−u−m−nのように6個の疑似音素単位のラベルの系列であるならば、各ラベルに対応する疑似音素単位のHMMを音響モデルメモリ5から読み出し、Left−to−rightにHMMを並べて、Pk(n)で示される第1の単語モデル106を出力する。これにより、英語を母国語としない話者が発声した英語音声における単語の発話様態を、英語を母国語とする話者の音声データで学習した疑似音素単位のHMMの系列で表現した第1の単語モデル106が生成されることとなる。このような処理を、全てのカテゴリkと各カテゴリのn=1...Nkについて行う。クラスタリング手段8は、単語データ切り出し手段4から出力された単語音声データ103を用いて、単語モデル生成手段7から出力された第1の単語モデル106に、各単語カテゴリについて英語を母国語とする話者の該単語音声の発話様態を表すネイティブ話者単語モデル107を加えた単語モデル群108に対してクラスタリングを行う。ネイティブ話者単語モデル107としては、例えば、英語辞書に記載されているような発音記号を表すような疑似音素単位の系列に沿って疑似音素単位のHMMをLeft−to−rightに接続したモデルを用いている。クラスタリング手段8における単語モデル群108のクラスタリングは、単語カテゴリごとに行われる。クラスタリングを行う単語のカテゴリナンバーをkとすれば、クラスタリングの対象となる単語モデルの数は、単語音声データ103の｛Tk(n)｜n=1...Nk｝に対応して単語モデル生成手段7により生成された第1の単語モデル106の｛Pk(n)｜n=1...Nk｝に、ネイティブ話者単語モデル107のPk,nativeを加えた(Nk+1)個である。このNk+1個の単語モデル群108の｛Pk(1),Pk(2)...Pk(Nk),Pk,native｝から、任意のM個の単語モデル｛Pk (m)｜m=1...M｝を、クラスタリングにおけるセントロイド(各クラスタリングの代表値)として選択したときの平均尤度Laveを次の(1)式で定義する。
英語の単語音声を正しく発声しない場合でも、精度の高い音声認識を実現する。再クラスタリング手段11は、第2の単語モデル109により、単語音声データ103に対しクラスタリングを行い隣接する単語音声データを見つけ、隣接する単語音声データに対する尤度をペナルティとして考慮して、単語モデル群108に対するクラスタリングを行い、このクラスタリングにおけるセントロイドとして選択したときの平均尤度を最大にする第3の単語モデル111を出力する。
347685号 音声認識装置及び音声認識方法、並びに音声モデル作成装置及び音声モデル作成方法 - astamuse
