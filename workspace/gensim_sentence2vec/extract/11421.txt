 iPhoneのSiriを始め、音声認識技術を活用したユーザーインターフェイスが注目を集めている。ビッグデータの活用による音声認識処理速度の高速化や、声の状態から感情やストレスを理解する技術など、新しい技術の開発や応用が進んでいる。なぜ、今、音声認識なのか? これまでの開発と研究の歴史を振り返りながら、注目が高まる音声認識の可能性を探る。
人間の音声を数式でモデル化する
音声入力インターフェイスが、急速に注目を集め始めている。
日本でも1990年代からパソコン用の音声入力ソフトウェアはあったし、音声認識で電話帳を検索できる携帯電話端末もドコモから発売されていたが、それほど話題に上ることはなかったように思う。
米国では1990年代から音声認識技術を利用した製品やサービスが普及してきたが、一般向け製品としてブレークしたのは、アップルのiPhoneに搭載されたSiriということになるだろう。iPhoneに話しかけるだけで、スケジュールの入力や、メッセージの送信、ウェブ検索などが簡単にできる。「人生」とは何かをSiriに尋ねると、ちゃんと「42」と答えてくれる(SF小説『銀河ヒッチハイクガイド』に出てくる、有名なジョーク)。ユーザーは、知性的だけれど、少し抜けたところもあるSiriのキャラクターを好意的に受け止めているようだ。
1987年に、アップルは「Knowledge Navigator」という未来の情報端末のコンセプトを発表していたが、Siriこそがそれを具現化したものだと熱狂しているユーザーもいる。
Androidにも音声でスマートフォンの操作を行えるGoogle Voice Actionが搭載されているし、Siriのようなパーソナルアシスタントアプリも登場している。また、モバイル用のGoogle検索アプリでは音声検索機能が付いている。
音声でデジタルデバイスを自在に操ることが現実となり、人工知能の登場まであと少しという気すらしてくる。
今一つブレークせずにいた音声認識によるユーザーインターフェイスが、これほど注目されるようになったのは、何か画期的な進歩があったのだろうか?
音声認識技術はどこに向かうのか? (1/5) | Telescope Magazine
