音声認識を紹介するページ
とにかくここでは、
だらだらと「音声認識」というモノを紹介します。
全体が(ほぼ)このページ一枚に収まっています。
ところどころにリンクがありますが、
そのリンク先には、
難しい話やこぼれ話みたいなものがちょこちょことあります。
ところで、話を簡単にするために、
ちょっと嘘を混ぜています。
そうでないと、ものすごく複雑な話になるので。
音声認識ってなにさ
簡単に言ってしまえば、
人間が喋った声を機械が文字に直すことです。
図で描くとこんな感じです。
左側が音声波形(つまり、声を図に表している)で、
右側がそれをひらがなに直したものです。
左側の音声波形を少し詳しく見てみる
人間は耳で音を聞きますが、
機械はマイクで音を聞きます。
そして、マイクで収録された音をそのまま表示させると、
下のような感じになります。
横軸が時刻で、縦軸が振幅です。
音声というのは、ようするに特殊な空気の振動です。
空気がどんなふうに震えているのかな、というのを表したのが、
上の図となっています。
空気の震えぐあいによって、
線が小刻みに上下に震えているのが分かると思います。
こういうグラフを「波形」と呼びます。
この場合、この波形は音声を表しているので、
「音声波形」とか呼ばれます。
(もう少し詳しい説明)
この音声波形をもっと詳しく見てみる
この音声波形は、ページの上の方で、
「てじぶん」
といっていると書きました。
じゃあ、いったい、どのあたりが、
「て」とか「じ」とか「ぶ」とか「ん」
なんだろうと思うんじゃないかと思います。
このあたりが、「てじぶん」です。
子音と母音に分けて書きましたが、
とにかく「てじぶん」です。
(「て」と「じぶん」の間にある「pau」というのは、
無音区間だとでも思ってください。
微妙に音があるように見えますが、
とりあえず気にしないことにしましょう。
それから、「ん」は、
「ナ行」の音と区別するために、大文字で書きました。)
意外と、音声と文字とが対応しているのが見てとれると思います。
特に、子音がちゃんと見えるのがびっくりなんじゃないでしょうか。
(音素についての補足)
「てじぶん」
あまり本筋とは関係のない話ですが、
「てじぶん」っていったいなんなんだ、
と思った人も多いと思います。
実はこれ、
「あらゆる現実を全て自分の方へねじ曲げたのだ」
という音声の一部なのです。
こういうシュールな文を使って、
音声工学の研究者は、
日々、音声について研究しているのでした。
(どうでもいい話)
何を解かねばならないのか
音声認識というのは、音声波形を文字に直すのが目標です。
だから、音声認識をする前というのは、
ただそこに音声波形があるだけで、文字はありません。
図にすると、こんな状況です。
波形だけが与えられていて、
それがどういう文字なのか、まるで分からないのです。
さて、あなたなら、どういうふうに解決しますか?
今のところ主流の方法
実は今は、ものすごく安直な方法で、
この問題は解かれています。
方法がシンプルだというのは結構いいこともあるのですが、
あまりにも単純に解きすぎていて、
ちょっと問題があるんじゃないかという声もあります。
現在の音声認識の手法は、
大きく二つの段階に分かれます。
「学習(ひな形づくり)」と「認識(照らし合わせ)」です。
また、そのほかに「データ集め」をする必要もあります。
それぞれを説明します。
その安直な方法の流れ
まずですね。
研究の前準備として、音声をたくさん集めます。
そして、人間がその音声波形を見たり聞いたりしながら、
波形を分類していきます。
人間が手作業で、地味にこれをやっているのです。
私はやったことがありませんが、かなり苦痛らしいです。
(そして、二週間くらい作業をしていると、
苦痛がやわらいでくるらしいです。)
そんな作業を黙々と遂行します。
(データ量の話)
その安直な方法の流れの続き
次に、それらのデータを解析して、
子音とか母音とかのひな形を作ります。
この作業は機械がやってくれます。
ちなみにこの解析のことを「学習」と呼びます。
ここまでは、製品化する前までにやっておきます。
こんな感じにひな形を作ります。
その安直な方法の流れの続きの続き
そして、ようやく、
音声認識ができるようになります。
「学習」の結果のひな形と解読すべき音声波形を照らし合わせます。
普通の家で音声認識をするときは、
この「照らし合わせ」しかやっていません。
機械が自動的に「照らし合わせ」をやってくれます。
これが世に言う「音声認識」です。
(フレーム分析の話)
一応、結果
そんな感じのことをして、
最終的に音声波形が何をいっているのか、
ということを機械が聞きとります。
音声認識の結果です。
もう少し細かい話
これからしばらく、
それぞれのステップについて、
ちょっと数学的な話をします。
でも、数式は出さないです。
数学チックな雰囲気を味わってください。
音声の指標
例えば、「あ」という音を機械に憶え込ませるとします。
つまり、「あ」を学習させるということです。
このときに何が必要かといえば、
たくさんの実際に発声された「あ」のデータと
「音声」を測るための指標です。
たくさんの実際の波形がないと
機械に憶え込ませることができないというのは、
なんとなく分かると思います。
じゃあ、なぜ音声を測るための指標がないといけないのかといえば、
声があまりにも多様だからです。
ひとくちに「『あ』っぽい波形」とか
「『い』っぽい波形」とかいっても、
男性の「あ」と女性の「あ」ではかなり違いますし、
同じ男性でも、かすれた声の人とか鼻声の人とか、
多種多様です。
その多様性をある程度消していかなければならないので、
多様性が消えてくれるような「指標」が必要となります。
これから、そんな指標の代表格である
「MFCC」
という指標を紹介します。
(ここまでで出てくるべき専門用語について)
耳で聞いた感じ
ものすごく安直な話で申し訳ないのですが、
音声の指標を作るのであれば「耳で聞いた感じ」を再現するのがよかろう
と誰かが考えました。
耳はどんなふうに音を聞いているのかということですが、
音の高さごとに聞いているっぽいということが、
いわれています。
というわけで、
まずは、あの「音声波形」を「音の高さ」ごとに表してみよう
と考えます。
音の高さごとに表す方法はいろいろとありますが、
「フーリエ変換」という方法が、
工学の世界ではとてもよく使われていて、
しかも簡単なので、
誰かがこれを採用しました。
「フーリエ変換」の結果は下の図のようになります。
フーリエ変換により、
音の高さごとにパワーを表すことができました。
この下の図は、
横の軸が「周波数」で、縦の軸が「パワー」です。
周波数というのは音の高さのようなものです。
そして、音の高さごとに、パワーが描かれています。
パワーというのは、音の強さのようなものです。
つまり、「このくらいの高さにはこのくらいの強さの音があるぞ」
というのが分かります。
(もう少し詳しい説明)
この周波数のグラフを詳しく見てみる
この図を見て、まずぱっと分かるのは、
「なんだか右肩下がりだ」
ということだろうと思います。
このグラフは有声音の母音の「あ」なのですが、
有声音はだいたい右肩下がりであるということが分かっています。
それから、
「ぎざぎざしている」
ということも見てとれるかと思います。
細かいぎざぎざがたくさんあります。
有声音はぎざぎざしています。
実は、このぎざぎざの間隔が耳に聞こえる音の高さを示しています。
(「周波数」と「耳に聞こえる音の高さ」は、実は違います。)
さらに、
「大まかにでこぼこしている」
というのも分かると思います。
下の図の赤い線のように、
なんか高いところと、なんか低いところとがあります。
実は、この赤い大まかな線が、
音声認識にとってはとても重要だということになっています。
この赤い大まかな線こそが、
声を出しているときの口の形状を示しているといわれているのです。
口の形状が分かれば、音声は認識できそうです。
というわけで、
周波数のグラフの大まかな形を
これから数値化していきます。
(声道パラメータのこと)
大まかな形の数値化
大まかな形を数値化してみました。
はい、説明はしません。
ちょこちょこと工夫すると、
数値化できるんだろうな、とか思っていてください。
このへんの計算はややこしいのです。
というわけで、あの右肩下がりの周波数のグラフが、
12個の数値になりました。
つまり、
これが「あ」を「MFCC」という指標で表したときの数値です。
「あ」のプロフィールみたいなものです。
(MFCCの数字は12個である必要はありません。
だいたい同じくらいなら何個でもよいです。)
(そのややこしい計算方法)
MFCC以外の数値化方法
MFCC以外にも、
周波数のグラフの大まかな形をうまい具合に数値化する方法は、
いろいろとあります。
あるんですが、
面倒なので説明はしません。
ちなみに、あの赤い線は、
「LPC分析」という方法で描きました。
で、LPCケプストラムという数値化の方法もあったりします。
ま、そんなことはどうでもいい話です。
大切なのは、このMFCCをどう扱うかということです。
(わずかにLPCの話)
MFCCをどう扱うのか
ここまでの話は、ようするに、
「音声波形の断片」「MFCC」
となります。
でもこれじゃあ、
単に波形を十二個の数字で簡単に表しただけで、
どうしようもありません。
我々は、このMFCCの数値を有効利用しなければいけないのです。
有効利用するために、次のようなMFCCの性質を使います。
MFCCは、発声された内容(「あ」とか「い」とか)によって、
だいたい似通った数値になるといわれています。
図にするとこんな感じです。
本当は12次元空間を図にしなければならないのですが、
それは無理なので、平面の図にしました。
(たとえば横軸がMFCCの一つ目の値で、
縦軸がMFCCの二つ目の値だとでも思ってください。
本当は違いますが、考え方としては似たようなものです。)
ところどころ重なっていることもありますが、
同じ音はだいたい似たような場所に集まります。
というわけで、
音ごとにその範囲を決めるのが、
当面の目標となります。
音ごとにMFCCの範囲を決める
MFCCの範囲を決めるためには、
材料として、データがたくさん必要です。
そして、そのデータは、
みんなで一生懸命集めました。
だからデータはそろっています。
というわけで、
「それらのデータから『何を』計算すべきか」
というのが重要な問題となってきます。
言い換えれば、
「何を計算すれば、範囲を決めたことになるのか」
ということです。
結論からいえば、
「範囲の中心」
と
「範囲の広がり具合」
を計算すればよいということになっています。
具体的な計算方法は省略しますが、
結構大変な計算によって、
「中心」と「広がり具合」を計算することができます。
この「中心と広がり具合」が、
音ごとの「ひな形」となります。
ここまでで、
「波形のデータ」「MFCC」「それぞれの音の範囲(ひな形)」
というステップを踏むことができました。
ここまでが、「学習(ひな形づくり)」です。
そして、ここから先が「音声認識(照らし合わせ)」となります。
(GMMの話)
照らし合わせの基本
すごく上の方で、こんな図を書きました。
「波形の断片」が「ひな形」に似ているかどうかを調べています。
これは、もう少し詳しく描くと、下の図のような感じになります。
つまり、「波形の断片」が次々と検査対象となって、
どの「ひな形」の範囲に入っているかが、
調べられるということです。
図では、「あ・い・う・え・お」しかありませんが、
もちろん、子音の範囲も同様に存在していて、
同様に照らし合わせに使われています。
照らし合わせの精度を上げる
ただ、上の方法だとちょっと問題があります。
断片の一つ一つをばらばらに照らし合わせているので、
例えば結果が下の図のような感じになってしまうのです。
本当は、
「げんじつを(genjitsuo)」という結果になってほしいのですが、
あいだによけいな音が認識結果として入ってしまっています。
これは、断片の一つ一つをばらばらに見ていることが原因です。
だから、「一連のものとして音声を扱う」ということをします。
詳しいことは省略しますが、
「HMM」
という考え方を使います。
そうすると、比較的きちんと下の図のように認識されます。
ここまでくるのに、五十年かかっているそうです。
(少しだけHMMの話)
このページのまとめ
音声認識には、「認識(照らし合わせ)」だけでなく、
「学習(ひな形づくり)」も必要なんだ、
ということを語りました。
また、MFCCという「指標」や、音の「範囲」についても語りました。
最後にちょっとだけ、「HMM」という言葉を出してみました。
このページでは、音声の認識についてだけ書きましたが、
ここに書いたことは、ほかの様々な分野にも応用が可能だったりします。
例えば、画像処理についてなんかでも、同じような考え方が使えます。
ところで、音声認識はまだ発展途上の技術です。
これからまだまだ考えていかなければならないことがたくさんあります。
そのうち多分、このページに書かれている技術が、
時代遅れのものになることだろうと思っています。
(その他の話)
プロフィール
プロフィール
更新履歴
サイトの更新が三ヶ月間止まっていると消されるシステムらしいので、
何もなくても更新履歴を載せます。
2006/01/09:とりあえず、立ち上げ。
2006/01/25:MFCCに高域強調をかけるのを忘れていたので修正。
2006/02/18:特に更新はしていない。保守。
………
2006/06/15:特に更新はしていない。保守。
2006/07/15:ページのタイトルを素直なものに変更。
2006/08/18:特に更新はしていない。保守。
………
2007/02/15:特に更新はしていない。保守。
2007/03/07:プロフィール作成。
2007/03/17:特に更新はしていない。保守。
………
2011/06/15:特に更新はしていない。保守。
音声認識のしくみ
