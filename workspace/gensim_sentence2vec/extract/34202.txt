
1.はじめに
ATR自動翻訳電話研究所では、自動翻訳電話の実現に向けて、音声認識・言語翻訳・音声合成のような構成要素技術の研究を行なっています。その中で、音声認識技術は、誰の声であっても発話内容が認識できることが望ましいのは言うまでもありません。
しかし、実際には、話者により音声の特徴は大きく異なっていて、音声認識を難しくしています。たとえば、私たちが電話などで相手が名乗る前に分かってしまうのも、このような音声の個人差を感じとっているからで、そのように個人ごとの声質は異なっています。
ATR自動翻訳電話研究所では、このような話し手の違いを克服するために、話者適応方式と呼ばれる音声認識のパラメータを話者の特性に適応させる方式の研究を精力的に行なってきました。ここでは、最近の研究成果である、少ない数の学習用データで高性能な話者適応が可能な方式について紹介します。
2.音声の個人性
話者による音声の特徴の違いは、大きく分けておもに発声器官形状の違いに起因する周波数スペクトル形状の違いと、おもに「くせ」も含めた発声方法の違いに起因するイントネーションなどの違いがあります。音声認識の場合に特に問題となるのは、前者の方です。この違いは、声帯、声道、口等の発声器官の物理的形状がおもな原因であり、人により大きく異なります。実際、親子、兄弟、姉妹のように身体的特徴が似ている場合は、聞き間違うほど声が似ていることは、時々経験することです。
一般に、男女間でも大きな差があります。図1に男性話者と女性話者が発声した「あ」のスペクトル形状例を示します。おなじ母音でもそのスペクトル形状が大きく異なることが分かります。
3.話者適応化
現在の主な音声認識方式は、あらかじめ相当量の音声データを用いて、母音や子音などの音素ごとに、音声信号のスペクトルとその時間特性を表現したモデルを作成するという方法を取っています。この音素モデルを作成するのに用いる音声データをモデルの学習データと言います。音声認識は、基本的には、入力音声がどの音素モデルにうまく合致するかを調べて、うまく合うものを認識結果とするものである、と考えて良いでしょう。
学習データを発声した話者自身が発声する場合は、音声認識は比較的容易です。これを、「特定話者音声認識」と呼んでいます。確かに、同一話者でも、音素パターンは発声のたびに変動しますし、また同じ音素でも前後の音素に影響されてパターンが変化します。しかし、他の話者の場合は、さらに大きな違いになります。
誰の声でも正しく音声認識をすることは、容易ではありません。人間の場合は、素早く話し手の声に適応し、順応しているものと考えられます。そこで、機械の場合でも、素早く話し手の声に適応できる手法が必要となります。このような技術を、「話者適応」と呼びます。具体的には、音声認識システムを使う前に定められた文章を話す、などによって自分の声を「学習データ」としてシステムに教えてやるものです。
話者適応化方法には大きく分けて、適応用の学習データの発声内容が分かっている「教師あり学習」と、分かっていない「教師なし学習」があります。教師あり学習は、発声内容の情報が利用できるので少量の学習データで適応化することが可能です。一方、教師なし学習は発声内容情報を利用しない分、適応用データが大量に必要となる傾向があります。また、これらの中間として適応用データを認識させてその結果を利用する学習法も考えられますが、認識を誤った場合の処理など、また別の未解決の問題があります。
4.移動ベクトル場平滑化法
ATR自動翻訳電話研究所では、高い話者適応効果が期待できる教師あり学習の研究をおもに進めてきました[1]。この方法では、あらかじめ標準話者が発声したいくつかの単語を、新しい話者にも発声してもらいます。そしてそれを、標準話者の発声した音声と比較し対応付けを行なうことにより、両話者のスペクトルの対応関係を学習します。この様子を図2に示します。発声内容は同一ですから、対応付けられたスペクトルは言語的に同じ音を表しているはずです。このようにして、標準話者と新しい話者の間で同じ言語音のスペクトルがどのように変化したかがわかります。このスペクトルの対応関係を、スペクトル空間内の移動ベクトルとして表現します。話者間のスペクトルの移動ベクトルを求めるためには、原理的にはすべてのスペクトルを含む学習データが必要となります。しかし、実際上は話者適応のたびに大量の音声を発声することは現実的ではありません。一方、学習データを少なくすると、すべてのスペクトルの対応関係が得られなくなる、また、データが少ないため精度が悪くなるという問題が生じます。この問題に対処するために、少ない学習データでも良好な適応化が行なえる方式の研究を行なっています[2]。
この方式では、話者は異なっていても同じ言語を発声しているのであるから、話者間のスペクトルの移動ベクトル場(移動ベクトルの集合を場としてとらえたのも)は、連続的で滑らかなはずであると考え、実際に少量の学習データから得られる移動ベクトルは真の滑らかで連続的な移動ベクトル場からの誤差を含んだサンプルであると考えます。この考えに基づいて、あるスペクトルが学習データ中に含まれず、その移動ベクトルが得られなかった場合には、その近傍のスペクトルの移動ベクトルから内挿により推定を行ないます。また、対応関係に含まれる誤差を減らすために、得られた移動ベクトルに平滑化と呼ばれる整形操作を行ないます。このような原理から、この手法を「移動ベクトル場平滑化法」と呼びます。
図3を用いてこの手法を説明します。図3.aは内挿による移動ベクトル推定の概念図を表します。今、学習データからはスペクトルa1、a1、a3の移動ベクトルは得られたが、スペクトルxの移動ベクトルは得られなかったものとします。この場合、移動ベクトル場が連続的で滑らかであるならば、xの移動ベクトルは近傍のスペクトルa1、a2、a3の移動ベトクルと似ているはずです。そこで、xの移動ベクトルをa1、a2、a3の移動ベクトルから内挿を行なうことにより推定します。
次に、図3.bに移動ベクトルの平滑化の概念図を示します。少ない学習データから得られた移動ベクトルは誤差を含んでいるため、それらからなるベクトル場は歪んだものとなってしまいます。したがって、そのようなベクトル場により写像されたスペクトルは図3.bに実線で示すようにスペクトルの位置が歪められてしまいます。この移動ベクトルに含まれる誤差を減少させるために移動ベクトル場の滑らかな連続性に基づいて平滑化を行ないます。平滑化を行なうことで誤差を低減することができるので、点線で示すような写像が得られます。
学習で得られる移動ベクトルに含まれる誤差は、データの量によって変化します。ここでは、データが十分多く移動ベクトルの誤差が少ないと思われる場合には平滑化をあまりかけず、反対にデータが少なく誤差が多いと思われる場合には平滑化を強くかけることにより、これに対処します。これは、学習データが少ない時は、それから取り出す情報に強い相関を与えて独立性を抑えて、結果的に情報を多く取り過ぎないようにすることに相当します。一方、学習データが多い時は、取り出す情報の個々の独立性を認めることに相当します。このように、話者特性を取り込むモデルの「容量」を、学習データ量に応じて調節できるのが、この手法の本質です。
本手法は従来方法[1]に比較して数々の利点を持っています。第一に、数単語程度の学習データを用いても話者適応化が行なえることです。従来の方法では新しい話者の学習データのみから、新しい話者のスペクトル空間を定義していたため、少なくとも学習データとして25単語程度のデータが必要でした。それに対し、本手法は標準話者のスペクトル空間を局所的に伸縮しながら移動するものなので、わずかな音声でも移動ベクトルの推定に利用できます。第二に、本手法では平滑化を行なうことにより推定誤差を低減させることができるので、同程度の話者適応性能を得るための適応用データが少なくてすみます。第三に、従来法では適応化処理を始めるために新しい話者の特徴の代表点であるコードブックと呼ばれるスペクトル群を学習データから求める必要がありましたが、本手法では新しい話者のコードブックを作成する必要がないことと、適応単語数が少ないので適応化処理での計算量が少なくてすむことから、適応化にかかる時間を大幅に短縮することができます。本手法は、今後の高性能な音声認識手法において、より広い大きな役割を果たすものと期待されます。
5.音声認識への適用と効果
この話者適応化方式を連続音声認識によって評価実験を行ないました。音声認識の手法はHMM-LRと呼ばれる方法を用いました。この手法ではHMMと呼ばれる確率理論に基づく手法を用いて基本単位である音素(母音、子音など)をモデル化し、このモデルを組み合わせることで単語や文を認識します。この手法については既に[3]で紹介されていますので詳細は省きます。この認識手法では、話者の音声スペクトルの特徴はコードブックと呼ばれる有限個のスペクトル群で表現されており、話者適応はこのコードブックを新しい話者に適応することで行ないます。
先に述べたように、音声の特徴は話者により非常に異なるため、話者適応方式の評価は様々な話者を用いて行なう必要があります。ここでは、未知話者としては男女各1名を、標準話者としては男性話者2名を用い、計4通りの組み合わせについて実験を行ないました。比較のために、話者適応を行なわない場合と、コードブックマッピングによる従来法[1]を用いた場合についても実験しました。適応用データの数は本手法では5〜25単語と変化させ、従来法では25単語を用いました。
図4に話者適応を行なわなかった場合(NA)、本手法を用いた場合(new)、従来法を用いた場合(old)の文節認識率です。評価実験は国際会議に関する問い合わせの会話を用いて行ないました。図中のは第1位候補の認識率、は第5位候補までの累積認識率を示します。また、+で示されている範囲は話者および適応用単語による認識率のバラツキです。適応なしの場合の第一位の認識率は52.3%ですが、話者適応化を行なうことにより、適応単語数が5、10、25の場合で、それぞれ、67.9%、70.9%、73.5%と向上しました。図には示していませんが、従来の方法では5単語の敵応用データしか与えられない場合には、適応化を行なわない場合よりもかえって認識率が低下してしまう場合がありました。しかし、本手法では5単語を用いて適応化を行なった場合でも、認識率が約15%向上しています。一方、25単語を用いている従来法の文節認識率は71.0%であり、本手法では半分以下の10単語でほぼ同等の性能が得られていることがわかります。また、認識率のバラツキは本手法の方が小さく、話者の組み合わせおよび適応単語によらず安定して認識率が得られています。
6.より高度な話者適応化
上で述べた話者適応方法では標準話者と未知話者の発声した同一内容の音声を用いて対応関係を学習しているため、未知話者はあらかじめ標準話者が発声したのと同じ内容の発声をする必要がありますが、そのような制限をなくすために認識時と同じように音素モデルを連結して適応用データとの対応づけを行なう方法も可能です[4]。この場合には適応データとその発声内容にしたがって連結された音素モデルとを用いて対応関係を学習します。ですから、発声内容を表す音素記号列を与えれば任意の発声を適応データとして使えるため、より使いやすくなり、話者適応の可能性がさらに広がります。
今まで、音声認識にとって一番大きな要素であるスペクトル形状の適応化について説明してきました。先に述べたように異話者間の音声の違いはこのスペクトル形状の違いだけではなく、イントネーションやアクセントなどの発声の仕方の違いもあり、より高度な話者適応化を行なうためにはこの発声の仕方の違いも適応化する必要があります。そのための一つの方法として、複数話者の音声を集めて、上で述べた話者適応方式により一人の話者のスペクトルへ適応化を行ない、その音声を用いて音素モデルの学習を行なう方法が考えられます。このようにすることで、声の質としてのスペクトル形状は一人の話者のものでありながら、複数の話者の発声の仕方を含む音素モデルが得られます。この手法を「話者重畳型モデル」[5]と呼んでいます。また、新しい話者の発声の仕方がどの既知の話者に近いかを調べることによって、どの話者の特徴を重視して認識するかを決定する方法もあります[6]。
今後、より高度な話者適応化を目指し、スペクトル形状および発声の仕方の両者の違いに対処できる話者適応化方式の研究を続けていく予定です。
7.むすび
ATR自動翻訳電話研究所で行なっている、話し手の違いを克服するための話者適応方式の最近の研究成果を紹介しました。最近の進歩により、従来の方法と比較して半分以下の学習用データでほぼ同程度の文節認識率が得られました。さらに、この適応方法には内容がわかっていれば任意の内容の音声でも話者適応に使えるなどの利点があります。
今後、さらに広い可能性を持ち、より高性能の話者適応を実現するための研究を続け、連続音声認識システムに組み込んでゆく予定です。
参考文献 
概要
