連続音声認識システムの言語モデルとしてはN-gramモデルが一般に用いられている。しかし、マルコフ性を仮定したN-gramモデルでは言語確率は文長が長くなるほど小さくなる。そのため、音響モデルに対する言語モデルの重みを大きく設定するほど認識結果文章の文長が短くなることを実験で確認した。本研究では一般化したベルヌーイ試行のモデルを用いて文長を考慮した言語モデルを提案し、文認識実験によりN-gramモデル、N-gramモデルによる対数言語確率を単語数で割ることで正規化する方法との比較を行なった。その結果、提案モデルでは文長を考慮することにより単語正解率、単評正解精度ともに改善され、また、重みによらず正解に近い文長で認識結果文章を得ることができた。
Recently the N-gram language model has been generally used in continuous speech recognition systems. But, in general, the N-gram based on Markov modeling give lower probabilities to longer sentences. Thus when the language model is weighted heavier than the acoustic model, the recognition results tend to be shorter. In this paper we propose a language model based on generalized Bernoulli trials. Since this model considers sentence length, it shows high word correct and accuracy rates in comparison with the usual N-gram model and its normalized version. Moreover, independent of the weight for the language model, we managed to realize sentences of almost the correct length.

