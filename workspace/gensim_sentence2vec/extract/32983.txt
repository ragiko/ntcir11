さて、調音結合など従来の音声認識が抱えていた問題を解決する、画期的な方法が登場したのは1980年代になってからである。IBMが1970年代に考案した「隠れマルコフモデル」(Hidden Markov Model)という手法を、カーネギーメロン大学が音声認識に応用したのだ。
隠れマルコフモデルは、実験で得た物理データに適合する数式モデルを考え、それに実際の音声を当てはめていくやり方とはまったく異なっていた。統計データを元に確率的にデータを扱うのが隠れマルコフモデルの特徴だ。
「例えば『あ』という音にもばらつきがあり、典型的な『あ』からかなり崩れた『あ』までさまざまなバリエーションがあります。それならば、たくさんの『あ』を集めて、平均的な『あ』からどれくらい離れているのかを表現しようというのが、隠れマルコフモデルの考え方です。隠れマルコフモデルでは、時間変化も含めて音声を統計的に表現することができます」(法政大学 情報科学部 伊藤克亘教授)
人間の音声を物理現象として研究してきた人たちは、隠れマルコフモデルに戸惑いを隠せなかった。統計データを元に、確率的にどの音かを判別するのは、サイコロを振って分析するようなものではないか?こんなやり方が有効なのだろうか?
隠れマルコフモデルが有効に働くためには、膨大なデータの統計処理が必要だ。音声データはテキストデータに比べて圧倒的にサイズが大きいため、昔のコンピュータでは扱えず、研究が難しかった。しかし、80年代以降、コンピュータの処理速度の向上、そして記憶装置の大容量化が進んだことで、研究が可能になった。
日本でも、1986年に設立された第三セクターのATR(国際電気通信基礎技術研究所)が中心になって、隠れマルコフモデルを用いた音声認識の研究を進めていった。
音声認識では音響的な分析だけでなく、同時に言語モデルも必要になる。人間が他人と会話する時、たんに音だけを聞いているわけではない。語と語がどのようにつながっているのかということがわかっているからこそ、多少不鮮明な音であってもきちんと理解ができる。例えば、「私」のあとには「が」とか「は」が続くが、「き」が続くことはない。こうした規則を記述したものが言語モデルだ。音声認識には、音自体を判別するための音響モデル(ここでは隠れマルコフモデル)と、語と語のつながりを判別する言語モデルの両方でできている。ATRが言語モデルを作るために使ったのは、「Nグラム法」というやはり統計的な手法だった。
ATRは、数百人規模の音声データ、そして新聞記事10年分のテキストデータを元に音声認識システムの開発に取り組み、1990年代半ばにはある程度実用的な音声認識システムの開発に成功した。2000年代初頭には、音声認識を使った観光地案内システムも登場している。
このような統計モデルに基づく日本の音声認識研究の成果は、多数の研究者・研究機関の協力により、オープンソースソフトウェアのJuliusとして公開された。
隠れマルコフという音響モデルと、Nグラム法の言語モデルは、音声認識システムの世界的な標準となり、現在ではほぼすべてのシステムがこれらに基づいているといっても過言ではない。条件によっても異なるため一概にはいえないが、日本語でも90%程度の認識率(読み上げた文章と音声認識システムが出力した文章の比較)は実現できるようになってきた。
音声認識技術はどこに向かうのか? (3/5) | Telescope Magazine
