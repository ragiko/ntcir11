  
　学習用データをクラスタリングして代表パタンを生成する統計的手法では、学習用データ量が少ないと学習用データの不足や偏りが起こる。これは、データスパースネス問題と呼ばれる。よって、安定性の高い韻律を生成できないという課題がある。
　［発明の目的］
　本発明の目的の一つは、上記の課題に鑑みてなされたものであり、統計的手法において安定性の高い韻律を生成する、韻律モデル学習装置、韻律モデル学習方法、音声合成システム、およびプログラムを提供することである。
　本発明の韻律モデル学習装置は、データを分割する条件であり、韻律の生成に与える影響が大きい条件を1以上含む第一の条件集合を用いて、前記データのクラスタリングを行う第一のクラスタリング手段と、前記第一のクラスタリング手段によるクラスタリング結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データのクラスタリングを行う第二のクラスタリング手段と、前記第二のクラスタリング手段によるクラスタリング結果に基づいて、韻律モデルを学習する学習手段とを有する。
　本発明の韻律モデル学習方法は、データを分割する条件であり、韻律の生成に与える影響が大きい条件を1以上含む第一の条件集合を用いて、前記データに対して第一のクラスタリングを行い、前記第一のクラスタリングの結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データに対して第二のクラスタリングを行い、前記第二のクラスタリングの結果を用いて、韻律モデルを学習する。
　本発明の韻律モデル学習プログラムは、データを分割する条件であり、韻律の生成に与える影響が大きい条件を1以上含む第一の条件集合を用いて、前記データのクラスタリングを行う第一のクラスタリングステップと、前記第一のクラスタリング手段によるクラスタリング結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データのクラスタリングを行う第二のクラスタリングステップと、前記第二のクラスタリング手段によるクラスタリング結果を用いて、韻律モデルを学習する学習ステップとをコンピュータに実行させる。
　本発明の音声合成システムは、データを分割する条件であり、韻律の生成に与える影響が大きい条件である第一の条件を1以上含む第一の条件集合を用いて、前記データのクラスタリングを行う第一のクラスタリング手段と、前記第一のクラスタリング手段によるクラスタリング結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データのクラスタリングを行う第二のクラスタリング手段と、前記第二のクラスタリング手段によるクラスタリング結果を用いて、韻律モデルの学習を行う学習手段と、前記学習手段で学習された韻律モデルに基づいて、入力されたテキストに対応する合成音声の波形を生成する合成手段とを有する。
　本発明は、係る韻律モデル学習プログラムが格納された、コンピュータ読み取り可能な不揮発性の記録媒体によっても実現可能である。
　本発明によれば、安定性の高い韻律を生成可能な韻律モデルを生成できるという効果がある。
図１は、本発明の各実施形態に係るハードウェア構成の一例を表す図である。 図２は、本発明の第１の実施形態に係るブロック図である。 図３は、本発明の第１の実施形態に係るフローチャートである。 図４は、本発明の第２の実施形態に係るブロック図である。 図５は、本発明の第２の実施形態に係るフローチャートである。 図６は、本発明の第３の実施形態に係るブロック図である。 図７は、本発明の第３の実施形態に係るフローチャートである。 図８は、本発明の第４の実施形態に係るブロック図である。 図９は、本発明の第４の実施形態を説明するための第一の図である。 図１０は、本発明の第４の実施形態を説明するための第二の図である。 図１１は、本発明の第１の実施形態に係る第二のブロック図である。 図１２は、本発明の第２の実施形態に係る第二のブロック図である。 図１３は、本発明の第４の実施形態を説明するための第三の図である。 
　次に、本発明の実施形態について図面を参照して詳細に説明する。なお、各実施形態について、同様な構成要素には同じ符号を付し、適宜説明を省略する。
　（第１の実施形態）
　図１は、本発明の第１の実施形態に係る韻律モデル学習装置１を実現する、コンピュータのハードウェア構成の一例を表す図である。
　図１に示すように、韻律モデル学習装置１を実現可能なコンピュータ１０００は、ＣＰＵ（Ｃｅｎｔｒａｌ　Ｐｒｏｃｅｓｓｉｎｇ　Ｕｎｉｔ）２、メモリ３、記憶装置４、通信ＩＦ（Ｉｎｔｅｒｆａｃｅ）５、表示装置６および入力装置７を有する。記憶装置４は、例えば、ＨＤＤ（Ｈａｒｄ　Ｄｉｓｋ　Ｄｒｉｖｅ）である。通信ＩＦ５は、図示しないネットワークを介してデータの通信を行う。表示装置６は、ディスプレイ装置などである。入力装置７は、キーボードやマウス等のポインティングデバイスを含む。これらの構成要素は、バス８を通して互いに接続されており、互いにデータの入出力を行う。なお、韻律モデル学習装置１のハードウェア構成は、この構成に制限されず、適宜変更することができる。
　また、後述される、第１の実施形態に係る韻律モデル学習装置１Ｂ、第２の実施形態に係る韻律モデル学習装置１Ａ及び韻律モデル学習装置１Ｃ、第３の実施形態に係る音声合成システム１００、及び第４の実施形態に係る音声合成システム１０１も同様に、図１に示すハードウェア構成を備えるコンピュータ１０００により実現できる。なお、各実施形態に係る韻律モデル学習装置及び音声合成システムは、図２、図４、図６、図８、図１１、図１２のうち、その韻律モデル学習装置又は音声合成システムに該当する図に示す機能を有する専用装置によっても実現できる。
　図２は、本発明の第１の実施形態に係る韻律モデル学習装置１の機能構成の例を表すブロック図である。
　図２を参照すると、本実施形態に係る韻律モデル学習装置１は、第一のクラスタリング部１１０と、第二のクラスタリング部１２０と、第一の学習部１３０とを有する。
　第一のクラスタリング部１１０は、第一の条件集合の少なくとも一部の条件を用いて、データのクラスタリングを行う。ここで、データとは、学習用データまたは暫定的に作成された韻律モデルのことである。韻律モデルは、第２の実施形態の説明において後述される。本実施の形態における第一のクラスタリング部１１０は、学習用データのクラスタリングを行う。
　ここで、第一の条件集合は、データを分割するための条件を、１以上含む条件集合である。以下の説明において、第一の条件集合が含むデータを分割するための条件は、第一の条件と表記される。第一の条件は、重要度が高い、すなわち、韻律の生成に与える影響が大きい条件である。第一の条件は、言語的あるいは音響的に重要な特徴に関する条件である。第一の条件は、例えば、アクセント位置に関する条件である。
　第一のクラスタリング部１１０は、第一の条件集合の少なくとも一部の条件を用いてもよい。また、第一のクラスタリング部１１０は、第一の条件集合の全ての条件を用いてもよい。全ての条件を用いる場合、重要度が高い条件が全てクラスタリングに用いられる。よって、後述する第一の学習部１３０は、より安定性が高い韻律モデルを学習することができる。
　クラスタリングの手法には、例えば、木構造クラスタリングがある。その場合、第一のクラスタリング部１１０は、第一の条件集合に含まれる条件を各ノードにもつ木構造を構築する。クラスタリングの手法として、Ｋ－ｍｅａｎｓ法（Ｋ－平均法）、ウォード法などの、その他の手法が用いられてもよい。また、第一のクラスタリング部１１０によるクラスタリングの手法には、数量化I類等の数量化理論も適用できる。
　第二のクラスタリング部１２０は、第一のクラスタリング部１１０によるクラスタリング結果と、第一の条件集合に含まれる条件とは異なる条件を含む第二の条件集合を用いて、学習用データのクラスタリングを行う。なお、第二の条件集合は、第一の条件集合に含まれる条件の全てまたは一部を、含んでもよい。
　第二のクラスタリング部１２０は、クラスタリング構造において、第一の条件集合が第二の条件集合に対して優位となるようにクラスタリングを行う。優位であるとは、クラスタリングによる分割条件の序列が上位であることである。例えば、木構造の場合には、その条件が上位構造に位置することである。
　例えば、木構造クラスタリングが用いられる場合、第二のクラスタリング部１２０は、第一のクラスタリング部１１０が構築した木構造を保ったまま、下位構造に、第二の条件集合の条件によるノードを追加していく。
　または、第二のクラスタリング部１２０は、第一のクラスタリング部１１０が構築した木構造のノードの間に、第二の条件集合の条件によるノードを追加してもよい。この場合でも、第一の条件集合が第二の条件集合に対して優位なクラスタリング構造になるように、ノードを追加することが望ましい。
　第一の学習部１３０は、第二のクラスタリング部１２０によるクラスタリング結果に基づいて、学習を行うことにより韻律モデルを生成する。例えば、第一の学習部１３０は、クラスタごとに、クラスタに属する学習用データから韻律モデルを生成する。
　なお、以上で説明した構成において、第一のクラスタリング部１１０および第二のクラスタリング部１２０は異なる部であるが、韻律モデル学習装置１の構成はこの構成に限られない。例えば、１つのクラスタリング部が、第一の条件集合が第二の条件集合に対してクラスタリング構造において優位となるようなクラスタリング構造を構築し、その構造に基づいてクラスタリングを行ってもよい。
　以上で説明した、本実施形態における韻律モデル学習装置１は、第一のクラスタリング部１１０および第二のクラスタリング部１２０によって、二段階のクラスタリングを行う。本実施形態における韻律モデル学習装置１は、二段階ではなく、三段階以上のクラスタリングを行ってもよい。韻律モデル学習装置１が行うクラスタリングの段階数をＮと表記すると、Ｎ段階のクラスタリングにおいて、例えば、第一のクラスタリング部、第二のクラスタリング部、#12289;第Nのクラスタリング部が、順にクラスタリングを行う。クラスタリング部の、使用される、データを分割する条件の重要度の高さの順番は、重要度が高い方から、第一のクラスタリング部、第二のクラスタリング部、#12289;第Nのクラスタリング部である。
　また、第一の条件集合および第二の条件集合は、記憶部に格納されている。図２において、その記憶部は図示されていない。第一のクラスタリング部１１０および第二のクラスタリング部１２０は、記憶部に格納された第一の条件集合または第二の条件集合を参照して、クラスタリングを行う。
　図１１は、上述の記憶部が図示された、本実施形態に係る韻律モデル学習装置１Ｂの構成を表すブロック図である。図１１において、条件集合記憶部１５０が、第一の条件集合および第二の条件集合が格納される上述の記憶部である。韻律モデル学習装置１Ｂは、条件集合記憶部１５０が図示されていることを除き、図２に示す韻律モデル学習装置１と同じである。
　次に、本発明の第１の実施形態の動作について詳細に説明する。
　図３は、第１の実施形態の韻律モデル学習装置１の動作の一例を示すフローチャートである。
　第一のクラスタリング部１１０は、第一の条件集合の少なくとも一部の条件を用いて、学習用データのクラスタリングを行う（ステップＳ１０１）。第二のクラスタリング部１２０は、第一のクラスタリング部１１０のクラスタリング結果と、第一の条件集合に含まれる条件とは異なる条件で構成される第二の条件集合を用いて、学習用データのクラスタリングを行う（ステップＳ１０２）。第一の学習部１３０は、第二のクラスタリング部１２０のクラスタリング結果に基づいて、韻律モデルを学習する（ステップＳ１０３）。
　本実施形態の韻律モデル学習装置１は、安定性の高い韻律を生成可能な韻律モデルを生成できる。統計的手法におけるクラスタリングでは、データを分割するための条件が重要であるほどクラスタリング構造の上位に位置する。しかし、重要な条件が上位に位置するためには、データが十分存在する必要がある。しかし、本実施形態によれば、データが少ない場合でも、重要な条件が上位となるクラスタリング構造に基づいてクラスタリングできる。
　また、統計的手法におけるクラスタリングでは、原則的に、統計量に基づいて、クラスタリングの構造が決定される。よって、言語的あるいは音響的に重要な特徴に関する条件が使用されない恐れがあった。例えば、日本語のように声の高低（ピッチ）によってアクセントが表現される言語の場合、ピッチパタンの形状によって、発声される音声のアクセントがほぼ決定される。つまり、ピッチパタン形状が不自然だと、合成音声は訛ったような音声となってしまう。したがって、ピッチパタンや状態継続長等で表される韻律情報を生成する場合には、ピッチパタンの概形に関する条件が非常に重要である。これに関する条件が使われないと、正しいアクセントを表現するピッチパタンが生成されないことがある。
　本実施形態の韻律モデル学習装置１は、ピッチパタンの概形などの、言語的あるいは音響的に重要な特徴に関する条件を、優先的にクラスタリングに利用する。よって、本実施形態の韻律モデル学習装置１は、より安定性の高い韻律を生成可能なモデルを、生成できる。
　（第２の実施形態）
　図４は、本発明の第２の実施形態に係る韻律モデル学習装置１Ａの構成例を示すブロック図である。
　図４を参照すると、本実施形態に係る韻律モデル学習装置１Ａは、第一の実施形態における第一のクラスタリング部１１０、第二のクラスタリング部１２０、第一の学習部１３０、が、各々、第一のクラスタリング部１１１、第二のクラスタリング部１２１、第一の学習部１３１に置き換えられている。さらに、本実施形態に係るモデル学習装置は、第二の学習部１４０を有する。
　第二の学習部１４０は、学習用データから、暫定的に、韻律モデルを作成する。
　第一のクラスタリング部１１１と、第二のクラスタリング部１２１は、韻律モデルのクラスタリングを行う。また、第一の学習部１３１は、第二のクラスタリング部１２０のクラスタリングの結果に基づいて、韻律モデルを再学習する。第一のクラスタリング部１１１と、第二のクラスタリング部１２１と、第一の学習部１３１の動作は、第一の実施形態における第一のクラスタリング部１１０、第二のクラスタリング部１２０、第一の学習部１３０、と各々同様であるため、説明を省略する。
　さらに、本実施形態に係る韻律モデル学習装置１Ａは、第１の実施形態に係る韻律モデル学習装置１と同様に、条件集合記憶部１５０を含んでいる。ただし、図４において、第一の条件集合および第二の条件集合を記憶する条件集合記憶部１５０は図示されていない。
　図１２は、上述の記憶部が図示された、本実施形態に係る韻律モデル学習装置１Ｃの構成を表すブロック図である。図１２において、条件集合記憶部１５０が、第一の条件集合および第二の条件集合が格納される上述の記憶部である。韻律モデル学習装置１Ｃは、条件集合記憶部１５０が図示されていることを除き、図４に示す韻律モデル学習装置１Ａと同じである。
　次に、本発明の第２の実施形態の動作について詳細に説明する。
　図５は、第２の実施形態の韻律モデル学習装置１Ａの動作の一例を示すフローチャートである。
　第二の学習部１４０は、学習用データから、韻律モデルを作成する（ステップＳ１１４）。第一のクラスタリング部１１０は、第一の条件集合の少なくとも一部の条件を用いて、韻律モデルのクラスタリングを行う（ステップＳ１１１）。第二のクラスタリング部１２０は、第二の条件集合の少なくとも一部の条件を用いて、韻律モデルのクラスタリングを行う（ステップＳ１１２）。第一の学習部１３０は、第二のクラスタリング部１２０のクラスタリング結果に基づいて、韻律モデルを再学習する（ステップＳ１１３）。
　本実施形態の韻律モデル学習装置１Ａは、より安定性の高い韻律を生成可能なモデルを生成できる。韻律モデルを再学習することで、モデルを学習する精度が向上するためである。
　（第３の実施形態）
　図６は、本発明の第３の実施形態に係る音声合成システム１００の構成例を示すブロック図である。図６を参照すると、本実施形態に係る音声合成システム１００は、学習部１０と音声合成部２０によって構成されている。学習部１０は、第一のクラスタリング部１１０と、第二のクラスタリング部１２０と、第一の学習部１３０と、韻律モデル記憶部３１０とを有する。音声合成部２０は、言語解析部２１０と、韻律生成部２２０と、波形生成部２３０とを有する。
　韻律モデル記憶部３１０は、第一の学習部１３０が生成した韻律モデルを記憶する。
　音声合成部２０は、入力されたテキストに対応する合成音声の波形を生成する。
　言語解析部２１０は、入力されたテキストを言語解析して、音韻情報を出力する。
　韻律生成部２２０は、韻律モデル記憶部３１０に記憶された韻律モデルに含まれるクラスタリング構造の情報を参照して、音韻情報が属するクラスタを判断する。さらに、韻律生成部２２０は、そのクラスタの韻律モデルに基づいて、韻律情報を生成する。
　波形生成部２３０は、生成された韻律情報に基づいて、合成音声の波形を生成する。波形生成方式には、例えば、波形接続方式、波形編集方式あるいはパラメトリック方式がある。
　本実施形態の学習部１０は、図２に示す第１の実施形態の韻律モデル学習装置１に、さらに韻律モデル記憶部３１０が含まれた韻律モデル学習装置である。本実施形態の学習部１０は、第１の実施形態の韻律モデル学習装置１と、韻律モデル記憶部３１０により実現されていてもよい。さらに、第１の実施形態の韻律モデル学習装置１と同様に、学習部１０は、図６において図示されない、前述の条件集合記憶部１５０を含む。すなわち、本実施形態の学習部１０は、図１１に示す、第１の実施形態の韻律モデル学習装置１Ｂに、さらに韻律モデル記憶部３１０が含まれた韻律モデル学習装置である。
　本実施形態の音声合成部２０は、言語解析部２１０と韻律生成部２２０と波形生成部２３０を有する音声合成装置によって実現されていてもよい。その音声合成装置は、韻律モデル記憶部３１０に格納されている韻律モデルを取得可能であればよい。例えば、その音声合成装置は、韻律モデル記憶部３１０を含む上述の韻律モデル学習装置に接続され、韻律モデル記憶部３１０に格納されている韻律モデルをその韻律モデル学習装置から受信することができればよい。
　次に、本発明の第３の実施形態の動作について詳細に説明する。
　図７は、第３の実施形態の音声合成システム１００の動作の一例を示すフローチャートである。
　ステップＳ１０１～ステップＳ１０３は、第１の実施形態と同じであるため、説明を省略する。
　言語解析部２１０は、入力されたテキストを言語解析して、音韻情報を出力する（ステップＳ２０１）。韻律生成部２２０は、音韻情報が属するクラスタを判断し、韻律情報を生成する（ステップＳ２０２）。波形生成部２３０は、生成された韻律情報に基づいて、合成音声の波形を生成する（ステップＳ２０３）。
　以上のように、本実施形態の音声合成システム１００は、安定性の高い韻律を有する合成音声波形を生成することができる。
　（第４の実施形態）
　続いて、本発明の第４の実施形態について説明する。図８は、本発明の第４の実施形態に係る音声合成システム１０１の構成例を示すブロック図である。
　本実施形態に係る音声合成システム１０１は、学習部１１と音声合成部２０を有する。学習部１１は、第二の学習部１４０と、第一のクラスタリング部１１１と、第二のクラスタリング部１２１と、第一の学習部１３１とを有する。音声合成部２０は、言語解析部２１０と、韻律生成部２２０と、波形生成部２３０とを有する。音声合成システム１０１は、さらに、韻律モデル記憶部３１０を有する。
　なお、本実施形態における音声合成システム１０１は、コンテクスト情報に依存したＨＭＭ（Ｈｉｄｄｅｎ　Ｍａｒｋｏｖ　Ｍｏｄｅｌ）モデルを用いるものとする。本実施形態における音声合成システム１０１は、ｌｅｆｔ－ｔｏ－ｒｉｇｈｔ型の連続分布ＨＭＭを、音素毎に1つあるいは複数の状態で連結する事によりモデル化する。コンテクスト情報とは、スペクトル、ピッチ、継続長等、音響的なパラメータに影響を与えると考えられる情報（すなわち変動要因）である。
　本実施形態における音声合成システム１０１は、日本語の音声を合成する。日本語は、声の高低によりアクセントを表現するピッチアクセント言語である。よって、アクセントは、主にピッチパタンと音素時間継続長が支配的となる。そこで、本実施形態では、韻律情報は、ピッチパタンと音素時間継続長の特徴量に関する情報とする。さらに、韻律情報は、パワー等を含んでもよい。また、本実施形態において、クラスタリング手法として、二分木の木構造クラスタリングが用いられる。そのため、データを分割する条件は、ノードを二分する質問となる。
　学習用データは、予め用意されている。学習用データは、音声合成で再現したい話者の音声を収録した音声波形データを少なくとも含む。さらに、学習用データは、音声波形データを分析して生成された付加情報を含む。付加情報は、発声内容のテキスト情報、音声波形データにおける各音素のコンテクスト情報、音声波形データにおける各音素の継続時間長、等間隔ごとの基本周波数情報（ピッチパタン情報）、等間隔ごとのケプストラム情報（音声波形データのスペクトル情報）、を含む。また、コンテクスト情報は、少なくともアクセント句のピッチパタン概形に関する情報を含み、先行／当該／後続の音素に関する情報、文／アクセント句／呼気段落のモーラ数に関する情報、アクセント位置に関する情報、疑問文か否かの情報等を含む。br>
　第二の学習部１４０は、学習用データを用いて、韻律モデルを作成するための学習を行う。韻律モデルは、クラスタリングや再学習を行うために作成する暫定的なモデルである。モデルの精度は、低くなることが多い。
　第一のクラスタリング部１１１は、第一の条件集合を用いて、韻律モデルのクラスタリングを行う。第一の条件集合は、アクセント句におけるピッチパタンの概形に関する質問のみで構成される。クラスタリングは、音声波形データを構成する各音素のコンテクスト情報に基づいて行われる。よって、アクセント句におけるピッチパタンの概形に関する質問は、例えば「３型アクセント句の２番目の音節か？」「平板アクセント句の３番目以降の音節か？」というような質問である。
　第一のクラスタリング部１１１は、アクセント句におけるピッチパタンの概形に関する質問のみをノードに持つ木構造（第一段木構造）を構築する。第一の条件集合は、後述する第二の条件集合と比べて小規模な集合となっている。よって、最終的に構築される木構造に比べると、第一段木構造は小規模な構造となる。図９に、第一段木構造の例を示す。
　第二のクラスタリング部１２１は、第二の条件集合を用いて、第一段木構造をさらに詳細化するためのクラスタリングを行う。具体的には、第二のクラスタリング部１１２は、第一段木構造を保ったまま、第二の条件集合の質問によってノードを追加していく。第二の条件集合には、例えば「当該音素が#65345;#65311;」「５モーラ目の音節？」といった当該音素に関する質問や、「先行音素が無声音？」「後続音素がポーズ？」といった、先行および後続環境に関する質問が含まれる。
　このようにして、第二のクラスタリング部１２１は、詳細な木構造（第二段木構造）を構築する。図１０に、第二段木構造の例を示す。図１０に示すように、第二段木構造は、第一段木構造で構築された終端ノードに対してさらに枝分かれした構造となる。
　なお、図１０において、第一段木構造の部分は省略されている。図１３は、図１０において省略されている第一段木構造の部分を表す図である。
　このように、第一のクラスタリング部１１１および第二のクラスタリング部１２１は、アクセント句におけるピッチパタンの形状に関する質問が上位構造にある、木構造を構築する。
　第一の学習部１３１は、第二のクラスタリング部１２１のクラスタリング結果を用いて、韻律モデルの再学習をクラスタごとに行う。韻律モデルは、木構造クラスタリングの構造情報も含む。
　第一の学習部１３１は、再学習によって生成された韻律モデルを、韻律モデル記憶部３１０に格納する。
　音声合成部２０は、入力されたテキストに基づいて、合成音声の波形を生成する。言語解析部２１０は、入力されたテキストを言語解析し、入力されたテキストの音韻情報を生成する。韻律生成部２２０は、この音韻情報から、韻律モデル内に含まれる木構造の情報に基づいて各音韻情報が属するクラスタを判断する。さらに、韻律生成部２２０は、音韻情報が属するクラスタの韻律モデルを用いて韻律情報（例えば、ピッチパタン、音素の時間継続長）を生成する。波形生成部２３０は、生成された韻律情報に基づいて、合成音声の波形を生成する。
　以上の説明において、本実施形態では、第一の条件集合は、アクセント句概形に関する質問のみを含んでいる。しかし、第一の条件集合は、それに限られない。例えば、第一の条件集合は、少なくとも「当該音素が有声音？」という質問を含んでもよい。有声音か無声音であるかは、韻律を生成する際に、重要な条件である。無声音はピッチ周波数が存在しないために無声音に対してピッチを生成する必要がないが、有声音に対してピッチを生成する必要がある。
　以上の説明において、本実施形態では、ピッチアクセント言語である日本語が対象であるため、韻律情報は、ピッチパタンと音素時間継続長である。英語を代表とした、声の強弱をアクセントとするストレスアクセント言語の場合は、韻律情報は、パワーと音素継続時間長であればよい。もちろん、ピッチアクセント言語かストレスアクセント言語に関わらず、韻律情報は、ピッチパタン、音素時間継続長、パワーおよびその他の特徴量を全て含んでもよい。
　韻律モデル記憶部３１０が記憶している韻律モデルは、クラスタ内の実際のデータであってもよい。韻律生成部２２０は、クラスタ内の実際のデータを選択することによって韻律情報を生成する。例えば、韻律モデル記憶部３１０は、クラスタごとに、アクセント句ごとのピッチパタンの複数のデータを記憶する。各クラスタの代表ピッチパタンは、セントロイド（すなわち、重心）に最も近いデータとする。韻律生成部２２０は、クラスタの代表ピッチパタンに基づいて、韻律情報を生成する。
　なお、第一の学習部１３１が生成した韻律モデルに対して、第一のクラスタリング部１１１および第二のクラスタリング部１２１が、再度クラスタリングを行ってもよい。このように、複数回の学習とクラスタリングを繰り返すことにより、モデルを学習する精度が向上する。よって、より安定性の高い韻律を生成可能なモデルが生成される。
　本実施形態の学習部１１は、図４に示す、第２の実施形態に係る韻律モデル学習装置１Ａである。本実施形態の学習部１１は、さらに、韻律モデル記憶部３１０を含んでいてもよい。その場合、本実施形態の学習部１１は、第２の実施形態に係る韻律モデル学習装置１Ａに、さらに音律モデル記憶部３１０が含まれた音律モデル学習装置である。また、第２の実施形態に係る韻律モデル学習装置１Ａと同様に、本実施形態の学習部１１は、図８においては図示されない、前述の条件集合記憶部１５０を含む。すなわち、本実施形態の学習部１１は、図１２に示す、第２の実施形態に係る韻律モデル学習装置１Ｃに、さらに音律モデル記憶部３１０が含まれた音律モデル学習装置である。
　本実施形態の音声合成部２０は、言語解析部２１０と、韻律生成部２２０と、波形生成部２３０とを含む音声合成装置であってもよい。その音声合成装置は、韻律モデル記憶部３１０に格納されている韻律モデルを取得可能であればよい。
　以上、実施形態を参照して本願発明を説明したが、本願発明は上記実施形態に限定されるものではない。
　本願発明の構成や詳細には、例えば統計的手法の種類、クラスタリングの種類、韻律生成方式および音声合成方式等に関して、本願発明のスコープ内で当業者が理解し得る様々な変更をすることができる。
　また、上述の説明で用いた複数のフローチャートでは、複数の処理が順番に記載されているが、各実施形態で実行される処理の実行順序は、その記載の順番に制限されない。各実施形態では、図示される工程の順番を内容的に支障のない範囲で変更することができる。また、上述の各実施形態及び第４の実施形態は、内容が相反しない範囲で組み合わせることができる。
　また、韻律モデル学習装置１、韻律モデル学習装置１Ａ、韻律モデル学習装置１Ｂ、韻律モデル学習装置１Ｃ、音声合成システム１００、音声合成システム１０１、学習部１０、学習部１１、及び音声合成部２０は、それぞれ、コンピュータ及びコンピュータを制御するプログラム、専用のハードウェア、又は、コンピュータ及びコンピュータを制御するプログラムと専用のハードウェアの組合せにより実現することができる。
　上で言及したように、図１は、韻律モデル学習装置１、韻律モデル学習装置１Ａ、韻律モデル学習装置１Ｂ、韻律モデル学習装置１Ｃ、音声合成システム１００、音声合成システム１０１、学習部１０、学習部１１、及び音声合成部２０を実現するために使用される、コンピュータ１０００のハードウェア構成の一例を表す図である。図１を参照すると、コンピュータ１０００は、さらに、記録媒体９にアクセスすることができる。メモリ３と記憶装置４は、例えば、ＲＡＭ（Ｒａｎｄｏｍ　Ａｃｃｅｓｓ　Ｍｅｍｏｒｙ）、ハードディスクなどの記憶装置である。記録媒体９は、例えば、ＲＡＭ、ハードディスクなどの記憶装置、ＲＯＭ（Ｒｅａｄ　Ｏｎｌｙ　Ｍｅｍｏｒｙ）、可搬記録媒体である。記憶装置４が記録媒体９であってもよい。ＣＰＵ２は、メモリ３と、記憶装置４に対して、データやプログラムの読み出しと書き込みを行うことができる。ＣＰＵ２は、通信ＩＦ５を介して、例えば、学習用データを入力する装置、入力テキストを入力する装置、韻律モデルを出力する装置、及び音声波形を出力する装置にアクセスすることができる。ＣＰＵ２は、記録媒体９にアクセスすることができる。記録媒体には、コンピュータ１０００を韻律モデル学習装置１、韻律モデル学習装置１Ａ、韻律モデル学習装置１Ｂ、韻律モデル学習装置１Ｃ、音声合成システム１００、音声合成システム１０１、学習部１０、学習部１１、又は音声合成部２０として動作させるプログラムが格納されている。
　ＣＰＵ２は、記録媒体９に格納されている、コンピュータ１０００を韻律モデル学習装置１、韻律モデル学習装置１Ａ、韻律モデル学習装置１Ｂ、韻律モデル学習装置１Ｃ、音声合成システム１００、音声合成システム１０１、学習部１０、学習部１１、又は音声合成部２０として動作させるプログラムを、メモリ３にロードする。そして、ＣＰＵ２が、メモリ３にロードされたプログラムを実行することにより、コンピュータ１０００は韻律モデル学習装置１、韻律モデル学習装置１Ａ、韻律モデル学習装置１Ｂ、韻律モデル学習装置１Ｃ、音声合成システム１００、音声合成システム１０１、学習部１０、学習部１１、又は音声合成部２０として動作する。
　第一のクラスタリング部１１０、第一のクラスタリング部１１１、第二のクラスタリング部１２０、第二のクラスタリング部１２１、第一の学習部１３０、第一の学習部１３１、第二の学習部１４０、言語解析部２１０、韻律生成部２２０、波形生成部２３０は、例えば、プログラムを記憶する記録媒体９からメモリ３に読み込まれた、各部の機能を実現するための専用のプログラムと、そのプログラムを実行するＣＰＵ２により実現することができる。また、条件集合記憶部１５０、韻律モデル記憶部３１０は、コンピュータが含むメモリ３やハードディスク装置等の記憶装置４により実現することができる。あるいは、第一のクラスタリング部１１０、第一のクラスタリング部１１１、第二のクラスタリング部１２０、第二のクラスタリング部１２１、第一の学習部１３０、第一の学習部１３１、第二の学習部１４０、条件集合記憶部１５０、言語解析部２１０、韻律生成部２２０、波形生成部２３０、韻律モデル記憶部３１０の一部又は全部を、各部の機能を実現する専用の回路によって実現することもできる。
　また、上記の実施形態の一部又は全部は、以下の付記のようにも記載されうるが、以下には限られない。
　（付記１）
　データを分割する条件であり、韻律の生成に与える影響が大きい条件を1以上含む第一の条件集合を用いて、前記データのクラスタリングを行う第一のクラスタリング手段と、
　前記第一のクラスタリング手段によるクラスタリング結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データのクラスタリングを行う第二のクラスタリング手段と、
　前記第二のクラスタリング手段によるクラスタリング結果に基づいて、韻律モデルを学習する学習手段と
　を有する韻律モデル学習装置。
　（付記２）
　付記１に記載の韻律モデル学習装置において、
　前記第一のクラスタリング手段は、前記第一の条件集合に含まれる全ての条件を用いてクラスタリングを行う
　韻律モデル学習装置。
　（付記３）
　付記１または２に記載の韻律モデル学習装置において、
　前記第一の条件集合は、少なくとも、アクセント位置に関する条件を含む
　韻律モデル学習装置。
　（付記４）
　付記１乃至３のいずれかに記載の韻律モデル学習装置において、
　前記第二のクラスタリング手段は、前記第一のクラスタリング手段のクラスタリング結果を上位構造とし、前記第二の条件集合を用いて下位構造をクラスタリングする
　韻律モデル学習装置。
　（付記５）
　付記１乃至４のいずれかに記載の韻律モデル学習装置において、
　前記第一の条件集合は、少なくとも、当該音素が有声音であるか否かに関する質問を含む
　韻律モデル学習装置。
　（付記６）
　データを分割する条件であり、韻律の生成に与える影響が大きい条件を1以上含む第一の条件集合を用いて、前記データに対して第一のクラスタリングを行い、
　前記第一のクラスタリングの結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データに対して第二のクラスタリングを行い、
　前記第二のクラスタリングの結果を用いて、韻律モデルを学習する
　韻律モデル学習方法。
　（付記７）
　データを分割する条件であり、韻律の生成に与える影響が大きい条件を1以上含む第一の条件集合を用いて、前記データのクラスタリングを行う第一のクラスタリングステップと、
　前記第一のクラスタリングステップによるクラスタリング結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データのクラスタリングを行う第二のクラスタリングステップと、
　前記第二のクラスタリングステップによるクラスタリング結果を用いて、韻律モデルを学習する学習ステップと
　をコンピュータに実行させる韻律モデル学習プログラム。
　（付記８）
　データを分割する条件であり、韻律の生成に与える影響が大きい条件である第一の条件を1以上含む第一の条件集合を用いて、前記データのクラスタリングを行う第一のクラスタリング手段と、
　前記第一のクラスタリング手段によるクラスタリング結果と、前記第一の条件集合に含まれる条件とは異なる条件を１以上含む第二の条件集合とを用いて、前記データのクラスタリングを行う第二のクラスタリング手段と、
　前記第二のクラスタリング手段によるクラスタリング結果を用いて、韻律モデルの学習を行う学習手段と、
　前記学習手段で学習された韻律モデルに基づいて、入力されたテキストに対応する合成音声の波形を生成する合成手段と
　を有する音声合成システム。
　この出願は、２０１２年１０月１６日に出願された日本出願特願２０１２－２２８６６３を基礎とする優先権を主張し、その開示の全てをここに取り込む。
　１、１Ａ、１Ｂ、１Ｃ　　韻律モデル学習装置
　２　　ＣＰＵ
　３　　メモリ
　４　　ＨＤＤ
　５　　通信ＩＦ
　６　　表示装置
　７　　入力装置
　８　　バス
　１０、１１　　学習部
　２０　　音声合成部
　１００、１０１　　音声合成システム
　１１０、１１１　　第一のクラスタリング部
　１２０、１２１　　第二のクラスタリング部
　１３０、１３１　　第一の学習部
　１４０　　第二の学習部
　１６０　　条件集合記憶部
　２１０　　言語解析部
　２２０　　韻律生成部
　２３０　　波形生成部
　３１０　　韻律モデル記憶部
　１０００　　コンピュータ
Patent WO2014061230A1 - 韻律モデル学習装置、韻律モデル学習方法、音声合成システム、および韻律モデル学習プ ... - Google Patents
