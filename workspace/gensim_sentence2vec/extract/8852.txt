前回は、標本を抽出して、ヒストグラムや要約統計量によって分布の性質を調べる方法について紹介をしました。これらは「記述統計学(Descriptive Statistics)」または「古典統計学(Classical Statistics)」と呼ばれる「古典的な」統計学です。もちろん、ヒストグラムを調べたり平均値や分散を求めることはデータを解析するための重要な手法の一つであり、今でもこれらは利用されています。
しかし、今までにも述べたように、全ての標本を元にその分布を調べるのは、特に母集団が巨大になると実質不可能な場合が多々あります。それは、調査に非常にお金がかかったり、時間がかかり過ぎたりすることが原因として挙げられます。そのような場合は、母集団から一部の標本を抽出してデータを解析するわけですが、それが母集団の分布状態を正しく反映していなければ、調査をしても無意味になってしまいます。そこで、一部の標本を元に調べた結果が本当に有用であるかを調べることを目的に「推計統計学(Inferential Statistics)」が誕生することになります。この章では、推計統計学の考え方から始めて、その中の手法の一つである「推定(Estimation)」について紹介したいと思います。
1) 推計統計学(Inferential Statistics)
例えば、紙に書かれた 10 個のデータがあって、その平均を求めたいとします。しかし、コンピュータはおろか、電卓もそろばんもなく、しかも暗算は苦手でできればしたくないので、かなり手抜きをして 10 個のデータから 2 個だけ抽出して平均を求めたとします。この時の平均値は、母集団である 10 個のデータに対する平均値として利用できるでしょうか。
平均 &mu;、分散 &sigma;2 の母集団から N 個のデータを抽出した時、その標本平均の分布は平均 &mu;、分散 &sigma;2 / N となることは今までにも何度か登場しました。10 個のデータの平均が &mu;、分散が &sigma;2 であれば、そこから 2 個のデータで平均を取る操作を繰り返すと得られる平均値は 10C2 = 45 個となって、その平均は &mu;、分散は &sigma;2 / 2 になると予想できます(実際には母集団の要素数が有限個なので分散は &sigma;2 / 2 にはならないのですが、これについては後述します)。よって、要素を一個だけ抽出するよりもバラツキは半分に抑えられ、分布を要約する量としてはランダムに一つ選ぶよりも適していることになります。しかし、平均を求めるために抽出する標本の数を多くすればさらにバラツキは小さくなり、10 個全てを使って平均値を計算すれば分散はゼロになるので、平均値として扱う値としては最も適したものになります。
上で述べたことは当たり前のことで、実際のデータに対して適当な値を一つ選んでそれを代表値として使うようなことは行わず、できるだけ多くのデータ(可能なら全データ)で平均値を計算して代表値として利用しようとするのが普通の考え方です。標本平均の分布は、それを数学を使って表したものに過ぎないわけです。
問題は、母集団が大きすぎて全てのデータを扱うことができない場合、一部のデータだけで全体の様子をどのように推定すればよいかということになります。記述統計学では、抽出した標本の状態を調べることが目的であるのに対し、その標本が全体の中の一部であるとして、その状態から全体の様子を観察するわけです。ちょうど、窓から見える景色から全体を考えるようなイメージで考えると分かりやすいかもしれません。窓から見える風景が海だけであったとしても、その外側に崖があったり、実は巨大な湖だったということもあるので、窓はできるだけ大きい方がいいのですが、それに限界があるのなら、見えている部分だけで全体を推測するしか手はないわけです。どのような推測・推定をすれば母集団を正しく見ることができるのかを調査する目的の学問を「推計統計学(Inferential Statistics)」といいます。推計統計学には大きく分けて、次の二つの手法があります。
推定(Estimation)
検定(Test)
推定とは、標本から求めた要約統計量から母集団の統計量を推測するための手法です。標本から得られた情報がどれだけ母集団の様子を反映しているかを確率的に調べることが主な目的になります。それに対して検定は、ある仮説に対して母集団の状態が一致するかどうかを確率的に判定するための手法で、仮説が正しいかどうかを検証することが主な目的になります。例えば、ある学校の身体検査で得られた体重の分布に対して、日本全国にある学校で測定された体重の分布を推定するという考え方と、日本全国での分布が分かっているとして、その学校の分布はそれと一致するかどうかを検定するという考え方の二種類に分けることができます。
この章ではまず、推定について紹介します。推定は大きく、以下の二つの種類に細分されます。
点推定(Point Estimation)
区間検定(Interval Estimation)
2) 点推定(Point Estimation)
まず、母集団は非常に大きく、全ての要素から要約統計量を求めることは不可能であるとします。もちろん、非常に大きいといっても有限ではあるので、理論的には求めることができるのですが、それを実現することが不可能な状態を考えます。このような母集団は、有限な大きさではありますが非常に大きいので通常は無限母集団として扱います。
母集団は、ある確率分布に従うと考えることができます。それは具体的なもの(例えば正規分布など)と考えられるものもあれば、そうでない場合もあります。その中からいくつかの標本を抽出し、母集団の確率分布が持つパラメータ(平均や分散など)に対する精度の高い「推定量(Estimator)」を求める手法のことを「点推定(Point Estimation)」といいます。
母集団から抽出した標本を x = ( x1, x2, ... xN ) とします。母集団の確率分布に対するパラメータ &theta; に対して、x を使った関数を使って推定量 &theta;^ を求めるとしたとき("^"はハットといって、推定量を表すためによく用いられます。通常はパラメータの上側に書くのですが、HTML では簡単に表現できないので右側に書いて表します)、その関数を &delta;(x) とすると、
と表すことができます。ここで、「良い推定量」を定義するため、二つの推定量 &theta;^1, &theta;^2 の優劣を決める基準を考えます。もし、任意の x について常に | &theta;^1 - &theta; | < | &theta;^2 - &theta; | が成り立つのであれば、&theta;^1 の方が &theta;^2 よりも良い推定量であると考えることができます。しかし、&theta; は未知数であり、通常はこのような比較はできません。そこで、&theta;^1, &theta;^2 が確率変数 x から得られた別の確率変数であることを利用して、&theta;^1, &theta;^ 2 に対する平均 E[&theta;^1], E[&theta;^2] を使って | &theta;^1 - E[&theta;^1] | と | &theta;^2 - E[&theta;^2] | の大小を比較することにします。さらに、任意の x について大小関係を比較する代わりに | &theta;^1 - E[&theta;^1] |, | &theta;^2 - E[&theta;^2] | の平均の大小関係を調べるようにします。よって、
確率・統計 (8) 推定
