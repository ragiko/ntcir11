
コミュニケーションとテクノロジーのはざまで［3］
人間にとって最も身近なコミュニケーション手段は音声である.なぜなら,音声を発する口,それを聞く耳を人間は生まれながらにして備えているからである.それがいま,マイクロエレクトロニクスやコンピュータ技術の進展に支えられ,「口」や「耳」が多機能化,高度化してきた.この先は何か? 最先端の研究には,研究対象を深く考え,その本質を捉えることが要求される.人間の音声コミュニケーションの研究は,めぐりめぐって,まさにわれわれ自身を理解することになる.ここでは特に「口」にかかわる技術を中心に,人間の音声コミュニケーションについて考えてみたい.
人間にとって音声とは?
ミードによれば［1］［2］,人間に特有な思考や創造は,自己とのコミュニケーションによって生じる.人間は他者とのやりとりにおいて,自分の行為に対する他者の反応を予測しており,この予測が自分の行為に対しての自己内部の反応であるという.そして,新たな問題が生じた場合に,自己内部の反応を次々と生じさせ,すなわち,他者がどのように反応するかを考えながら,その反応と自己とのコミュニケーションによって問題を解決するというのである.問題を解決するということはすなわち思考や創造である.さて,ここでミードの論を引き合いに出したのは,彼によれば,人間が自己内部の反応を引き起こすことができるのは,「音声ジェスチャー(vocal gesture)」を使うことができるためとしているからである.ジェスチャーは社会的行為の第一の外的側面であり,コミュニケーションの基本であるという.例えば,一匹の犬が飛びかかろうとするジェスチャーを示すと,他の犬は逃げようとするジェスチャーを見せる.この逃げようとするジェスチャーは,飛びかかろうとする犬の次の行動に影響を及ぼす.このようにジェスチャーのやりとりを行なう.音声は,ジェスチャーのひとつの形態であると同時に,自己内部の反応を引き起こす点において最も重要な形態なのである.つまり,人間は自分が発する「音声」を他者に聞かれるだけでなく,自分自身もまた聞くことができ,そのことによって,人間は自分の「音声」に対して他者がどのような反応するかを考えうるようになる.音声によるコミュニケーションを行なうことは,このようなプロセスを繰り返すことにほかならず,次々に思考や創造の種を生成していると言えるであろう.また,ジェスチャーによる自己内部の反応は,一個体だけがもっているものではなく,他の個体との関わりから生じるものであることから,そこに人間の社会性がもたらされる.このように考えると,人間の最大の特権である創造力や人間の社会性などは,人間が音声を使うようになったことに端を発しているとも言えそうだ.
電話の歴史、音声合成の歴史
人間の音声情報処理に踏み込む!
音声コミュニケーションに貢献した技術としてまっさきに思い当たるのは電話である.年表に示したように,電話は「距離」の克服に始まり,「場所」克服を実現しつつある.またその普及に伴って,緊急事態等を伝えるライフライン的な位置づけから,おしゃべりを楽しむ道具となってきており,音声コミュニケーションの日常の場となっている.また,電話なしのビジネスなど考えられないように,社会,経済にも多大な影響を及ぼした.今後は,電話機が小型軽量化され,体の一部となってしまうのだろうか? 一方,技術的な側面から考えてみると,電話は口から放射された音波を処理しているだけであって,人間が聞き,考え,話すというアルゴリズムやメカニズムとは無関係であった.しかし,高度な情報処理を行なうためには,これらのアルゴリズムやメカニズムにまで踏み込む必要が出てきている.例えば,携帯電話に用いられている高能率デジタル音声符号化では,音声を1/16に圧縮しているが,そこでは,音声の生成過程のモデル化や,音声の聴覚特性を考慮することによって初めて高圧縮率を達成した.さらに踏み込んだ領域では,人間と機械とのインターフェイスに音声を利用することが考えられる.情報機器が普及し,老若男女,子供に至るまで情報機器を操作するようになる近未来では,音声は親しみやすいインターフェイスのひとつになると期待されている.音声コミュニケーションの恩恵を享受してきた人類にとっては,自然な発想とも言えよう.
人間と機械とのインターフェイスに音声を利用するとは,さまざまなレベルがあると考えられるが,老若男女が一様に満足するものを実現することは,人間の音声コミュニケーションそのものを解明することにほぼ等しいのではないか? 人間の音声コミュニケーションに関わる能力は高度に進化しており,いまなお多くの問題が解明されずに残されている.その問題の複雑さを,音声が発せられるメカニズムを例にとって見てみよう.音声は,肺から送り出された空気が,声帯の開閉振動によってほぼ周期的に断続する空気流となり,それが,口の中を伝搬する.口の中は,舌,顎,唇等の調音器官によってある種の共鳴管(これを声道と呼ぶ)を形成しており,この共鳴の特性によって,周期的に断続する空気流は音韻性をもった音波となる.音声を発声するためには,調音器官を適切に動作させることが重要である.誰しも/a/と/i/を発声してみれば,舌や顎,唇の位置が異なることはわかるし,/aiueo/と発声してみれば,舌,顎,唇が連続的に滑らかに動いていることがわかるであろう.このように,われわれは意識せずとも,いとも簡単に調音器官を動かし音声を発声しているが,調音器官の制御は複雑である.ペンフィールドによる運動野の分業地図によれば(図1参照)［3］［4］,運動野の1/3は調音器官の制御に関わっている部分である.これは,ほぼ手の制御に関わる部分に匹敵している.音声生成のメカニズムだけでもこれだけ複雑なわけであるから,人間の音声コミュニケーションの解明は簡単に達成できそうもない.もっとも,現生人類が生まれて5万年間の進化と,140億ともいわれる大脳皮質の神経細胞で,成人するまで20年間にわたり日夜学習して身につけたものを,おいそれと解明できるわけもなかろう.
図1
以上述べてきたように,音声コミュニケーションは人間であることの起源に関与していると考えられ,またその仕組みも複雑であって,サイエンスとして興味深い研究対象である.また,工学的には,電話のように音声コミュニケーションに貢献できる技術が確立できれば,人間の経済活動,社会のあり方にも影響を及ぼす.以下では,音声研究の具体例として,音声を人間と機械とのインターフェイスに利用する研究について,特に筆者が携わっている音声を作り出したり,音声を変形したりする研究分野を取り上げ,音声コミュニケーションと最新技術との関わりを考えてみたい.
音声のとらえ方と研究スタンス
具体的な研究例を紹介する前に,音声をどのようにとらえているかを説明したい.図2に全体像を示す.音声には,元来,人間の個体に依存した要素がある.個体に依存した要素には,先天的な側面と後天的な側面とがある.先天的な側面とは,もって生まれたハードウェアで決定されるものであり,基本的に個人の努力によって変えることができない.例えば,男性が女性のような声を出せないこと,兄弟姉妹,親子の声が似ていることなどである.一方,後天的な側面とは,生後の学習によって獲得するものであって,いわばソフトウェアとでも呼べるであろう.例としては,言語や方言がある.両親が日本人であっても,米国で育てば完全な英語を喋ることができるようになる.これは,英語の音韻を出すための調音器官の制御を学習できるからである.このように音声は人間の個体に依存した要素がある.これとは別に,音声に影響を与える要素として,音声が使われる環境というものがある.人間の音声コミュニケーションでは,時と場所,状況,対人関係等の環境に応じてさまざまに口調を変えている.例えば,多くの人の前で何かを説明する場合には声を張りあげるし,目上の人に話す時には,敬語を使いちょっと緊張した話し方をする.また,複数人での会話,楽しい状況,緊張した状況などによっても口調が変わる.こういった環境に適した音声の多様性が音声コミュニケーションを円滑に進め,豊かな社会生活を支えている［5］.また,この環境の観点から考えれば,電話は,「距離」「場所」の問題を克服し,音声が使われる環境の拡張に寄与してきたと言える.人間一人ひとりに依存した要素がさまざまな環境へ投影されて,さまざまな情報を発生し,それを担ったものが音声なのである.一方,音声が担う情報は,音韻,韻律,声質とに大別される.音韻とは,母音や子音であり,言葉を伝えるために必要な情報である.母子音がはっきりと聞き取れる音声は明瞭性が高い音声と呼ばれる.韻律は,声の高さの上げ下げによるアクセントやイントネーション(抑揚)と,音韻の長さによるテンポとがある.外国人の喋る日本語の多くは,日本人の韻律とは異なり,何か違和感を感じる.声質とは,男性・女性の声の差,個人がもつ声の特徴などである.
図2
音声を人間と機械とのインターフェイスに利用する研究は,機械が音声を聞き取る「音声認識」の研究と,機械が音声を生成する「音声合成」の研究とに大別される.個体に依存した要素が環境へ投影されてさまざまな音声が発声されるわけであるが,図3に示すように,音声認識はさまざまな音声から音韻,韻律情報などの必要な情報を抽出し,抽象化,シンボル化をすることであり,音声合成とは,その逆に,抽象化,シンボル化された情報から,さまざまな音声を生成することである.ここで,強調しておきたいのは,音声合成が,抽象化された情報から音声を創造する点である.音声を創造するために,音声の生成過程をモデル化したり,人間の言語処理を近似したり,人間の聴覚特性を考慮したりする.この点は,サイエンスとしての人間の音声情報処理と密接に関係している.また,創造という点を極端に押し進めれば,何も人間の発声する音声を合成する必要はない.人間の発声能力を高めたり,人間には発声できない音声を創造するという発想もできる.さらに,その先は,アートの世界にもつながっていく.人間の能力で不可能なことを実現することが技術の真骨頂とするならば,音声合成は,まさに音声の創造という点で貢献できるのである.以上のような考え方に基づいて,研究を進めている.以下では,具体的な例を取り上げながら,音声合成の研究を紹介する.
図3
規則音声合成の研究
音声合成には,分析合成と規則合成とがある.分析合成とは,人間の発声した音声を分析し,情報圧縮して蓄えておき,これを再び音声信号へ逆変換する技術である.しゃべる自動販売機,炊飯器,カメラ等に利用されている.音声合成の分野で,現在盛んに研究され夢があるのは,規則合成である.規則合成とは,人間の発話をモデル化し,人間が音声を操るように任意の音声を創造する技術である.将来は,情報機器がまるで自分の召使いのように音声で答えてくれるようになるかもしれない.規則合成は,現在,任意のテキストを入力するとそれを読み上げてくれるところまで来ている.これは,「テキストからの音声合成 (Text-To-Speech:TTS)」と呼ばれる.このようなソフトウェアは,最近ではパーソナル・コンピュータを購入するとついてくることが多くなった.テキストの読み上げは,人間にとっても必ずしも易しいものではない.ちょっと試してみればよくわかることだが,テキストを左から右へとすらすらと声に出して読むのは難しい.どこで息つぎをするかを決める必要があったり,黙読して意味内容を理解しなければどのように読むかが定かでなかったりする場合もある.ろれつが回らなくて言い直すこともある.朗読ともなるとさらに難しい.感情移入や演技が必要となる.テキストを読み上げるとは,チャレンジングなテーマである.TTSは,テキストというシンボルだけから,音声の音韻,韻律情報を生成するのであるから,いかに驚くべき創造が必要であるかがわかる.音声合成の歴史は古く,年表に示すように音声生成過程の解明に端を発し,物理的な共鳴器による模擬［6］,電気回路による模擬［7］,音声生成の音響理論［8］へと発展した.TTSは,このあたりから研究が開始された［9］.その後,計算機の発展とともにデジタル信号処理に基づく理論が確立され［10］［11］,これを用いたTTSシステムが登場する.最近になっては記憶容量の低コスト化に伴って波形処理が現実的なものとなり［12］,TTSの高品質化を図ることができるようになった.
これら一連の合成音声を聞いてみると,ここ20年の進歩は画期的である.テキストからの音声合成を最初に考えた人は,夢物語と思っていたかもしれないが,今やテキストを音声に変換し,その音声を聞いて情報を得ることができるまでに至ったのである.合成音の印象は,音韻が聞き取れ何を言っているかはわかるものの,人間の音声とは異なる淡々とした韻律である.一般の方は,「テキストを読み上げる」と聞くとおそらく人間の朗読を想定されるのであろうが,それに比べれば現在の合成音はあまりに貧弱である.ここで一言,合成音声の品質について述べておきたい.TTSの感想を聞くと,もう少し自然にとか,もう少し人間らしくとかと言われる.また,ここまできているのだから,もう少しですねとも言われる.しかし,よくよく考えてみると,ことはそれほど容易ではない.まず,合成音声が何を言っているかがそれなりにわかるのは,人間の音声コミュニケーション能力によるところが大きい.多少音韻の明瞭性が欠けたり,韻律が不正確であったりしても,トップダウン的な情報処理,すなわち,話している話題に関する知識を利用したり,前後の文脈情報を利用したりして,人間は合成音声を聞き取るのである.また,音声が身近にあるため,人間はその品質に敏感である.たとえば,身内や親しい友人同士では,何気なく交わした挨拶の声を聞いて,音声がほんの少し鼻声だったりすると,「風邪気味なのかな?」などと気遣う.これは,その人の声に日頃親しんでいるため,声の質の微妙な変化に気づくからである.これと同様に,人間は「人間が発したという意味での」音の品質に,敏感であると考えられる.人間の声とちょっと違っただけでも,何か変だと感じるのである.以上のように考えると,あとわずかと感じられる差が,途方もない難題であるかもしれないのである.
環境に適した合成音声
さて,テキストからの音声合成の次のステップは何であろうか? 現状の合成音声は淡々とした韻律もさることながら,ひとつの口調でしか出力することができない.ニュース文を入力しようと,小説を入力しようと,冗談を入力しようと,すべて同じ口調となってしまうのである.先に述べたように,音声は環境に応じて変化する.合成音声も環境に応じて生成されるべきではないか? つまり,合成音声の多様化が重要であると考えられる.このような動機から,3つの口調を分析してみた［13］.それらの口調は,小説を朗読する口調,ニュース等を読み上げる口調,呼び込みをするような威勢の良い口調である.その分析結果によると,音声のスペクトル特徴,抑揚の付け方,しゃべりのテンポ等にわたって特徴が現われる.どうやら,口調を変えるということは,調音器官のさまざまな動きを総動員して変化させる必要があるようだ.しかも,その変化の度合いは大きい.たとえば,音声のスペクトル特徴では,口調がかわると他人の声と言ってもいいほどの変化を生じるのである.以上の結果から察しても,音声生成過程がいかに広いダイナミックスを秘めているかがわかる.今後はより多くの口調を分析することによって,音声生成過程の秘めているダイナミックスを明らかにするとともに,操作性の高い音声合成方式を開発して,一歩一歩,人間の発話能力に近づけて行きたいと考えている.
音声対話における合成音声
音声を用いた人間と機械との対話は,有益なアプリケーションと考えられ,さまざまな観点から多くの研究が行なわれている［14］.人間と機械との対話という環境で,いかに合成音声を利用するかも重要な研究項目である.そのひとつのポイントとして,呼称があると考えている［15］.人間の音声コミュニケーションでは,人間関係によって相手の呼び方(呼称)が変化する.また,同じ呼び方であっても,場面,状況によって声質,韻律が変わる.呼ばれた声を聞いただけでも,楽しい話が始まるのか怒られるのかなど,それに続く話の内容におおよその見当がつくこともある.このように,短い言葉でさまざまな情報を伝えられることは音声の特徴であり,円滑なコミュニケーションに有益である.また,呼称は,人間と機械との対話では,いかにユーザーの気持ちを引き込むかに重要な役割を果たすものと考えられる.以上のような動機によって,呼称の分析を行なった.呼称のヴァリエーションを得るために23種類の感情や場面を設定し,それぞれ1文ずつ作成した.すべての文は,「あなた」から始まっている.実験は「あなた」という言葉だけを取り出して被験者に聞かせ,23種類の「あなた」が聴覚心理的にどのように分類されているか,その分類を特徴づけるパラメータは何かを検討した.その結果,「驚愕の声」に代表されるような,比較的早いテンポで発声され,音量が大きく,高い声と,「甘えた声」に代表されるように,比較的遅いテンポで発声され,音量が小さく,低い声とが,最も明確に聞きわけられており,両者の特徴のほぼ中間的な音声として,「歓喜の声」が存在することが明らかになった.現在のところ韻律特徴しか分析していないが,今後は,スペクトルの特徴を分析するとともに,分析結果を規則化し,どの程度呼称として有効に働くかを明らかにしていこうと考えている.
合成音声の特徴を生かす
明瞭性を向上させ,単調な韻律を改善して,人間の音声と区別つかないような音声を合成することだけが重要なのであろうか? また,そのレベルに達しないと使い道がないのであろうか? このような疑問に対するひとつの実験結果がある.その結果は,合成音声をどのように使うと有益であるかを調べる実験を行なったときに得られた［16］.実験では,被験者はコンピュータのディスプレイの前に座り,ディスプレイ上に描かれた赤,緑,紫のいずれかの色で塗られた,,×,のカードをマウスでつかみ,それを移動させる.この作業を行なう際に,被験者が誤るように仕掛けを作り,誤りが生じた時に,ブザー音,合成音,人間の音声のいずれかで作業の誤りを知らせるという実験である.この実験から得られた知見のひとつは,合成音声が人間の音声よりも好まれる場合があるということである.アンケートの結果によると,人間の音声の場合,他人に見られている感じがするので不快であると言う.そのために,合成音声のほうを好むのである.現状の品質でも,受け入れられるアプリケーションはありそうである.また,合成音声らしさは,その出所が機械であることを明示できるという利点がある.音声によるサービスを受けていて,人間と思って喋っていたのに,それが途中で機械であることが判明すると,騙されたような気分となることもあるだろう.音声コミュニケーションが人間固有であるという固定観念があるために,合成音声が本物の人間の声と聞き分けがつかないほど改善された場合でも,合成音声らしさが要求されるのかもしれない.
「声質」からの解放
先に述べたように,声質は人間の個体に依存した要素のうち先天的な側面によるところが多く,個人に固有な特徴であって,自由に変えることはできない.声帯模写は,必ずしも声質そのものを似せているわけではなく,人の話し方や口癖をまねて,その人らしさを表現しているのである.人間の発声能力を高める意味で,技術の力で声質を変化させたらどうか? 声質を自由に変化させることができるようになると,音声コミュニケーションの幅が広がる可能性がある.たとえば,ヴァーチュアルな世界での活動である.最近は,インターネットが大流行であるが,電子メール,電子掲示版,チャットとよばれるお話広場などは,ある意味ではヴァーチュアルな世界である.そこでは,ペンネーム,匿名が可能であり,必ずしも現実の自分を反映させる必要はない.チャットでは,自分の好みの洋服を分身であるキャラクターに着させ,登場することができる.つまり,変身できるのである.将来は,「声の質を自由に変えてヴァーチュアルな世界に登場」ということがあるかもしれない.ヴァーチュアルな世界での音声コミュニケーションばかりが目的ではないが,音声コミュニケーションにおける「声質」からの解放は,新たな広がりをみせる可能性があると考えている.このような動機から,高品質に音声の質を変換する方式を考案した
［17］.ここでのポイントは,自然性をそこなうことなく音声が変形できる点である.変形した音声は,この世の中に存在しそうな人の声であり,しかも,本人の声とも異なる.これは,実時間で動作しているので,リアルタイムの会話などにも利用できる.これから,どのような使い方をされていくのか楽しみである.
音声符号化に音声合成の発想を
音声合成の考え方の大きな特徴は,創造してしまう点にあると述べた.この考え方を,音声符号化に適用したらどうか? この発想に基づいて,音声合成の音声符号化への適用も試みている［18］.それは,電話の音声を擬似的に広帯域な音声へ変換してしまおうという試みである.図4に,広帯域音声と電話音声のスペクトルを示す.図から明らかなように,電話帯域の音声では,300Hz以下の周波数と,3.4−7.2kHzの周波数がないことがわかる.このない部分の信号を生成して付け加えることができれば,広帯域音声が得られるはずである.その生成のポイントは,電話音声にない部分のスペクトルと電話音声のスペクトルの間の関係をうまく使うことにある.図では3.4−7.2kHzの周波数帯域に直線を引いて,そのおおまかな形状を示してみた./a/ではやや右下がり, /i/ では平坦,/s/ではやや右上がり等の傾向がある.すなわち,電話音声がどのような音素を伝える信号であるかによって,3.4−7.2kHzの周波数帯域のもつ傾向が異なるわけである.これは,300Hz以下の帯域でも同様である.つまり,広帯域音声と電話音声とを突き合わせて比較を行ない,生成すべき特徴を電話音声のもつ特徴と結びつけてルール化することができる.このルールをあらかじめ求めておけば,受信した電話音声の特徴に応じて適切な信号を生成することができるのである.
図4
図5は,以上のような考え方に基づいて考案した方式である.上記では,/a/ /i/ /s/ の音素毎のルールを説明したが,実際には音素単位では大雑把すぎるので,ベクトル量子化という技術を使う.ベクトル量子化とは,連続空間のパターンをいくつかの代表パターンで表現するものであり,代表パターンの集まりをコードブックと呼ぶ.提案方式では,電話音声を用いてひとつのコードブック,広帯域音声を用いてもうひとつのコードブックを作成する.さらに,この2つのコードブック間で1対1の対応を取っておく.このようにしておけば,受信した電話音声の代表パターンに代えて広帯域音声の代表パターンを用いて音声合成すれば,広帯域音声の特徴をもった合成音声が得られる.つまり,細かなルールは,コードブック間の1対1の対応によって実現されるのである.広帯域化音声は,合成音声のうち電話音声にない部分のみをフィルタリングにより取り出し,これと受信した電話音声を足し合わせて得る.
図5
図6に,処理の例を示す.この図はスペクトログラムとよばれる表示法であり,いわゆる声紋である.図からわかるように,失われた信号が適切に生成できていることがわかる.聞き取りの評価実験によって,この方式は低域信号の生成に特に有効であることが確認されている.以上のように,音声合成の発想を音声符号化に適用することによって,高圧縮率が実現できるのではないかと考えている.
図6
まとめ
研究を進めるにあたって日頃考えていることを述べながら,音声合成の研究を紹介した.音声コミュニケーションは,人間とは何かという本質的な問題に通じている部分もあり,非常に興味深い研究対象である.人間の音声コミュニケーションを考えることは,音声ならではの機能,音声が生かせるアプリケーションを発掘するために有益であり,研究の方向性を決定する指針となっている.また,工学の立場からの音声研究では,人間の音声コミュニケーションの能力を高める技術や,人間の能力ではできないことを実現する技術を確立することも重要であると考えている.本稿が音声コミュニケーションを考えるうえで何か情報を提供できたとすれば幸いである.
Twin-VQにより音声データをお楽しみいただけます。
TWIN-VQをダウンロードする
tts.tvq
これは,テキストからの音声合成によって合成した音声です.漢字かな混じり文を入力するとこのような音声が自動的に生成されます.
anata.tvq
実験に用いた音声の例です.同一話者が同じ言葉を発声しても様々なバリエーションがあることが分ります.
natural.tvq
vario_h.tvq
vario_l.tvq
natural.tvq 人間の音声
vario_h.tvq 高めに変換した音声
vario_l.tvq 低めに変換した音声
変換された音声は,元の人とは違った人が発声した音声に聞こえると思います.
tel_speech.tvq
giji_speech.tvq
tel_speech.tvq  電話の音声
giji_speech.tvq 電話の音声を広帯域化した音声.
擬似的に広帯域化した音声では,すこし厚みのある音声になっていることがお分りでしょう.
参考文献
1——G・H・ミード『精神,自我,社会』(稲葉三千男ほか訳),青木書店,1973.(原著1934年)
2——船津衛『コミュニケーション入門』有斐閣,1995.
3——時実利彦『人間であること』岩波新書,1970.
4——伊藤正男『脳の設計図』自然選書,中央公論社,1980.
5——阿部匡伸「小特集——声質:音声言語の多様性に迫る——発話様式のバリエーション」『日本音響学会誌』,51巻11号,1995,pp.882-886.
6——Flanagan, J. I., Voices of men and machines, J. Acoust. Soc. Amer., 51, 1972, pp.1375-1387.
7——Dudley, H. R. R., Watkins, S. S. A., A synthetic speaker, J. Franklin Inst., 227, 1939, pp. 739-764.
8——G. Fant, Acoustic Theory of Speech Production, Mouton, 1970.
9——D. H. Klatt,Review of text-to-speech conversion for English,J. Acoust. Soc. Am. 82(3), September 1987, pp. 737-793.
10——J. L. Flanagan, Speech Analysis Synthesis and Perception, Second, Expanded Edition, Springer-Verlag, 1972.
11——J. D. Markel, A. H. Gray, Linear Prediction of Speech, Springer-Verlag, 1976.
12——F. J. Charpentier, M. G. Stella, Diphone synthesis using an overlap-add technique for speech waveforms concatenation, ICASSP86, 1986, pp. 2015-2018.
13——阿部匡伸「異なる発話様式の特徴分析とその制御」『日本音響学会誌』,51巻12号,1995.12,pp. 929-937.
14——財団法人機械システム振興協会「音声の知的処理に関する調査研究報告書」1992.
15——阿部匡伸「呼びかけ音声のバリエーションとその韻律的特徴」,『音学講論』,1-4-7,1996.9,pp.203-204.
16——阿部匡伸「誤り指示音声の特徴分析と音声出力への適用」,『信学論』(DII Vol. J79-D-II No.12 1996.12, pp. 2191-2198)
17——阿部匡伸「波形処理による声質変形装置(VarioVoice)」,『音学講論』,1997.3(予定)
18——吉田,阿部匡伸「コードブックマッピングによる狭帯域音声から広帯域音声の生成法」,『信学論』(DII Vol. J79-D-II, No.3, 1995.3, pp.391-399.
(あべ  まさのぶ・電気工学)
IC020 音声合成技術がもたらすコミュニケーション革命(J)
