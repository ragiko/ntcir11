 Webシステムが遅いってどういうこと?
日本では1994年ごろから商用のインターネットサービスが開始され、以降、爆発的に利用者は増えつつあります。1998年2月には約100万人程度であったインターネットの利用者が2003年2月には5倍以上の約565万人となっています。(インターネット白書2003調べ)インターネットの普及は利用者の増大のみならず、TCP/IPで利用されるアプリケーションの多様化、アクセス回線の高速化と低価格化の間接的な要因になったと考えられます。
現在特に多く利用されているアプリケーションはHTTP/ HTTPSです。Eコマースはいうに及ばず、B to Bサイトや過去には汎用機で運用されていた社内システムでさえ、Web化が急速に進んでいます。ところが、利用者が増え、利用形態が多様化するにつれてWeb化されたこれらのシステムの遅延という問題がクローズアップされるようになってきています。Webシステムが遅いということはどういうことでしょうか。
本特集では、現在のWebシステムの遅延背景をみながら、今どのような解決策が求められているのか?従来の手法を取り上げながら考えてみましょう。
Webシステムが遅い原因は?
Webシステムが遅い原因については、いくつかのスキームに分けて考える必要があります。
さまざまな要因が考えられるのですが、代表的なものを挙げてみましょう。
クライアントの接続回線が遅く、回線がボトルネック
このブロードバンドの時代にそんなことが、と思われるかもしれませんが、エクストラネットのシステムでは、たとえば本社—支店・営業所が128Kbpsのフレームリレーで接
続されているケースがあり、夕方の最繁時等に回線が込んでWebシステムのコンテンツ
ダウンロードに時間がかかってしまうということがよくあります。
また、携帯電話サイトや営業マンなどがPHSのカードを利用してモバイル端末で社内の
Webシステムにアクセスする場合にもコンテンツのダウンロードタイムに時間がかかる
という話もよく耳にします。
WebサーバのI/O部分での処理遅延
インターネット白書2003の調査では、未だ6割のユーザが電話回線やISDNなどのナロ
ーバンドを利用しているという調査結果がでています。また、前述のPHSカードを利用
したモバイルアクセスもナローバンドの部類に入るでしょう。この場合、WebサーバのCPU使用率などはそれほど高くないのですが、これらのナローバンドユーザのコネクションハンドリングにI/O制御の多くのリソースが割かれ、遅延が発生しています。また、
SSLの暗号化/ 複合化をサーバで行っているような場合、Webサーバの負荷となり、遅
延の原因となっていることがあります。
動的Webページの生成による遅延
いまや一般コンシューマ向けのEコマースサイトやポータルサイトのみならず、社内情
報系・基幹系のWebシステムの大部分がWebサーバのみではなく、アプリケーションサ
ーバやデータベースサーバを利用しています。これは、取り扱い品目が増えるに従い、
Webサーバのみで静的コンテンツ(スタティックコンテンツ)を手動でメンテナンスす
ることが不可能となり、動的Webページ(ダイナミックコンテンツ、.asp, .jsp, .cgi, .phpなど)の利用がメインとなってきたためです。動的Webページの利用はメンテナンスが主な目的ではなく、Eコマースサイトであれば他社との差別化やユーザ毎にパーソナライズされた情報を提供したり、ユーザニーズをいち早くサービスにフィードバックするためであり、また、社内システムであれば膨大な量のデータのマイニングのためであったり、刻々と変化する情報をアップデートする社内ポータルなどに利用されるものと考えられます。
動的Webページ生成による遅延の例としては、IISサーバの場合には、ASPエンジンの処理能力がいっぱいになり、新規に動的Webページを生成するためのスレッドが立ち上げられないために処理待ちが発生し、利用者にはサイトが遅くなったように見えます。この場合にも、IISサーバやDBサーバ自身のCPU負荷率などはさほど高くなりません。
どのような解決策があるの?
それでは、Webシステムが遅いという現象に対してはどのようなソリューションがあるのでしょうか。従来の解決策と、まったく新しい解決のための概念を対比し、さらにどのような注意が必要なのかについてお話しましょう。
クライアントの接続回線が遅く、回線がボトルネック
従来の解決策
回線を増強するのが定石な気がします。エクストラネットの場合、128Kbpsのフレーム
リレーをもっと早い広域イーサネットなどのサービスに切り替えればよいのではないで
しょうか。しかしながら、拠点数が多い場合、切り替えのための導入コストや導入時の評価を考えた際に簡単にいくでしょうか。また、携帯電話やPHSのユーザを抱えているEコマースサイトや営業支援のためのWebシステムにおいては、クライアントのアクセス回線を早くする、というソリューションは物理的に不可能です。
新しい解決のための概念
回線速度をそのままでクライアント側のダウンロード時間を早くするためには、コンテンツの圧縮が効果的です。gzipなどのコンテンツ圧縮方法は一般的なもので、IEなどは
デフォルトで解凍機能を搭載しています。コンテンツが半分の大きさになれば、理論的
にはダウンロードタイムは1/2になるわけです。逆にいうと、同じ帯域の回線を2倍のキャパシティで利用できる、ということができます。クライアントPCの性能向上が著しい昨今では、コンテンツの解凍がクライアントPCの負荷になったり、遅延につながるようなことはありません。また、システム管理者は、拠点やクライアントがどのような回線を利用しているかを考慮する必要はありません。
※
注意点
コンテンツ圧縮は画像変換ではありません。回線帯域等にあわせて画像の解像度を変え、最適化するという製品もありますが、コンテンツが正常に表示されなかったり、それらの製品を利用するために、Webサイトを作り変える必要があったります。これらの製品を否定するものではありませんが、導入前の事前検証を行い、動作の確認を十分に行う必要があります。
一方、gzipなどの圧縮方式はテキストの圧縮ですため、画像の表示が云々といった心配はありません。画像が多く見えるサイトにおいても、動的なページのソースを見ると、圧倒的にテキストが多いため、テキストの圧縮でも十分に効果が期待できます。
WebサーバのI/O部分での処理遅延
従来の解決策
サーバの価格も安価になっていますので、サーバを増設すればよいような気がします。しかしながら、冷静に考えてみますと、前述のとおりWebサーバのI/O部分で遅延が発生している場合においても、Webサーバの負荷自体はそれほど高くないため、Webサーバ追加の必要性を説明するのが難しいかもしれません。また、データセンターなどにシステムがある場合、ラックの数が増え、月々のランニングコストは上がります。また、パッチの適用やバージョンアップ作業もWebサーバの台数が多ければ、かかる工数も多くなります。
Web I/Oにおける問題の根本は、クライアントのコネクション管理をWebサーバがしな
ければならないことにあります。Webサーバはその上位にあるルータやファイアウォー
ルと100MbpsのLANでつながっているにもかかわらず、ハンドリングしている各クラ
イアントのコネクション管理はそれよりはずっと遅いはずです。また、再送要求が発生
したり、クライアントが早い回線を利用している場合にもTCPのスロースタートによっ
て、ハンドリングすべきクライアントコネクションはどんどん増えていきます。
したがって、Webサーバの手前にキャッシュなどを配置し、コネクションを集約することによってWeb サーバのI/Oの負荷を軽減することが考えられます。この方法は静的なコンテンツには有効かもしれませんが、動的なコンテンツには効果がありません。また、サーバのコンテンツアップデートのタイミングとキャッシュに反映されるタイミングのずれにより、クライアントが古いコンテンツを見てしまう危険が常に付きまといます。
新しい解決のための概念
前述のコネクション集約は、WebサーバのI/Oの負荷軽減という意味においては解決策としては有効であると考えられます。クライアントからの100のコネクションをクライアントの回線スピードに合わせ、コネクションが終了するまでをサーバが処理するのではなく、WebサーバはLANのスピードで集約のための装置にデータを送り込んでしまい、後はその装置とクライアントが通信をすればいいのです。その際に、装置とサーバ間はhttp 1.1のパーシステントコネクションで常時接続されていれば、装置—サーバ間は、装置—クライアント間より少ないコネクション数ですべての通信をハンドリングができるはずです。同様の効果はキャッシュでも期待はできますが、キャッシュが利用できない原因はコンテンツをキャッシュするところにありますので、バッファというテクノロジが有効です。バッファの場合には、各クライアントコネクション毎・通信毎にユニークにバッファを割り当て、通信終了とともにバッファもクリアされるため、コネクション集約の機能だけではなく、システム管理者は静的・動的なコンテンツのいずれに対してもオリジナルサーバのコンテンツとの整合性を気にする必要がまったくありません。
※
注意点
このソリューションは、WebのI/Oに明らかに原因があってWebサイトの遅延が発生している場合に有効です。アプリケーションサーバやデータベースサーバの負荷で遅延が発生している場合には、Webサーバのフロントの処理能力が上がってしまうため、アプリケーションサーバやデータベースサーバのさらなる過負荷につながり、サーバダウンを招きかねません。前述のASPエンジンの処理による遅延は、クライアントのアクセススピードにWebサーバのI/Oが縛られていたために発生していますので、上記の方法を取ることでLANのスピードで処理ができることとなり、解決されます。しかしながら、データベースサーバには単位時間あたり、何倍ものリクエスト処理が発生することになります。
動的Webページの生成による遅延
従来の解決策
処理遅延はアプリケーションサーバやデータベースサーバで発生しますので、それらのサーバのCPUやメモリを追加したり、物理的に台数を増やすことが主な解決策です。この場合、ハードウェアの費用だけではなく、CPU毎にライセンスを追加しなければならないなど、WWWサーバを増設するのとは比較にならないほど費用がかかります。また、アプリケーションをチューニングする、という方法もありますが、どの程度パフォーマンスが改善するのかは作業をはじめた段階では不明です。仮にパフォーマンスが改善されなくても作業費用はかかってしまいます。
新しい解決のための概念
動的Webページ(ダイナミックコンテンツ)は大きく2つに分類できます。参照系(
クエリー)と更新系(アップデート)です。
たとえば、航空券の予約などを考えてみましょう。
チケットを購入する場合には、フライト情報や空き席かあるかどうかを確認してから、目的地・時間などの条件にあったフライトの予約をします。最初のフライト情報の確認
は参照系のトランザクションですし、フライトの予約は更新系になります。ところが、
最初の確認の時点で自分の目的に合うフライトがいっぱいであった場合、再度違う便を
探したり、ひょっとすると飛行機をあきらめ、新幹線を使おうとするかもしれません。
上記すべてがダイナミックコンテンツ(アプリケーションやデータベースまで利用した
コンテンツの生成)で行われていた場合、参照系の何%かしか、実際の販売にはつなが
りません。一般的なEコマースサイトにおいては、20%のアップデートに対し、80%は
クエリーであるといわれています。このクエリー、つまり、直接的にはビジネスにつな
がらないトランザクションがアプリケーションサーバやデータベースサーバの負荷を上
げ、実際の収入になるべきアップデートまでも圧迫します。
新しい概念として、アプリケーションアクセラレーションという概念があります。これはクエリー部分をキャッシュし、キャッシュされたダイナミックコンテンツの更新トリガーを複数持つことによってコンテンツの整合性をとらせるテクノロジーです。つま
り、アプリケーションサーバやデータベースサーバにかかっている負荷のうち80%はア
プリケーションアクセラレーション装置から返し、残り20%のアップデート処理のみを
オリジナルのサーバで行わせることが可能です。もっといえば、この装置を追加するの
みで、現状の環境をいじることなく、アプリケーションサーバやデータベースサーバの
処理能力を向上させることができる、といえます。
上記の航空券の予約の例にアプリケーションアクセラレーションを当てはめてみましょ
う。
最初のユーザがフライト情報を確認すると、情報はアプリケーションアクセラレーショ
ン装置にキャッシュされます。同じフライトの情報を複数のユーザが確認する場合には、キャッシュから情報が返されます。ただし、あるユーザがチケットを購入した場合、ア
プリケーションアクセラレータがユーザリクエストに含まれる購入に関する固有の情報
を検知し、該当キャッシュをクリアします。なぜならば、データベース上ではチケット
の購入によって残り座席数が変更されるからです。その後は、また同様のプロシージャ
で処理がされます。したがって、参照系のトランザクションに対してはその都度ページ
を生成する必要がなくなり、非常に高速にユーザリクエストにページを返すことができ、サーバの負荷も軽減できるわけです。
※
注意
動的Webページのアクセラレータ=ダイナミックコンテンツのキャッシュは、従来のキ
ャッシュソリューションでは実現できません。従来の静的(スタティック)コンテンツキャッシュ装置はコンテンツの保持時間の制御(TTL)程度の機能しかないためです。
アプリケーションアクセラレーション装置は、ネットワークにインストールしただけでは機能せず、どのURL(アーギュメントを含む)をキャッシュし、どのようなメソッドでクリアするか、といった設定をする必要があります。その場合、Webサーバのログを解析し、どの動的ページが良く利用されるのかを把握し、設定ポリシーを作成していくのが効果的です。
特集記事
