グーグル株式会社のブラッド・エリス氏。災害情報を扱う「Google Crisis Response」の中心的人物だったが、7月にYouTubeプロダクトマネージャーに就任した
グーグル株式会社は14日、動画共有サイト「YouTube」において、動画の中で話されている日本語を音声認識し、自動的に字幕として表示する機能を追加した。
投稿した動画に日本語字幕を表示するための機能はすでにあったが、これまでは動画投稿者が字幕のテキストデータを用意しなければならなかった。今回ベータ公開した「自動キャプション機能」では、それが用意されていない動画についてもYouTubeのシステム側が自動的に字幕データを生成する仕組みだ。視聴者が、動画プレーヤーの右下にある「CC」アイコンのメニューから「音声を文字に変換」を選択することで字幕が表示される。
自動キャプション機能で使っている音声認識技術は、グーグルが音声検索サービスで導入しているのとほぼ同じもの。ただし、よく使われる単語や文章の流れなどが検索サービスと異なるため、YouTubeの動画で学習してチューニングした。
グーグルによると、日本語の自動キャプション機能は、日本語の音声が入っていると認識された動画であれば適用されるとしており、基本的には、多くの日本語動画に「音声を文字に変換」のオプションメニューが付くとしている。
人による手動作業を経ないため、字幕がすべて完全というわけにはいかないが、例えばニュース番組のアナウンサーによる説明など、言葉が明確な映像については高い精度で字幕を自動生成できるとしている。一方、アニメや時代劇など、口調に特徴があるものや、背景に音楽や雑音が入っているものはやはり難しいという。
14日以降にアップロードされた動画については、アップロード後にすぐに字幕を生成し、公開と同時に日本語字幕を表示できるようになる。また、過去にアップロードされた動画についても、すでに150万件以上が自動キャプション機能による日本語字幕に対応済みだという。
自動キャプション機能は、すでに英語版を2009年11月から提供。今回、それに続く2言語目として日本語に対応したかたち。
英語では4000万点以上の動画が自動キャプション機能に対応しており、これまでに2300万回以上利用された。多くの動画で同機能が使われたことで、YouTube動画における音声認識技術の改良も進み、自動キャプション機能による間違いを20%減らすことに成功したという。
動画の投稿者は、動画の管理画面において、自動キャプション機能で生成された字幕データをダウンロードできる。これをベースに手動で間違いを修正したり、編集を加えることで、より正確な字幕を付けられる。英語では、自動キャプション機能の公開後、手動によるキャプションが付けられた動画も3倍に増えたとしている。
なお、YouTubeのコンテンツパートナーであるテレビ朝日(ANN NEWSチャンネル)では、自動キャプション機能を実験的に使う考えだという。
各動画に字幕データが用意されていれば、あとは従来からある機械翻訳機能により、50以上の言語へ翻訳表示することが可能だ。原発事故などで海外からの関心が高まっている日本のニュース映像なども、世界の多くのYouTube視聴者に内容を理解してもらえるとしている。
さらに、言語の壁を越えるという意味だけでなく、耳の不自由な人にもYouTubeを利用してもらえると説明。YouTubeのアクセシビリティを向上させる機能としても、自動キャプション機能の重要性を強調している。
15日に開かれた記者説明会で、グーグル株式会社YouTubeプロダクトマネージャーのブラッド・エリス氏は、東日本大震災後に公開された桜井勝延・福島県南相馬市長の動画「SOS from Mayor of Minami Soma City」を例示。市内の窮状を訴えたその動画は、英語の字幕が入っていたからこそ世界中の視聴者に理解され、共感を呼んだと指摘する。
ただし、この動画の字幕はYouTubeのツールを使って作成されたものではなく、もともとの動画の編集時に埋め込まれたものだという。動画投稿者にとって同様の字幕を作成するのは非常に手間がかかる作業だとして、YouTubeで用意しているキャプション関連ツールの有用性をアピールした。
YouTubeのキャプション機能は2008年に提供を開始し、その後3年かけて改良を重ねてきた。当初は、動画の中で話している内容をすべてテキストに書き起こした上、それをどのタイミングで表示させるかを指定する「タイムコード」を含んだキャプションファイル形式のデータをアップロードする必要があった。YouTubeのツールを使ったとしても手間がかかり、もし指定したタイミングで映像とずれてしまうことがあれば、さらに調整が必要になる。
そこで、字幕の付与を少しでも簡単に行えるように1年半ほど前から提供を開始したのが「キャプション自動同期機能」だ。これは、タイムコードを含まないテキストファイルだけを用意してアップロードすれば、音声認識技術により自動的に音声と字幕表示を同期してくれるというものだ。英語のみの対応だったが、細かい調整作業不要で字幕表示のタイミングをぴったり合わせられるため、キャプション制作が非常に速く行えるようになったとしている。
さらに東日本大震災の発生後、今年3月には、キャプション自動同期機能が日本語にも投入された。震災の発生後、重要な情報を含む動画が多数アップロードされている中、より多くの人に内容を理解してもらえるよう、完全な準備が整う前に急きょ公開したのだという。
キャプション自動同期機能は、YouTubeのコンテンツパートナーであるTBS(TBS News-iチャンネル)でも活用していくという。音声認識による自動生成ではなく、字幕原稿テキストをTBS側で用意して同期させるかたちだ。これにより、間違いのない正確な字幕が表示される。テレビのニュースは映像と音声を組み合わせることで1つのコンテンツとして成り立っていることから、音声部分を字幕化することで、音を出せないオフィスなどで視聴するコンテンツとしても活用されるとみている。
このほかエリス氏は、字幕のメリットについて検索面も挙げた。すなわち、YouTubeの動画をキーワード検索した際、動画のタイトルだけでなく、動画に含まれるスピーチや会話の内容にもヒットするようになるわけだ。
検索結果ページでは、字幕部分がヒットした動画については、「検索キーワードから再生を開始する」というリンクも表示される。これをクリックすることで該当部分付近から動画を再生できるため、動画を最初から見ていく必要がなくなる。
さらに、動画プレーヤーの下にある「インタラクティブなキャプション」のボタンをクリックすれば、字幕のテキストが時間軸に沿って1行ごとにリスト表示される。見たい部分をクリックすることで直接その部分にジャンプすることが可能だ。
YouTube、日本語音声を認識して字幕を自動生成・表示する機能を追加 -INTERNET Watch
