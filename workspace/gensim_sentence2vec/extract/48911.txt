複数の話者と話題からなる討論音声の認識のための,統計的言語モデルの話題・話者適応を提案する.話題をカバーするコーパスと話者性をカバーするコーパスからそれぞれ構築した言語モデルを混合することで,ベースライン言語モデルを構築する.それぞれのコーパスを用いて,話題と話者に関するPLSA (Probabilistic Latent Semantic Analysis)を行い,初期の(話者ごとの)音声認識結果にこのPLSAを適用することで,当該の話題と話者に適応したunigram確率を求める.この確率によるスケーリングをベースライン言語モデルに行ってそれぞれの適応を実現する.実際の討論音声を用いて評価を行い,それぞれの適応によりテストセットパープレキシティが削減され,あわせて平均6.8%の改善が得られた.
We address an adaptation method of statistical language models to topics and speaker characteristics. A baseline language model is composed of a topic-oriented model and a speaker-oriented model, which are trained from different corpora covering various topics and speakers, respectively. Then, PLSA (Probabilistic Latent Semantic Analysis) is performed on the same corpora and initial ASR result to provide unigram probabilities conditioned on input speech. Finally, the baseline model is adapted by scaling N-gram probabilities with these unigram probabilities. Experimental evaluation on real discussions showed that both of topic and speaker adaptation improved test-set perplexity, and total improvement of 6.8% was obtained.

