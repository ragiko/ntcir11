
専門用語(キーワード)自動抽出用Perlモジュール
"TermExtract" の解説
はじめに  テキストデータから、専門用語を取り出すためのPerlモジュール"TermExtract"を解
説します。
日本語の文章中から単語を切り出す定番のソフトとして、「茶筅」や「案山子」があ
りますが、そのまま専門用語の抽出に使うには次の2つの問題があります。
ひとつは、複合語に対応していないことです。専門用語の多くは単語を組み合わせて、
複雑な概念を表すことが多くなります。特に「茶筅」の場合は単語を品詞単位で細かく
分割するため、そのまま使うには難があります。
もうひとつは、どの用語が重要であるか判断する仕組みを持たないことです。
その問題点を解決したソフトに東京大学・中川裕志教授、横浜国立大学・
森辰則助教授が作成した「専門用語自動抽出システム」があります。
それは、1)「茶筅」の形態素解析結果を複合語に組み立て、2)その複合語(単語の場
合もある)を重要度の高い順に返すものです。
TermExtractは、この「専門用語自動抽出システム」を東京大学情報基盤センター・中川
裕志教授の教示を受け、東京大学経済学部・前田朗が全面的に組みなおしたものです。
また、形態素解析によらない、英文及び中文の専門用語自動抽出機能なども追加されてい
ます。
実行環境 
Perl
TermExtract は バージョン5のPerl(JPerlを含む)で動作します。
Perl DB_Fileモジュール
TermExtract で学習機能を使うには、PerlのDB_File モジュールの使用を推奨
しています。これは標準のPerlモジュールには含まれていません。マシンの環境
によっては、別途インストールする必要があります。
もし、DB_Fileが使えない場合は、SDBM_File を使うよう設定できます。専門
用語の抽出機能自体は変わりませんが、学習用DBの内容確認で、いくつか使えな
くなる機能があります。
形態素解析ソフト
TermExtractは形態素解析ソフトの処理結果を入力とします。なお、
英文に関しては、version 1.35 からストップワード方式も使えるよう
になっており(EnglishPlainText.pm) 、これを使う場合は形態素解析
ソフトは不要です。
組み合わせられる形態素解析ソフトは、現在のところ次のとおりです。
和文
「茶筅」(ver 2.3.3 では英単語が区切りなしで処理されます。
「和布蕪」かver.2.1以前の「茶筅」がお勧めです)
「和布蕪」
英文
"Brill's Tagger"
"Monty Tagger"
中文
"ICTCLAS"
他の形態素解析ソフトにもTermExtractの仕様に沿った派生クラスを自作するこ
とで対応が容易です。
形態素解析ソフトの入手やインストール手順は上記のリンクからお願いします。
ファイル及びディレクトリの新規作成権限(「学習機能」使用時)
TermExtract はPerlのDB_File モジュールが使える環境にあれば、学習機能を実
現するためバークレーDB用のファイル(2種)を作成します。バークレーDBの代わ
りに、SDBMを使う設定もできます。
もし、指定したDBファイルが存在しなければ新規に作成を試みます。デフォルト
はプログラムの実行ディレクトリの"stat.db"と"comb.db"です。(SDBMの場合は、
"stat.db.dir", "stat.db.pag", "comb.db.dir","comb.db.pag")
ただし、学習機能をまったく使わないのであれば、DBファイルを作成しないこと
もできます。
また、このモジュールは上記DBの排他制御のための機能を持ちます。ただし、こ
の機能のためマシン上にディレクトリの作成・削除ができる場所を用意する必要が
あります。
オプションでこの排他制御を行わないこともできます。データの保障はされませ
んが、マシン上に一時ディレクトリを作らずにすみます。
モジュールのインストール  次からモジュールを入手し、解凍・展開します。OSに応じて次のとおりインス
トールします。
(1)Unix
次のコマンドを順次実行することでインストールします。
perl Makefile.PL
make
su
make install
もし、上記の方法でうまく動作しない場合は、解凍した"
TermExtract"フォルダを、Perlのライブラリのパスが通っている
ディレクトリにフォルダごとコピーしてください。Perlのライブ
ラリの位置は、 perl -Vコマンドで確認できます。
(2)Windows (ActivePerl)
展開したフォルダのWindowsサブフォルダにあるアイコン
"win_install.pl" をダブルクリックし、実行します。自動的に
ActivePerlの"site\lib"ディレクトリに必要なファイルが展開
されます。
もし、上記の方法でうまく動作しない場合は、Windowsのコマ
ンドプロンプトから"win_install.pl"を実行します。cd コマン
ドで、win_install.plのあるディレクトリ(フォルダ)まで移動
し、perl win_install.plとコマンド入力して下さい。
TermExtract(tar.gz形式) 
TermExtract(ZIP形式) 
使いかた  入力となる形態素解析ソフトによって、モジュールを選びます、
また、その際の使用法のサンプルを示します。
「茶筅」 の場合は、TermExtract::Chasen サンプルスクリプト
「和布蕪」の場合は、TermExtract::MeCab  サンプルスクリプト
和文(EUC)そのもの場合は、TermExtract::JapanesePlainTextEUC サンプルスクリプト
和文(SJIS)そのもの場合は、TermExtract::JapanesePlainTextSJIS サンプルスクリプト
英文そのもの場合は、TermExtract::EnglishPlainText
サンプルスクリプト
"Brill's Tagger"、"Monty Tagger" の場合は、TermExtract::BrillsTagger
サンプルスクリプト
中文(GBコード)そのもの場合は、TermExtract::ChainesPlainTextGB
サンプルスクリプト(GBコード)
中文(UTF-8)そのもの場合は、TermExtract::ChainesPlainTextUC
サンプルスクリプト
ICTCLASの場合は、TermExtract::ICTCLAS
サンプルスクリプト(GBコード)
サンプルスクリプトを見ればわかりますが、専門用語の重要度の計算方式で、いく
つものオプション指定ができます。
オプションの設定方法は、以下に示す各モジュールのドキュメントをご覧ください。
また、専門用語の重要度の指定をデフォルトによらず、任意に設定するには専門
用語重要度計算の理解が必要です。東京大学情報基盤センター中川研究室のホーム
ページに詳しい説明がありますので、ここでは理論の概要と、補足情報を示します。
なお、以下は日本語の文章の例で示していますが、英文でも同じです。
専門用語の生成
和文の場合は「茶筅」や「和布蕪」といった形態素解析ソフトを使い、文章を
単語に分割します。その際に、分割した単語の品詞情報も合わせて情報として出て
きます。
複合語は、語の並びと品詞情報を元に組み立てます。
基本的には名詞が連続で出現した場合、それらを統合し複合語とします。
英文については、Bill's POD Tagger やMonty Tagger といった品詞タグ付け
ソフトを使い和文と同様の処理を行う方法と、指定したストップワードで文章を複
合語に分割する方法の2つを用意しています。ストップワードは、次の文献に書か
れていたものを基本としています。
William B. Frakes, Ricardo Baeza-Yates. 1992. Information retrieval : 
data structures & algorithms. Upper. Saddle River, N.J. :  Prentice
Hall PTR
(ISBN 0-13-463837-9)
重要度計算の仕組み
このモジュールでの専門用語は、単語そのものか複数の単語を組み合わせて作
られます。この複合語を構成する最小単位の名詞を特に「単名詞」と呼びます。こ
の単名詞が他の単名詞と連結して複合語をなすことが多いほど、重要な概念を示す
と考えます。
簡単な例で、「情報科学技術」を考えます。この語は次のとおり3つの単名詞に
分割できます。この際、それぞれの単名詞が他の単名詞とどれだけ結びつくか統計
的に分かっているとします。
単名詞  前の語に連結した回数  後の語に連結した回数
=========================================================
「情報」     1               2
「科学」     2               3
「技術」     1               1
複合語全体の重要度はこれらの6つ(単名詞数x2)の数値の平均から求めます。
「日本語マニュアル文における名詞間の連接情報を用いたハイパーテキストのた
めの索引の抽出」(『情報処理学会論文 第38巻 第10号』 平成9年10月)に
より、相乗平均がもっともよい結果になることがわかっていますので、平均は相乗
平均でとるようにしています。
また、相乗平均をとる際に、連結した回数が0回の単名詞に対応するため、各回
数に1を加算した値を用いています。
ドキュメント中の用語の出現頻度
前述した重要度に、ドキュメント中の専門用語の出現頻度を掛けることもでき
ます。これはオプションにより選択できます。デフォルトは、出現頻度を用います。
この計算方式は、異なる2つの要素の掛け合わせとなりますので、重要度中に占
める、それぞれの比率が問題となります。デフォルトは、連接回数の相乗平均に、
ドキュメント中の用語の頻度を掛けたものです。これを、連接回数の相乗平均のx乗
にすることができます(xは任意)。
連接の「延べ数」、「異なり数」、「パープレキシティ」
単名詞の連接情報は、連接した単語の種類をカウントする方法(異なり数)と、
種類にかかわらず出現しただけカウントする方法(延べ数)、そして情報理論的に
見た連接回数(パープレキシティ)の3つの方法があります。
例えば、統計データで、「情報」という語が「科学」の前に2回、「技術」の前
に3回連接したことが分かっているとします。
この場合連接語の異なり数と延べ数は次のようになります。
異なり数  2回 (「科学」 + 「技術」」で2種)
延べ数   5回 (「科学」2回 + 「技術」3回)
* パープレキシティは、「情報理論的に見ていくつの単名詞が連接可能か」を
示します。詳しくは、パープレキシティの仕様の詳細をご参照ください。
これはオプションによって選択できます。デフォルトは「延べ数」を用います。
学習機能(オプション機能)
単名詞の連接情報は、元となるデータが多ければ多いほど正確な統計データが
得られると推定されます。この学習機能は、いままでに処理対象としたテキストか
ら単名詞の連接情報を蓄積し、重要度計算で用いるものです。ただし、雑多な
文献を扱うと、結果として一般すぎる語が上位にきます。分野を特定した上でお使
い下さい。
デフォルトは現在処理対象となっているテキストのみから連接情報を得ます。
これはオプションによって選択できます。デフォルトは学習機能がOFFになってい
ます。次のメソッドを実行することで「学習機能」が有効になります。
$obj->use_storage;
$obj->use_stat;
その他の重要度計算モード(Frequency, TF, TF*IDF)
バージョン 4.02 より、連接情報以外の重要度計算手法も実行できるようになりま
した。
専門用語抽出システムでは用語の文章中の出現頻度をいままでも使ってきました。こ
の用語の出現頻度のカウント方法には、Frequency と TF(Term Frequency) の2つがあ
ります。いままでは、Frequency のみ使ってきました。今回のバージョンから、TF も
オプション指定できるようになります。また、用語の連接情報をカットすることで、
Frequency, TF のみで重要度計算することも可能です。Frequency と TF の違いは次の
とおりです。
Frequency ------------ 用語が他の用語の一部として使われていた場合にカウントしません
TF(Term Frequency) --- 用語が他の用語の一部として使われていた場合もカウントします
たとえば、「情報システムと情報」という例でみてみます。この場合、"TermExtract"
において、FrequencyとTFは次のようにカウントされます。
Frequency の場合 ---------  「情報」が1回、「情報システム」が1回
TF の場合 ----------------  「情報」が2回、「情報システム」が1回
また、IDF(Inverted Document Frequency) の値も掛け合わせることができます。これには
重要度計算の前に、処理対象とする文献群をプログラムに読ませ、DF(Document Frequency) の
データベース作成しておく必要があります。
TFとIDFの組み合わせにより、オーソドックスなTF-IDF法の重要度計算も行えます。その他、
(1)連接のカウント法、(2)用語頻度、(3)IDF のそれぞれのパラメータを自在に組み
合わせることができます。詳しくは以下をご覧下さい。
(1)連接のカウント法
*1)連接の「延べ数」 ($obj->use_total;)
2)連接の「異なり数」 ($obj->use_uniq;)
3)連接の「パープレキシティ」 ($obj->use_Perplexity;)
4)連接情報を使わない  用語頻度か用語頻度*IDFのみ ($obj->no_LR;)
(2)用語頻度
*1)Frequency ($obj->use_frq;)
2)TF(Term Frequency) ($obj->use_TF;)
3)頻度情報を使わない ($obj->no_frq;)
(3)IDFの有無(重要度計算前に処理対象文献群のDF(Document Frequency)情報をとる必要あり)
1)IDFを使う ($obj->use_idf;)
*2)IDFを使わない ($obj->no_idf;)
# 上記でアスタリスク(*) を付与した項番はデフォルト値です。
TF*IDF はオーソドックスな手法ですが使用法が難しいのでお気をつけください。
まず、TF*IDFの計算式をしめします。
TF*IDF =
用語の出現頻度 * log (総文献数 / 該当の用語を含む文献数)+1
処理は次のステップで行う必要があります。なお、termmi 中に含まれる
mi_chasen.pl などのスクリプトも参考になると思います。
(1)処理対象文献ごとに次の処理を実行。DF用のデータベースを作成。
$obj->use_storage_df;
$obj->get_imp_word("File Name");
(2)IDFを有効にして、用語抽出と重要度計算を行う。また用語出現頻度をTF(Term Frequency)でとる。
$obj->use_TF;
$obj->with_idf;
$obj->get_imp_word("File Name");
(3)不要になったDF用のデータベースの内容をクリア
$obj->clear_df_db();
結果の掛け合わせ
異なる重要度計算方式で求めた結果を掛け合わせる(フィルタリングする)こ
とができます。例えば、学習機能を使った場合と、そうではない場合の結果を掛け
合わせることもできます。
単名詞の連接情報の統計
ある単名詞が、どの単名詞と結びついて複合語をなすことが多いかという情報
が、学習機能用データベースには蓄積されます。
それらの情報をデータベースから抽出することもできます。これにより語学研究
といった目的での使用もできます。
その際のサンプルスクリプトを次に示します。
連接情報統計抽出  サンプルスクリプト
TermExtractの各モジュールの説明(PODをHTML化したもの) 
Calc_Imp.pm 
の説明(重要度計算のベースモジュール) 
Chasen.pm 
の説明(「茶筅」用モジュール) 
MeCab.pm 
の説明(「和布蕪」用モジュール) 
JapanesePlainTextEUC.pm 
の説明(和文[EUC]用プレーンテキスト用モジュール) 
JapanesePlainTextSJIS.pm 
の説明(和文[SJIS]用プレーンテキスト用モジュール) 
EnglishPlainText.pm 
の説明(英文プレーンテキスト用モジュール) 
BrillsTagger.pm 
の説明("Birll's POS Tagger", "Monty Tagger"用モジュール) 
ChainesPlainTextGB.pm 
の説明(中文プレーンテキスト、GBコード用モジュール) 
ChainesPlainTextUC.pm 
の説明(中文プレーンテキスト、UTF-8用モジュール) 
ICTCLAS.pm 
の説明(ICTCLAS用モジュール) 
"TermExtract"を使ったスタンドアロンシステム"termmx" 
の紹介
"TermExtract"を使ったスタンドアロンシステム"termmx" 
(中文版)の紹介
"TermExtract"を使ったテキストマイニングツール"termmi" 
の紹介
専門用語(キーワード)自動抽出サービス「言選Web」
トップページに戻る
専門用語(キーワード)自動抽出用Perlモジュール "TermExtract"の解説
