専門用語(キーワード)自動抽出システム を見てみることにする。このシステムは文章からキーワードを抜き出すシステムで、次の特長を持っているとのこと。
(1)形態素解析プログラムによる単語分割、(2)複合語の作成、(3)文章中における重要度の計算、という3つのステップを踏むことで、複合語により複雑な概念を表すことが多い専門用語をキーワードとして文章中から抽出することに成功しました。
まずは 「言選Web」 で実際の動きを見てみる。URL 指定欄に http://plaza.rakuten.co.jp/kugutsushi/ や http://www.kantei.go.jp/ を入力して試してみた。ちょっと不満なところはあるが、なぜくっつけるかなぁとかいうところもあるが、大方よさそうな感じ。東京大学経済学部図書館サブジェクトゲートウエイサービス"Engel のデータ入力補助でも使われれているそうだ。
専門用語(キーワード)自動抽出システム利用統計 を見てみると、平成15年はだいたい毎月 100件程度はコンスタントにダウンロードされているようだ。
専門用語自動抽出システム のページで
重要度計算には単名詞バイグラムを用いることにより複合名詞がどのような単名詞で構成されているかという連接情報と候補語の頻度情報を手掛かりとしています。
などの説明がされている。この重要度の計算の論文 をざっと眺めてみる。案外シンプルなやり方で、ここまでの結果が出せてしまうのだな。現在公開されているものは、これを改良したものらしい。
Windows用専門用語(キーワード)自動抽出システム "termex" の解説 を見ながら使ってみることにする。形態素解析器は、茶筅 と 和布蕪 のいずれも使えるももの、和布蕪は、ver 0.76 以前のバージョンを使えとある。mecab の古いバージョンをインストールし直すのはいやなので、とりあえず茶筅を使うことにした。
動かしてみると、うん、なるほどちゃんと動く。出力結果を見てみると、あれっ、なんでこういうのが出るなというのもあるが、だいたいのところよいものを出してくれている。納得いかないものが出ているところは、地道にハックしてみようかな。
形態素解析を使わない Windows用専門用語(キーワード)自動抽出システム "termex lite" の解説 の方も見てみる。termex とけっこう結果が違うのだな。結果を比較しながらハックするとおもしろいか。
東京大学情報基盤センター 中川裕志教授
中川研究室
多言語用例検索ツール:Kiwi
Webページの名寄せシステム(同姓同名の人のWebページを実際の同一人物ごとにまとめる): Nayose
横浜国立大学 大学院 環境情報研究院 社会環境と情報部門 森 辰則教授
こういうものを一般公開してくれている大学/研究者はありがたい存在だなと思う。もっとも、莫大な税金が国立大学には注がれているんだから社会還元されていると考えればよいのだけれど。ただし、そうした形の社会還元をしない方々も多いのが現実だから、こうして一般の人でも利用しやすいようにインターネットで公開する方々はナイスな存在といえるだろう。講義資料なども各研究室や研究者単位だけでなく、もっと大がかりにやればおもしろい方向になるのに。
待っていれば Google や Microsoft が検索できるようにしてくれるっていうのもあるんだけれど。
専門用語(キーワード)自動抽出システムを使ってみる | 傀儡師の館.Python - 楽天ブログ
