文字や単語のnグラム確率は統計的言語処理で強力な道具立てである。しかし、nが大きくなると推定すべきnグラム確率(パラメータの数が増加し、推定精度が低下するとともに、確率の値を格納する領域も大きくなるという問題があった。本文では、nグラム確率をn個の確率変数の同時分布と捉え、それらの確率変数に対する2次の周辺分布としてバイグラム確率を考える。その上で、周辺分布から同時分布を求める一般的手法である最大エントロピー法を適用して、バイグラム確率からnグラム確率を求める手法を提案する。本手法によって、パラメータの数を増加させることなく、精度良くnグラム確率を求めることができる可能性がある。次に、本手法を、文字トライグラムに適用して、有効性を実験する。その結果、(1) トライグラム自体を用いるよりも、未知データに対する被覆率が高くなること、(2) 隣接バイグラムのみを用いる手法よりも、精度が高いこと、などが分かった。
N-gram probability for characters or words is one of the most powerful tools in a statistical natural language processing. However, when n increases, the number of parameters, which should be estimated, also increases and estimation of them becomes inaccurate. And the area for storing these parameters becomes large. The author proposes the method to estimate n-gram probability from bi-gram probabilities using Maximum Entropy heuristics. This method provides n-gram probability from peripheral bi-gram probabilities accurately, not increasing the number of parameters. We show the experimental results to get character tri-gram from bi-grams. Here, character means Japanese kanji character and/or Kana character. Their results show (1) our method has more wide coverage for unseen data than the method which uses tri-gram itself; (2) our method is more accurate than the method which uses usual contiguous bi-gam.

