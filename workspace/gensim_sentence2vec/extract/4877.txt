本稿では音声認識の誤り訂正モデルに着目する.このモデルは音声認識器の出力する複数の認識結果候補から,それらの言語的素性に基づいて,より誤りの少ない単語列を選択するために用いられる.一般に,言語的素性に単語N-gramを採用し,それにより表現された正解パターンと誤りパターンの識別学習を通してモデルのパラメータ推定が行われる.しかし従来の学習法では,認識スコアの高い一位候補(もしくは上位候補)を対立単語列とするため,下位候補に出現する多様かつ潜在的な誤りパターンをモデルに反映できず,また単語N-gram素性のデータスパース性により,学習データに出現しない多くのパターンをカバーできない等の問題があった.そこで本稿では,日本語話し言葉コーパスを用いた実験により,WER基準での対立単語列選定,および素性分類別の誤り訂正モデル学習を行い,効果を検証する.それによりWERの高い単語列との識別がモデル性能に支配的であること,品詞N-gram等のスパース性を軽減可能な素性を採用することで,評価データの違いへの頑健性が向上することを示す.
We focus on error corrective models for ASR, which select a more accurate word sequence among multiple word sequences produced by a speech recognizer. In such approaches, the corrective model is usually trained discriminatively using hypothesis/reference pairs, typically using word N-gram features to improve discrimination of the reference word sequence from hypothesis word sequences with high recognition scores. However, it is also important for error correction to consider various error patterns. This can be efficiently achieved through the use of hypothesis word sequences with high word error rates (WERs). The various error patterns can be expressed using features that alleviate the data sparseness problem. In this paper, we evaluate the impact of training using competitors with various WERs, as well as the impact of different features, on the corrective model's performance. Our experiments using the Corpus of Spontaneous Japanese show that an accurate and compact model can be generated via training to discriminate the reference from the single worst competing word sequence (with the highest WER), and that models using features that alleviate the data sparseness problem, such as Part-of-Speech N-gram features, achieve robust error correction on evaluation sets.

