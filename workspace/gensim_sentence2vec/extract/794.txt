  
　従来のクライアント・サーバ型の音声認識方法の場合、クライアントとサーバの認識結果のどちらかを選択する際に両者の認識結果の確からしさを示す数値である認識スコア、尤度などを比較する必要があるが、サーバ側からこれらの情報が得られない場合がある。また、得られたとしてもクライアント側の音声認識と同一基準で算出したものである保証はない。そのため、クライアントとサーバの認識結果のどちらかを選択する場合、正確な比較ができず十分な音声認識精度が得られない場合があるという課題があった。
　この発明は、上記のような課題を解決するためになされたもので、クライアントの認識結果とサーバの認識結果を同一条件下で比較して最終的な認識精度を向上させる音声認識装置および音声認識方法を得ることを目的とする。
　この発明の音声認識装置は、音声の特徴量をモデル化した音響モデルと、音声認識装置が認識対象とする１個以上の語彙の表記と読みを格納している言語モデルと、認識対象および認識対象外の語彙の表記とその読みのペアを格納している読み辞書と、入力音声データを分析して特徴ベクトルを算出する分析部と、音響モデルを用いて、分析部の算出した特徴ベクトルと言語モデルに格納されている各語彙とのパターン照合を行って音響尤度を算出し、当該音響尤度の高い上位１個以上の語彙の表記、読みおよび音響尤度を内部認識結果として出力する内部認識部と、外部認識部により入力音声データを認識処理した外部認識結果を取得し、読み辞書を用いて当該外部認識結果に対する読みを付与し、当該外部認識結果とその読みから構成される読み付与結果を出力する読み付与部と、音響モデルを用いて、分析部の算出した特徴ベクトルと読み付与部の出力した読み付与結果とのパターン照合を行って、外部認識結果に対する音響尤度を算出する再照合部と、内部認識結果の音響尤度と外部認識結果の音響尤度を比較して、最終的な認識結果を決定する結果決定部とを備えるものである。
　この発明の音声認識方法は、入力音声データを外部認識部へ送信する送信ステップと、入力音声データを分析して特徴ベクトルを算出する分析ステップと、音声の特徴量をモデル化した音響モデルを用いて、分析ステップで算出した特徴ベクトルと、音声認識装置が認識対象とする１個以上の語彙の表記と読みを格納している言語モデル内の当該各語彙とのパターン照合を行って音響尤度を算出し、当該音響尤度の高い上位１個以上の語彙の表記、読みおよび音響尤度を内部認識結果として出力する内部認識ステップと、外部認識部により入力音声データを認識処理した外部認識結果を取得し、認識対象および認識対象外の語彙の表記とその読みのペアを格納している読み辞書を用いて当該外部認識結果に対する読みを付与し、当該外部認識結果とその読みから構成される読み付与結果を出力する読み付与ステップと、音響モデルを用いて、分析ステップで算出した特徴ベクトルと読み付与ステップで出力した読み付与結果とのパターン照合を行って、外部認識結果に対する音響尤度を算出する再照合ステップと、内部認識結果の音響尤度と外部認識結果の音響尤度を比較して、最終的な認識結果を決定する結果決定ステップとを備えるものである。
　この発明によれば、同一の音響モデルを用いて内部認識結果の音響尤度と外部認識結果の音響尤度を算出して比較することにより、最終的な認識精度を向上させた音声認識装置および音声認識方法を得ることができる。
この発明の実施の形態１に係る音声認識装置の構成を示すブロック図である。 実施の形態１に係る音声認識装置の有する言語モデルの内容例を説明する図である。 実施の形態１に係る音声認識装置の有する読み辞書の内容例を説明する図である。 実施の形態１に係る音声認識装置の動作を示すフローチャートである。 実施の形態１に係る音声認識装置の変形例として、英語の読み辞書の内容例を説明する図である。 この発明の実施の形態２に係る音声認識装置の構成を示すブロック図である。 実施の形態２に係る音声認識装置の動作を示すフローチャートである。 この発明の実施の形態３に係る音声認識装置の有する読み辞書の内容例を説明する図である。 この発明の実施の形態４に係る音声認識装置の構成を示すブロック図である。 実施の形態４に係る音声認識装置の有する結果決定用言語モデルの内容例を説明する図である。 
　以下、この発明をより詳細に説明するために、この発明を実施するための形態について、添付の図面に従って説明する。
実施の形態１．
　図１に示すように、本実施の形態１に係る音声認識装置１は、送信部３、分析部５、内部認識部７、言語モデル８、音響モデル９、読み付与部１２、読み辞書１３、再照合部１５、再照合結果１６を備えている。この音声認識装置１は、クライアント・サーバ型の音声認識システムを構成するクライアントに相当し、例えば利用者が携帯するスマートフォンなどのポータブル機器、車両等の移動体に搭載または持ち込まれるナビゲーション装置などの既存の機器に対して組み込んだり搭載したりしてもよく、または別体で用いてもよい。
　外部認識部１９は、ネットワークを介して音声認識装置１と接続されている音声認識サーバとする。ネットワークを介さず、有線または無線で直接接続されていても構わない。
　音声認識装置１において、音響モデル９は、音声の特徴ベクトルをモデル化した音響モデルを格納している。本実施の形態１では、音響モデルは音素をモデル化したものとし、音響モデル９には全ての音素に対する音響モデルを格納している。全音素の音響モデルがあれば、音素の音響モデルを接続することにより、任意の語彙の音声の特徴ベクトルをモデル化することができる。
　なお、音響モデル９がモデル化する特徴ベクトル（即ち、図１の特徴ベクトル６）は、例えばＭＦＣＣ（Ｍｅｌ　Ｆｒｅｑｕｅｎｃｙ　Ｃｅｐｓｔｒａｌ　Ｃｏｅｆｆｉｃｉｅｎｔ）とする。また、音響モデルは、例えばＨＭＭ（Ｈｉｄｄｅｎ　Ｍａｒｋｏｖ　Ｍｏｄｅｌ）とする。
　言語モデル８は、内部認識部７で認識対象とする語彙の表記と読みを格納している。なお、ここで言う読みとは、音響モデル９との対応付けが可能な記号の系列である。例えば、音響モデル９が音素をモデル化したものであれば、言語モデル８の読みは音素系列等である。本実施の形態１では、音声認識装置１の認識対象を神奈川県内の施設名とする。この場合の言語モデル８の内容例を、図２に示す。図２では読みとして音素の系列を用いている。
　読み辞書１３は、内部認識部７では認識対象としない語彙も含む大量の語彙の表記と読みのペアを格納している。なお、読みは、言語モデル８と同様に、音響モデル９との対応付けが可能な記号の系列としておく。本実施の形態１では読み辞書１３の読みを音素系列とする。この読み辞書１３の内容例を、図３に示す。
　これらの言語モデル８、音響モデル９、および読み辞書１３は、共通の記憶素子または記憶装置などに記憶してもよいし、それぞれ独立した記憶素子または記憶装置などに記憶してもよい。
　また、音声認識装置１を、プログラムを格納したメモリと、そのプログラムを実行するＣＰＵとを有する構成にして、ＣＰＵがプログラムを実行することにより送信部３、分析部５、内部認識部７、読み付与部１２、再照合部１５、および結果決定部１７が持つ機能（詳細は後述する）をソフトウエアによって実現してもよいし、あるいはその一部をハードウエアで実現してもよい。
　次に、図４のフローチャートを参照して、音声認識時の動作を説明する。
　ステップＳＴ１において、利用者が発話すると、その発話の入力音声２が送信部３に入力される。送信部３は、入力音声２を音声データ４にＡ／Ｄ変換して分析部５に出力する。また、送信部３は同一の音声データ４を外部認識部１９に送信する。
　ステップＳＴ２において、分析部５は、音声データ４を特徴ベクトル６に変換して内部認識部７と再照合部１５に出力する。特徴ベクトル６は、上述したように、例えばＭＦＣＣとする。
　ステップＳＴ３において、内部認識部７は、言語モデル８と音響モデル９を用い、例えばビタビアルゴリズムに従って特徴ベクトル６と言語モデル８に記述された各語彙との間でパターン照合（パターンマッチング）を行って音響尤度を算出し、音響尤度が最も高い語彙を選択して内部認識結果１０として結果決定部１７に出力する。
　なお、ここでは音響尤度の高い上位１個の語彙のみを内部認識結果１０に含める場合を説明するが、これに限定されるものではなく、例えば音響尤度の高い上位１個以上の各語彙を内部認識結果１０に含める構成にしてもよい。
　この内部認識結果１０は、語彙の表記、読み、および音響尤度から構成される。例えば、入力音声２が「舞浜国際競技場（まいはまこくさいきょーぎじょー）」であった場合、同一の語彙は言語モデル８中に存在しないが、言語モデル８の語彙のうち音響尤度が最も高い語彙が出力される。本例では「横浜国際競技場（よこはまこくさいきょーぎじょー）」の音響尤度が最も高かったとする。従って、内部認識部７はその語彙の表記「横浜国際競技場」、読み「ｙｏｋｏｈａｍａｋｏｋｕｓａｉｋｙｏｏｇｉｚｙｏｏ」、および音響尤度を、内部認識結果１０として出力する。
　ステップＳＴ４において、読み付与部１２は、外部認識部１９から外部認識結果１１が返送されるのを待つ。なお、本実施の形態１では、外部認識結果１１が少なくとも音声データ４の認識結果である語彙の表記を含むが、その語彙の読みは含まないものと仮定する。
　読み付与部１２が外部認識結果１１を受信すると（ステップＳＴ４#65337;ＥＳ#65289;、読み辞書１３を参照して外部認識結果１１に含まれる語彙の表記と一致するものの読みを抽出し、読み付与結果１４として再照合部１５に出力する（ステップＳＴ５）。例えば、外部認識結果１１が「舞浜国際競技場」であった場合、読み付与部１２は読み辞書１３を参照して一致する表記「舞浜国際競技場」と読み「ｍａｉｈａｍａｋｏｋｕｓａｉｋｙｏｏｇｉｚｙｏｏ」を抽出し、読み付与結果１４として出力する。
　ステップＳＴ６において、再照合部１５は、特徴ベクトル６と読み付与結果１４を入力とし、内部認識部７でパターン照合に使用したものと同一の音響モデルを用いて、即ち音響モデル９を用いて、特徴ベクトル６の読みと読み付与結果１４の読みとの間でパターン照合を行い、読み付与結果１４に対する音響尤度を算出する。再照合部１５のパターン照合方法は、内部認識部７で使用するパターン照合方法と同一のものとする。本実施の形態１ではビタビアルゴリズムを使用する。
　このように、再照合部１５が、内部認識部７と同一の音響モデルとパターン照合方法を使用することによって、内部認識部７で算出した内部認識結果１０と外部認識部１９で算出した外部認識結果１１の音響尤度が比較可能になる。再照合部１５は、読み付与結果１４と算出した音響尤度とから構成される再照合結果１６を結果決定部１７に出力する。
　ステップＳＴ７において、結果決定部１７は、内部認識結果１０と再照合結果１６を入力とし、音響尤度の高い順に認識結果を並べ替えて、最終認識結果１８として出力する。上記説明例では、入力音声２が「舞浜国際競技場」で、内部認識部７による内部認識結果１０が「横浜国際競技場」、外部認識部１９による外部認識結果１１が「舞浜国際競技場」なので、同一の音響モデル９を用いてパターン照合を行い音響尤度を算出すれば、外部認識部１９の「舞浜国際競技場」のほうが音響尤度が高くなることが期待でき、音声認識精度改善に寄与する。
　以上より、実施の形態１によれば、音声認識装置１は、音声の特徴量をモデル化した音響モデル９と、音声認識装置１が認識対象とする１個以上の語彙の表記と読みを格納している言語モデル８と、認識対象だけでなく認識対象外も含めた大量の語彙の表記とその読みのペアを格納している読み辞書１３と、入力音声２の音声データ４を分析して特徴ベクトル６を算出する分析部５と、音響モデル９を用いて分析部５の算出した特徴ベクトル６と言語モデル８に格納されている各語彙とのパターン照合を行って音響尤度を算出し、当該音響尤度の高い上位１個以上の語彙の表記、読みおよび音響尤度を内部認識結果１０として出力する内部認識部７と、外部認識部１９により音声データ４を認識処理した外部認識結果１１を取得し、読み辞書１３を用いて外部認識結果１１に対する読みを付与し、外部認識結果１１とその読みから構成される読み付与結果１４を出力する読み付与部１２と、音響モデル９を用いて分析部５の算出した特徴ベクトル６と読み付与部１２の出力した読み付与結果１４とのパターン照合を行って、外部認識結果１１に対する音響尤度を算出する再照合部１５と、内部認識結果１０の音響尤度と再照合結果１６の音響尤度を比較して最終的な認識結果を決定する結果決定部１７とを備えるように構成した。このため、外部認識結果１１に対し、内部認識部７と同一の音響モデルとパターン照合方法を使用して音響尤度を求めることができ、外部認識結果１１の音響尤度と内部認識結果１０の音響尤度の正確な比較が可能になり、最終的な認識精度を向上することができる。従って、例えば音声認識装置１のハードウエア資源が十分でなく言語モデル８の語彙数が少ない場合であっても、大規模な言語モデルを有する外部認識部１９の認識結果を利用することができ、音声認識装置１の認識性能が改善するという効果がある。
　なお、本実施の形態１に係る音声認識装置１は、日本語以外の言語にも適用可能である。例えば、音声認識装置１を英語に適用する場合は、言語モデル８、音響モデル９および読み辞書１３をそれぞれ英語用に変更すればよい。その場合、読み辞書１３には大量の英語の語彙の表記と読みを登録しておけばよい。なお、読み辞書１３の読みは音響モデル９と対応付けが可能な表記にしておく。例えば、音響モデル９が英語の音素であれば、読み辞書１３の読みは音素表記、または音素表記に変換可能な記号にしておく。図５に、英語の読み辞書１３の例を示す。図５の１列目に表記、２列目にその読みとして音素表記を記している。
　また、読み辞書１３には、外部認識結果１１の語彙に一致する読みが存在しないことがないように、大量の語彙の読みを格納しておくが、それでも一致するものが読み辞書１３に存在しない場合は、予め内部認識部７と外部認識部１９のどちらの認識結果を採用するか決めておき、結果決定部１７がその決めておいた方の認識結果を最終結果とすればよい。
実施の形態２．
　図６は、本実施の形態２に係る音声認識装置１の構成を示すブロック図である。図６において図１と同一または相当の部分については同一の符号を付し説明を省略する。本実施の形態２に係る音声認識装置１では、第２音響モデル２０を追加したことが特徴である。
　第２音響モデル２０は、上記実施の形態１の音響モデル９と同様に、音声の特徴ベクトルをモデル化した音響モデルを格納している。但し、第２音響モデル２０は、音響モデル９よりも精密で認識精度の高い音響モデルとする。例えば音響モデルで音素をモデル化する場合に、モデル化の対象とする音素だけではなくその音素の前後の音素も考慮したトライフォン音素をモデル化したものとする。トライフォンの場合、「朝／ａｓａ」の第２番目の音素／ｓ／と、「石／ｉｓｉ／」の第２番目の音素／ｓ／とでは、前後の音素が異なるので、異なる音響モデルでモデル化することになり、これによって認識精度が向上することが知られている。但し音響モデルの種類が増えるため、パターン照合時の演算量が増加する。
　次に、図７のフローチャートを参照して、音声認識時の動作を説明する。
　利用者が発話すると、送信部３が入力音声２を音声データ４にＡ／Ｄ変換し、分析部５と外部認識部１９に出力する（ステップＳＴ１）。分析部５および内部認識部７は、上記実施の形態１と同一の動作をして（ステップＳＴ２，ＳＴ３）、内部認識結果１０を出力する。但し、上記実施の形態１のステップＳＴ３では内部認識結果１０を内部認識部７から結果決定部１７に出力したが、本実施の形態２のステップＳＴ３では内部認識部７から再照合部１５に出力する。
　ステップＳＴ１１において、再照合部１５は、特徴ベクトル６と内部認識結果１０を入力とし、第２音響モデル２０を用いて特徴ベクトル６の読みと内部認識結果１０の読みとの間でパターン照合を行い、内部認識結果１０に対する音響尤度を算出する。このときのパターン照合方法は、内部認識部７で使用する方法と同一である必要はないが、本実施の形態２ではビタビアルゴリズムを使用する。再照合部１５は、内部認識結果１０と算出した音響尤度とから構成される再照合結果１６ａを結果決定部１７に出力する。
　なお、前述したとおり、第２音響モデル２０は音響モデル９と比較してモデルの種類が多いため、パターン照合に要する処理量が増加するが、再照合部１５での照合対象は内部認識結果１０に含まれる語彙に限定されるため、処理量の増加を小さく抑えることができる。
　読み付与部１２は、上記実施の形態１と同一の動作をして（ステップＳＴ４，ＳＴ５）、外部認識結果１１に対する読み付与結果１４を求め、再照合部１５に出力する。
　ステップＳＴ１２において、再照合部１５は、読み付与結果１４が入力されると、上記実施の形態１と同等の動作によって読み付与結果１４とその音響尤度とから構成される再照合結果１６を求め、結果決定部１７に出力する。但しパターン照合には第２音響モデル２０を用いる。
　ステップＳＴ１３において、結果決定部１７は、内部認識結果１０に対する再照合結果１６ａと外部認識結果１１に対する再照合結果１６を入力とし、音響尤度の高い順に認識結果を並べ替えて、最終認識結果１８として出力する。
　以上より、実施の形態２によれば、音声認識装置１は、音響モデル９とは異なる第２音響モデル２０を備え、再照合部１５は、第２音響モデル２０を用いて、分析部５の算出した特徴ベクトル６と内部認識部７の出力した内部認識結果１０とのパターン照合を行って内部認識結果１０に対する音響尤度（再照合結果１６ａ）を算出すると共に、特徴ベクトル６と読み付与部１２の出力した読み付与結果１４とのパターン照合を行って外部認識結果１１に対する音響尤度（再照合結果１６）を算出し、結果決定部１７は、再照合部１５の算出した内部認識結果１０の音響尤度と外部認識結果１１の音響尤度を比較して、最終的な認識結果を決定するように構成した。従って、音響モデル９よりも精密で認識精度の高い第２音響モデル２０を用いて再照合することにより、外部認識結果１１の音響尤度と内部認識結果１０の音響尤度の比較がより正確になり、認識精度を改善させる効果がある。
　なお、内部認識部７において第２音響モデル２０を使用しない理由は、内部認識部７のパターン照合に第２音響モデル２０を使用すると音響モデル９よりもモデルの種類が増えるため、パターン照合時の演算量が増加するからである。本実施の形態２のように音響モデル９と第２音響モデル２０で別々のモデルを使用することにより、演算量の増加を小さく抑えつつ認識精度を向上させる効果がある。
実施の形態３．
　本実施の形態３に係る音声認識装置は、図１または図６に示す音声認識装置１と図面上では同様の構成であるため、以下では図１を援用して説明する。本実施の形態３に係る音声認識装置１では、読み辞書１３の内容、ならびに読み付与部１２および再照合部１５の動作を後述するように変更するものである。
　図８は、本実施の形態３に係る音声認識装置１の読み辞書１３の内容例を示す図である。本実施の形態３に係る音声認識装置１において、読み辞書１３は、図３に示した単語および施設名の辞書の他に、図８に示す１文字単位程度の語彙の辞書も格納している。このように１文字単位程度の細かい単位の語彙を持つことにより、外部認識結果１１の様々な表記に対して読みを付与することが可能になる。
　次に、音声認識時の動作を説明する。
　利用者が発話すると、送信部３が入力音声２を音声データ４にＡ／Ｄ変換し、分析部５と外部認識部１９に出力する。分析部５および内部認識部７は、上記実施の形態１と同一の動作をして内部認識結果１０を出力する。例えば入力音声２が「鈴鹿坂（すずかさか）」であった場合、「鈴鹿坂」は言語モデル８中に存在しないが、言語モデル８に記述された各語彙との間でパターン照合が行われ、音響尤度が最も高い語彙が出力される。本実施の形態３では、「鈴木酒店（すずきさけてん）」の音響尤度が最も高かったとする。従って、内部認識部７はその語彙の表記、読みおよび音響尤度を内部認識結果１０として出力する。
　読み付与部１２は、外部認識部１９から外部認識結果１１が返送されるのを待ち、外部認識結果１１を受信すると図８に示す読み辞書１３を参照して、外部認識結果１１に含まれる語彙の表記（例えば「鈴鹿坂」）と一致するものの読みを抽出する。外部認識結果１１の表記に一致する読みが読み辞書１３中に複数個存在する場合は複数個の読みを出力する。また、一致する読みが存在しない場合は、読み辞書１３中の表記の接続によって外部認識結果１１の表記を構成できるものを抽出する。この抽出作業は、例えば外部認識結果１１の表記を、分割数最小の基準で、読み辞書１３中の全表記を照合対象とした連続ＤＰ（Ｄｙｎａｍｉｃ　Ｐｒｏｇｒａｍｍｉｎｇ）マッチングを行うことによって可能である。
　本実施の形態３の例では外部認識結果１１の「鈴鹿坂」と一致する表記が読み辞書１３中に存在しないため、読み付与部１２は、読み辞書１３中に存在する表記「鈴」「鹿」「坂」を抽出する。このように抽出した表記に対する読みが複数個存在する場合は、全ての読みの組み合わせを抽出する。この場合、「鈴」の読みは「ｓｕｚｕ」と「ｒｅｉ」、「鹿」の読みは「ｓｉｋａ」と「ｋａ」のそれぞれ２個、「坂」の読みは「ｓａｋａ」の１個なので、外部認識結果１１の「鈴鹿坂」の読みとして、「ｓｕｚｕｓｈｉｋａｓａｋａ」、「ｒｅｉｓｈｉｋａｓａｋａ」、「ｓｕｚｕｋａｓａｋａ」、「ｒｅｉｋａｓａｋａ」の４種類の読みが抽出される。そして、読み付与部１２は、抽出した４種類の読みを、表記「鈴鹿坂」と共に読み付与結果１４として出力する。
　再照合部１５は、特徴ベクトル６と読み付与結果１４を入力とし、内部認識部７でパターン照合に使用したものと同一の音響モデル９を用いて、特徴ベクトル６の読みと読み付与結果１４の複数個の読みとの間でそれぞれパターン照合を行い、そして音響尤度が最も高い読み付与結果１４の読みを、読み付与結果１４に対する音響尤度として算出する。再照合部１５は、読み付与結果１４と算出した音響尤度とから構成される再照合結果１６を出力する。
　このように、外部認識結果１１の語彙の表記に対して複数個の読みの候補が存在する場合に、再照合部１５において特徴ベクトル６と複数個の読みとをパターン照合することによって、読みの決定とともに音響尤度を算出することができる。上記説明例では、外部認識結果１１の「鈴鹿坂」の４種類の読みのうち、最も音響尤度が高い読み「ｓｕｚｕｋａｓａｋａ」を再照合結果１６に含める。
　結果決定部１７は、内部認識結果１０と再照合結果１６を入力とし、上記実施の形態１と同一の動作をして音響尤度の高い順に認識結果を並べ替え、最終認識結果１８として出力する。上記説明例では、入力音声２が「鈴鹿坂」で、内部認識部７による内部認識結果１０が「鈴木酒店」、外部認識部１９による外部認識結果１１が「鈴鹿坂」（ｓｕｚｕｋａｓａｋａ）なので、同一の音響モデル９を用いてパターン照合を行い音響尤度を算出すれば、外部認識部１９の「鈴鹿坂」（ｓｕｚｕｋａｓａｋａ）のほうが音響尤度が高くなることが期待でき、音声認識改善に寄与する。
　以上より、実施の形態３によれば、読み付与結果１４は、読み辞書１３に、外部認識結果１１に対する読みの候補が複数個存在する場合、当該複数個の読みを付与した読み付与結果１４を出力し、再照合部１５は、読み付与結果１４に含まれる読みごとにパターン照合を行って音響尤度を算出し、当該音響尤度が最大の読みを選択して結果決定部１７に出力するように構成した。このため、外部認識結果１１の表記のみでは読みを一意決定できない場合でも、再照合部１５にて特徴ベクトル６とパターン照合することによって読みの決定とともに音響尤度を算出することが可能となり、音声認識精度が改善する効果がある。
　また、実施の形態３の読み辞書１３に対しては単語より細かい単位で表記と読みを与えているので、その組み合わせで多用な単語の表記が作れることになり表記の一致するものが見つかる確率が高くなるというメリットがある。一方、上記実施の形態１の読み辞書１３に対しては単語ごとに表記と読みを与えているので、読み付与の精度が高いというメリットがある。
　なお、上記実施の形態３では、上記実施の形態１の音声認識装置１に対して読み付与部１２および再照合部１５の動作を変更した場合について説明したが、上記実施の形態２の音声認識装置１に対しても同様に、読み付与部１２および再照合部１５の動作を変更することが可能であり、外部認識結果１１の表記のみでは読みを一意決定できない場合に対して同一の効果がある。
実施の形態４．
　図９は、本実施の形態４に係る音声認識装置１の構成を示すブロック図である。図９において図１および図６と同一または相当の部分については同一の符号を付し説明を省略する。本実施の形態４に係る音声認識装置１では、結果決定用言語モデル２１を追加し、結果決定部１７の動作を以下に説明するように変更するものである。
　図９に示す結果決定用言語モデル２１としては、語彙、または複数個の語彙の並びに対して尤度を与えるものであれば任意のモデルを使用することができる。本実施の形態４では、結果決定用言語モデル２１として単語のユニグラム言語モデルを用いる場合を例に説明する。結果決定用言語モデル２１の内容例を、図１０に示す。一列目が語彙の表記、２列目が言語尤度である。結果決定用言語モデル２１は事前に大量の語彙のデータベースを用いて作成しておく。例えば、本例のユニグラム言語モデルであれば、大量の語彙のデータベースから各語彙の出現確率を算出し、出現確率の対数値を尤度として結果決定用言語モデル２１に登録する。
　次に、音声認識時の動作を説明する。
　利用者が発話すると、その発話を入力として送信部３、分析部５、内部認識部７、読み付与部１２、および再照合部１５が上記実施の形態１と同一の動作をして、結果決定部１７に対して内部認識部７から内部認識結果１０を出力するとともに再照合部１５から再照合結果１６を出力する。
　結果決定部１７は、結果決定用言語モデル２１を参照して、内部認識結果１０と再照合結果１６のそれぞれに対して言語尤度Ｓｌを求める。例えば内部認識結果１０の表記が「鈴鹿酒店」であれば、図１０の結果決定用言語モデル２１を参照して言語尤度Ｓｌ＝－０．３２である。同様に、再照合結果１６の表記が「鈴鹿坂」であれば、言語尤度Ｓｌ＝－０．３０である。そして、結果決定部１７は、内部認識結果１０と再照合結果１６のそれぞれに対して、下式（１）に従って総合尤度Ｓを算出する。式（１）中のＳａは音響尤度、ｗは事前に実験的に定めた定数であり、例えばｗ＝１０である。
　　Ｓ＝Ｓａ＋ｗ#65331;ｌ　　　（１）
　結果決定部１７は、内部認識結果１０と再照合結果１６の認識結果を、総合尤度Ｓの高い順に並べ替えて、最終認識結果１８として出力する。
　以上より、実施の形態４によれば、音声認識装置１は、語彙とその言語尤度のペアを格納している結果決定用言語モデル２１を備え、結果決定部１７は、結果決定用言語モデル２１を用いて内部認識結果１０の言語尤度と再照合結果１６（即ち、外部認識結果１１）の言語尤度を算出し、内部認識結果１０の音響尤度および当該言語尤度と再照合結果１６の音響尤度および当該言語尤度とを比較して、最終的な認識結果を決定するように構成した。このため、内部認識結果１０と再照合結果１６に対して同一の結果決定用言語モデル２１を用いて言語尤度Ｓｌを算出するので、言語尤度Ｓｌを考慮した比較が可能になり、認識精度が改善するという効果がある。
　なお、上記実施の形態４では、結果決定用言語モデル２１として単語のユニグラムを使用した例を説明したが、これに限定されるものではなく、バイグラムおよびトライグラムなどを含めた任意の統計言語モデル（ｎ－ｇｒａｍ）を使用してもよい。
　また、上記実施の形態４では、上記実施の形態１の音声認識装置１に対して結果決定用言語モデル２１を追加し結果決定部１７の動作を変更した場合について説明したが、上記実施の形態２，３の音声認識装置１に対しても同様に、結果決定用言語モデル２１を追加し結果決定部１７の動作を変更することが可能である。
　また、上記実施の形態１～４では、１個の外部認識部１９から受信した外部認識結果１１を使用したが、複数個の外部認識部１９から受信した複数個の外部認識結果１１を使用してもよい。また、結果決定部１７が音響尤度等の高い順に並べ替えた認識結果を最終認識結果１８として出力するようにしたが、これに限定されるものではなく、音響尤度が高い順に所定の数だけ最終認識結果１８として出力するなどの構成にしてもよい。
　上記以外にも、本願発明はその発明の範囲内において、各実施の形態の自由な組み合わせ、あるいは各実施の形態の任意の構成要素の変形、もしくは各実施の形態において任意の構成要素の省略が可能である。
　以上のように、この発明に係る音声認識装置は、同一の音響モデルを用いて内部認識結果の音響尤度と外部認識結果の音響尤度を算出して比較するようにしたので、クライアント・サーバ型の音声認識システムを構成するクライアント側のカーナビゲーション装置およびスマートフォンなどに用いるのに適している。
　１　音声認識装置、２　入力音声、３　送信部、４　音声データ、５　分析部、６　特徴ベクトル、７　内部認識部、８　言語モデル、９　音響モデル、１０　内部認識結果、１１　外部認識結果、１２　読み付与部、１３　読み辞書、１４　読み付与結果、１５　再照合部、１６，１６ａ　再照合結果、１７　結果決定部、１８　最終認識結果、１９　外部認識部、２０　第２音響モデル、２１　結果決定用言語モデル。
Patent WO2014136222A1 - 音声認識装置および音声認識方法 - Google Patents
