AMDのCPUアーキテクチャの積み重ね
AMDの次世代CPUアーキテクチャ「Bulldozer(ブルドーザ)」は、2個のCPUコアを融合させたモジュールを基本ユニットとしている。モジュールは、2スレッドで共有の命令デコーダと浮動小数点ユニット、スレッド毎に分離された2個の整数コアで構成されている。これまでのPC用CPUにない構成のBulldozerの、命令デコードと実行の仕組みが、徐々に推測できるようになってきた。
Bulldozerの命令デコードと命令発行の仕組みは、AMDの過去のCPUアーキテクチャの積み重ねの上に成り立っていると推測される。
AMDのK7/K8/K10(Hound)のアーキテクチャでは、x86命令のデコードは2段階になっている。正確には、前段のプリデコード(L1命令キャッシュフィルの段階)も含むと3段階となる。K7/K8/Hound(K10)系の命令フェッチユニットは、プリデコードが済んだキャッシュラインからx86命令をフェッチする。命令デコーダは、単純なx86命令なら、1対1でMacroOPに変換する。これが1段階目のデコード。MacroOPは、命令スケジューラでuOPに分解される。これが2段階目のデコードだ。
2段階でデコードするのは、x86命令のアーキテクチャ上の事情があるからだ。CISC(Complex Instruction Set Computer)系であるx86の演算命令は、その特徴としてオペランドに、メモリを指定できる。RISC(Reduced Instruction Set Computer)系命令のように演算命令のオペランドがレジスタだけに限定されていない。典型的なx86演算命令では、メモリ上の値にレジスタの値を加えて、それをレジスタに納めるパターンがある。
演算した値をメモリに格納するケースもあるが、とりあえずメモリから読み出すだけのケースを考える。その場合、そのままのx86演算命令の実行には、高速性と効率性の問題が生じる。メモリからのデータのロードにはL2ヒットでも最大10サイクル以上のレイテンシがあるため、その間、実行パイプが止まってしまうからだ。それを避けるためには、ロードを先行して実行する必要がある。
そのため、AMDやIntelはCPUのパイプラインを、演算パイプとロード/ストアパイプに分割している。ロードオペレーションを先に実行して、データがロードされてから演算オペレーションを実行する。そして、それに対応して、x86命令も演算uOPとロード/ストアuOPに分解する。演算uOPを演算パイプに、ロード/ストアuOPをロード/ストアパイプに発行する。RISC的な命令に分解するため、uOPはx86系CPUの内部のRISC系命令と言ってもいい。
複合型の内部命令MacroOPを使うAMDアーキテクチャ
AMDのK6、IntelのNetBurstなどでは、命令デコーダの段階でx86からuOP(K6ではRISC86とも呼んでいた)に変換していた。しかし、この方法にも問題があった。uOPに分解すると、パイプライン中で制御しなければならない命令数が増えて、CPUが複雑になることだ。
そこで、メインストリームCPUでは、AMDはK7、IntelはCore Microarchitecture(Core MA)から、複合型の内部命令を採用した。x86演算命令をデコードする際に、演算uOPとロード/ストアuOPを分解せずに、1つの内部命令に止める方法だ。この複合型内部命令をAMDはMacroOP、Intelは「Fused uOP」と呼んでいる。
AMD K7/K8/Hound(K10)アーキテクチャの場合は、命令デコードの段階で、最大で3個のx86命令をMacroOPにデコードできる(命令デコーダは実際には2つのパスに分かれている)帯域を持つ。命令デコーダは、最大3個のMacroOPを命令スケジューラに発行できる(正確にはその前ステージのInstruction Control Unitに発行する)。MacroOPはスケジューラのリザベーションステーション(Reservation Station)に納められ、ここでuOPに分解される。リザベーションステーションは実際にはOut-of-Order発行のキューとなっており、ここから実行できるuOPから順番に実行パイプに発行される。
K7/K8/Hound(K10)では、整数演算系の実行パイプは、整数演算ユニット(ALU)とアドレス生成ユニット(AGU)の2つのユニットがペアで構成されている。1ペアで1つのMacroOPに対応するイメージだ。整数演算パイプ群には、3組のペアがあり、合計で整数演算(ALU)が3個、アドレス生成(AGU)が3個の6パイプ構成となっている。
K7/K8/Hound(K10)では、6パイプでピークで6uOPsを1サイクルで実行できる。全てのMacroOPが2個のuOPに分解されるとしたら、3個のMacroOP分に相当するオペレーション(6uOPs)を1サイクルで実行できる。命令デコーダからスケジューラへは、1サイクルにピークで3MacroOPsが発行されるため、命令デコード&発行の帯域と実行帯域がマッチしている。AMDアーキテクチャの特徴は、このピーク帯域がマッチしていることにある(Intelはジョウロ式で異なる)。
4-wayと見られる強力なx86命令デコーダ
では、おぼろげながら見えてきたBulldozerの構造ではどうなっているのか。推測も交えて命令の流れを辿ると次のようになる。
Bulldozerの命令フェッチやプリデコード、分岐予測の詳細はまだわからない。上の図は、K7/K8/Hound(K10)系と同じようにL1命令キャッシュに、プリデコードや分岐予測の機能が統合されているものと推定したものとなっている。この部分は推定だ。
命令デコーダについては4-way、4個のx86命令のデコードが可能であることがほぼ確実だ。これには複数の証拠がある。まず、AMDの発表によると、命令デコーダからの発行が4命令/サイクルであること。AMDの米国での特許申請「United States Patent Application 20090006814」でも、Bulldozerそっくりの構成での命令デコーダは4-wayとなっている。そして、命令デコーダが4-wayだとすると、前述のように実行パイプとの帯域がピタリと合う。命令デコーダのパスはK7/K8/Hound(K10)系と同じように2つに分かれているとしても、帯域は4-wayだろう。
命令デコーダが、各サイクルに最大4個のx86命令をデコードして最大4個のMacroOPに変換できると仮定する。その場合、同サイクルにデコードされるx86命令は、同じキャッシュラインから切り出されるため、いずれも同じスレッドに属することになる。1サイクル毎にスレッドの切り替えが可能としても、この段階では、各サイクルでスレッドが揃うことになる。
ピークで1サイクルに4 MacroOPの命令発行帯域か
実際には命令デコーダの後段に、命令のスケジューリング全般を制御する命令コントロールユニット(ICU)に相当するものが控えていると推定される。BulldozerがMacroOPを使っているとすれば、ICUから、MacroOPが3つの命令スケジューラへと発行される。この時の帯域が4MacroOP/Cycleで、AMDの説明にあった、命令スケジューラへの4命令発行の意味だと推定される。
命令デコーダからの出力のライン毎にMacroOPが発行されるとすると、命令デコーダから命令スケジューラへのMacroOPの発行はスレッド単位になると推定される。例えば、あるサイクルにはスレッドAのMacroOP群が整数コア0のスケジューラに発行され、次のサイクルにはスレッドBのMacroOP群が整数コア1のスケジューラに発行されるといった具合だ(同じサイクルに同スレッドの浮動小数点演算命令が含まれていない場合)。
その場合は、1サイクル毎にそれぞれの整数コアのスケジューラが空いてしまうことになる。しかし、整数コアへの命令発行ポートはどちらも4ポートで、ピークで4uOP/Cycleだ。そのため、スケジューラに発行された4個のMacroOPが、もし8個のuOPに分解されるとすると、キューには2サイクル分のuOPが貯まることになる。
こうした仕組みと推定されるため、Bulldozerでは各サイクルにどちらか片方のスレッドしかデコード&発行できなくても問題はない。命令デコーダはキューを見て、キューに貯まったuOPが少ない方のスレッドのx86命令から優先してデコードするように調整できそうだ。実際、特許申請でそうした具体例に触れられている。
【後藤弘茂のWeekly海外ニュース】 AMDのBulldozerの命令発行の仕組み
