世の中データ分析部門を立ち上げる企業が増えてきて、「データサイエンティスト」と名乗ろうが名乗るまいがデータ分析者を置いて様々なビジネス上のデータを分析させるところが目立ってきました。
でも、一方で実際のデータ分析者たちが何をやっていて、どういうアウトプットを出しているのか?について、きちんと理解している人はあまり多くなさそうに見えます。うっかりすると、「金とデータは渡すから良きに計らえ」*1ってところも少なくないかも。。。
それではあまりにもざっくりし過ぎているので、実際のデータ分析者がどんなことをしているのかを、超絶大ざっぱに4つに分けてみました*2。即ち、「回帰・分類・推定・予測」の4つのコンセプトです。今回はこの4つのコンセプトについて、データ分析を「させる(依頼する)」側の人たちに出来る限り分かりやすく説明してみようと思います。
ということで、データ分析を「させる(依頼する)」側のマネージャーさん、部長さん、はたまたコンサルに分析をしてもらっているカスタマーさんあたりに是非読んでもらえると嬉しいです。
この記事では分かりやすさ&イメージしやすさを最優先にして、厳密性は完全に度外視*3してますので、念のため。厳密な説明や数式に関する解説などはこの記事の最後に載せた参考文献とか読んでもらえたら良いかなーと思います。
(※モデリングが重視される傾向にある現状を鑑み、「検定」まわり*4や「分布」絡み*5は今回は割愛しました)
回帰:「で××を説明するモデルを作る」
「回帰」と名の付くものはほぼ全てがこれです。みんな大好き重回帰分析も、時々名前の聞こえてくるロジスティック回帰も、これです。で、これはどういうものかというと。。。
よく統計学の教科書に出てくる重回帰分析*6の式ですが、これだけ見ても何が何だかよく分かりませんよね。これは例えばあるバナー広告のclick数のモデルとしてたとえると、という感じに解釈できます。既に測定されたデータであるのうち、click数であるを各種の指標であるで説明できるように様々な数学的な計算をして、パラメータを算出するというものです。
つまり例に沿って言い換えると、「バナー広告のclick数を掲載webサイト内でのアクションやバナーのクリエイティブの指標で説明できるモデル式を作る」ということです。このモデル式があればこそ、この後の「推定」とか「予測」もできるようになります。すなわちデータ分析の最重要コンセプトと言っても良いでしょう。
ちなみに、あるデータyを指標xで説明したいというような単回帰(2つのデータしか使わない回帰)のケースでは、よく下のような図で説明されることが多いかと思います。これは青い点で表されているデータに対して、最もシンプルにというモデル式を計算してみた結果です。試しに赤い線でモデル式を表してみると、まぁ大体合っていることが分かるかと思います。
重回帰の場合は、これと同じものをたくさんある指標のそれぞれについて「互いに影響が出ないように独立に」計算して出しています。この辺の話は後で「推定」のところで説明します。
分類:「ととに分けるモデルを作る」
いわゆる機械学習の多くがこれです。これはもうサポートベクターマシン(SVM)の分類結果*7を見てもらうのが早いでしょう。要は、というような入り組んだデータを、様々な繰り返し計算や最適化計画をコンピューターに解かせて、予め定めておいた基準(一般には「今あるデータだけでなく未知のデータに対してもある程度パフォーマンスが良くなるように」というもので理論的に決まってます)を満たすように切り分ける直線(平面)or曲線(曲面)を算出するというものです*8。実際に上のデータをSVMで分類してみるとこうなります。SVMはその性質上「できるだけ滑らかに(ある程度の誤差を許してでも)切り分ける」ように曲線を引きます。実際に、そのような結果になっているのが上の図を見ると分かるんじゃないかと思います。
この例では2次元(つまりxとyの2つの変数で決まる)データを分類していますが、もちろん上の「回帰」の例同様にもっと多次元=もっと多くの変数で決まるデータを分類することも可能です。ただしあまりにも大量のデータを相手にする場合は、さらに数学的な工夫も必要だし、デカい計算機クラスタとか必要になりますが。。。
推定:「モデルを表現するパラメータを算出する」
「回帰」にせよ「分類」にせよ、モデルを表すパラメータそのものが役立つことが多いです。何故かというと、そのパラメータが高い指標ほど、求めたい数字(e.g. click数・CV数・売上高…)への影響力が高く、簡単に言えばその指標を上げる努力さえすれば求めたい数字も上がる!という結果につながりやすいからです。例えば、「回帰」であればに出てくるがそうですね。これを例えば以前の記事(「使い分け」ではなく「妥当かどうか」が大事：重回帰分析＆一般化線形モデル選択まわりの再まとめ)で用いたclick数とアクションとの関係を調べた重回帰分析のデータに、モデル式の直線として重ねて表してみるとこうなります*9。に当たるd1というデータに対応しているパラメータで表現したモデル式の直線が、一番傾きが大きいですね。ということで、d1が最もclick数を増やすのに貢献したとみなせるわけです。
「分類」でこの手のパラメータの推定ができる手法は意外と限られますが、機械学習の中でも例えば「ランダムフォレスト」というものは個々の指標の「貢献度」の大きさも分類ついでに計算することができます。別の以前の記事(単純な集計とデータサイエンスによる分析とで結果が食い違うかもしれない3ケース)で用いた個々のユーザーがCVするか否かとアクションとの関係を調べた機械学習分類のデータに、ランダムフォレストを用いて分類した上でa1-a7の指標の重要度を計算してプロットした結果がこちらです。a6が断トツで個々のユーザーがCVするという行動に強く影響している、ということが読み取れます。ちなみに他にも同様の貢献度の算出が可能な機械学習のメソッドは多数あります。
予測:「作ったモデルに、これから入ってくるデータをインプットして、まだ見ぬ未来の結果を得る」
実はものすごく難しいことなんですが、「回帰」にせよ「分類」にせよ、モデルを作ることの究極的な理由は「まだ見ぬ未来の結果を得る」ためです。それを「予測」と呼びます。
「回帰」して得られたモデルを使って「予測」するというのは、例えば上の単回帰の例で言えばx = 27の時にyの値がどれくらいになるのか?というのを求めることです。これを図にするとこんな感じになります。緑の点のyの値を求めるというのが「予測」ですね。もちろんこれは重回帰=もっと沢山の指標がある時にも共通して使えるメソッドです。
これに対して、「分類」して得られたモデルを使って「予測」するというのは、新しいデータを与えた時にそれがどちら(どれ)に分類されるか?をシミュレートするというものです。例えば上のSVMの例で言えば、というように緑のマークが赤と青どちらのグループに属するのか?をシミュレートするということですね。ちなみに何となくもう見た目で分かると思うんですが、このケースでは赤のグループに属するという予測結果になっています。
データ分析を「させる(依頼する)」側に最低限知っていて欲しい4つの分析コンセプト - 銀座で働くData Scientistのブログ
