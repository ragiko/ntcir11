
テキストについて、何らかの処理や統計分析を行うときには、まず単位を決めることが必要である。テキストについて機械的にスペルチェックを行う際には、文字と単語を単位とし、文体分析や意味論的に統計分析を行うときは、単語、文節などを単位とする。文字、音素、単語、品詞、文節、文などを単位とした場合、単位ごとに記号siで表すと、テキスト処理は記号列s1s2…si-1sisi+1…snの処理として見なすことができる。
記号列を統計分析する最も基本となるのは、それぞれの記号がテキストの中に現れる度数(頻度)である。さらに拡張した統計モデルは、2つの記号、3つの記号、…、n個の記号が隣接して出現する共起度数である。1つの記号、隣接する2つの記号、3つの記号、…n個の記号の度数を統計分析する方法をn-gram(エヌグラム)モデルと呼ぶ。
n-gram のnは、統計分析を行うために切り取った記号列の長さであり、nが1のときunigram(ユニグラム)、nが2のときbigram(バイグラム)、 nが3のときtrigram(トライグラム)、nが4のときにはfour-gram(フォーグラム)のように呼ぶ。
大量のテキストから得られたn-gramの出現度数に関する統計データは、そのテキストの解析および処理に広く用いられている。例えば、英文ではqの後ろにはほとんどの場合、uが続くことから、qの後に続く文字が識別できない場合はuと断定しても間違う確率は非常に小さい。このような情報は、qのbigramの統計データから得られる。
例文「きしゃのきしゃがきしゃできしゃする。」のunigram、 bigram、 trigramの集計結果を表1に、 例として示す。
形態素解析システムJUMANは、元京都大学総長、長尾真氏の研究室を中心に、多くの研究機関の協力により開発され、1992年に公開された。現時点では、同大学の黒橋禎夫氏の研究室で改良が続いている。最新バージョンは、次のサイトからダウンロードできる。
http://nlp.kuee.kyoto-u.ac.jp/nl-resource/top.html
インストールなどに関しては、ソフトに同梱されているマニュアルに説明されている。
JUMANの使用例を示すため、例文「テキストについて計量分析を行う。」をテキストエディタに入力し、exMP.txtというファイル名でC:\tempの中に保存したとする。また、コマンドプロンプトが作業フォルダにアクセスしたとする。コマンドプロンプト上で次のようにコマンドを入力し、
統計的テキスト解析(4)～統計モデルとツール～
