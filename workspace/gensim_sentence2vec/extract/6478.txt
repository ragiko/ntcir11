タイムストレッチ とは、オーディオ信号のピッチはそのままで、テンポ(持続時間)だけを変更する処理である。 ピッチシフト (またはピッチスケーリング) はその逆で、テンポ(持続時間)はそのままで、ピッチだけを変更する処理である。同様な方法で、テンポやピッチを個別もしくは両方同時に時間変化させる事もできる。
これらの処理はたとえば、(再演奏や再収録が不可能な)複数の録音済みクリップをミックスする時に、ピッチやテンポを合わせるのに使用される。(ピッチ感の薄いドラム・トラックは、適当にリサンプリング処理(訳注: あるいはBeat slicing)でテンポ変更しても悪影響が出にくいが、ピッチのあるトラックでは難しい) またピッチシフト処理は、楽音の音域拡張(たとえばギター音を1オクターブ下で出す)などのエフェクト処理にも使われる。
実装方法
リサンプリング
「リサンプリング」も参照
最も簡単にディジタル録音クリップの持続時間とピッチを変更する方法は、リサンプリング処理である。これはサンプルから(訳注: 推測に基づく補間で)連続波形を効率的に再構成し、それを別のサンプルレートでサンプリングし直す数学的処理である。そうして得た新しいサンプルを元のサンプルレートで再生すると、音はゆっくり再生されるか、あるいは素早く再生される。ただしサンプル音の周波数は常に速度と同じ比率でスケールされるので、聴覚上のピッチは上下に移動する: 言い換えれば、ゆっくり再生すればピッチが下がり、素早く再生すればピッチが上がり、二つの効果 (速度 と ピッチ) は分離できない。これはレコードやテープといったアナログ録音の再生速度を速くしたり遅くするのと同様で、Chipmunk効果が得られる。
フェーズボコーダ
詳細は「フェーズボコーダ」を参照
ピッチに影響を与えずに信号の長さを変える一つの方法は、Flanagan & Golden 1966, Portnoff 1976 らに従ってフェーズボコーダを組み立てる事である。[1][2]
基本ステップ:
分析: STFTを使って信号の瞬時周波数と瞬時振幅の組を計算する: STFTとは、短くて互いにオーバーラップした、スムーズな窓関数適用でブロック化した信号サンプルを、離散フーリエ変換 (DFT) したものである。
変更: STFTの位相や振幅になんらかの処理を適用 (たとえばFFTブロックのリサンプリング[要説明]);
合成: 逆STFTの実行: 各FFTブロックを逆フーリエ変換 (IFT) し、得られた短いサンプル波形を足し合わせる。波形重畳法 (OLA)とも呼ばれる。[3]
フェーズボコーダは正弦波成分をうまく扱うことができるが、初期実装系では非整数比の時間スケール伸縮で トランジェント ("beat") 波形にかなりの不鮮明さ(smearing)が生じ、これが位相臭く散漫な結果(the results phasey and diffuse)をもたらす。[要説明](訳注: フェーズボコーダ#位相コヒーレンス問題参照) 最近の改善により全ての比の時間スケール伸縮でより品質の高い結果が得られるようになったが、[4] 依然として不鮮明な残留成分が残っている。[要説明]
またフェーズボコーダ技術は、ピッチシフト/コーラス効果/音色操作/ハーモナイズ効果/その他特殊な変更などの実現に使用でき、これらは全て時間の関数として変化させる事ができる。[要説明]
SOLA
「PSOLA」も参照
Rabiner と Schaferは1978年、時間領域で動作する代替策を打ち出した: それは与えられた波形区間の周期(または等価な基本周波数)を何らかのピッチ検出アルゴリズム(英語版) (一般に信号の自己相関ピークあるいはケプストラム処理) で見つけようと試み、そしてクロスフェードで各周期をつなぐ方法だった。
この手法は 時間領域調波構造伸縮 (TDHS: Time-Domain Harmonic Scaling)[5] あるいは 同期波形重畳法 (SOLA: Synchronized OverLap-Add method) と呼ばれ、遅い計算機上でフェーズボコーダより多少速く実行できるが、倍音構造が複雑な信号(管弦楽曲など)の周期を自己相関が誤って推定すると失敗する。
Adobe Audition (以前のCool Edit Pro) はこの問題を、ユーザ指定の中心周期 (テンポの整数倍 かつ 30 Hz〜最も低いベース周波数の間で指定)に最も近い周期を探す方法で解決しているように見える。[要説明][要出典](訳注: Adobe Audition CS6は"Splicing Frequency"を指定可能[6])
この手法のスコープはフェーズボコーダよりずっと限定されているが、リアルタイム応用向けにプロセッサ負荷をずっと軽くすることができる。この手法は、声や単音楽器の録音といった単一ピッチ音の場合に、もっともコヒーレントな結果が得られる。
ハイエンドの商用オーディオ処理パッケージは、高品質なタイムストレッチ結果を得るために、二つ(以上)の技術を組み合わせたり(例えば信号を正弦波成分と過渡的波形に分離)、他のウェーブレット変換や人工ニューラルネットワーク処理に基づく技術を採用している。[要出典]
Sinusoidal spectral modeling
訳注: この章の記述は、主にMcAulay-Quatieriアルゴリズムに代表されるSinusoidal modelingを扱っていますが、タイトルや記述の一部はSpectral modeling (残差成分を拡張)や Transient model (過渡成分)拡張を含む一体の手法として扱っている形跡があります。章のスコープを明確にし、記述を整理する必要があります。
「Sinusoidal modeling」、「Spectral modeling synthesis」、「Transient model」、および「McAulay-Quatieriアルゴリズム」も参照
タイムストレッチの他の代替手法は、信号のスペクトルモデルに頼っている。この手法では、信号のSTFTを使ってSTFTフレーム中のピーク成分を識別し、隣接フレームのピークをつないで正弦波トラック("tracks"訳注: ≒周波数の軌跡)を生成する。次にこのトラックを、新しい時間スケールで再合成訳注: してタイムストレッチを実現する。この手法は、特に信号が複数のサブ帯域に分離している時に[要説明]多声の素材やパーカッシブな素材の両方で良い結果をもたらす。しかしこの手法は他の手法と比べ、より多くの計算資源を必要とする。[要出典]
位相と時間をほどく
ピッチシフトとタイムストレッチの別の方法は、旋律楽器などの単音を位相と時間に分離する手法である。[要検証 – ノート] 訳注: この手法で時間コントロールだけを変更すれば、訳注: オーディオ・サンプルの伸長/短縮/時間反転/ループ生成(サンプラー用)が可能である。時間短縮は圧縮用途にも使える。[要説明] また位相コントロールだけを変更すれば、既存の音のピッチシフトやFMシンセシス・ディスト—ションの適用が可能である。これはウェーブテーブル・シンセシスに対し楽器を別のやり方で演奏するのに使用できる。(play instruments alternatively to wavetable synthesis)[要説明](訳注: ウェーブテーブル音源(PCM音源)と混同している可能性)
位相と時間を独立してコントロールするには、全ての位相と時間の組に関する音の変位を把握する必要がある。これは右図に示す円筒に相当する。ただし音響信号は一次元信号に過ぎない。音響信号は円筒上の完全な関数 (full function) の観測と見なす事ができる。これは図中に黒い螺旋曲線として描かれている。円筒上の完全な関数は、(おおよそ)同じ位相の螺旋上の点間の補間で近似できる。この関数から異なる音響信号を導ける。例えば図中の薄灰色のゆるい螺旋曲線は、元信号と時間発展が同じで周波数がより低い音、または元信号と周波数が同じで時間発展がより速い音、あるいはその中間の音、の経路(path)を示している。最終的に全体プロセスは、類似した位相と類似した時間における値を補間した離散音響信号のために実装できる。[8]
ここに記述された手法は、Melodyneソフトウェアのモノフォニック・バージョンで使用されている。[9]
ピッチシフト
これらの手法は、オーディオサンプルを速度や持続時間を一定に保ったまま、トランスポーズするのに利用できる。例えばタイムストレッチして、元の長さとなるようにリサンプルし直せば実現できるだろう。あるいはsinusoidal modelの正弦波の周波数を直接変更し、適切な時間スケールで信号を再構築すれば実現できるだろう。
トランスポーズは、 視点や文脈に応じて周波数スケーリング あるいは ピッチシフトと呼ぶことができる。 例えば各ノートのピッチを完全五度上に移動し、テンポは同じに保つ事ができる。この移調は「ピッチシフト」と見なす事ができ、ピアノ鍵盤上で各ノートを7キー上に「シフト」したり、メル尺度や線形ピッチ空間上での一定量の加算に相当する。同じ移調を「周波数スケーリング」と見なす事もでき、各音符の周波数を3/2倍に「スケーリング」(乗算)する事に相当する。
音楽的な移調は、音の音色(訳注: や和声学的響き)を決める 倍音や和音の周波数比 (the ratios of the harmonic frequency) を維持する。これに対し振幅変調などで実現される「周波数シフト」は各ノートの周波数に固定の周波数オフセットが加わる(訳注: ので音色や響きは維持されない)。(なお「ピッチ・スケーリング」という表現は、音楽的ピッチ空間で各ノートの位置をピッチに応じてスケール(伸縮)する[たとえば線形ピッチ空間上で、最も高いノートを低いノートよりも広い間隔にシフトする]という極めて稀な操作を指し、その場合は音楽的な調性が崩れるので、本件の表現としては適さない[要出典])
汚れ(smearing)が目立たない場合、時間領域処理はここでずっとうまく機能するが、[要説明] スケーリングしたボーカル・サンプルのフォルマントは、それが望ましい効果であろうとなかろうと、一種のChipmunks的効果で歪む。フォルマントや声の性質を維持する処理では、チャンネルボコーダやLPCボコーダおよび何らかのピッチ検出アルゴリズム(英語版)による信号分析と、異なる基本周波数による分析結果の再合成、に関わっている。[要出典]
(なお昔のアナログ・レコーディング手法によるピッチシフトの詳細説明は、英語版記事 Alvin and the Chipmunks で見つけることができる)
応用
速聴 (高速音声再生)
「時間圧縮音声」、「:en:Time-compressed speech」、および「スピードリスニング」も参照
特定の場合のスピーチについては、タイムストレッチはPSOLAを使って実現できる。[要説明]
タイムストレッチはオーディオブックや講義録音訳注: の再生に使える。再生速度を落とす事で外国語の理解度を高める事ができる。[10]
他方、再生速度が上がると理解度が低下すると想像するかもしれないが、Herb Friedmanは次のように語っている:実験によれば、脳は話し言葉を通じた耳からの情報速度が「平均的」読解速度の時に最も効率的に働き、その速度はおよそ200〜300 wpm (wpm:一分あたりの単語数)であり、他方、話し言葉の平均的速度は100〜150 wpm 程度に過ぎない。[11]
再生速度を上げた音声訳注: の聴取(速聴)は「速読」と等価なものだと見なされている。[12][13]
タイムストレッチはしばしば、ラジオコマーシャル[14]やテレビコマーシャル[11]のオーディオをCM枠の長さ(例えば30秒あるいは60秒)に正確に合わせる(尺合わせ)ために使用される。
関連項目
音響信号処理   (Audio signal processing)
エフェクター
時間圧縮音声   (Time-compressed speech)
ピッチコントロール  (Pitch control)
ピッチ同期波形重畳法   (PSOLA: Pitch Synchronous Overlap and Add)
参考文献
タイムストレッチ/ピッチシフトとは - goo Wikipedia (ウィキペディア)
