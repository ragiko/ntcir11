
Grant Ingersoll は、LucidWorks の共同創設者であると同時に CTO でもあり、Lucene コミュニティーのアクティブなメンバー — Lucene および Solr のコミッター、Apache Mahout 機械学習プロジェクトの共同設立者、そして Apache Software Foundation の長期にわたるメンバー — にもなっています。Grant は、シラキュース大学の自然言語処理センターで自然言語処理および情報検索の研究に携わった経験があり、アマースト大学で数学およびコンピューター・サイエンスの学士号を取得し、シラキュース大学でコンピューター・サイエンスの修士号を取得しています。彼は、『Taming Text』(Manning Publications、2013年) の共著者でもあります。Twitter の @gsingers で Grant をフォローしてください。
私が初めて Lucene と Solr に関する developerWorks の記事を書いたのは、6 年前のことです (「参考文献」を参照)。この 6 年の間に、Lucene と Solr は信頼できるテクノロジーとしてそれぞれの地位 (Lucene は Java API の基盤としての地位、Solr は検索サービスとしての地位) を確立しました。その証拠に、Apple iTunes、Netflix、Wikipedia をはじめとする多数の検索ベースのアプリケーションがこの 2 つのテクノロジーによって駆動されています。また、Lucene と Solr は IBM が開発した質問応答システム Watson の実現にも一役買っています。長年にわたり、Lucene と Solr は、主にテキスト・ベースの検索に焦点を絞って使用されてきました。その一方で、ビッグ・データという新たな興味深いトレンドが生まれ、それとともに分散コンピューティングおよび大規模アナリティクスに新たな (刷新された) 焦点が当てられるようになってきました。さらに、ビッグ・データには多くの場合、リアルタイムでの大規模な情報アクセスも必要となります。こうした推移のなか、Lucene と Solr のコミュニティーは岐路に立たされていることを自覚しました。Twitter 界のすべてに対してインデクシングする (「参考文献」を参照) などといったビッグ・データ・アプリケーションからの高い要求が出てくるなかで、Lucene のコアとなっている基盤は古びてきたからです。しかも、Solr には分散インデクシングのネイティブ・サポートが欠けていたことから、Solr を使用する IT 組織が検索インフラストラクチャーをコスト効果の高い方法でスケーリングするのがますます難しくなってきました。コミュニティーは、Lucene および Solr の基盤 (および、場合によってはパブリック API) の全面的な見直しに着手しました。私たちの焦点は、スケーラビリティーの容易な実現、ほぼリアルタイムのインデクシングと検索の実現、さまざまな NoSQL 機能の実現 — いずれもコア・エンジンの能力を活かして行うこと — に移されました。この全面的な見直しが、Apache Lucene および Solr の 4.x のリリースに結集されています。これらのバージョンが目指しているのは、まさに、次世代の大規模データ駆動型アクセスとアナリティクスの問題の解決です。この記事では、Apache Lucene および Solr のバージョン 4.x の見どころを順に紹介し、その一部でサンプル・コードを記載しますが、まずは「検索エンジンを利用して検索の枠を超える」という概念を実証する、実際のアプリケーションを体験することから始めます。この記事を最大限活用するには、Lucene と Solr の基本 (特に Solr リクエスト) を十分に理解している必要があります。この前提に当てはまらない場合は、Lucene および Solr の基本を学べるサイトや書籍へのリンクを「参考文献」から参照してください。クイック・スタート: 検索およびアナリティクスの実際検索エンジンは、テキストを検索するためだけのものだと思っているとしたら、それは違います!基本的に検索エンジンとは、迅速かつ効率的にデータをフィルタリングして、類似度に関する何らかの概念 (Lucene と Solr では柔軟に定義されている概念) に従ってデータにランクを付けするものに他なりません。また、検索エンジンは、最近のデータ・アプリケーションに特徴的な、疎なデータや曖昧なデータを効果的に処理します。Lucene と Solr には、数値の高速処理や (この後、話題にする) 複雑な地理空間の質問への応答をはじめ、さまざまな機能が備わっています。これらの機能は、検索アプリケーションと従来のデータベース・アプリケーション (さらには NoSQL アプリケーション) との間の区別を曖昧にします。例えば、Lucene および Solr には現在、以下の特長があります。結合オプションとグループ化オプションを数種類サポートします。オプションで列指向ストレージを使用できます。テキストや、列挙データ、数値データを扱ういくつかの方法が用意されています。ユーザーが複合データ型や、ストレージ機能、ランキング機能、アナリティクス機能を独自に定義できます。検索エンジンは、あらゆるデータ問題を解決する特効薬ではありませんが、これまで Lucene と Solr の主な用途がテキスト検索であったからと言って、現在あるいは将来のデータに対する要求に対処するために Lucene や Solr を使用できないわけではありません。検索エンジンの用途については、おなじみの (検索) ボックスで使用することにまったく捉われずに検討することをお勧めします。検索エンジンが検索のみにとどまらず、どのような用途にまで適用できるかを実際に示すために、このセクションの残りでは、航空関連のデータを Solr に取り込むアプリケーションを紹介します。このアプリケーションはデータ (その大部分はテキストではありません) を照会し、D3 JavaScript ライブラリー (「参考文献」を参照) を使用してそのデータを処理して表示します。照会するデータ・セットは、米国運輸省運輸統計局の RITA (調査・革新技術庁) のデータと OpenFlights のデータです。これらのデータには、特定の期間における全フライトの出発空港、到着空港、時間遅延、遅延原因、航空会社情報などの詳細が含まれます。このデータを照会するアプリケーションを使用して、特定の空港間での遅延、特定の空港での輸送量の増加など、さまざまなことを分析できます。まずはアプリケーションを稼働させる方法を説明してから、アプリケーションのインターフェースの一部について見ていきます。以降の説明を通して、アプリケーションはさまざまな方法で Solr に問い合わせを行うことによってデータを操作することに留意してください。セットアップ始めに、以下の前提条件を満たす環境を用意する必要があります。Lucene および SolrJava 6 またはそれ以降のバージョンの Java最近の Web ブラウザー (私は Google Chrome と Firefoxでテストしました)4GB のディスク領域 (すべてのフライト・データを使用するのでなければ、必要な領域はこれよりも小さくなります)*nix 上でのターミナルからの bash (または同様の) シェルによるアクセス。Windows の場合は、Cygwin が必要です。私は OS X で bash シェルを使用した環境でのみテストを行いました。wget。サンプル・コード・パッケージに含まれるダウンロード・スクリプトを使用してデータをダウンロードする場合に必要です。フライト・データのダウンロードは、スクリプトを使用せずに手作業で行うこともできます。Apache Ant 1.8+。サンプル Java コードを実行する場合、コンパイルとパッケージ化のために必要です。Lucene、Solr、wget、Ant の各ダウンロード・サイトへのリンクについては、「参考文献」を参照してください。前提条件を満たす環境が揃ったら、以下の手順に従ってアプリケーションを稼働させます。この記事のサンプル・コードが含まれる zip ファイルをダウンロードして、任意のディレクトリーに解凍します。ここでは、このディレクトリーを $SOLR_AIR と呼びます。コマンドラインで、カレント・ディレクトリーを $SOLR_AIR に変更します。
Apache Lucene および Solr 4 による次世代の検索とアナリティクス
