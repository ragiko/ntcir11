本稿では,N-gramでは表現できない広範囲の文脈に依存した言語知識をモデル化するために,用例文を用いた新しい言語モデルである用例文モデルの提案を行う.用例文モデルでは収集された用例文の中から,最も単語列および音順列の近いものが候補として選択される.この後,N-gramでの認識結果と用例文モデルでの結果を対応する単語ごとに比較し,N-gramでの認識結果が誤りである可能性が高い単語に対しては積極的に用例文モデルでの結果を採用し,誤りである可能性が低い単語に対しては用例文モデルでの結果が信頼性の高いものである場合のみ用例文モデルでの結果を採用する.この各単語に対する判定に対しては,N-gramでの認識結果から得られる信頼度尺度と,用例文モデルで用いられる単語列および音順列の近さの尺度である編集距離を入力とするサポートベクターマシン(SVM)を用いる.本手法は旅行対話表現集コーパスを用いた実験において約20%の誤認識率の改善が見られ,有効性が確認できた.
This paper proposes a novel example-based language model (ELM) in order to incorporate language structures dependent knowlage which cannot be modeled with N-grams. In this model, we first select candidate sentences from an example corpus which are closest to the result based on word and phoneme sequences. The recognition result and ELM candidate sentences are compared word-by-word to produce a final result. The result addopts the ELM if N-gram recognition has low confidence measures, otherwise, the ELM result is only adopted when reliablity is high. The word comparison method we used is based on a SVM with N-gram confidence measures, and edit distances, for word and phoneme sequences in the ELM, as feature. The proposed method achieved a 20% decrease in WER on the travel arrangement task corpus.

