並列計算(へいれつけいさん、英語: parallel computing)は、コンピュータにおいて複数のプロセッサで1つのタスクを動作させること。並列コンピューティングや並列処理とも呼ばれる。問題を解く過程はより小さなタスクに分割できることが多い、という事実を利用して処理効率の向上を図る手法である。また、このために設計されたコンピュータを並列コンピュータという。ディープ・ブルーなどが有名。
関連する概念に並行計算(へいこうけいさん)があるが、並行計算は一つのタスクの計算を並列化することにとどまらず、複数の相互作用しうるタスクをスレッドなどをもちいて複数の計算資源にスケジューリングするといった、より汎用性の高い処理をさす。
特に、並列計算専用に設計されたコンピュータを用いずに、複数のパーソナルコンピュータやサーバ、スーパーコンピュータを接続することで並列計算を実現するものをコンピュータ・クラスターと呼ぶ。このクラスターをインターネットなどの広域ネットワーク上に分散させるものも、広義には並列計算に属すが、分散コンピューティングあるいはグリッド・コンピューティングと呼び、並列計算とは区別することが多い。
可能性と問題点[編集]
並列計算は、プロセッサ同士が独立して同時に仕事をするため、理想的な状況下ではプロセッサの回路規模を大きくすること無く、プロセッサの数に比例して性能が得られると考えられ、スーパーコンピュータなどで古くからとられた手法である。
しかし、問題点もある。並列計算を行う場合、もっともパフォーマンスを発揮するのはこれら複数のプロセッサが全て100%使い切られた時と考えられるが、従来のプログラムの多くは、複数のプロセッサを均等に全て使い切るようにはできておらず、また、そういったプログラミングは難しい。
買い物を例にとろう。まず買い物の前に、財布の中身を確かめなければならないし、足りなければ銀行で補充もしなければならない。その後はじめてお店にも行かなければならない。銀行に行くのと、お店に訪れるのは同時にできないし、財布の中身を確認してからでなければ、お店には行けない。プログラムもこれと似て、実行順番が変えられなかったり、同時に実行できなかったりする部分がどうしてもできてしまう。このため複数のプロセッサで同時に、かつ実行順番に依存しないようなプログラムのみでプログラムを構成することは難しい。
並列計算では、処理の"ある瞬間"ではそれぞれのプロセッサは実質まったく別に動作しており、そのため実行順番が全く問題にならないプログラムなら性能は引き出しやすい。しかし、先の例のように実行順番が強く束縛される場合は、あるプロセッサだけが働き、ほかのプロセッサはすることがなくなってしまうといった状態になり、性能が引き出しにくい。そのため,並列計算はそうでない場合と比べて性能を引き出すプログラミングが困難となる。
一般に、プログラムの処理が複数のプロセッサで均等に処理できる割合をプログラムの並列度と言うが、地球シミュレータの高い性能はこの並列度が他に比べて極めて高いことも重要な要因である。
以上のように、並列計算では高い性能を発揮する為にはソフトウェアの並列環境への最適化が重要な鍵となる(詳しくは並列化を参照)。
背景[編集]
従来、コンピュータソフトウェアは逐次的に計算されるものとして書かれてきた。問題を解くためにアルゴリズムが構築され、それによって逐次的に実行される命令列が生成される。その命令列は、コンピュータのCPU上で実行される。命令は一度に1つずつ実行される[1]。
一方並列計算では、複数の計算ノードが同時並行的に動作して問題を解く。問題は独立した部分に分割され、各計算ノードがアルゴリズムの一部を同時並行的に実行する。計算ノードの実体は様々であり、マルチプロセッサ型のコンピュータの各CPUだったり、ネットワーク上のコンピュータだったり、専用ハードウェアだったり、それらの組合せだったりする[1]。
1980年代から2004年まで、コンピュータの性能向上の主たる要因はクロック周波数の向上にあった。プログラムの実行時間は、命令数と1命令あたりの平均実行時間をかけたものに比例する。他の要因が全く変化しないと仮定すると、クロック周波数の向上によって1命令あたりの平均実行時間が減少する[2]。
一方で、マイクロプロセッサの消費電力は  という式で与えられる。ここで、P は消費電力、C はクロックサイクル毎に切り替えられる静電容量(入力が変化するトランジスタの総数に比例)、V は電圧、F はプロセッサの周波数(正確には1秒あたりのサイクル数)である[3]。従って、クロック周波数が高くなると、プロセッサの消費電力も増大する。プロセッサの消費電力の増大は、インテルが2004年5月に開発中だったプロセッサをキャンセルした最大の理由であり、この時点がクロック周波数向上が性能向上の主たる要因となっていた時代の終焉であった[4] 。
ムーアの法則は、マイクロプロセッサでのトランジスタの実装密度が18カ月から24カ月毎に倍になるという経験則である。消費電力の問題は以前から指摘されていたが、ムーアの法則は未だに有効である。クロック周波数向上の時代が終わると共に、増大したトランジスタ数は周波数向上以外に利用されることになり、並列計算をマイクロプロセッサ上で実装する時代が到来した。
アムダールの法則とグスタフソンの法則[編集]
並列計算のプラットフォームにおけるアルゴリズムの性能は、そのアルゴリズムをどれだけ並列化できるかに依存する。そのため、1960年代にジーン・アムダールが定式化したアムダールの法則が重要となってくる[5]。それによると、プログラムの中の並列化できない部分が並列化による性能向上を制限する。大規模な工学的問題や数学問題には、一般に並列化可能な部分と並列化不可能な部分(逐次実行部分)がある。アムダールの法則によれば、以下のような関係が成り立つ。
ここで、S はプログラムの性能向上率(逐次実行版での実行時間を1としたときの倍率)、P は並列化可能な部分の比率である。逐次実行部分がプログラムの実行時間の10%を占めている場合、性能向上は10倍となり、それ以上の多くの計算ノードを追加しても意味はない。これにより、並列実行ユニットを追加して意味のある個数の上限が得られる。
アムダールの法則の概念を図示したもの。タスクが独立した二つの部分 A と B から構成されている。B は計算時間の約30%を占めている。がんばって B を改良して5倍の性能にしても、全体としての性能向上は少しでしかない。逆に A を2倍の性能に改良した方が全体性能はより向上する。
グスタフソンの法則は、アムダールの法則とも密接に関連する計算機工学における法則である。グスタフソンの法則は以下の式で表される。
ここで、P はプロセッサ数、S は性能向上、 は処理の並列化できない部分である[6]。アムダールの法則では問題のサイズが固定であり、逐次実行部分はプロセッサ数に依存しないと仮定されている。一方、グスタフソンの法則ではそのような仮定がない。
データ従属性[編集]
データ従属性(data dependency)を理解することが、並列アルゴリズムの実装法を知る基礎の一つとなる。計算と計算の間に従属関係があるということは実行の順序性が生じるということである。したがってプログラムは、従属性のある計算の連鎖のうちで最長のものより高速に実行することはできない(これをクリティカルパスと呼ぶ)。幸運なことに、多くのアルゴリズムにはそのような従属関係の長い連鎖は存在せず、計算のほとんどの部分は並列に実行できる。
Pi と Pj というプログラムの断片があるとする。Bernstein's conditions[7]は、2つの部分が独立していて並列に実行できる条件を示している。Pi への入力変数の集合を Ii で表し、Oi を出力変数の集合とする。Pj についても同様に表す。P i と Pj が独立であるための条件は以下の通りである。
最初の条件が成り立たない場合、フロー従属性(flow dependency)が存在し、最初の文の結果を次の文で使う場合などに相当する。第二の条件は反従属性(anti-dependency)を意味し、最初の文が書き換える変数の元の値を次の文の式で必要としている場合などに相当する。第三の条件は出力従属性(output dependency)を表す。2つの変数が同じメモリ上の位置にある場合、それぞれの更新は元のプログラムの順序関係通りに行われる(後から書き込んだ方が残る)必要がある[8]。
例として以下の関数を考える。
1: function Dep(a, b)
2:    c := ab
3:    d := 2c
4: end function
Dep(a,b) の3行目は、2行目の前に実行できないし、並行して実行することもできない。何故なら3行目は2行目の結果を利用しているからである。これは上述の第一の条件に反しており、フロー従属性があると言える。
1: function NoDep(a, b)
2:      c := ab
3:      d := 2b
4:      e := a+b
5: end function
こちらの例では、各命令には従属関係はないので、並列に実行可能である。
Bernsteins conditions では、異なるプロセス間でメモリは共有されないと仮定している。そのため、アクセスの順序性を確保する手段として、セマフォなどの同期機構が必要となる。
競合状態、相互排他、同期、並列スローダウン[編集]
並列プログラムにおけるサブタスクをスレッドと呼ぶ。システムによってはさらに小さく軽量なスレッドであるファイバーを使っており、もっと大きな単位であるプロセスを使っているシステムもある。いずれにしても、並列プログラムのサブタスクをここではスレッドと呼ぶ。
スレッドは、スレッド間で共有している何らかの変数を更新することがよくある。2つのスレッドの命令実行順序は一定ではない。例えば、次のようなプログラムを考える。
並列計算 - Wikipedia
