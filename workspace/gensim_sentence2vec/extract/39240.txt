学会等で一般的に行われているポスター発表における会話(ポスター会話)は、マルチモーダルな多人数インタラクションに関する様々な興味深い研究テーマを提供してくれる。本稿では、著者らが進めているポスター会話のマルチモーダルなセンシング・分析・認識に関するプロジェクト、及び構築しているシステムの概要を紹介する。我々は特に、視線配布や相槌などの聴衆の反応(聞き手行動)に着目し、発話パターンの予測・検出を行い、さらに興味・理解度を推定することを目指している。そのために、ポスター会話をマルチモーダルに収録した上で、会話参加者の行動を捉え、会話の場を視覚化するシステム「スマートポスターボード」を設計・実装している。 
Conversations in poster sessions in academic events, referred to as poster conversations, pose interesting and challenging topics on multi-modal analysis of multi-party interactions.  This article gives an overview of our project and system for multi-modal sensing, analysis and understanding of poster conversations.  We focus on the audience's feedback behaviors such as non-lexical backchannels (reactive tokens) and noddings as well as eye-gaze events by the presenter and the audience.  We investigate whether we can predict when and who will ask what kind of questions, and also interest level of the audience. We also design and implement a smart posterboard, which can detect human behaviors and visualize interactions during poster sessions.
研究会 - スマートポスターボード: ポスター発表における場のマルチモーダルなセンシングと認識
