音声合成(おんせいごうせい、Speech synthesis)とは、人間の音声を人工的に作り出すことである。これを行うシステムをスピーチ・シンセサイザー(Speech synthesizer)、これにより生成した音声を合成音声(ごうせいおんせい)と呼ぶ。
人工的に人の声を合成するシステムであり、テキスト(文章)を音声に変換できることから、しばしばテキスト読み上げ(text-to-speech、略してTTS)システムとも呼ばれる。また、発音記号を音声に変換するシステムもある。
歴史[編集]
現代的な電子信号処理が発明されるずっと以前から、西アフリカのトーキングドラム等のように音声を模倣する試みがなされてきた。
音声を合成する初期の試みとしては、のちに教皇シルウェステル2世となるオーリヤックのジェルベール(1003年没)、アルベルトゥス・マグヌス(1280年没)、ロジャー・ベーコン(1294年没)などの人物が音声合成を試みている。1779年にはドイツ人クリスティアン・クラッツェンシュタインは母音 (a, e, i, o, u) を発声できる機械を製作した[1]。
この流れはふいごを使った機械式音声合成器を作ったオーストリア(ハンガリー)のヴォルフガング・フォン・ケンペレンに引き継がれた。彼は1791年に論文[2]を発表し、その機械について説明している。この機械は舌と唇をモデル化しており、母音だけでなく子音も発音できた。
1837年、チャールズ・ホイートストンはフォン・ケンペレンのデザインを元にしゃべる機械を製作し、1857年、M. FaberはEuphoniaを製作した。ホイートストンの機械は1923年Pagetによって再現されている[3]。
1930年代、ベル研究所のホーマー・ダドリー(Homer Dudley)は通信用の電子式音声分析・音声合成マシンであるヴォコーダー (Vocoder、Voice Coderの略) を開発した。その後これを応用し、音声合成部にキーボードを付加した鍵盤演奏型のスピーチ・シンセサイザーであるヴォーダー(voder)を製作し、ニューヨーク万国博覧会 (1939年)に出展した。その発声は十分理解可能だったと言われる。1940年代、ハスキンズ研究所(Haskins Laboratories)のフランクリン・S・クーパー(Franklin S. Cooper)らはPattern playbackという名の機械の開発に取り組み、1950年に完成した。この機械にはいくつかのバージョンがあるが、実際に機能したのは一つだけである。この機械は、スペクトル形式の音声パターンの図を音に変換するものであった。アルヴィン・リバーマン(Alvin Liberman)らはこれを音声学の研究に利用した。
最初のコンピュータを使った音声合成システムは1950年代終盤に開発され、最初のテキスト読み上げシステムは1968年に開発されている。1961年、物理学者John Larry Kelly, Jr.とLouis Gerstmen[4]はベル研究所にてIBM 704を使って音声合成を行った。そして『デイジー・ベル』という歌をコンピュータに歌わせた。友人のジョン・ピアースを訪ねてベル研究所に来ていたアーサー・C・クラークは、このデモを聴いて感銘を受け、『2001年宇宙の旅』でHAL 9000が歌うクライマックスシーンが生まれた[5]。
初期の電子式スピーチ・シンセサイザーの発声は、ロボット的であまり明瞭ではないものが多かった。その後の発達により、今日のTTSシステムはむしろ人間の声と区別が付かない場合が少なくない。(ただし電子式の成功後も、人間型ロボットに発声させるため、機械式音声合成の研究は続けられた。電子式ではスピーカーの音質に制限されるが、ロボットで人間の体の構造を模倣した機械式音声合成なら、もっと人間に近い発声になると考えられていたからである[6])。
合成技術[編集]
音声波形を生成する主要技術は、大きく波形接続型音声合成 (concatenative synthesis) とフォルマント合成 (formant synthesis) の2つに分ける事ができる。
波形接続型音声合成[編集]
波形接続型音声合成は、基本的には録音された音声の断片を連結して合成する方法である[7][8][9]。一般に波形接続型音声合成は最も自然な合成音声になるといわれているが、発声のバリエーションと波形の断片化の細かさによっては出力音声に欠損が生じ、自然さを損なうことがある。
波形接続型音声合成には以下にあげる三種類がある。
単位選択合成 (Unit selection synthesis) 
別名としてコーパスベース音声合成方式とも呼ばれる。大きな音声のデータベース(通常一時間以上の録音された音声から成る)を使用する。データベースを作成する為には、録音する音声を「音」、「音節」、「形態素」、「単語」、「成句」、「文節」などに分割し、それらを人の手によって検索できるようにインデックスを調整して作成する。音声合成を行う際には、アルゴリズムに従って最も適した音の組み合わせをデータベースから探し出して合成する。これにより極めて肉声に近い自然な音声に合成することが可能となる。しかし、より自然に聞こえる音声を合成するにはデータベースの情報量を増やす必要があり、データサイズが膨大となる問題も発生する。
Diphone合成 (Diphone synthesis)
音声ライブラリにターゲットとする言語のDiphone(音と音のつながり部分)を全て持ち、それを使用して合成する。Diphoneの個数はその言語の音素配列論で決まっている。(スペイン語なら800、ドイツ語なら2500のDiphoneを持つ。)Diphone合成では、各Diphoneの音声がひとつだけデータベースに格納されている。実行時にはDiphoneを並べたものに線形予測分析法(PSOLA、MBROLAなど)のようなデジタル信号処理技法を施して韻律を作る。できあがった音声は単位選択合成に比較すると音質が劣るが、フォルマント合成よりは自然な音質になる。しかし、Diphone合成は結合部の欠陥が目立ち、フォルマント合成のようなロボット的な発生になってしまう問題がある。そのため商用では徐々に利用が減っているが、フリーソフトウェアや研究用としては使われ続けている。
分野限定合成 (Domain-specific synthesis)
録音された単語や文節を連結して音声を合成する。これは特定分野のテキスト読み上げに使われる。例えば乗り換え案内の放送や天気予報などである。これは実装が簡単なので商用にも長年使われてきた。例えば、しゃべる時計や電卓などである。この方式は分野を限定しているので自然に聞こえる音声を合成するのが簡単である。しかし、汎用ではないので、利用は限定される。内部のデータベースにある単語や文節しか話せないため、内容が登録されている音声によって限定される。また、例えばフランス語のリエゾンなど、前後の単語との関係で発音が変わる場合を再現するのが難しい。この場合、文脈を考慮して合成する必要がある。
フォルマント合成(合成音声)[編集]
フォルマント合成は録音された人間の音声は使用せず、基底周波数、音色、雑音レベルなどのパラメータを調整して波形を作り、人工的な音声を作る。合成された音声はロボット的に聞こえる音声になるため、人間の音声と間違えることはない。フォルマント合成は波形接続型音声合成と比べ次の様な特徴も持っている。
音の欠損がないので、高速に発声させても明瞭に聞き取れる。このため高速さを要求されるテキスト読み上げにはよく使われている。
波形接続型音声合成のような音声データベースを必要としないので、データのサイズが小さくなる。
出力音声を容易に変化させることができるので、イントネーションや音色を自由に変えることが出来る。
上記の様な特徴のため、組み込みシステムでもよく使われ、フォルマント合成の例として、1970年代末にテキサス・インスツルメンツが発売した玩具Speak & Spell、セガの1980年代のいくつかのアーケードゲームがある(Astro Blaster、Space Fury、Star Trek: Strategic Operations Simulatorなど)。これらのイントネーションの再現は非常によく、リアルタイムのテキスト読み上げインタフェースでの実現はこれからである[10]。
その他の合成手法[編集]
Articulatory synthesis
最近まで純粋に学術的研究として使われてきた手法である。それは人間の声道部分の構造を研究してそこで起こっていることを人工的に再現するものである。最近になってその成果が商用の音声合成でも使えるレベルになってきた。NeXTで使われていたシステムはカナダのカルガリー大学の研究チームがスピンオフして作ったTrillium Sound Research Inc.が開発したものである。Trilliumはこれをフリーなgnuspeechとして公開しており、GNU savannah siteで入手可能である。
Hybrid synthesis
フォルマントと波形接続型音声合成を組み合わせたもので、音の欠損をなるべく少なくしたものである。
HMM-based synthesis
隠れマルコフモデル(HMM)に基づいた合成である。このシステムでは、周波数スペクトル、基本周波数、持続時間(韻律)がHMMによって同時にモデル化される。音声波形はHMM自体が最尤法に基づいて生成する[11]。
Sinewave synthesis
フォルマントを純粋な正弦波の合成によって構成する技法である[12]。
実用例[編集]
音声合成技術は文字を読むことが困難な障害者や、文字が読めない人(幼児、外国人など)に画面読み上げソフト(スクリーンリーダー)として長く利用されてきており、言葉を発することが困難な人が代替手段として利用することも多い。また、21世紀に入ってからは家電製品の音声ガイダンスや、公共交通機関や防災関係のアナウンス用途として音声合成されたものが広く使用されるようになっている。
これは、人間が発声したものを録音すると、台詞の変更の度にその部分を録音をし直さなければならないが、音声合成であればデータの作成で済むためである。実際に、鉄道用アナウンスでは、駅が追加されたり名称変更があっても、その箇所のみが変更されている。
また、個人向けのソフトウェアなどにも活用されてきている。
テキスト読み上げシステム[編集]
テキスト読み上げシステムは、フロントエンドとバックエンドのふたつの部分からなる。一般に、フロントエンドは入力したテキストから記号化言語表現 (symbolic linguistic representation) を出力する。バックエンドはフロントエンドで合成された音声の波形を出力する。音声合成の自然さは、出力される音声がいかに現実の人間の音声に似ているか、明瞭度は聴きやすさ(出力音声の理解しやすさ)で評価される。
フロントエンド
フロントエンドにはふたつの大きな仕事がある。ひとつはテキストの中の数字や省略表現を読み上げるときの表現に変換することである。これは、「テキストの正規化」、「プリプロセッシング」、「トークン化」などと呼ばれる。もうひとつは各単語を発音記号に変換し、テキストを熟語や文節、文などの韻律単位に分割することである。単語に発音記号を割り当てる処理をテキスト音素(text-to-phoneme、略してTTP)変換または書記素音素(grapheme-to-phoneme、略してGTP)変換と呼ぶ。発音記号と韻律情報を組み合わせて記号化言語表現を作成し、フロントエンドの出力とする。
訳注
この部分は言語によってかなり違いがある。日本語の場合、わかち書きをしない為、文章を正確に処理するためには単語を分割する作業が必要となる。
バックエンド
フロントエンドの出力結果を元に、より自然な音声にするため韻律などの音声の調整を行い、実際の音声データを出力する。この処理にて音声の性質が決定されるため、音声合成ソフト独自色が出ることが多い。また、一般的に「話言葉」を目指す物が多いが、歌声の様な調整を行なう音声合成ソフトもある。
オペレーティングシステムでの音声合成[編集]
アップル
1984年、アップルコンピュータにMacInTalk機能を搭載した。その後も新しいOSバージョンでは音質が改善されている。また、音声認識も導入しており、これらの機能を統合したPlainTalkは視覚障害者のためのサポートプログラムであった。Mac OS X v10.4以降にはVoiceOverという音声合成機能になっている。
AmigaOS
1985年のAmigaOSでも音声合成機能が組み込まれていた。男性と女性の声を選択できる[13]。AmigaOSでは音声合成を仮想デバイスとしていたため、コンソール出力を音声合成にリダイレクトすることも可能であった。このため、ワープロソフトなど各種アプリケーションで容易に音声合成を利用可能であった。
Microsoft Windows
Windowsでは、SAPIという音声関係のAPIを用意している。Windows XPではNarratorという音声合成プログラムが追加されている(英語版)。コールセンターなどでの音声認識と音声合成のパッケージとしてMicrosoft Speech Serverが用意されている。
その他
TI-99/4Aには音声合成機能をオプションで追加可能であった[14]。
PC-6001mkIIには音声合成機能が内蔵されていた。後継のPC-6001mkIISRやPC-6601では歌うことも可能であった。
FM-7/FM-77シリーズには音声合成ボード (MB22437/FM-77-431) がオプションとして用意されている。
MZ-1500/2500/2861にはオプションとしてボイスボード(MZ-1M08)が存在する。英語での数字などの音声をチップに。五十音と、いくつかのフレーズを外部チップにサンプリングされROMとして焼きこまれており、制御によって再生するものである。
インターネットでの音声合成[編集]
音声合成マークアップ言語
テキストを音声に変換するためのXML準拠のマークアップ言語がいくつかある。最近ではSSMLがW3Cから提案されドラフト状態である。他にもSABLE、JSMLなどがある。Cascading Style Sheets 2のサブセットはAural Cascading Style Sheetsを含んでいる。音声合成マークアップ言語はVoiceXMLのようなダイアログ・マークアップ言語とは異なる。ダイアログ・マークアップ言語はテキスト読み上げだけでなく、音声認識などにも対応している。
音声合成ソフトウェア[編集]
日本語[編集]
自分の声再現ソリューションサービス Voice Science (株式会社コティレドン・テクノロジー)
自分の声・口調をユーザーが入力した自由な文章で再現可能な音声合成ソフトウェアサービスです。機械的な合成音ではなく、個人の特徴や感情表現、発話の自然性といった「本人性」の再現ができます。
AIVoice(株式会社エーアイ)
AITalk(株式会社エーアイ) ゲーム『StarBoat』『StarHorse3』で使用。ニンテンドー3DS向けに軽量化されたモデルも存在する。
VOICEROID (AH-Software) - 文章読上げ専用ソフト。エーアイの音声合成エンジン「AITalk(最新版は、AITalkⅡ+)[15]」を使用。現在、VOICEROID+(2014年10月30日にVOICEROID+EXシリーズ[16]を発売予定。)
ALTAIR for Windows
AquesTalk(株式会社 アクエスト) - ライブラリ。同エンジンを使用し、歌唱させることに特化したAquesToneも存在する。
SofTalk - AquesTalkのフロントエンドソフト。動画サイトでは、「ゆっくりしていってね!!!」の声としてこのソフトを用いた事例が多いので「ゆっくり声」と呼ばれる事がある。また、テレビ神奈川等で放映されている音楽トーク番組『Run Run LAN!』で使用されている。
CHATR
CSVIEW/VoiceOperator(NEC) - オプションとして音声合成機能が提供されている。
Document Talker
FineSpeech
FineVoice (NTT-IT)
FreeTTS[17]
FutureVoice (NTT-IT)
Galatea Talk - 音声認識、音声合成、顔画像合成、対話制御で構成されるGalatea Toolkitの一部。オープンソースソフトウェア。
Hipervoice (NTT-IT)
音声合成ソリューション(株式会社 日立ケーイーシステムズ)
Hitachi Speech Synthesizer - ゲーム『DERBY OWNERS CLUB 2008』で使用。
HTS - HMM音声合成システムを学習するためのツールキット。オープンソースソフトウェア。[18]
InnoVoice
JukeDoX2 - 他言語テキストの合成音声読み上げ可能なソフトウェア[19]
JPNTAKE - フリーソフト。使いやすい設計。
LaLaVoice 2001 東芝製PCのバンドルソフト。単体販売もあり。
Open J-Talk - HMMベースの日本語テキスト音声合成システム.オープンソースソフトウェア。[20]
ProTALKER 97, ProTALKER/2 (日本IBM)
Sinsy(名古屋工業大学国際音声技術研究所) - 隠れマルコフモデルにより、読み込んだ楽譜から歌唱法を学習していく。
CeVIO Creative Studio - FREE 版も存在する音声合成ソフト。
SmartVoice (NEC)
Text To Wav - 読んでいる所をハイライト表示する。wavやmp3化も出来る。
Aozoravoice2 - 青空文庫をmp3に変換するソフト。他言語にも対応。
SpeeCAN - ゲーム『ときめきメモリアル4』で使用。
S-PLG100-SG(ヤマハ株式会社)まずハード音源としてModular Synthesis Plug-in Systemの一つとして販売。(現在は生産終了)[21]その後、ソフトシンセとしてS-YXG100plus(生産終了)にバンドルされる形で販売されていた。[22]
VOCALOID™(ヤマハ株式会社)- メロディと歌詞を入力し歌声を生成する。エンジン部をヤマハが開発し、クリプトン・フューチャー・メディア、ZERO-G、PowerFX等が音声部分を作成している。ゲーム『大合奏!バンドブラザーズP』では採用された。現在、VOCALOID™3が製品化されている。
Voice of Japan
VoiceSommelier(日立ビジネスソリューション株式会社)
VoiceText(ペンタックスHOYAサービス) - 日本語以外の言語にも対応。SDKも存在する。テレビ東京系列のバラエティ番組『モヤモヤさまぁ〜ず2』にて、日本語男声話者のSHOW(ショウ君)がナレーションに利用されている。
VOStalk
Wizard Voice
WorldVoice 日中英韓(高電社)
XIMERA
Yomi
YOMOYOMO - 日本語テキスト音声合成も可能な無料システム。日本国外向けサービス。
唄詠 - フリーソフト。読み上げソフト(SofTalkなど)の声質としてUTAU用の音声ライブラリを選べるようにするためのツール。
エールプレイヤー(アルチザン アソシエーション)
しゃべるんです - テキストを音声で読み上げる。WAV/MP3保存可。クリップボード監視機能
自分の声ソフトウェアPOLLUXSTAR - 特定個人の声質・抑揚を再現する、個人向けシステム構築サービス。喉摘者・神経難病者などを主な対象。喉摘した大学教授の教壇復帰事例、学習院大 篠沢名誉教授による講演事例など。
ボイスキーボード(声が出ない) - セクシーボイス合成ができる。
ボイス君のテキストスピーチ2(株式会社NTTデータ)
英語[編集]
Microsoft Speech(英語)
expressivo 日本語版(やなさ株式会社)。
WorldVoice 日中英韓(高電社)
中国語[編集]
WorldVoice 日中英韓(高電社)
韓国語[編集]
WorldVoice 日中英韓(高電社)
音声合成の技術を採用している主な製品[編集]
バスの車内放送装置 - クラリオンや指月電機製作所、レゾナント・システムズなどが製造しているワンマンバス用の放送装置は音声合成の技術を採用しているものもある。
コンピュータゲーム - コナミの『ときめきメモリアル』シリーズに用いられたEVS (Emotional Voice System) [注 1]が有名。
脚注[編集]
音声合成 - Wikipedia
