計算機などの情報機器を身につけて利用するウェアラブルの考え方が注目されるようになってきた.ウェアラブルによる情報提示では,従来の情報機器と異なり,ながら作業やハンズフリーな状態での使用などの可能性が指摘されている.聴覚情報はヘッドホンのような日常的でウェアラブルな装備により提示が可能であることから,ウェアラブルのためのインタフェースとしての活用が期待されている.このような背景をふまえて,筆者らは聴覚定位を利用したウェアラブルとユーザとのインタラクション手法を提案する.具体的には,従来のGUIで用いられてきた視覚的なメニューやアイコンとポインタによる処理や対象の選択と同様の操作を,空間定位をともなう聴覚提示によって実現することを検討している.本論文では,このようなインタラクションの基本となる聴覚的アイコンおよびポインタによるポインティング操作について,被験者を用いた評価実験を通して,精度と時間に、関する特性を明らかにしている.具体的には,頭部伝達関数を利用して聴覚情報の方向定位を行うデバイス,頭部および手先の姿勢を計測するセンサ,これらを統括するノートPCより構成されるシステムを用いてウェアラブルな聴覚提示を実現し,これを用いて,定位方向の認識誤差,ポインティング時間,ポインティングにおけるノイズの影響などを定量的に評価している.また,これらの実験を通して,聴覚によるポインティングの実現可能性を確認している.
It is a merit of using wearable systems that we can use computers while doing other tasks. Even before the emergence of wearable computers, we were using auditory devices such as head phone stereos in a wearable style. The audio is hence thought to be a media that is most suitable for wearable interactions. We propose an interaction method between the user and the wearable systems based on the auditory localization. The concept of the method is based on the notion to introduce the selection mechanism of visual GUI into auditory interaction. In our approach, users interact with auditory icons using auditory pointers to select functions and objects. In this paper, we report the experiments on the efficiency and the accuracy of auditory pointing. We used a wearable auditory system, which consists of an auditory localization deyice based on HRTF, motion sensors to measure the angular posture of the head and the pointing device, and a notebook PC to control these device and sensors. We quantitatively evaluated the accuracy in the recognition of sound orientation, the time required for pointing the target icon, and the effect of noise during the pointing operation. Through these experiments, we confirmed the feasibility of the interaction method based on the auditory localization.

