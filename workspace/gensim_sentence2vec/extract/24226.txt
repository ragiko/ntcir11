本稿では,日本語書き言葉を対象とした参照表現の自動生成課題,特に参照表現を省略するか否かを分類する問題を対象に,既存研究で利用されている談話的特徴を考慮した自動分類モデルを提案する.このモデルの性能を調査するために新聞記事にアノテーションされた結果を正解として評価を行い,提案モデルがセンタリング理論 [4] に基づくヒューリスティックな手法と比較して有効であることを示す.提案モデルは,元の新聞記事の省略箇所を正解として F 値で 0.550 の分類性能で省略する場合を同定できた.評価用データとして利用する新聞記事コーパスにアノテーションされた共参照・ゼロ照応関係は新聞固有の省略や言い回しのため,必ずしも人間の直感的な判断とは一致しない.そこで,3 人の専門家に新聞記事 50 記事中の参照表現を対象に省略すべきか否かを判断させ,その結果を正解として再評価を行った.この結果,人間の判断が一致する箇所のみを対象に評価した結果,50 記事全体を対象に分類した結果を上回る結果を得た.また,人間が一致した結果を分析し,省略生成の問題に関する今後の課題についても議論する.
This paper focuses on generating referring expressions in Japanese written texts, especially the task of deciding whether a referring expression is realised or not in a text. We propose a model for generating zero-anaphors, taking into account discourse information utilised in the previous work. The proposed model was evaluated using an annotated corpus which contains coreference and zero-anaphoric relations. Our empirical evaluation demonstrated that our model achieved 0.550 in f-score, which is better than the results of a heuristic method based on Centering Theory [4]. Our error analysis revealed the problem that the test data set has a skewed distribution of zero-anaphors due to the specific writing style of newspaper articles. We prepared an alternative gold standard which was made based on the agreement among three experts who judged each referring expression to be realised or not in coreference chains selected from 50 newspaper articles of the data set. We re-evaluated performance of our model with this human-made gold standard. The model performed better with the human-made gold standard than with the tags annotated in the annotated corpus. We also manually analysed the consistent annotation by the three experts and discuss the future directions of generating zero-anaphors.

