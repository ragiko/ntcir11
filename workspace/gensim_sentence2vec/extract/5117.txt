今回は、クラウドサービス「VoXT」と単体のアプリ「AmiVoice SP2」を比較しつつ、「VoXT」の特徴を探ります。
私の発音を学習したAmiVoiceだとこんな感じ
AmiVoice SP2を直接入力モードにし、取材時の音声を聞きながらマイクに向かって復唱してみました。認識結果を候補から選び直す等の作業をしないで、そのまま表示させます。読みやすさのため、最低限の句読点と改行、話者名表記は手で入力しました。
−−−
廿:これを使うシチュエーションとして想定しているのは、たぶんこういう話はできないので、氏講演会とか
河村:そうですね後援会とかセミナーとか
廿:ほぼそれに特化するという。それ以外の用途にはあまり音声認識としては使えないですよねレシピひねってしまいますよね必然的に
鶴田:あとはインタビュー形式であるとか一対一であれば、認識はそこそこできます。ICレコーダーも一対一であれば、真ん中に置けば均等ですので、こういった静かな環境であればインタビューでも。
廿:行くかな。人が違う時に。話者が3人いる時にそれぞれの話加藤ドコモで認識するか。
−−−
「講演会」が「後援会」、「どこまで認識するか」が「ドコモで認識するか」になっています。さらには「レシピひねって」などという謎の言葉になったりしていますが、私自身が読めば、全体としてここが何の話題であるかは判断できます。ちょっと修正すれば全文書き起こしデータとしても十分に使えます。
複数の人の話し方を認識できるか?
鶴田さんの発言内容は、上の認識結果で問題なく分かります。それに対して私は意地悪に「話者が3人いるときにそれぞれの話し方をどこまで認識するか」という疑問を投げかけています。「話し方を」が「話加藤」になっているのは、私のリスピークする際の発音がいまいちだったせいでしょう。
候補から選び直すという処理なしでもここまで正確に認識されるまでには、私もリスピーク技術を結構研究したのです。また、AmiVoice側も、私の発音のくせをずいぶん蓄積して、いい認識結果を出してくれるようになっています。
私一人の声で学習を積み重ねているAmiVoiceに対して、複数の話者の発話を認識させるVoXTの精度はどうなのでしょうか。その疑問が、「話者が3人いるときにそれぞれの話し方をどこまで認識するか」です。
VoXTはさまざまな声に対応できるエンジン
答えを、また私がリスピークした文字化データから持ってくると、次のようになります。
−−−
鶴田:基本的には汎用的なモデルを使っています。音響的な部分ではいろんな人に貸与できるものをあっています。SP2は音響モデルを使っている方に寄せていくんですけれども、今回ば老若男女さまざまな人の声に対応できるようなエンジンを使っています。
−−−
誤「貸与できる」&rarr;正「対応できる」、誤「ものをあっています」&rarr;正「ものになっています」、誤「今回は」&rarr;正「今回ば」。
いずれの誤認識も、AmiVoiceが悪いというより、私の発音の問題や、復唱の途中でつかえたなどの問題だと思います。
つまり鶴田さんの解説によると、AmiVoice SP2は特定のユーザーの声や話し方を学習して、音声認識のエンジンを作り上げていく。これに対してVoXTはクラウドサービスなので、多くの人の声を学習しながら進化していく。そのために、「さまざまな人の声、話題に対応できるような音声認識エンジン」を採用していて、音質さえよければ3名がしゃべる音声でも問題ないということですね。
鶴田さんが所属する議事録の事業部は、都道府県や市町村の議会の討議音声を文字化するサービス、つまり「さまざまな人の声や各自治体に応じた話題、固有名詞などに対応できるような音声認識エンジン」を扱っています。議会用は初期費用が約300万～、年間の保守料が数十万という高価なシステムですが、VoXTはそちら系のエンジンを、一般用に音声1分あたり30円で使えるサービスというわけです。
VoXTとAmiVoiceの性質の違いが、だいぶ分かってきました。最終回は、録音音声をうまく認識させるための条件をもう一歩踏み込んで考えてみます。
次回へ
音声認識による文字起こしサービス「VoXT」とは バックナンバー
第1回  第2回  第3回  第4回
音声認識による文字起こしサービス「VoXT」とは(第3回) | テープ起こしならokoso(オコソ)
