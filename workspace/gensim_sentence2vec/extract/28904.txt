どうもです。ゆゆ式2期を待ち続けるsoRaです。
このエントリでは先のエントリに引き続いて発音判定の難しさについて述べたいと思います。今回は、音声認識寄りの話になります。
音素
人の音声は言語学的には音素の単位で識別されます。
音素(おんそ、phoneme)とは、言語学・音韻論において、客観的には異なる音であるが、ある個別言語のなかで同じと見なされる音の集まり http://ja.wikipedia.org/wiki/%E9%9F%B3%E7%B4%A0
自動発音評価では、正解音声の発音と学習者による発音の、音素単位の比較を行います。そのためには、音声信号から音素列を取得できなくてはなりません。
まず、音声信号からこちらのエントリで説明のあったフォルマントに関する情報を抽出します。(実際にはメル周波数ケプストラム係数 MFCC を取得しますが説明は割愛します。)
続いて抽出した情報から音素列を取得するために音響モデルというものを使います。
音響モデル
音響モデルは、音響情報から音素を予測するパターン認識モデル(音声の特徴である時間的伸縮を扱うのに適した隠れマルコフモデルを使うことが多い)で、音声標本から機械学習により構築します。
音響モデルの性能には音声標本の量と質が大きく影響を与えます。
なお、音素の発音は、先行・後続する音素によって変化するため、音響モデルでは3連する音素を一つの組(トライフォン)として扱い、音響情報との対応を学習します。その分、必要な標本数の数も増えます。
人の発音は、音響的には性別・年齢・身長等により大きく異なります。多様な属性を持った人をたくさん集めて標本を取って均すことで、特定の話者の特徴を隠すことができます。
また、当然のことがら、同じ話者が同じように発音を繰り返したつもりでも音響的にまったく同じ形になるわけではありません。読み上げなのか自然発話なのか、どのような感情がのっているか、といった要素の影響も受けます。
音素の持つ音響的な幅・揺らぎに対応できるような、高性能な音響モデルの構築するためには、巨大な音声標本が必要となります。
ちなみに、こちらの論文によると、Google Voice Searchでは5000時間の音声標本が音響モデルの構築に使われているようです。
このような大規模な音声標本の収集・整備と、音響モデルの構築がかなり大変な作業なのは想像に難くないでしょう。
音声認識との違い
発音判定に使われる技術は、音声認識に使われる技術とほとんど同じです。
ただし、その目的が違います。
音声認識は,話者の発話をもとに,その「意図する語」を推測することを目指す.
発音矯正は,話者の発話と,理想とする発話の違いを示すことを目指す.
音声認識においては音響モデルだけでなく,単語の発音辞書,文法,語の共起情報といった,言語モデルを活用して意図する語を推測します.そのため,話者の発話が,理想とする発話と音響的に離れていようが,(言語モデル的に妥当性が高い語が他に無いならば)意図する語の推測に成功する可能性があります。そのため発音判定目的では、言語モデルをそのまま使うわけにはいきません。しかし、言語モデルを使わない場合、認識精度がひどく落ちます。
人間の音(声)の聞き取りには様々な心理学、認知科学的な現象が関与しており、物理的な音をそのまま聞いているわけではありません。実際、マスキング(ある音の影響で他の音が聞こえにくくなる)、選択的注意(カクテルパーティ効果)、プライミング (先行する音声刺激が後続する音声刺激を増幅、抑制)、マガーク効果 (視覚情報により聞こえる音が変わる)等、様々な現象が日常的に起こっています。
ここで注目したいのは、発音されていない音を聞いたと認識してしまう「知覚的補間」現象です。これについて、次のリンク先で体験することができます。
イリュージョンフォーラム 錯聴 知覚的補完 連続聴効果
皆さんも是非リンク先に飛んで、Aの音声を再生した後に、Bの音声を再生してみてください。聞こえないはずの音が聞こえる現象を体験できると思います。
人間が、このように何らかの補完機構を用いていることを考えると、言語モデル無しで行う発音判定は、人間よりも(必要以上に)厳しいものといえるのかもしれません。言語モデルをどう扱うか、というのは意外に難しい話なのです。
やっぱり発音判定は難しい
他にもノイズの問題や、具体的な評価の方法など考えなくてはならない課題がいろいろあります。
さて、世の中には発音判定アプリがいろいろありますが、それらはどの程度信用できるものなのでしょうか。高い精度で判定してくれるでしょうか。学習者が役立てるようなフィードバックを本当に返しているでしょうか。華々しい宣伝文句は妥当なものでしょうか。
私自身は、発音判定技術自体がまだまだ発展途上だと認識しています。しかし、そこまで認識精度がなくても使い方次第では十分発音の学習に役立たせることができる、と考えており、参謀本部では、発音判定技術と教育現場の実情に則した、実用的なアプリケーションを実現すべく英語教育の先生と共同で研究開発を進めています。
はじめまして、soRaと申します。初Wordpressでドキドキです。
ブログは自由に書いていい、検閲はしないと社長に言われているので、今後どんどんフリーダムにしてきたいと考えていますが、初回はおとなしく自分が関わった案件に関わる話をしたいと思います。
私は参謀本部では英語発音判定アプリの受託案件に携わっています。といっても、当該案件の具体的な話をするわけにもいかないので、もう少し一般的な話、「発音判定がいかに面倒くさいか」について書きたいと思います。
今回は言語編ということで、「そもそも正しい英語の発音って何なの?」という話をします。なお、予め断っておきますが、筆者は言語学は専門ではなく、また英語も堪能というわけではありません。あくまで一つの見解として受け取っていただけると幸いです。
正しい英語の発音とはなにか?
発音教育では英語を母語とする人をネイティブスピーカー、英語を母語としない人を非ネイティブスピーカーとして位置づけたうえで、非ネイティブの発音がネイティブの発音に近付くことを目指します。
発音は母語の転移を受けやすく、臨界期(敏感期)以降の第二言語の発音の習得は困難を極め、NSと区別不可能な程度なほど熟練するのはかなり稀です。
非ネイティブスピーカーの学習者は(ネイティブと同等は無理でも)ネイティブに近い(native-like)発音の獲得を目指して学習を行うことになります。その過程において、発音が理解可能な明瞭さ(intelligibility)を獲得することが期待されています。
では、学習者が目指すネイティブらしさとは一体何なのでしょうか?
EIL(English as a International Language、国際語としての英語)
英語を母語、公用語とする国は世界中にあり、地域によって訛りが異なります。
アメリカ英語、イギリス英語の間にも違いがありますし、アメリカ国内、イギリス国内の間ですら多様な訛りがあり、どの訛りが正しいとは客観的に言うことができませんし、訛りによって発音の明瞭さが損なわれるとも一概には言えません。
しかしながら、社会言語学によると、訛りは社会的評価と関連しており、聞き手の態度に影響を及ぼすことがわかっているそうです。
つまり、特定の外国語訛りは、また別の特定の外国語訛りと比べて社会的に有利ということになるため、何が正しいかという議論はさておいても学習・習得の価値があるとも言えそうです。
intelligibility(理解可能な明瞭さ)
先述のように非ネイティブな学習者は intelligibility を獲得することが、当面の目標となります。しかし、intelligibilityもまた基準として曖昧で、実際には聞き手に大きく依存することがわかっています。
伝統的にはintelligibilityはネイティブに判断させればよかろうとということになっていました。しかし、ネイティブといっても先述のように多様であり、実際、ネイティブスピーカ自身の訛りが、発音評価に影響を与えていることがわかっています。(Marinova-Todd 2000)評価者の訛りへの慣れや、英語学習に関する思い込みが評価に影響を与えるとも考えられています。
国際語としての英語(EIL)の立場から非ネイティブ同士のintelligibilityを評価する研究も行われています。興味深いことに、非ネイティブスピーカー相手に話すときの方がネイティブ相手に話すときよりも、より明瞭な発音を求められる傾向があるようです。(英語について深い言語知識のあるネイティブスピーカーは背景知識を元に発話内容を推測しやすいからと考えられています。)
intelligibilityに資する発音のポイントについても研究が進められていますが、こちらも聞き手によって違いがあると考られており、発音評価のための基準に使うにあたっては留意が必要です。
正しい発音の判定
何が「正しい」発音か、というのは考えてみると難しい話です。
ただ、それでも、ある程度の共通見解はありますし、発音の判定が全く無意味というわけでもありません。
上級者に対する細やかな発音評価は「正しい発音」が何か分からない以上難しいですが、初学者に対するざっくりとした発音評価ならば、多くの評価者の間でコンセンサスが得られるでしょう。
発音の初学者は、自分の発音が稚拙に聞こえることを分かっているため人前で発音指導を受けることに抵抗を持つ人も多いようです。発音の自律的な学習を支援するソフトウェアは、そのような初心者にとって大きな価値があるものだと信じています。そして、そのような初心者はかなり多いと踏んでいます。
さて、今回は技術的な話は特にしなかったのですが、次のエントリではもう少し技術的な側面に焦点を当てたいと思います。
皆様、はじめまして。oceoと申します。
株式会社「参謀本部」で働かせてもらってます。どうぞよろしく。
さて、今回のテーマは「声について科学的に考える」です。
考えてもらうのは、このお二人です。
どうもー!参謀本部の広報です!名前はまだないです!
どうぞよろしくー!!
こんにちは。参謀本部の受付です。名前はまだありません。
よろしくお願いいたします。
…若いっていいですね。おっさんにはそんな元気残ってません。
さて、お二人は「フーリエ変換」についてご存知でしょうか?
そんなもん知るかー、ボケーッ!
すみません。文系なので聞いたこともないです。
…。
(チッ!それも初対面の女にボケ呼ばわりされましたが…)
あー?なんかいーましたー?
いえ、別に…。
しかし、出鼻を挫かれましたね…。おっさん困りました…。
では、話題を変えましょう。
今回は「声」「音声」について考えるのですが、流石のお二人でも、こういうのを見たことがあるはずです。
あ!これ、見たことある!
私もあります。Windowsの旧サウンドレコーダーで録音したときに見ました。
これは「あいうえお」と私が喋ったときの音の波形です。
グラフは縦方向に振幅してますが、実際には、音は進行方向に空気が振動しています。
スピーカーの振動板が振動しているのを見たことありますよね。糸電話でもいいです。
あれです。
振幅…
進行方向に空気が振動…
とりあえず、音とはこういうものだと思ってください。
で、これを短時間フーリエ変換というものをすると、下のようになります。
ふむふむ。わからん。
これは「スペクトログラム」と呼ばれ、声紋の鑑定に使われたりします。
犯罪捜査とかでよく登場しますね。
わたし、お昼のテレ東で見たことあります!
ホレイショかっこいーですよね!
…さて、「音の波形」を短時間フーリエ変換して「スペクトログラム」を得たわけですが、その逆、
つまり「スペクトログラム」から元の「音」に逆変換することもできます。
これについては後ほど話します。
音の波形 ⇔ スペクトログラム
???
なんでそんなややこしーことするの?
そもそも、なんで変換する必要があるの?
元の音のままじゃダメなの?
それをこれから説明していくのですが、そうですね…。
話が脱線しますが、個人的には「変換」とは「異次元への扉」みたいなものだと思ってます。
い、いきなりファンタジー小説ですか!?
例えば、今回登場したフーリエ変換ではなくて、別にラプラス変換というものがあるのですが、これで微分方程式を変換すると、ややこしい問題が簡単な足し算引き算の問題になったりします。
ファンタジーに例えると、現実世界で難しい問題があっても、それを異次元に転送すると、異次元では簡単な問題になる、という感じでしょうか。
なるほどー。
冴えない主人公でも、異世界に転送されると、ハーレム展開になるというアレですな!
…話を戻しますと、今回音をスペクトログラムに変換する理由は、元の状態では見えない大切なものが、変換すると見えるようになるのです。そのために変換する必要があるのです。
スペクトログラムは、横方向が時間軸、つまり右に向かって時間が進んでいきます。
縦方向が周波数です。下の方ほど低い音、上の方ほど高い音、と言えば分かりやすいでしょうか。
「あいうえお」がそれぞれどの時点で当てはまるのか、書き加えてあります。
で、二人にスペクトログラムをよく見てもらいたいのですが、明らかに濃いところと薄いところがありますよね。
濃いところというのは、振幅が強い周波数、パワーがある周波数ということです。
これを線で結びます。
この線は手ではなくWaveSurferというソフトを使って自動抽出したものです。
この周波数の線を「フォルマント」と言います。
下から、第一フォルマント(赤)、第二フォルマント(緑)、第三フォルマント(青)、第四フォルマント(黄)、…、と言います。
無音のところはフォルマントがごちゃごちゃしてますが、それは無視してください。
さて、何か気が付きませんか?
それぞれのフォルマントが「あ」「い」「う」「え」「お」それぞれで比較的一定になってる感じがします。
そのとおりです。
「あ」のときの第一フォルマント、第二フォルマント、…、「い」のときの第一フォルマント、第二フォルマント、…、
はほぼ決まっています。そして、これは声の高さなど人物個々の特性に依存しづらい性質です。
つまり、これはコンピュータが、人間が何を喋っているかを理解する、音声認識にもつながるわけです。
音声からフォルマントが分かれば、コンピュータは人間が喋っているのが「あ」なのか「い」なのか分かるはずです。
と言っても、現実はそう簡単ではなく、男性と女性でフォルマントが若干異なったり、データは理想的に綺麗ではないので、安易に判定できなかったりします。
今回は割愛しますが、そのためには様々な工夫をする必要があります。
さて、先ほど逆変換、つまりスペクトログラムから元の音に逆変換できる、可逆である、と説明しました。
これを使うと面白いことができます。
The Analysis & Resynthesis Sound Spectrograph : Examples
の上から三番目のHAL 9000の音声は、上から二番目のHAL9000のスペクトログラムを人間がPhotoshopでたった15分で真似て描いたものを音に変換したものです。
白い線で描かれている中にフォルマントも含まれています。(白黒は逆になってるだけで同じです)
手書きのスペクトログラムから変換した音ですが、何を喋っているのかある程度は分かりますね。
つまり、ちょっと人力ですが、音声合成ができているということです。
同じ原理でコンピュータを喋らせることができる、ということです。
さて、最後に、日本では英語の発音で「L」と「R」の違いがよく問題になりますが、それぞれのフォルマントを見てみましょうか。
Linguistics Handbook Downloads (Department of Linguistics, University of Victoria)
のAmerican-Englishの「rye」と「lie」の音声データからフォルマントを見てみます。
子音は先ほどの「あいうえお」のような母音ほどはっきりフォルマントは出ません。
母音のフォルマントは第一、第二がメインですが、子音は第三以降に表れます。
また、子音はフォルマントの変化(フォルマント遷移)が特徴になります。
「rye」は第三フォルマント(青線)が下から上がっているんですね。
「lie」は緩やかに下がってます。
そうですね。
フォルマントは舌の位置とも関係があるようです。
それから、個人的な感想ですが、実験していて、単語の頭の「R」の発音は手前に「ウ」と言えばいい、という説は的を射ている気がしました。
以上、声を認識するにはフォルマントが分かればいい、ということ、
英語の「L」と「R」はフォルマントで違いが分かる、ということ、
スペクトログラムにフォルマントの線を描いて音に変換すれば音声合成ができる、ということ、
について解説しました。
では、またどこかでお会いしましょう。
まったねー!
こんにちは、株式会社参謀本部の社長の齊藤です。
対談や技術ブログの記事のアップにもう少し時間がかかるので、代わりに私が参謀本部の基本理念に関して説明する記事を書きます。
株式会社参謀本部はブラック企業と戦います
長引く景気低迷で企業の収益が悪化し、安価な長時間労働や残業代の未払いなど労働者を苦しめて過酷な労働条件を突きつけるブラック企業が急増しています。しかし、非正規雇用が急激に増加している日本社会で明日の生活を守るには、このようなブラック企業で働くことを受け入れざるを得ない人々も多くいます。労働基準監督署も当てにはならず、生活の貧困や短期間で転退職を繰り返す大きな要因になっています。
株式会社参謀本部は、このようなブラック企業が蔓延する状況を問題視し、ブラック企業と戦っていきます。ブラック企業は「現在の会社しか選択肢がない」状況を巧みに利用して、労働者の抵抗を無力化する無言の圧力を掛けてきます。それこそが悪の温床です。株式会社参謀本部は、ブラック企業で過酷な条件で雇用されることのない「もうひとつの選択肢」を社会に提案していきます。そして誰もがブラック企業に努めて社畜になってしまう状況を変革します。
株式会社参謀本部は社会的弱者の味方です
いま日本では急激に非正規雇用が増えています。その中で働いても生活が楽にならないワーキングプアが急増しています。また、ニートや引きこもりなど社会を拒絶して働くことに壁を作っている人々もいます。また、うつ病などメンタル面で問題を抱えている人や転職回数が多い人には不利な社会状況が未だ続いています。東京と地方の格差や、子供の貧困や高齢者の増加も深刻な問題です。
株式会社参謀本部は、このような社会的弱者の味方です。ワーキングプア、ニート、引きこもり、メンヘラ、転職回数の多い人、地方在住者などの味方になって、彼らが働きやすい社会を目指していきます。それは社会主義のように全員が結果の平等を受け入れる社会ではありません。全ての人にチャンスが開かれ、今現在冷や飯を食わされている社会的弱者でもチャレンジしやすい社会環境を整えていくのが使命です。
株式会社参謀本部は中間搾取や中抜きの構造を打ち破ります
社会の貧困の問題となっている大きな要因は、中間搾取や中抜きの構造です。労働者は仕事を得る際に中間マージンを差し引かれ、会社間においても中抜きの構造で多重請け負いが常態化しています。これでは社会全体が豊かになっていかないのと、フレキシブルな社会構造を作ることができません。派遣労働などはその際たるものです。かつてマルクスが指摘したように、労働者が労働によって生み出した価値というのは本来は労働者自身に還元されるべきなのです。そうでなければ資本主義であっても豊かな社会は築けません。
いま、世界経済の危機で格差が顕在化して、世界の経済格差の水準は19世紀まで戻ろうとしています。株式会社参謀本部は、その温床である中間搾取や中抜きの構造の打破を考えています。そして労働者や企業が、生み出した価値の分だけ正当に対価を受け取り、レジャーなど余暇に使う余裕も生まれる豊かな社会を目指します。
株式会社参謀本部は現代資本主義文明に代わる新しい文明の創造を目指します
かつて資本主義は競争によって優れた商品を生み出して豊かな経済を達成し、社会主義陣営に打ち勝ちました。今日、多くの国で資本主義が採用されて、私達の文明の基礎となっています。しかし、世界経済の危機やグローバル化で行き過ぎた中間搾取や中抜きが横行するようになってきました。ブラック企業は日本だけの問題ではありません。かつて修正資本主義によって、福祉や労働組合が整備されて資本主義が成長していくモデルが提示されていましたが、今やそれらは制度疲労を起こし、現状への無力を露呈しています。
株式会社参謀本部は、 現代文明に対して修正が必要であると考えています。それは具体的には雇用の見直し、中間搾取と中抜きの構造の打破です。そのために株式会社参謀本部は、社会的弱者や苦境に立たされている人達と手を組み、新たに発展したWebを使って、現代文明に新しいワークスタイルを提起するものです。それはクラウドによって、人と人、あるいは人と企業や企業と企業がダイレクトにつながり、正当な評価と富の拡大を生み出していく革命です。
ゲーム文明の可能性
世界がゲームのようであったら、どんなに素晴らしいことでしょう。Ingressの登場で私達はその可能性の一端を見たように思います。また、MMORPGなどのように例えば引きこもりであってもゲームの世界でなら大きな活躍を見せることがあります。私達は現代文明のゲーム化を進めていくことによって、失われてしまった人々の繋がりや公平なチャンスのある社会を取り戻し、新しい文明を築いていく原動力になれたらと思っています。そこでは、ニートや引きこもりやメンヘラにも誰にでもチャンスが開けていますし、中間搾取の構造はありません。世界のゲーム化によって正当な対価を受け取ることが出来るのです。しかも、労働の苦痛を感じることなくゲームを楽しみながら。
これによって現代資本主義は大きく変わり、過酷で劣悪な条件を突きつけてふんぞり返っていたブラック企業は窮地に立たされます。世界経済はゲームとクラウドを基軸として動くようになります。
そういう「現代文明を変える」革命にあなたも参加してみませんか。それが「参謀本部オンライン」です。
ニュース | 株式会社参謀本部 - Part 2
