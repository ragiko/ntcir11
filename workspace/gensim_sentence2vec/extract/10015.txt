
回帰分析 regression analysis
例えば身長と体重のような,相互依存の関係にある2変量があるとき,一方の数値が与えられたとき,他方の組を予測することができます.
回帰分析とは,乱暴にいってしまえば,複数の変数間の関係を一次方程式(Y=aX+bってやつ)で表現する分析方法です.
用途としては,制御や予測に用いることができる.例えば,
売上高と宣伝費の関係が分かっていれば:目標とする売上高に対して宣伝費を決定する(制御)
人口と商店数の関係が分かっていれば:ある市の人口からその市の商店数を予測する(予測)
なんて用途が考えられます.
予測したい変数のことを目的変数といい,目的変数を説明する変数のことを説明変数と呼びます.目的変数は1つですが,説明変数の数はいくつでもよく,説明変数が2つ以上の時は重回帰,1つのとき特に単回帰と呼びます.また,求められた一次方程式を回帰式と呼ぶこともあります.
回帰式を求めるイメージ
例えば,2つの変数間の関係を回帰式で表現することを考えよう.推定するのは
・直線の切片であるb
と
・傾きaである.
回帰式はデータに最も良くあてはまる直線である.しかし,実際には各データに対して必ず誤差が存在している.回帰式の推定に用いられる最小二乗法は,求める直線とデータとのy軸でみた誤差(残差)dの二乗和(つまり誤差の面積)が最小になるように直線を求める方法である.イメージとして以下の図をあげておく.
図で青の直線が回帰式,赤点が実際のデータの値である.回帰式からの距離(誤差)dの二乗(緑の正方形)の合計が最小になるように回帰式を描いてみよう,というのが最小二乗法のアイデアである.最小二乗法の具体的内容については統計学のテキストを参照して下さい.
重回帰分析
重回帰分析は複数の変数からなる回帰モデルである.例えば,3変数による重回帰式を示せば,
y=a+b1X1+b2X2+b3X3
具体的な推定方法については単回帰の場合と同じ.
おまけ
重回帰分析で得られた各推定値は,他の変数の影響がない,という状態で得られる被説明変数と当該変数の関係を示している.したがって,重回帰分析では次のような問題が発生する
12‐1.多重共線性
多重共線性(Multicollinearity)とは,重回帰モデルの説明変数間に相関が存在することにより,推定結果に信頼が置けなかったり,有意な推定が行えなくなる現象を指す.山本[1995]によれば,多重共線性の症状として,
推定値の符号が理論と合わない.
決定係数は大きいのに,個別のt値は低い.
観測値を増加させるたびに,推定値が大きく変動する.
説明変数を増減すると,推定値が大きく変動する.
などが挙げられる.刈屋他[1985]では,「一般にわが国の時系列データには,上方トレンドを持つものが多く,変数間の相関が高いため,分析上常に注意が必要である」,としている.説明変数間に大きな相関が存在している場合は多重共線性を考慮した方が良い.多重共線性を解決する方法としては,変数の除去 ,変数の合成 ,リッジ回帰 などが提案されている.
12-2.ダービン・ワトソン比
回帰分析を行うにあたっては,誤差項について異なる誤差項間には相関が存在しないことを仮定していた.誤差項間に相関が存在する場合(自己相関,系列相関と呼んでいる),求めた係数が不偏推定量である保証ができない.ダービン・ワトソン比はこれをチェックするものである.
誤差項間に系列相関が存在するかどうかは得られたDWの値と判別のために数表(統計学より,計量経済学のテキストに付いてることが多い)により判断するが,大まかには,
と考えて良い.誤差項に系列相関が存在する場合の対応としては,コクラン・オーカット法,一般化最小二乗法(GLS),最尤法などがある.
12-3.不均一分散
回帰分析での誤差項に関する仮定の一つにすべての誤差項は一定の分散を有するというものがある.しかし,実際のデータではこの仮定が崩れていることがある(つまり不均一分散).一般にクロスセクションデータについては誤差項の分散が不均一に,時系列データでは系列相関が生じやすいのだという.
チェック方法としてはBreusch-Paganテスト,Whiteテストなどがあり,対応策として,加重最小二乗法,Box-Cox変換などがあるが,その方法についてはこれまた省略.
戻る 
表計算ソフトで統計処理
