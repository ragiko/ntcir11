Emacs キーバインド 備忘録
Emacs
すべてのキーバインドを表示
M-x describe-bindings
バッファ再読み込み
M-x revert-buffer
選択リージョン内の文字数をカウント
M-x count-lines-region
正規表現検索(前方,後方)
Ctrl-u Ctrl-sCtrl-u Ctrl-r
カーソル部分の英字を大文字,小文字に修正
M-cM-l 
行頭からカーソルまでの範囲を削除(キルリングに保存)
M-x 0 Ctrl-k
Permalink | コメント(0) | トラックバック(0) | 09:46
UNIX コマンド 備忘録
UNIX コマンド
二つのファイル a,b の共通部分を表示
sort a b | uniq -d
二つのファイル a,b の和集合を表示
sort a b | uniq
二つのファイル a,b の差集合(a-b)を表示(ただし,各行先頭に「< 」という文字列も表示される)
diff <(sort a b | uniq -d) b
なお,「<()」は「()」内のコマンドの実行結果をファイルとして扱う機能で,プロセス置換という模様.ファイル a の中で,"xy" を含まず "x" を含む行を表示(ただし,"xy xz" などの行も表示されなくなる)
grep "x" a | grep -v "xy"
Permalink | コメント(0) | トラックバック(0) | 10:53
Confidence-Weighted Linear Classification を読んだ
機械学習, 論文
最近,オンライン学習アルゴリズムとして,SCW が話題に上っている気がしたので,まずは,手始めに CW の論文を読んでみることにした.
Confidence-Weighted Linear Classification.Mark Dredze, Koby Crammer and Fernando Pereira.Proceedings of the 25th ICML, 2008.
CW(confidence-weighted)は,強力なアルゴリズムであるがノイズに弱いという弱点を持つ.一方,SCW(soft confidence-weighted)は,ノイズに頑強となるように CW を拡張したモデルである.以下,CW の論文の内容について書く.背景
NLP の多くのタスクにおいて,素性ベクトルは非常に高次元かつ,多くの素性(=素性ベクトルの要素)は低頻度にしか出現しない.しかし,低頻度な素性も分類において重要な役割を果たす.
一方,代表的な線形分類アルゴリズム(perceptron や PA)では,ある素性に対応するパラメータは,その素性が出現した時にしか更新されない.
そのため,頻繁に現れる素性のパラメータは適した値になりやすいが,稀にしか現れない素性のパラメータは不正確な値になりやすい.
上のような背景の下,任意の素性に対して一様にパラメータの更新を行うのではなく,パラメータの confidence という概念を導入し,confidence に基づいて素性ごとに更新の仕方を変化させる,というのが CW において肝となる考え方である.では,更新の仕方を状況に応じて変化させるのはいいとして,具体的にどのようにするのがよいだろうか.次の例を見ながら,現状のアルゴリズムを適用する際に起こる問題点について見てみよう.例
商品レビューの肯否極性(ポジティブまたはネガティブ)を決定するセンチメント分析を考える.また,素性ベクトルは n-gram で表されるとする.
"I liked this author." というポジティブなレビューがあったとすると,"liked" と "author" に関する重みが更新される.
これらは一般的な単語であるため,対応する重みは,いくつかの事例の学習を経て正しい値に収束する."liked" の重みは正の値,"author" はネガティブなレビューにも出現するため(理想的には)0 となる.
次に,"I liked this author, but found the book dull." というレビューがあったとすると,"like" および "dull" の重みが減少するように更新される.なお,"dull" はこのレビューがネガティブである根拠となる単語であり,また,その出現は低頻度であると考えられる.
この場合における問題点は,"like" の重みが不当に修正されることと,頻出でない単語 "dull" の重みが十分に学習されないことである.
上に挙げた問題点に対処するには,次のような方法が考えられる.過去の事例についての情報——0/1 値をとる素性に対しては出現回数(より一般的に,実数値をとる素性に対しては分散)を記憶しておき,出現回数の値が大きいほど,素性の重みは高い confidence をもつと考える.そして,confidence の低い素性ほど大きく重みを更新すればよい.直感的には,confidence の高い素性("liked")は,既に十分に重みが学習されているので,重みの値を大きく変える必要はなく,逆に,confidence の低い素性("dull")は,分類に十分に寄与するようにするために重みを大きく更新させる必要があるということか.CW が提案されるに当たっての背景・モチベーションは以上の通りである.confidence を用いた定式化の妥当性に納得できる一方,ノイズに弱いと言われるのにも頷ける.ここからの詳細な定式化やアルゴリズムの部分が,この論文の重要であり面白い部分であるのだが,既にここまで書くので力尽きたので,それらについては機会があれば後日書くことにしたい.最後に,CW に関して参考にしたスライド,ブログのエントリを挙げておく.オンライン凸最適化と線形識別モデル学習の最前線_IBIS2011 Exact Soft Confidence-Weighted Learning (ICML2012) 読んだ - kisa12012の日記
Permalink | コメント(0) | トラックバック(0) | 21:56
環上の代数(後編)
代数学
環上の代数(前編)で代数の2つの定義について述べた。結論から言うと、2つの定義が異なるのは見かけ上のことであって、それらは同じ構造を持つ代数系を表している。そのことを確認するために、改めて2つの定義を与える。以下、簡単のため、環 R は可換環であるとしておく(可換環でない場合を考える際は、適宜 R-加群を左 R-加群と読み替えてほしい)。まず、(M) に対応する加群から代数を構成する定義を次で与える。定義1 環 R 上の加群 A において,(A における和と合わせて)A が環となるような積が定義され,x,y∈A および c∈R に対してが成り立っているとき,A を R 上の代数という.定義1は、(M) におけるベクトル空間を加群に一般化しただけにすぎない。要するに、加群に積を入れて環としての構造を持つようにしたものが代数であると言えるだろう。次に、(H) に対応する環から代数を構成する定義を与える。定義1' 環 R と環 Aの間に凖同型が存在し,Im f の元が A の元と可換である,つまり,Im f⊂Z(A) (Z(A) は A の中心)であるとき,RからAへの作用をと定義すると,A の和とこの作用に関して A は R-加群となる.また,x,y∈A および c∈R に対してが成立する.このとき,A を R 上の代数という.このように定義した代数 A は、定義1と同じ構造・性質を持つことがわかるだろう。つまり、2つの環の間に準同型写像が存在するとき、上のように作用を定義することで、環は「自然に」代数としての構造を持つのである。代数 A が R-加群としての構造を持つこと、積とスカラー倍についての条件が成り立つことの証明は易しいので省略するが、c(xy)=x(cy) の成立のために Im f⊂Z(A) が必要となっている。なお、環からの構成の定義を理解する際には、Wikipediaの結合多元環のエントリを大いに参考にした。
Permalink | コメント(0) | トラックバック(0) | 18:27
僥倖の閾値
