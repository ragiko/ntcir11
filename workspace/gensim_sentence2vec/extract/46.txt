これ、買って損したと思いました。
なんていうかね、説明が中途半端なんですよ。解析に使えるパッケージの紹介に留まっていて、実際に解析を行うには情報が足りなさすぎる。
「こういう解析がしたい」と思ったときに R のパッケージ名を調べるような、逆引き辞書として使うには便利なんだろうけど、それだけのために 4,830円出したのかって思うとね、やっぱり損した気分になるわけですよ。
まあ、そんなことをグチグチ言っても仕方ないので、今日はもうちょっと建設的なことをしようと思います。
僕は機械学習を少しかじっているので、この本の SVM の節がこれだけでは実用に足りないことが分かります。
そこで、僕の知っている実用的な知識をここに記しておくことにします。
この本に足りない情報を補完することで、みんなが幸せになればいいと思います。
SVM(Support Vector Machine) はみなさん御存じ機械学習の手法です。
この本の SVM の項(7.15)では、デフォルト設定でモデルを作って、学習データを判別して、ハイ終わりです。
これだけの情報では実際の解析は絶対にできません。
一番足りないなと感じたのは、SVM のチューニングについてです。
SVM はデフォルト設定でモデルを作ってもしょうがないです。gamma と cost というパラメータがあるので、これらの値に最適値を設定しなければなりません。R の SVM の Help にもこう書いてあります。
Parameters of SVM-models usually must be tuned to yield sensible results!
(訳) SVM でいい結果出したかったらチューニングしろよな!
というわけで、SVM のチューニングのしかたについて説明したいと思います。
交差検定
おっと、その前に、交差検定の話をしなければなりません。
SVM モデルをチューニングする際、二つのパラメータでグリッドサーチをします。
すなわち、パラメータをいろいろ変えてみて、一番いい SVM モデルとなる組合せを選ぶのです。
この「一番いい SVM」というのはどうやって評価すればよいでしょうか?
この SVM の評価方法として良く使われるのが交差検定です。
交差検定を説明するために、SVM を評価する単純な方法から順を追って説明していきたいと思います。
単純な方法			まず考えられるのは、SVM を作るのに使った学習データを再び評価にも用いるという方法です。*1
学習に使ったデータを判別してみて、うまく判別できた割合(正答率)を出します。
しかし、これはうまいやり方ではありません。
学習に使ったデータがうまく判別できるのは、当たり前のことだからです。
我々がやりたいことは、SVM で学習データ(既知データ)を判別したいのではなく、まだ手元に無いデータ(未知データ)をうまく判別できるかどうかで SVM を評価したいのです。
そこで、次の方法が考えられます。
ホールドアウト検定
ホールドアウト検定は、SVM の評価方法としてはかなり単純です。
学習に使用するために集めたデータのうち、何割かを評価専用のデータにするのです。
このとき、評価に使うデータは学習データに含めてはいけません。
つまり、集めたデータを学習専用と評価専用の二つに分け、学習用データで SVM を作成し、評価用データで評価する、ということです。
これにより、作成した SVM が、どのくらい未知データを判別できるのかが評価できます。
これがホールドアウト検定です。
ただし、ホールドアウト検定には次のような欠点があります。
集めたデータを学習専用と評価専用に分けるため、学習に使えるデータの量が減る。
データを学習用と評価用に分ける際、分け方に偶然偏りができた場合にはうまく評価ができない。
これら二つの欠点をうまく解決しているのが、次に説明する交差検定という手法です。
交差検定
交差検定では、学習に使うために集めたデータをいくつかに分割します。
いま、例えば 150サンプルのデータを集めたとします。これを 50サンプルづつ、3個のグループに分割したときのことを考えてみましょう。
まず、第1グループと第2グループの合計 100 サンプルを学習データとして SVM を作成します。
そして、残りの第3グループの 50 サンプルを評価用データとして正答率を出します。
次に、第1グループと第3グループを学習データ、第2グループを評価用データとして正答率を出します。
最後に、第2グループと第3グループを学習データ、第1グループを評価用データとして正答率を出します。
これを表にすると次のようになります。
SVM のチューニングのしかた(1) - ほくそ笑む
