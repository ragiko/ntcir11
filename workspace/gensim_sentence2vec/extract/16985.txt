大語彙連続音声認識の枠組みで必要不可欠とされている言語モデルには,長らくブレークスルーがないというのが現状であろう.実用的な言語モデルとして広く利用されているn-gramモデルには,``モデル制約の局所性'',``モデルのタスク依存性'',``データスパースネス''といった問題があることは明白であるが,これらの問題を個々に解決するだけでは大幅な性能改善を得るに至っていない.この現状に対して我々は,大幅な性能改善を実現するためには,これら複数の課題を同時に解決していくことが重要なのではないかと考えている.そこで本稿では,言語モデルの課題を全体的に解決できた場合に,どの程度の性能改善を実現できるのかを明らかにするために,これまで提案されてきた様々な言語モデリング技術を併用することを試みる.我々は現状の言語モデリング技術に対して,``1パスデコーディング'',``教師なし適応'',``リスコアリング''という3つの観点を設け,観点ごと,および全体で技術併用を行った場合の性能を調査する. 
Recent large vocabulary speech recognition systems consist of two statistical models, the acoustic and language models. In acoustic modeling, deep neural networks have realized a breakthrough and significant performance improvements have been achieved. On the other hand, in language modeling, there have not been any reports of comparable improvements. Although it is clear that recent practical language models have several problems such as ``locality'', ``task dependency'' and ``data sparseness'', we cannot obtain significant performance improvements by solving these problems separately. In this paper, we try to use various language modeling techniques simultaneously to cover the entire problem. Our investigation is conducted by dividing language modeling techniques into three viewpoints, ``one pass decoding'', ``unsupervised adaptation'' and ``rescoring''.Recent large vocabulary speech recognition systems consist of two statistical models, the acoustic and language models. In acoustic modeling, deep neural networks have realized a breakthrough and significant performance improvements have been achieved. On the other hand, in language modeling, there have not been any reports of comparable improvements. Although it is clear that recent practical language models have several problems such as ``locality'', ``task dependency'' and ``data sparseness'', we cannot obtain significant performance improvements by solving these problems separately. In this paper, we try to use various language modeling techniques simultaneously to cover the entire problem. Our investigation is conducted by dividing language modeling techniques into three viewpoints, ``one pass decoding'', ``unsupervised adaptation'' and ``rescoring''.
研究会 - 日本語話し言葉音声認識における複数言語モデリング技術併用時の性能評価
