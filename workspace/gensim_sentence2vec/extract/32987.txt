
モデルの精度を推定する
代替推定法
テストサンプル法
交差検証法
これまでの説明で、決定木による分類モデルがどのようなものか分かってもらえたと思います。次にモデルの精度について話を進めていきましょう。分類モデルの生成では、その精度(Accuracy)が非常に重要となります。分類モデルを構築しても、未知のデータを当てはめればいつも「はずれ」では困ります。
分類モデルにおける精度とは、全ケース(ゴルフの例では14件)をモデルに当てはめたとき、何件のケースが正しく分類されているかを率で表したものです。ゴルフの例では、14件のケースを全て正しく分類しているので、精度は100%となります。
しかし、これら14件のデータは、「解答」、すなわちゴルフをしたかしなかったが分かっているデータですので、それらのデータのみを正確に分類できるモデルを作成できることはあたりまえです。問題は、そこで作ったモデルが未知のデータにも対しても正確であるかどうかです。
これは、受験勉強に例えることができます。参考書の問題を「解答をみながら」解いていけば、参考書に載っている問題ならばどのような問題でも100%正解できるようになるでしょう。だからといって、本番のテスト(解答は見れない!!)でも良い結果が得られるとは限りません。 
そこで、何らかの方法で未知のデータに対するモデルの精度を推定してやる必要がでてきます。受験勉強で言えば、「あなたは大学に合格できる確率は60%です」といった目安が必要になってきます。モデルの精度の推定(Accuracy estimation)には大きく次の3つの方法があります。
a) 代替推定法(Resubstitution estimate)
これは非常に単純な考え方で、上記の例で言えば、決定木(d)で表されたモデルに、そのモデルを構築したケース(N件とする)を再度あてはめ、どのくらい正確に分類される(t件とする)かをそのままモデル精度の推定値としてやろうという方法です。代替推定法による精度A(d)は次の式で表されます。
しかしこれは、モデルの構築に使ったデータをそのまま精度推定のために使っているので、非常に楽観的な推定法(高い精度になる)であると言えるでしょう。
b) テストサンプル法(Test sample estimate)
そこで、モデルを構築するためのデータと、その精度を推定するためのデータを予め分けて用意する方法がテストサンプル法です。まず基のデータを、トレーニングデータとテストデータと呼ばれる二つのデータにランダムに分割します(分割の比率は、テストデータを1/3、トレーニングデータを2/3とするのが一般的です)。また、両データとも、元のデータを代表するようなデータであることが望まれます。例えば、トレーニングトデータに「ゴルフをする」ケースが全く含まれていなかったり、気温が高いケースばかりが含まれていては問題です。そこで通常は「層化(Stratification)」と呼ばれる手法が用いられます。もとデータからサンプリングを行なう際に、各属性の値の分布が、元データの分布と同じようになるようにサンプリングするのです。
モデルの生成はトレーニングデータ(解答付きデータ)を用いて作成し、そのモデルにテストデータを当てはめます。そしてテストデータにおける分類精度を、そのモデルの精度とします(下図参照)。受験勉強で言えば、参考書のいくつかの問題を解答を見ずに解いて見て、どのくらい正解するかを確かめることに当たります。
テストデータの総件数をNtsとし、そのうち、モデルに当てはめて実際に正解であった件数をttsとすると、テストサンプル法による推定精度Ats(d)は次式で表されます。
c) 交差検証法(n-flod cross-validation estimate)
テストサンプル法は、データ量が十分ある場合には問題になりませんが、データ量が少ない時には、テストデータの選び方によって、推定精度に大きな誤差が生じる可能性が高くなります。そのような場合には、ここで説明する交差検証法が使われます。この方法では、まず元のデータをn個のブロックに分割します(通常nとしては10〜20の値が用いられます)。その際、各ブロックに割り当てられる件数が同程度になるようにします。また各ブロックとも、層化されていることが望まれます。
そしてまず、一つ目のブロックをテストデータ、その他のブロックをトレーニングデータとして、モデルの構築と精度の算出を行ないます。次に二つ目のブロックをテストデータとし、その他のブロックをトレーニングデータとし、モデル構築を行なっていきます。このような手続きをn回繰返し、各回で算出された精度の平均を、モデルの推定精度としようというものです。お気づきと思いますが、各回の試行は、テストデータの割合が1/nによるテストサンプル法であることがわかります。
交差検証法を使うと、全てのケースが、一回はテストデータとして選ばれ、なおかつ見かけ上元データのn−1倍の件数のトレーニングデータを用いてモデルを構築したことになり、少ないデータであっても推定誤差が少くなります。
下の図でn回目に構築された決定木をdnとし、その精度をAts(dn)とすると、交差検定による推定精度Acv(d)は次の式で与えられます。

