人の音声の発話では,調音器官の運動特性に起因したなまけや,音素環境に依存した調音特徴の変動などが生じる.本研究では,このような調音結合に由来した声道スペクトルの変動を陽な仕組みとして表現するため,調音器官の状態を表すパラメータを基とした声道スペクトルの生成モデルの構築をおこなった.本モデルでは,まず,発話内容を表す音素列に対して,調音タイミングの決定と空間的な調音目標の設定とをおこなう.この調音目標は,各音素を調音する上でより本質的な調音的状態とし,なおかつ,調音パラメータの自由度を部分的にのみ拘束する.残された不確定的な自由度は,発話全体の運動軌道の計算において,隣接する音素の調音目標を滑らかに補間する際に解消される.この調音運動モデルによって,音素環境に依存しない固定的な調音目標から,音素環境に起因した調音運動の変動性を表現することができる.最後に,事前に学習を施したニューラルネットワークを用いて,調音運動より声道スペクトルの推定をおこないモデルの出力とする.
This paper presents a model for generating the vocal-tract spectrum based on an explicit model of the coarticulatory phenomena. The model receives a string of phonemic symbols for which the articulatory target is specified both in the spatial and temporal domains. The spatial target represents features of the articulatory state inherent in the articulation of each phoneme. The phonemic target constrains degrees-of-freedom of the articulatory parameters only partly and some freedoms are remained. Then the trajectory formation model of articulatory movements resolves this redundancy by smoothly interpolating the targets of adjacent phonemes. Thus, our model can represent the variability of articulatory movements from fixed target patterns. Finally, the vocal-tract spectrum is estimated using neural networks learned with the articulatory and acoustic data in advance.

