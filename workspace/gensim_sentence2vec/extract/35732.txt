あるタスクについてN-gram言語モデルを作成するには, そのタスクに属する言語資料を大量に集めなければならない. 本稿では, 大量の一般的な言語資料(大量テキスト)と, 小量の特定タスクのサンプル(適応テキスト)から, 特定タスク向きのN-gramを作成する「タスク適応」について述べる. ここで用いているタスク適応法は, 大量テキストと適応テキストとを重みつきで混合するという方法である. まず, この手法とMAP推定, Bayes推定との関係を明らかにする. 次に, 適応時のモデルの語婁の設定法について検討する. 一般的な言語資料には目的のタスクと無関係な単語が多く含まれるため, これらを未知諸として語彙から除外することにより, モデルの精度を高めることができる. 本稿では, 大量テキストと適応テキストの語彙を独立に設定することで, モデルのバープレキシティが低減できることを示す.
While N-gram language model requires large corpus for good probability estimation, it is often difficult to gather large number of samples for a specific task domain. This paper describes task adaptation technique to make N-gram model for the specific domain from a task independent large corpus (TI text) and a task specific small corpus (AD text). Simple weighted mixture is employed to mix two corpora. This paper first points out the relationship between weighted mixture method and MAP/Bayes eatimation. Next, the effect of vocabulary restriction is investigated. As the TI text has many words which don't appear in the object task, perplexity of the model decreases by replacing these words to "unknown" symbol. In this paper, it is shown that perplexity of the model can be reduced by the vocabulary restriction and the vocabulary sizes of TI and AD texts must be determined individually.

