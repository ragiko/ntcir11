ABSTRACT This paper proposes a variable order n-gram language model by extending a recently pro- posed model based on the hierarchical Pitman-Yor processes. Introducing a stochastic process on an infinite depth prediction suffix tree, we can infer the hidden n-gram context from which each word originated. Experiments on standard large corpora showed validity and efficiency of the proposed model. Our architecture is also applicable to general Markov models to estimate their variable orders of generation.
Bayesian Variable Order n-gram Language Model based on Hierarchical Pitman-Yor Processes - ResearchGate
