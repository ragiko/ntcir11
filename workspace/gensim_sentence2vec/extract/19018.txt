前回までいくつか機械学習の入門書を読み、今なら多少読めるのではとPRMLに挑んでみました。
目標はPRML/course - 機械学習の「朱鷺の杜Wiki」で紹介されてる中間(修士)レベルです。どこから読もうかと考えたのですが、上巻は以前読ん(で死ん)だので下巻、それも機械学習の入門書だと省かれることの多いベイズ理論あたりに挑戦しました。PRMLの下巻は6章と7章がSVM関係、8章から11章までがベイズ理論関係、12章が主成分分析、13章が隠れマルコフモデル、14章が決定木と言った構成となっています。
(ちなみに上巻は1章が機械学習の基礎、2章が確率分布、3章と4章が線形回帰/識別モデルの基礎、5章がニューラルネットワークです。)「はじめてのパターン認識」では、線形モデルを最小二乗法からニューラルネットワーク、SVMといった流れで説明し、後半でEMアルゴリズムや主成分分析、決定木を個別に扱っていました。
前半の線形モデルの説明の流れはとてもわかり易いのですが、ベイズ理論でこれにあたるのがPRML下巻の8章から11章だと思います。というわけでこの4章を通して読んだので、その時にどういった資料を参考にしたかを書いていきます。
全体の流れ
ベイズ理論の機械学習への応用例として、現在大きく分けて2つの手法に分けられます。変分推論(10章)とサンプリング法(11章)です。
入門書でも扱われることの多いk-Means法やEMアルゴリズム(9章)は、変分推論の特別なケースであると考えられます。
また、変分推論とサンプリング法は条件付き確率や同時分布を扱うのですが、これを視覚的に扱えるように考案されたのがグラフィカルモデル(8章)です。まず8章で確率に対する感覚を養い、9章でk-MeansやEMアルゴリズムを学び、10章でこれらをベイズ的な枠組みで一般化します。この流れで変分推論に対する理解を深めるのがPRMLの目的だったんですね...変分推論は決定論的なアプローチであり、解析的に計算可能な近似をすることで、大規模な問題にも適用可能な手法です(と言ってもEMアルゴリズムは1次収束ですが)。
これに対し、サンプリング法は数値的なアプローチで近似することを考えます。これは計算量こそ変分推論より多いですが、より一般的に分布の近似に用いることができます。ちょうど長所と短所が対照的になっている訳ですね。
11章では変分推論への対比を意識しつつサンプリングを学びます。
8章
この章は計算もほとんどなく、事前知識も必要ないため、頑張れば他の資料に頼らなくても読み進めることができると思います。
それでも細かい疑問が多かったのですが、sleepy_yoshiさんのPRML読書会での資料(PRML読書会10回: 第8章グラフィカルモデル (前半) - 睡眠不足？！, 
第11回PRML読書会: 第8章グラフィカルモデル (後半) - 睡眠不足？！)が多いに参考になりました。素晴らしいです。
「パターン認識と機械学習」に挑戦 その1 ベイズ理論あたり(8章から11章まで) - old school magic
