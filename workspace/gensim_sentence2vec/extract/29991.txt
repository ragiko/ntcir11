文書分類メモ
自然言語処理
はじめに
文書分類マスターを目指して修行の旅に出るために必要そうな知識を、ざっとメモしておく。(かなり雑だけど・・・)
文書分類とは
テキスト分類、Text Classification
あらかじめ決められたカテゴリ集合に基づき、与えられた文書に適切なカテゴリを付与する事
排他的分類 : 1つのテキストにカテゴリを1つだけ付与される場合
マルチラベル分類 : 1つのテキストに複数のカテゴリ付与を許す場合
基本的には、目的の分類をどのような分類手法に落とし込むか?を考えることになる
主なアプローチとして、以下のような流れで処理する(教師あり分類)
学習データから素性(なんらかの特徴)を抽出し、それらの規則を見つけだす
規則に基づく分類モデルを作成
未知の文書に対して素性を抽出したものにモデルを適用し、分類結果を返す
利用例
内容に関する分類
ニュースジャンル分類
SPAMフィルタ
属性に関する分類
著者同定
言語判定
書き手の属性の推定、デモグラ属性推定
曖昧性解消(カテゴリがわかる事で、単語の曖昧性を解消している)
Webページの階層構造構築
など
分類手法
分類モデルの作成にはいくつかの種類がある。
kNNによる分類
k-nearest neighbor
訓練データ中の各テキストと類似度を計算し、上位k個のカテゴリから判定する
多数決、重み付き多数決など
確率モデルによる分類
訓練データから確率モデルのパラメータ推定を行う
テキストdにカテゴリcがつけられる確率p(c|d)をモデル化し、計算する
NaiveBayesなら、p(c|d)=p(d|c)p(c)/p(d)で、各パラメータを推定
ルールベースによる分類
分類ルールを用意し、それを用いてテキストを分類する
分類ルールは、人手で用意したり、決定木などで訓練データから抽出する
機械学習による分類
文書を素性を要素とするベクトル表現(Vector Representation of Text)で表すことで、各機械学習手法を適用できる
各文書を「正解ラベルと素性ベクトル」で表現しなおす
SVMなどを単体で用いるだけでなく、アンサンブル学習などの複数の分類器を組み合わせる事で高性能な分類を実現する手法など、機械学習の成果を取り入れられる
ランキング学習による分類
教師データとして、文書に正解ラベルがついているという情報ではなく、文書間でどちらがそのカテゴリに関連しているか、の情報を与える事で、カテゴリの関連度のランキングを作る問題と考えられる
教師データの準備
最初から十分な「正解ラベル付きの文書(教師データ)」が得られる場合はそれを利用すればよいが、そうでない場合もありうる。しかし、上記の分類手法の多くは教師あり学習手法で、十分な教師データがあることを前提としている。教師データが十分に用意できない場合は以下のような方法が研究されている。
EMアルゴリズムによる半教師あり学習
少量の教師ありデータと大量の正解ラベル情報なしのデータ使ってEMアルゴリズムに基づいてパラメータ推定を行う方法
正解ラベル情報なしのデータをうまく利用する事を考える
Abney, Semisupervised Learning for Computational Linguistics
Nigam et al., Learning to Classify Text from Labeled and Unlabeled Documents
http://www.kamalnigam.com/papers/emcat-aaai98.pdf
Nigam et al., Text Classificatioin from Labeled and Unlabeled Documents using EM
http://www.kamalnigam.com/papers/emcat-mlj99.pdf
Active Learningを利用した分類性能向上
少量のデータしか準備できない場合、なんらかの戦略に基づき、性能向上の効果の大きい正解ラベル情報なしのデータを選択してアノテーションしていく
闇雲に教師データを増やすのではなく、効率的に増やす事を考える
shuyo, Active Learning入門
http://www.slideshare.net/shuyo/introduction-to-active-learning-25787487
素性設計/素性選択
素性にどのようなモノを使うかで性能が大きく変わる場合が多い。分類のタスクに応じて有効な素性を考える事が重要。
単語の抽出
日本語の文書は切れ目などがないので、なんらかの単位で切り分けなければいけない
連続n文字(文字Ngram)
形態素
フレーズ
固有表現
形態素やフレーズの抽出精度は形態素解析器などの精度に依存する
Twitterや口語表現、くずれた表現、顔文字などが出現する文章の場合、新聞記事を学習データにしているような形態素解析辞書を用いると精度が低いかもしれない
「内容に関する分類」を行う場合
文章中に含まれる単語、特に内容語が有効な場合が多い
形態素unigram、形態素bigram、など
素性値はTF,IDFや各種正規化を行う事で精度を上げられる場合が多い
「属性に関する分類」を行う場合
「内容に関する分類」同様に文章中に含まれる単語は重要
助詞、助動詞、代名詞、文の長さ、単語の長さなども有効な場合がある
ドメイン依存の素性、ドキュメントからとれる素性、メタ情報の利用
扱う文書がどのような特徴を持つかがわかる場合、それを利用する事で精度を改善できたりする
ニュース文などでは最初に重要なことが書かれている場合が多いので、最初の3行だけ利用するなど
その他にもいくつかドキュメントからとれる素性,素性値を利用するなど
品詞、単語の出現位置
固有表現
数量表現、日付
文字Ngram
係り関係、構文情報
文書の長さ
各単語の出現頻度分布
TF(文書中に何回出現したか)
BINARY(文章中に出現したか否か)
DF,IDF(何文書で出現したか、その逆数)
MDF(重複あり出現文書数)
wMDF(重み付きMDF)
など
メタ情報の利用
テキストには著者や出版社、文書公開日時、URLなどのメタ情報が含まれるが、これが分類に有効な場合もあり得る
語義が曖昧な単語は、語義曖昧性解消できなければ誤りになりやすいが、できれば有効な素性になる可能性がある
有効な素性の選択
素性選択(feature selection)をすることで、よりコンパクトなモデルにできたり、ノイズとなる素性が取り除かれる事で精度向上が見込める
素性の種類数が多すぎ&学習データ数が少ない場合に過学習おきやすい
表層などを素性にすると高次元になりすぎる
学習データ数を増やせるならば、がんばって増やす
教師データの準備は高コストなので、難しい場合が多い
「教師データの準備」などの手法を使ったり
学習データ数が増やせないならば、素性数を制限する(次元を削減する)、などが考えられる
ストップワードを除く
よく効きそうな(または、なんらかの統計指標でソートした)素性の上位n個のみ使う(下位を切り捨てる)
単語であれば、DFが1以下の単語は除く、または、素性の値を小さくする
語彙目録(lexicon)を使って一般化した素性を利用する
代表表記に戻す
様々な次元圧縮手法
正則化の利用
など
統計指標を用いて素性を順位付けする場合は以下のようなものがある
自己相互情報量
情報利得
カイ2乗値
相関係数
オッズ比
TF値、DF値、IDF値
GSS, BSS, WSS coefficient
など
精度評価
分類システムの分類結果がどの程度の性能かを評価する
一つの多クラス分類器として評価
分類正解率(マルチラベルならばすべてあっていれば正解か、どうするか)
そのクラスかそうでないかの二値分類を複数考える評価
二値分類での評価指標(TP/FP/FN/TN, pre/rec, f値, acc, など)
システム全体の評価
評価指標の平均値を利用
マクロ平均
マイクロ平均
参考
奥村,高村, 言語処理のための機械学習入門
奥村, 自然言語処理の基礎
萩原ら, 入門 自然言語処理
H. Marmanisら, インテリジェントウェブアルゴリズム
徳永, 日本語入力を支える技術
岡野原, 高速文字列解析の世界 データ圧縮・全文検索・テキストマイニング
當山ら, 集合知プログラミング
北, 言語と計算4 確率的言語モデル
http://arxiv.org/pdf/cs.ir/0110053.pdf
http://nlp.ist.i.kyoto-u.ac.jp/member/kuro/lecture/LIP10/LIP09.pdf
http://nlp.stanford.edu/IR-book/pdf/13bayes.pdf
http://www.infoautoclassification.org/public/articles/Ikonomakis-et.-al._Text-Classification-Using-Machine-Learning-Techniques.pdf
http://www.slideshare.net/shuyo/introduction-to-active-learning-25787487
http://www.slideshare.net/abicky/r-22325351
http://developer.smartnews.be/blog/2013/07/23/bayes-classification-based-channel-categorization-in-smartnews/
Permalink | コメント(0) | トラックバック(0) | 12:33 
文書分類メモ - Negative/Positive Thinking
