私は英語のためのシャノンエントロピーは文字ごとに1.0から1.5ビットであり、知っているといくつかの文字ごとに0.6から1.3ビットという低言うが、私は思っていたし、テキストの大音量で見えるのアルゴリズムを実行してから判断する方法はありませ集団的テキストの期待値は、集団のテキストの文字ごとに0.08ビットを言うのですか?
あなたがその言語の文字列を発生させる要因を持っている場合 entropy rate of a language の数学的な定義は、ソースがあると仮定し、(N-1以前のものを条件と、、、n個の th シンボルのエントロピーの限界である). stationary このようなソースの良い十分な近似が英語のテキストの大規模なコーパスである.  Open national american corpus は(書かれたテキストのすべてのタイプをカバーし、100M文字)かなりいいです.次に、上記の制限を近似するための基本的なアルゴリズムは、テキストで表示されるすべてのn-グラムで、与えられたnに対して、見て、に関わる条件付きエントロピーの定義の中に発生するさまざまな確率の統計的推定を構築することであるエントロピー率の計算.それを行うための full source code は短く、(〜Pythonコードの40行)に簡単です.私は、数学的な定義と完全な実装を含む、はるかに詳細に入り、 blog post about estimating the entropy rate of English recently をやった.また Shannon's original article を含む様々な関連の論文への参照が含まれています.
テキストのシャノンエントロピーの値が推定される.それはこれまでとまったく見つけるために人間の力を超えています.あなたはそれ以上の効率的な圧縮アルゴリズム(PAQ)を実行し、それを予測したり、与えられた文字列の次の文字を予測するために、人間を使用することができます.これらは意味的な知識だけでなく、統計的な知識や文法的な知識を適用されるため、人間は良い仕事をします.短い答え:データ/あなたが持っているテキストだけでなく、可能な圧縮して、経験的に必要なビット数、計算してみてください.それはあなたが数に取り掛かることができるものの具体的なアルゴリズムに依存する.これは、常にちょうど(正確な値が知られることはありませんことを覚えておいてください)​​シャノンエントロピーの上​​限となります.
テキストのシャノンエントロピーを見つけるためのアルゴリズムはありますか?  -- IT専門質問の答え -- 彼山の知識
