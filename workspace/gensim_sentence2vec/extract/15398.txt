本研究の目的は,同時発話を高性能に音声認識することである.認識のためには音源分離が必要であるが,その過程で生じる音響的な歪みや残留雑音により,認識精度の改善幅はある水準に留まる.また,従来用いられてきた独立成分分析による分離は,処理時間が長いことも問題である.本研究では,歪みを含む分離音を用いて音響モデル学習を行うことと,混合音から推定した他者発話スペクトルを減算する音源分離手法を提案する.計算機シミュレーションによる認識実験で,提案法による分離音の認識精度は従来法に比べて約6%改善し,処理時間が約1/5に短縮された.また,分離音を学習データに用いることにより,認識精度がさらに約20%改善されることを示した. 
The purpose of this study is to recognize overlapped speech more accurately. In order to achieve this, it is necessary to separate overlapped speech. However, recognition accuracy is insufficient due to the distortion and residual noise caused by the processing of separation. Also, the conventional methods based on Independent Component Analysis, take heavy computational cost. In this study, we propose to train acoustic models using distorted speech and to separate overlapped speech by spectral subtraction of estimated speech uttered by the other speakers. In a recognition task of simulated overlapped speech, the proposed method improved recognition accuracy by approximately 6% and reduced 4/5 of the computational cost compared with a conventional method. Also, training acoustic models using separated speech improved recognition accuracy by approximately 20%.
研究会 - 同時発話の高性能な音声認識 〜 スペクトル減算による分離の高速化と分離音を用いた音響モデル学習 〜
