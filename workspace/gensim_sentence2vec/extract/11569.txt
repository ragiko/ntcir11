 2006年度と2007年度、同志社大学ビジネススクールに招かれて、技術評価について各3回の講義と、実習レポートを担当しました。この際に、自分自身で手がけた「要約」技術の開発をケーススタディの対象とし、その評価手法の中で、なるべく普遍性、汎用性のあるものを選んで、社会人院生さん達に「是非使ってみて!」と呼びかけました。
それが、「適合率vs再現率」の議論です。 定義は実にシンプルです。何かを検索する、というタスクを考えていただけると分かり易いと思います。あるデータベース(Web全体みたいに巨大なものでもいいし手元のノートPCやタブレット内蔵の文書でもok)の中で、目的の文書群をみつけるための検索式(問い合わせ文)を打ち込みます。その結果返ってきた文書群が右図中の「検索システムの出力S」。そして、実は、データベース全体のどこかにある、「本当の正解A」という文書群があります。 どんなに素晴らしい検索エンジンでも、また、文抽出型の要約システムでもSとAが100%一致することはまずありません。ではそのズレをどう評価するか。 システムの出力結果Sのうち、正しくヒットしたものをHとします。このHは、当然、「本当の正解A」にも含まれるため、上記のベン図(Venn's Diagram) のような包含関係となります。その右に記したように、 H/Aが再現率(Recall)で、 H/Sが適合率(Precision)です。再現率は、「本来の正解のうちどれだけ(何%)をカバーできたか?」という意味なので、カバレージとか、「取りこぼしの少なさ」と読み替えると、すっとアタマに残ると思います。適合率は、英名Precisionの通り、いわゆる精度のこと。システムが「これが正解よ」と拾ったものの中に、どんだけ間違いが混ざってい【ない】かの指標。言い換えれば、「勇み足(誤り)の少なさ」と読み替えることができます。 前にも書きましたが文章要約の厳密な正解を1つに決める、なんて不可能に近いほど難しい仕事でしょう。どの程度の予備知識もった誰が何をするために読むのか?によっても正解が違うし、分量だけでも何通りもありそうです。我に返って考えてみれば、情報検索の正解だって定義するのはとても大変なはずですが、、、それはおいといて。
つまり、【正解が定義できたことにする】と、上図のシンプルな定義、再現率Rと適合率Pとで、精度の定量評価が出来てしまうのがポイントです。 いったん検索や要約を忘れて、PとRを、「なんらかのシステム(人手で一定の手順で処理するのでもok)の出力と本当の正解の食い違いを評価する指標」ととらえてみましょう。実に普遍的、幅広い分野、テーマの評価に応用できそうだと思えませんか? 同志社ビジネススクールでの講義で私が強調させていただいたのは、なんらかの評価を行うとき、なぜ、どういう事情で、ある局面ではPを重視し、別の局面ではRを重視すべきか、正しい使い分けを行うべし、というポイントでした。
例えば、企業の中で、特許のブレインストーミングを行ってある新規事業向けの技術開発を社内で行うべきか否かを決める局面。あるいは、もう製品発表間近で、他社の特許を侵害していないか調べる局面。同じ特許調査でも、P,Rどちらが重要であるかは、局面によって変わってきます。こんなとき、得てして、どうやって正解を定義できるか、すべきかの議論も非常にエキサイティングになってきます。 こう考えていくと、それまで退屈で苦痛だった「評価」の仕事が実にクリエイティブなもの、ととらえることができるのではないでしょうか? 先日の要約特有の評価基準5つを「発明」したときも非常に大きな知的興奮がありました。そんな時に大きく技術が進歩、応用が発展するものだ、という実感をもった瞬間でもありました。
評価指標再論:適合率vs再現率:メタデータが拓くリアルタイムでパーソナルなサービス:ITmedia オルタナティブ・ブログ
