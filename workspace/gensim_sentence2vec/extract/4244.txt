
統計的言語モデル生成装置及び音声認識装置
【要約】言語モデルの適応データにおいて話題や文型などのドメインを考慮して、効率的に統計的言語モデルを生成する。  言語モデル生成部20は、学習用テキストデータメモリ13,14内の学習用テキストデータに基づいてすべての単語を処理対象の単語の前に接続される単語の品詞属性に基づく後向きクラスの品詞クラスに分類し、処理対象の単語の後に接続される単語の品詞属性に基づく前向きクラスの品詞クラスに分類する。次いで、複数の単語が連続したときに固有の読みが与えられる結合単語について後向きクラスについて結合単語内の最先の単語の品詞クラスにクラス分類し、前向きクラスについて結合単語内の最後の単語の品詞クラスにクラス分類した後、処理対象の単語の前の接続と後ろの接続毎に複数の品詞クラスを有する多重クラスN?gramの出現確率を計算してその統計的言語モデルを生成する。
【背景技術】0002連続音声認識における言語モデルの性能は学習データと認識対象のデータのドメインの一致度に強く依存することが知られており、学習データと認識対象のデータのドメインにずれがある場合には性能が大きく劣化する。この問題を解決する手段として言語モデルの適応が一般に用いられる。しかしながら、言語モデル適応においても適応効果は適応元データと適応先データのドメインの一致度に依存するため、適応元データとして適応先データとなるべく近いものを選ぶことが望ましい。ディクテーション等の書き言葉においてはドメインとしては認識対象のデータの話題等が対象となることが一般的であるが、話し言葉を認識対象とした場合、ドメインとして話題等の他に文型も同時に考慮する必要が生じてくる。0003次いで、ドメインの多次元性について説明する。発声音声文を書き下したテキストデータなどのディクテーション等の書き言葉を対象とした言語モデル適応においては、ドメインの違いは話題等の違いとして取り扱われることが多い。この場合ドメインの違いは主として内容語の違いの形で現われ、機能語に対しては変化がないことを意味している。しかしながら、話し言葉においては話題が同じでも話者の立場の違いに伴って文型が変化し、機能語の連鎖に対しても変化を伴うと考えられる。このため、話し言葉におけるドメインの違いとしては話題の他に文型の違いを同時に考慮しなければならないと考えられる。
【解決課題】0004さらに、従来法である単語N?gramベースの適応における問題点について説明する。言語モデル適応におけるドメインの違いとして、話題、文型のように複数の要素を考慮した場合、適応元データとして望ましい認識対象のデータに近いデータの収集は困難になってくる。従って、適応元データとして全てのドメイン要素にたいして違いの少ない適応元データではなく、話題のみ、文型のみのように個々のドメイン要素に対して近い適応元データの組を使わざるを得なくなる。具体的な例を表1に示す。
0005多次元ドメインにおける適応元データと認識対象のデータの組み合わせ———————————————————————————————————                話題(不問)          話題(経済)———————————————————————————————————文型(新聞)                        適応元データD2文型(講演)  適応元データD1      認識対象のデータ(適応先データD3)———————————————————————————————————0006表1に示すように、認識対象のデータとして経済に関する講演データを、適応元データの組として経済に関する新聞データと一般の講演データの2つを用いる場合があげられる。このような場合、従来の言語モデル適応法では全ての適応元データを混合して用いることになるため、適応先データD3と認識対象のデータのずれは大きくなってしまい、単一ドメインの場合と同等の適応効果を得るためにはより多くの適応先データ、すなわち認識対象のデータか必要になってくる。
0007次いで、クラスN?gramベースの適応における問題点について説明する。適応先データの不足を補う方法として、クラスN?gramベースの適応が提案されている(例えば、従来技術文献1「Gareth Moore et al.,Class-based language model adaptation using mixtures of word-class weight,Proceedings of ICSLP-2000, Vol.4, pp.512--515, 2000」参照、)。単語N?gramベースの適応においては、適応先データD3に現われた単語に対してしか適応がなされないのに対して、クラスN?gramベースの適応では適応先データD3に現われた単語が所属する全ての単語に対して適応がなされるため、少量の適応先データD3でも効率的に適応がなされると考えられる。
0008しかしながら、クラスN?gramにおける単語クラスが適応先データD3にとって不適切なものであれば適切な適応は望めない。実際、上述したような適応元データと適応先データの組合わせの場合、次のような問題が生じる。すなわち、適応元データD1では単語Xには必ず単語Aが、適応元データD2では単語Xには必ず単語Bが後続するとする。一方、単語Yには適応元データD1、適応元データD2に関わらず単語Aまたは単語Bが後続するとする。この場合、適応元データD1と適応元データD2の混合データにおいては単語X、単語Yは同じような接続特性を示すことになるため、同一の単語クラスに割り当てられることになり、単語X、単語Yから単語A、単語Bに対する接続特性も同じと見なされることになる。この適応元データの条件で、適応先データD3において単語列X,Aのみが観測されたとするならば、本来適応によって強調したい組合わせは単語X,Aのみであるべきところが、クラスN?gramベースの適応では単語X、単語Yの接続特性は同じと見なされるため単語Y,Aの組合わせまで強調されることになるという問題が生じる。
0009本発明の目的は以上の問題点を解決し、従来技術に比較して、言語モデルの適応データにおいて話題や文型などのドメインを考慮して、効率的に統計的言語モデルを生成し、さらには適応することができる統計的言語モデル生成装置、及び、当該統計的言語モデルを用いて従来例に比較して高い音声認識率で音声認識することができる音声認識装置を提供することにある。
【解決手段】0010本発明に係る統計的言語モデル生成装置は、所定の第1の話題に関する発声音声文を書き下した学習用テキストデータと、上記第1の話題と異なる第2の話題に関する文でありかつ上記発声音声文とは異なる文型を有する文の学習用テキストデータとに基づいて、すべての単語をそれぞれ、処理対象の単語の前に接続される単語の品詞属性に基づく後向きクラスの品詞クラスに分類する第1の分類手段と、上記2つの学習用テキストデータに基づいて、すべての単語をそれぞれ、処理対象の単語の後に接続される単語の品詞属性に基づく前向きクラスの品詞クラスに分類する第2の分類手段と、複数の単語が連続したときに固有の読みが与えられる複数の単語の列である所定の結合単語について、後向きクラスの品詞クラスについて結合単語内の最先の単語の品詞クラスにクラス分類する一方、前向きクラスの品詞クラスについて結合単語内の最後の単語の品詞クラスにクラス分類する第3の分類手段と、上記第1の分類手段と上記第2の分類手段と上記第3の分類手段とによってクラス分類された単語データに基づいて、処理対象の単語の前の接続と後ろの接続毎に複数の品詞クラスを有する単語クラスN?gramの出現確率を計算することにより単語クラスN?gramの統計的言語モデルを生成する第1の生成手段とを備えたことを特徴とする。
0011また、上記統計的言語モデル生成装置において、上記第2の話題に関する別の発声音声文を書き下した学習用テキストデータを適応先データとして用いて、上記生成された単語クラスN?gramの統計的言語モデルに基づいて適応させて、単語クラス間の遷移確率と、単語クラス内の遷移確率とを計算することにより、適応された統計的言語モデルを生成する第2の生成手段をさらに備えたことを特徴とする。
0012さらに、本発明に係る音声認識装置は、入力される発声音声文の音声信号に基づいて、所定の統計的言語モデルを用いて音声認識する音声認識手段を備えた音声認識装置において、上記音声認識手段は、上記統計的言語モデル生成装置によって生成された統計的言語モデルを用いて音声認識することを特徴とする。
【発明効果】0063以上詳述したように本発明に係る統計的言語モデル生成装置によれば、話題と文型の異なる2つの学習用テキストデータに基づいて、すべての単語を後向きクラスの品詞クラスに分類する一方、すべての単語を前向きクラスの品詞クラスに分類し、2つの学習用テキストデータに基づいて、すべての単語をそれぞれ、処理対象の単語の後に接続される単語の品詞属性に基づく前向きクラスの品詞クラスに分類した後、複数の単語が連続したときに固有の読みが与えられる複数の単語の列である所定の結合単語について、後向きクラスの品詞クラスについて結合単語内の最先の単語の品詞クラスにクラス分類する一方、前向きクラスの品詞クラスについて結合単語内の最後の単語の品詞クラスにクラス分類し、上記クラス分類された単語データに基づいて、処理対象の単語の前の接続と後ろの接続毎に複数の品詞クラスを有する単語クラスN?gramの出現確率を計算することにより単語クラスN?gramの統計的言語モデルを生成する。さらに、生成された統計的言語モデルに対して適応先データを用いて適応させて、単語クラス間の遷移確率と、単語クラス内の遷移確率とを計算することにより、適応された統計的言語モデルを生成する。
0064従って、従来技術に比較して効率的に言語モデルを生成し、さらに適応できる。また、生成された統計的言語モデル又は適応された統計的言語モデルを用いて、音声認識装置においては、次の単語の予測精度及び信頼性を大幅に向上させることができるので、音声認識率を大幅に向上させることができ、しかもパラメータ数が増大しないので、使用メモリ容量を低減させることができる。
【図面簡単説明】0065図1   本発明に係る一実施形態である言語モデル生成部20及び言語モデル適応部30とを備えたことを特徴とする連続音声認識装置のブロック図である。図2   図1の言語モデル生成部20によって実行される言語モデル生成処理、並びに、図1の言語モデル適応部30によって実行される言語モデル適応処理を示すデータのフロー図である。図3   図1の言語モデル生成部20によって実行される言語モデル生成処理を示すフローチャートである。図4   図3のサブルーチンである前向き単語クラスの分類処理(ステップS2)を示すフローチャートである。図5   図3のサブルーチンである後向き単語クラスの分類処理(ステップS3)を示すフローチャートである。図6   図1の連続音声認識装置における単語仮説絞込部6の処理を示すタイミングチャートである。
【請求項】
※以下の情報は公開日時点(2002年9月20日)のものです。
請求項1
所定の第1の話題に関する発声音声文を書き下した学習用テキストデータと、上記第1の話題と異なる第2の話題に関する文でありかつ上記発声音声文とは異なる文型を有する文の学習用テキストデータとに基づいて、すべての単語をそれぞれ、処理対象の単語の前に接続される単語の品詞属性に基づく後向きクラスの品詞クラスに分類する第1の分類手段と、
請求項2
上記2つの学習用テキストデータに基づいて、すべての単語をそれぞれ、処理対象の単語の後に接続される単語の品詞属性に基づく前向きクラスの品詞クラスに分類する第2の分類手段と、
請求項3
複数の単語が連続したときに固有の読みが与えられる複数の単語の列である所定の結合単語について、後向きクラスの品詞クラスについて結合単語内の最先の単語の品詞クラスにクラス分類する一方、前向きクラスの品詞クラスについて結合単語内の最後の単語の品詞クラスにクラス分類する第3の分類手段と、
請求項4
上記第1の分類手段と上記第2の分類手段と上記第3の分類手段とによってクラス分類された単語データに基づいて、処理対象の単語の前の接続と後ろの接続毎に複数の品詞クラスを有する単語クラスN?gramの出現確率を計算することにより単語クラスN?gramの統計的言語モデルを生成する第1の生成手段とを備えたことを特徴とする統計的言語モデル生成装置。
請求項5
請求項1記載の統計的言語モデル生成装置において、
請求項6
上記第2の話題に関する別の発声音声文を書き下した学習用テキストデータを適応先データとして用いて、上記生成された単語クラスN?gramの統計的言語モデルに基づいて適応させて、単語クラス間の遷移確率と、単語クラス内の遷移確率とを計算することにより、適応された統計的言語モデルを生成する第2の生成手段をさらに備えたことを特徴とする統計的言語モデル生成装置。
請求項7
入力される発声音声文の音声信号に基づいて、所定の統計的言語モデルを用いて音声認識する音声認識手段を備えた音声認識装置において、
請求項8
上記音声認識手段は、請求項1又は2記載の統計的言語モデル生成装置によって生成された統計的言語モデルを用いて音声認識することを特徴とする音声認識装置。
【技術分野】5B009文書処理装置5B091機械翻訳5B109文書処理装置5D015音声認識
【出願人】株式会社エイ?ティ?アール音声言語通信研究所
【発明者】山本  博史、匂坂  芳典
【出願日】2001年3月7日(13年3ヶ月経過)
【出願番号】2001-063485
【公開日】2002年9月20日(11年9ヶ月経過)
【公開番号】2002-268677
【特許期限】2021年3月7日(残6年9ヶ月)
【状態】未査定
統計的言語モデル生成装置及び音声認識装置 特開2002268677
