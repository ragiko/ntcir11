パイロットタスクの目的
多くの場合、ユーザは自分の欲しいと考えている検索要求を適切に表現する検索
語を、初期検索式としてうまく選択することが困難である。例えば、NTCIR-4の
Webタスクのtitleで与えられている検索式をブーリアンの検索式としてとらえた
場合、3割〜4割の正解文書が、ブーリアンの式を満たさないという事が確認され
ている。
このような文書を取り出すためには、ブーリアン式の完全照合ではなく、確率型
モデルやベクトル空間モデルのような部分照合と組み合わせた文書検索が必要と
なる。しかし、初期の検索式で与えられる検索語が少ない場合(実際にWebで用い
られるような検索語が長くても3語〜5語くらい)には、単純な部分照合では、利
用できる検索語の数が少なくなり、結果として、適合文書と非適合文書を区別す
るための情報が乏しく、ブーリアン式を満たさない文書を上位のランクの文書と
して取り出すことが困難となる。
よって、Web検索などの与えられる検索語が少ないような検索課題では、ユーザ
にとって役に立つ検索語の候補を生成し、検索に利用する支援方法が望まれてい
る。よって、本パイロット・タスクでは、この検索語の選択支援に関する技術を
議論するための基盤となる項目についての検討を行う。
TRECにおける関連Track
TRECで関連するTrackとしては、TREC 7〜9で行われたQuery TrackとTREC 11〜12
で行われているHARD Trackがある。
Query Trackはユーザが持っている情報要求をいかにQueryという形で表すことが
できるのかに注目したTrackで、トピックと適合文書の情報から適切と考えられ
るQueryを生成する方法や、生成したQueryを共有した上で、幾つかのシステムで
検索結果の性能比較を行い、システムとQueryの関係を議論すると言ったことが
行われている。
HARD (High Accuracy Retrieval from Documents) Trackは検索者の興味などの
プロファイル(検索の目的、興味のある文書のジャンル)や、検索者に対する質問
(適合文書の選択など)を積極的に利用することにより、平均的なユーザを想定し
た検索結果ではなく、より、ユーザが欲しいものに直結した検索結果を作成する
ことを目指している。
これらのTrackで行っている検索においては、ユーザは自分の欲しいと考えてい
る検索要求を適切に表現する検索語を、初期検索式としてうまく選択することが
困難であり、それらをクリアにしていくことが検索性能の向上に役立つと考えて
いる点で共通している。
タスク設計に関わる情報
現時点で、具体的なタスク設計と評価の指標が定まっていないが、タスク設計に
関係するであろうと思われる要件の列挙と、それが前提とする評価の手法などの
関連について整理を行う。
タスク設定に関係する視点
ユーザ(判定者)フィードバックの利用
pre-defined  フィードバック (limitted number):あらかじめ用意しておいた検索
式の補完情報を利用する
逐次 フィードバック:TRECのHARDトラックのように、ユーザとのフィードバック
を利用する
疑似 フィードバック:全自動の検索拡張などの検索語の有効性の評価
使える情報
適合文書(pre-defined or 逐次)
ユーザが明示的に与えた適合文書を利用する。自動の場合は、ユーザに予備
検索をしてもらい、その結果を利用。逐次の場合は、上位5件〜10件くらい のプーリングを行うか?何件くらいの適合文書を与えるのが適当か? 
関連分野・カテゴリー(pre-defined(?) or 逐次)
逐次の場合は、検索結果のクラスタリングなどを行った結果などが存在する場合に役立ちそうなクラスタを選択するために使える情報。pre-defined
の場合は、一般的な
カテゴリーわけというのが必要になり、どれくらい適切に行えるのかが不透明 
ユーザ情報(pre-defined or 逐次 or 疑似)
HARDトラックのようなユーザの情報を与える方法、同一ユーザが作った検索
質問をセットとして取り扱う方法などにより、ユーザ情報として利用する。 
評価に関係する視点
検索タスクタイプの違い
サーベイ検索タスクでは、適合文書全体の集合の情報を用いた評価を行って良
いが、ターゲット検索タスクでは、上位数件(10件くらいまで)の検索結果がど
のように変わったかを調べる必要がある。そもそも、ターゲット検索タイプで この様な検索拡張が意味があるのかどうかは不明
ユーザ観点からの評価
ユーザが直感的に役に立ちそうだと思う語を良い検索語だと考え、そのような
語を見つけられるかどうかを評価する。自動で行う場合には、予備検索で見つ けた適合文書中の語から役立ちそうな語をあらかじめ抽出するという方法が考
えられ、逐次で行う場合には、ユーザに個別に判定してもらうことになる.
システム依存の評価(リファレンスシステムの利用を検討)
統計的情報からの評価
検索語の適合文書・非適合文書の弁別性に注目した統計的情報(例えば、
Robertson/Sparck-Jonesの式)や、各検索語が適合文書のどれくらいの割合 を網羅しているかといった指標を用いて評価する。 
検索結果の絞り込みに役立つ語と網羅性に役立つ語
適合する検索結果が膨大なときに、絞り込みを行うのに役立つものと網羅性
の向上に役立つ語があると考えられる。絞り込みへの効果を検討するために は、初期検索の結果集合と適合文書集合の関係を考慮する必要があり、網羅
性の向上という観点からは、補完関係にある語を用いて適合文書の網羅性な どを調べる必要がある。 
検索性能への影響
追加した検索語により検索性能がどの様に変わるかを評価する。実際には、
検索結果による検索語の重み付けの変更などの要素もあるので、どの様に評 価するのが適切なのかは検討の余地がある。 TRECのQuery
Trackのように、同じ検索式を利用した評価を個別の参加者に やってもらう方法も考えられる。 
考えられるタスク
上記のような議論を踏まえて、次のようなタスクを考えている。
ターゲット検索タスクにおける検索語選択の支援タスク
全自動の検索語の提案(ユーザフィードバック:疑似)
利用する情報:初期検索式のみ
提出項目
役に立つ検索語の順序つきリスト
検索語拡張を行った検索結果(上位100件)と初期検索式による検索結果(上位100件)
サーベイ検索タスクにおける検索語選択の支援タスク
全自動の検索語の提案(ユーザフィードバック:疑似)
利用する情報:初期検索式のみ
提出項目:
役に立つ検索語の順序つきリスト
検索語拡張を行った検索結果(上位1000件)と初期検索式による検索結果(上位1000件)
ユーザ選択の適合文書の利用(ユーザフィードバック:pre-defined)
利用する情報:初期検索式+適合文書(3〜5件)
提出項目
役に立つ検索語の順序つきリスト
検索語拡張を行った検索結果(上位1000件)と初期検索式による検索結果(上位1000件)
逐次型のユーザ評価の利用(ユーザフィードバック:逐次)
利用する情報:初期検索式
提出項目
第一次提出項目:検索結果の上位+質問
第二次提出項目:検索結果と利用した検索式と検索語拡張を行った検索結果(上位1000件) 
その他
実際に、逐次型で、ユーザとのインタラクションを行うためには、タスクとして、
相当しっかりとした準備を行う必要があり、コストがかかる。自動型であれば、
最小限のコストで、評価が可能になると思われるが、それで充分なのかどうかは
不明である。
ユーザが元々作成した検索式の質が与える影響が大きいと考えられるが、それを
勘案した評価と言ったことができるかどうかを検討する必要がある。
リファレンスシステムを用意することにより、適合文書群だけに注目して検索式
を作るといった参加も可能であると考えている。
連絡先
上記のタスクに興味のある方、内容について質問やコメントがある場合は以下のメールアドレスまで。
タスクに関する検討,情報交換:
内容に関する議論は本タスクのメーリングリスト(ntc-webj-qt)で行う予定です。興味のある方は誰でも参加できます(ただし,投稿は参加者のみ)。参加希望の方はこちらを参考にしてください
(本メーリングリストはこのページには記載されていません)。不明の際は下記WEBタスク事務局にお問い合わせください。
技術的な質問等:
WEBタスクオーガナイザ ntcweb-org
手続きその他:
WEBタスク管理者 ntcadm-web
Query Term Expansion Task (pilot subtask)
