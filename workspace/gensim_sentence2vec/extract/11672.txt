はじめに
最近の単語重み付け(用語重み付け)の分野ではTF-IDFを差し置いてOkapiのBM25という手法がスタンダードとなっている.
一般的にTF-IDFよりも良い結果が得られると言われ,比較手法としてのベースラインとなっている.
これを実装するためにはTF-IDFに一手間(文書長と平均文書長)加えればよい.
以下がBM25の式である.
出典:http://en.wikipedia.org/wiki/Okapi_BM25
各パラメータは
D:特定の文書
Q:全部の単語
qi:i番目の単語
IDF (qi):単語qiのIDF値
f(qi,D):文書Dの中での単語qiのtf
|D|:文書Dのドキュメントの長さ文書の単語数で置き換えられるはず
avgdl:全文書の平均ドキュメント長
k1:パラメータ 1 < k1 < 2 で1.2や2.0がよく使われるらしい
b:文書正規化をどれだけ効かせるかのパラメータ 経験的にb=0.75がよく使われるらしい
となる.
IDFはOkapiオリジナルでは
N:全文書数
df_i:i番目の単語の文書頻度
である.
しかし,好みでTF-IDFの通常のIDFを使用しても良いと思う.
IDF(qi) = log(N/df_i))
TF-IDFを既に実装している場合にはドキュメントの文書長|D|と平均文書長avldlを新たに計算すれば,BM25を実装することができる.
この式から感じた疑問
クエリが与えられた時のランキングのアルゴリズムみたいに感じる
単語重み付け手法ではないのでは?
どうやらクエリを与えられたときの文書のランキング方法の手法だけど,単語重み付けとしても使えるみたい
クエリをすべての単語と考えればいい
情報検索のランキングに使う際にはすべての単語に対して値を計算する必要はなく,クエリに含まれる単語のみを文書から抜き出して,そのスコアを計算する.そのため,クエリに含まれる単語のみを計算している.
単語重み付けに使うときにはすべての単語で値を計算すれば良い.
【実装してわかったこと】
TFを正規化(割合化)するのとしないのでは重みの値が変わる
確率化しないで使うのが一般的 TF=log(tf,d + 1)の記述より+1してるってことは通常の出現回数を使っている可能性が高い
IDFが負の値をもつ
<Wikipediaより>
IDFのためのいくつかの解釈とその式に若干のバリエーションがあります。元BM25導出では、IDFコンポーネントが由来であるバイナリ独立モデル。
もっとコーパスの文書の半分以上に現れる用語のためにそれを使用する際にIDFについては、上記の式は、潜在的に大きな欠点を示していることに注意してください。これらの用語 'IDFが負であるので、任意の二つほぼ同一の文書、それが含まれていない言葉と1が含まれているいずれかの、後者はおそらく大きくスコアを取得します。これは、より多くのコーパスの半分以上に現れる用語は最終文書のスコアにマイナスの貢献を提供することを意味します。これはしばしば望ましくない動作ですので、多くの実世界のアプリケーションでは、別の方法でこのIDF式に対処します:
・各加数は、一般的な用語をトリミングする、0の床を与えることができます;
負の値をスパっと消し去る?
・IDF関数は、一定のフロアを与えることができ、全く無視されている一般的な用語を避けるために、;
・IDF機能は全く無視される条件を回避するために、負でない、または厳密に正で同様の形状のものに交換することができる。
重みの値を見ての感想
通常のTF-IDFよりもより特徴的な単語(この文書にしか出現しない単語)がTFが弱くても出現するように感じた.
情報検索に応用すると確かにTF-IDFよりも良くなると思う.
Okapi BM25 実装方法 - 旧みずぎわブログ
