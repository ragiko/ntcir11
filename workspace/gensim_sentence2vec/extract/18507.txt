 
1. 音声インターフェース
音声インターフェースは、ボタンを押したり、キーボードを叩く代わりに、自分の声で機器を操作するインターフェースの総称です。分かりやすい例として、カーナビに搭載されている音声による目的地設定や音声案内の機能がありますが、最近では、スマートフォンで利用できる音声インターフェースが利用者の関心を集め、より身近なものとなりました。例えば、スマートフォンに「明日の朝10時から会議」と話しかけると、スケジューラが起動し、「明日の朝10時、会議をセットしました。」と音声で知らせてくれます。また、自分の声で知りたい情報を簡単に検索することも、海外旅行先で日本語で話しかけた内容を英語や中国語など他の言語に翻訳し、店員に合成音声で提示することもできるようになりました。
音声インターフェースが身近になったのは、ハードウェア技術の進歩やワイヤレスネットワークの高速化、クラウド技術の進展が背景にありますが、音声認識などの音声処理技術の進歩、高度化が大きな要因です。
東芝グループは、1980年代から音声処理技術の研究開発を行っており、音声インターフェースを支える各種の基盤技術を長年、研究・開発し、技術を蓄積してきました。その成果は、カーナビやパソコン、スマートフォンの音声インターフェースや音声コンテンツサービス、文書情報の機械翻訳システムなどに活用されています。
2. 音声インターフェースを構成する音声処理の基盤技術
図1に示す通り、音声インターフェースは、利用者の発声内容を自動的に認識するための音声認識、利用者に音声で情報を伝達するための音声合成、利用者の意図を理解して適切に応答するための音声対話、日本語から外国語、外国語から日本語に自動的に通訳するための機械翻訳など音声処理の複数の基盤技術に支えられています。
この中で形態素解析技術はかな漢字交じりの日本語文章を単語ごとに分割し、品詞情報を特定する技術であり、音声認識や音声合成、機械翻訳において、読み情報の付加や構文の解析のため用いられます。また、テキストデータや音声データの学習コーパスは音声認識など上記の音声処理のモデルや辞書の学習のために用いられます。
図1 音声インターフェースを支える基盤技術
3. 実用的な音声認識技術の開発
カーナビやスマートフォンを利用する環境下で心地よく音声入力機能を利用するためには、街角や車中などの雑音環境下でも90%以上の高い認識精度が必要です。また、「明日の天気を教えて」のように対話的に音声を利用できるようにするためには、連続的に発声された音声の認識技術が不可欠であり、さらに友人に話しかけるような砕けた表現に対応するためには話し言葉の音声認識が必要です。
図2は音声認識の主な応用と使用される環境の雑音レベル、音声認識の対象との関係を模式的に示しています。音声認識の対象が孤立的に発声される単語から連続的に発声されたフレーズや文、話し言葉になるに従って、音声認識機能を利用する利用者にとって、認識対象の単語を正確に発声する必要がない、文章を読み上げるような話し方をする必要がない、ふだん通りに話せばよいなど制約が少なくなり、使い易くなります。しかし、音声認識にとっては、認識対象が孤立単語から連続発声された文、話し言葉になるに従い難しいタスクとなり、認識の精度も低下します。
一方、音声認識機能が利用される環境が静かなオフィスから街角や車中など雑音レベルが高くなるに従って、音声認識の精度は低下します。音声認識の機能を様々な環境の中で気軽に利用できるようにするためには雑音に頑健な高精度の音声認識技術が必要となります。
このようなことから、音声認識技術の研究開発は図2の右上方向に進められ、スマートフォンの音声アプリのようにうるさい環境でも高い認識精度が実現されています。
図2 音声認識の応用分野における雑音レベルと認識対象
4. 人間に近い自然な音質と多様な音声の合成
音声合成は、音声を人工的に生成するための技術であり、音声インターフェースを気持ちよく利用するためには明瞭で自然な韻律(イントネーション、抑揚とも呼ばれる)の音声合成が必要です。音声合成の音質は長い間、鼻にかかったこもった音で人間の音声と程遠く、韻律の点でも抑揚のないロボット的な話し方でした。
しかし、最近では、予め収録された大規模な音声データベースに基づいて音声信号を作成するコーパスベース方式と呼ばれる方式により音質は良くなりました。ただ、その一方で、コーパスベース方式では、大規模なメモリと大規模なデータベースを探索処理するための高性能なプロセッサが必要であり、メモリ容量に制約のある機器や処理能力の低い機器への搭載は難しいという問題がありました。
このような課題に対して、東芝グループは、「あ」「い」のような音節単位の短い音声波形(音声素片と呼ばれる)に対して韻律を変更処理して音声を合成する波形編集方式において、「閉ループ学習方式」と言う画期的な手法によりデータ量が少なく、音質に優れた音声合成方式を開発しました。この技術の原理は、合成音声の良し悪しを人間の音声との誤差という形で定式化し、その誤差を最小化する音声素片と韻律パターンを人間の音声データから自動的に学習するところにあります。本技術は、カーナビやビデオゲーム、電子辞書などに広く採用されています。
音質の向上に伴って、インターネット上での音声コンテンツ作成や情報提供などの応用のため、親しみのある話し方やキャラクター性のある声質など多様な合成音が求められるようになってきました。このような要求に対して、様々な声や話し方が合成できる、抑揚や声質を楽しい、悲しいなどの状況に応じて自在に制御できる音声合成方式の研究開発に取り組んでいます。
5. 今後の展望
音声インターフェースのスマートフォンへの搭載により、音声インターフェースは身近なものとなりました。しかし、現在の音声インターフェースは極論するとボタンやキー操作を音声操作に置き換えているに過ぎないと言うこともできます。例えば、スケジュール登録の場面では、キー操作の代わりにシステムが利用者の発話を認識してアプリを起動しています。現状では、「インターネットに接続できない、困った。」とスマートフォンに話しかけても、問題解決に向けたアドバイスは期待できません。
今後は、単純な音声インターフェースから気の利く個人秘書のようなコグニティブ・アシスタントの実現が望まれると思われます。利用者の状況や、時に利用者自身が自覚していない意図をも理解して、適切にアドバイスしたり、情報提供したりなどのサービスが24時間、自動的に提供されれば、利用者の便はより高まり、関連のビジネスも拡大するものと期待されます。コグニティブ・アシスタントの実現のためには、現在の音声処理技術の高度化、高精度化だけではなく、利用者の発話認識を超えた意図の理解、画像や位置など種々のセンサー情報も利用した状況理解、状況認識や判断、アドバイスのための常識や分野知識の獲得、対話フィードバックや情報提供のための合成音声やアバターなどの表現モデルが必要となります。これらの技術の開発に取り組むとともに、これらの技術を融合、統合して、利用者に新たな価値をもたらす製品、サービスの開拓、開発に努めていきます。
<著者プロフィール>
IT社会展望
