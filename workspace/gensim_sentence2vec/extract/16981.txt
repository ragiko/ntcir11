
概要[編集]
プログラミング言語処理系の実装は、一般にインタプリタとコンパイラの2つがある。しかし、相互排他的に2つに分類できるわけではない。なぜなら多くのインタプリタ方式の処理系は、コンパイラが行っているような変換も内部で行っているからである。「インタプリタ言語」あるいは「コンパイラ言語」といった呼称も見掛けることがあるが、これらは単にその言語の規範的実装がインタプリタかコンパイラかを示しているに過ぎない(実際、詳しく調べれば、実験的な程度の実装まで含めれば両方ともあるということも多い)。高水準言語は基本的に抽象であり、(理想的には)特定の実装からは独立している。しかし、動的プログラミング言語のようにインタプリタでの実装が向いている方向性の言語、あるいはその逆もあるということは確かである。
インタプリタがおこなう、コンパイラが行っているような変換のひとつに、高速化などを目的とした、実行時コンパイラによる動的コンパイルがある。
インタプリタはプログラムを逐次機械語に変換して実行する、という説明を仄聞するが、正しくない[2]。そのような動作は動的コンパイルであり、それを行うインタプリタもあるが、全てのインタプリタがそのような動作をおこなうわけではないので、インタプリタの説明とは言えない。
歴史[編集]
世界初の、インタプリタが実装された高水準言語はLISPだと言われている。最初のLISP処理系はスティーブ・ラッセル(英語版)が IBM 704 上に実装した。ラッセルはマッカーシーの論文を読み、マッカーシーも驚いたことにLISPの eval 関数を機械語で実装してみせた[3]。これによりLISPプログラムを実行できる、より正確には「LISPの式を評価」できるLISPインタプリタが生まれた。
インタプリタの長所と短所[編集]
開発サイクルの違い[編集]
プログラム開発中、プログラマは頻繁にソースコードに手を加える。コンパイラの場合、ソースコードを変更するたびにコンパイルし、リンクして実行ファイルを完成させないと、そのプログラムを実行できない。プログラムが大きくなると、ビルドの完了を待っている時間が長くなる。一方、インタプリタではソースコードをそのまま実行するか中間表現に変換するだけなので、ほとんど待つ必要がなく、修正がうまくいったかどうかのテストをより素早く確認できる。
配布[編集]
コンパイラは一般にソースコードを特定のプロセッサアーキテクチャの機械語命令列に変換するので、生成されるプログラムは特定のアーキテクチャのプロセッサでしか動かない。この変換は開発者の環境で一度だけ行われ、そのバイナリが配布され、ユーザー側では変換を行う必要がない。クロスコンパイラを使えば、他のプロセッサアーキテクチャ向けのバイナリを生成することができる。
インタプリタの場合、ソースコードを配布できる。その変換はユーザー側で行う必要があるが、特定のアーキテクチャに依存しないプログラムの配布が可能である。ただし、その場合ユーザーのマシン上に適当なインタプリタが実装されていなければならない。インタプリタとソースコードを同時に提供する必要があるなら、単に実行ファイルを配布した場合よりインストールが全体として複雑化することもある。
インタプリタ用コードは人間が容易に読むことができるため、著作権保護の観点から問題があるとする見方もある。しかし、そのための様々な暗号化やオブファスケーション(英語版)のシステムも存在する。バイトコードのような中間コードを配布する場合、ある程度はオブファスケーションと同様の効果があるが、バイトコードを逆コンパイラあるいは逆アセンブラでデコードすることも可能である。抗逆コンパイル性のあるオブファスケーションを考慮したバイトコードとする設計もありうる。
性能[編集]
インタプリタ最大の短所は、コンパイラよりも実行時の性能が低いことである。この性能差は様々で、時には桁違いとなることもある。プログラムの実行時間はコンパイラよりもインタプリタの方が長いが、コンパイル時間と実行時間を合計すればインタプリタでの実行時間よりも長くなることがある。プロトタイピングとテストにおいては、この差が重要となる。
コンパイラではプログラム内の文の解析を実行前に1回だけ行うが、単純な実装のインタプリタではそれを文ごとに実行時に毎回行うため、実行性能が低くなる。単純な実装のインタプリタでは変数にアクセスする際も識別子とメモリ上の位置のマッピングを確認しなければならず、しかもそれを実行中に何度も行わなければならないので、性能が悪くなる。
単純な実装のインタプリタ方式が速度が遅くなる最大の原因は、一命令ごとにswitch文を実行することにある。現代のCPUはパイプライン方式を採用しており、命令の先読みが可能でないと、実行速度が著しく低下する。switch文の場所が命令の先読みが不可能であるため、単純な実装のインタプリタ方式は遅くなる。単純な実装のインタプリタ方式で実装された処理系を高速化(最適化)するための、最初にとられるステップがswitch文を廃止し、コンパイラ方式に切り替えることである。それゆえ、実装不可能というわけではないが、効果が薄いため、インタプリタ方式で実装する場合は、一般には、制御フロー解析や静的単一代入などを使った、複数の命令を超えての最適化が実装されないことが多い。
インタプリタによる開発の速さとコンパイラによる実行の速さの間で、様々な妥協案が考案されてきた。一部のLISP処理系などでは、インタプリタのコードとコンパイルされたコードが相互に呼び出しあうことができ、変数も共有できる。そのため、あるルーチンをインタプリタで評価しデバッグした後、先行してコンパイルして実行性能を高めつつ、他のルーチンを開発し続けることができる。多くのインタプリタはソースコードをそのまま実行するわけではなく、よりコンパクトな内部形式に変換している。多くのBASICインタプリタは予約語を1バイトのトークンに置換し、それをジャンプテーブルのインデックスとして使用する。PBASICなど一部のインタプリタでは、バイト単位ではなくビット単位でプログラムの短縮を行っており、例えばコマンドを5ビットで表し、一般に16ビットで表される定数をその数値の大きさに対応して可変長(3、6、10、18ビットなど)で表し、アドレスオペランドとして「ビットオフセット」を用意している。多くのBASICインタプリタは独自にトークン化された内部表現を保存し、読み込むことができる。
インタプリタがコンパイラと同様の字句解析と構文解析を行い、その結果生成された抽象構文木を解釈することもある。
バリエーション[編集]
バイトコードインタプリタ[編集]
^ この意味では、CPUは機械語インタプリタであると見ることができる。
^ 伊藤 潔、interpreter and virtual machine : インタプリタと仮想機械、2007年4月22日
^ ポール・グレアムの『ハッカーと画家』(原著 Hackers & Painters, p.185)によれば、マッカーシーは「ラッセルは『ねえ、この eval をプログラムしようか』と言った。…私は『ほう、ほう。君は理論と実際を混同している。この eval は読み物として書いたもので、実際に動かすために書いたものじゃない』と答えた。しかし彼はそれをやってのけた。つまり彼は私の論文にある eval を IBM 704 の機械語にコンパイルして、バグを修正し、それをLISPインタプリタだと宣伝したし、実際それはそのとおりだった。だからその時点でLISPは今日のような形態を本質的に備えていた」と述べたという。
^ AST intermediate representations, Lambda the Ultimate forum
^ A Tree-Based Alternative to Java Byte-Codes, Thomas Kistler, Michael Franz
^ Annoucing SquirelFish
^ L. Deutsch, A. Schiffman, Efficient implementation of the Smalltalk-80 system, Proceedings of 11th POPL symposium, 1984.
インタプリタ - Wikipedia
