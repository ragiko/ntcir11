
ベイズ学習についての基礎的な概念の定義を知りたい方は、
初めてのベイズ学習を参考にしてください。
1. クロス・バリデーションとは
(1) 真の分布 q(x) から n 個の独立なサンプル D=(X1,X2,...,Xn) が
得られたとき、パラメータ w を持つ学習モデル p(x|w) と事前分布φ(w)とを
用いて、逆温度βのベイズ推測をして予測分布をつくり、その予測分布が
真の分布 q(x) に近いだろうと考える方法をベイズ学習といいます。
(普通はβ=1を使います)。
(2) 交差確認法(クロスバリデーション)について説明します。
交差検証法と呼ばれることもあります。
サンプルの集合 D から、ひとつだけサンプルを取り出して、
残りの(n-1)個のサンプルを用いてベイズ学習して予測分布を作り、
別に取り出しておいた残りの1個のサンプルをテストに使うことで
汎化損失を推定することができます。ここで
「ひとつだけサンプルを別に取り出す」という操作は n 通りあるので、
その n 通りの、それぞれについて予測を行ったときの誤差の平均を取ります。
この n 通りの全てについて事後分布を作ってテストを行うには、
相当な根性が必要ですが、時間さえあればやってできないことではありません(注)。
(注意)実は n 通りの全てについて事後分布を作らなくも、ベイズ事後分布を
一度作れば、その補正としてひとつのデータを加えない場合の事後分布を作ることは
容易に実行できます。ただしマルコフ連鎖モンテカルロ法で事後分布を
作っている場合にこの方法で交差確認法を実行すると、パラメータ空間上の平均操作が
発散するなど不安定になることがあることが知られています。
このようにして汎化誤差を推測したものを交差確認損失(Cross Validation loss)と
呼ぶことにします。もちろん、交差確認損失はサンプルの集合 D に依存して
確率的に変化しますから確率変数です。交差確認損失は、汎化損失とは異なる確率変数ですが、
定義から交差確認損失の平均値は汎化損失の平均値と一致します。
(正確には(n-1)個で学習した時の汎化誤差と平均値が一致します)。
(注意)交差確認法には他にも多くの方法があります。データセットを、幾つかの組に
分けたりする場合や、テストのやり方にも、いろいろあります。上記で説明したのは、
「ひとつだけ別に取り出す交差確認(Leave-one-out Cross-Validation)」というものです。
理論的に考える場合は、この確認法を対象とすることが多いようです。
つまり、交差確認法と呼ばれる多くの方法の中で、いちばん、シンプルかつ
本質を含んでいるものではないかと思われます。
2. 正則でも特異でも使える情報量規準
(3) さて、交差確認法とは別の方法で汎化損失を推測する方法があります。
予測分布を用いたときの汎化損失を G と書き、
学習損失を T と書き、汎関数分散を V と書きます。
WAIC(広く使える情報量規準, Widely Applicable Information Criterion)を
交差確認法(クロスバリデーション)
