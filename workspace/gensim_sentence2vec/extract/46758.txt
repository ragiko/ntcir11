項目応答理論(こうもくおうとうりろん)または項目反応理論(こうもくはんのうりろん)、略称IRT (Item Response Theory; Item Latent Theory) は、評価項目群への応答に基づいて、被験者の特性(認識能力、物理的能力、技術、知識、態度、人格特徴等)や、評価項目の難易度・識別力を測定するための試験理論である。この理論の主な特徴は、個人の能力値、項目の難易度といったパラメータを、評価項目への正誤のような離散的な結果から確率論的に求めようとする点である。
IRTでは、能力値や難易度のパラメータを推定し、データがモデルにどれくらい適合しているかを確かめ、評価項目の適切さを吟味することができる。従って、試験を開発・洗練させ、試験項目のストックを保守し、複数の試験の難易度を同等と見なす(例えば異なる時期に行われた試験の結果の比較をする)ためにIRTは有用である。また、コンピュータ適応型テスト (Computerized Adaptive Testing) もIRTによって可能になる。
より古典的なテスト理論(素点方式、偏差値方式)と比べると、IRTは、試験者が評価項目の信頼性の改善に役に立つ情報を提供し得る、標本(受験者)依存性・テスト依存性にとらわれずに不変的に受験者の能力値とテスト項目の難易度を求められる、という利点がある。
欧米諸国では既に広く使用されているが、日本で試験にIRTを用いるようになったのは最近のことである。
概要[編集]
例えば、4択問題100問、配点が1問につき10点で構成され、600点で合格出来るテストを考える。この場合、全く問題に対する知識がない者でも、全ての選択肢を埋める事が出来れば理論上250点は正解出来てしまい、テストが50問ずつ違うジャンルで構成されている場合は片方のみ完璧に仕上げれば、後はまぐれ当たりでも理論的には合格できてしまう。また、きちんとした知識があれば50問のうち大半が正解できて然るべき問題群で12問前後当てられてしまう事もあり、正確な実力判定が難しくなる。 さらに、平均点が低い=実力不足なのか問題が難しかったのかという判定も相対的な尺度でしか確認できず(逆も同じ)、例えば1000点満点獲得した受験者は500点の受験者に比べて単純に実力が2倍あるという訳ではない。
項目応答理論ではこう言った運や問題の難易度による実力判定の困難さをもたらす要素をなるべく排除し、受験者の実力を正確に図ろうとする理論と言える。具体的には下記のモデルを用い、例えば10問の問題群で知識があれば8問以上解けて然るべき問題で散発的にしか正解出来ない場合はまぐれ当たりとみなし、1問あたりの配点を10点未満にするという処置を取れる。
IRTモデル[編集]
一般的なモデルでは、項目への離散的な応答(正誤など)の確率が、1つの人パラメータと1つ以上の項目パラメータによる関数であるという数学的な仮説に基づいている。用いられる変数は以下の通りである。
:人パラメータ
各受験者の特性の大きさを表す実数値。
:識別パラメータ
項目iが被験者の能力を識別する力を表す実数値。
:難易度(困難度)パラメータ
項目iの難しさを表す実数値。一般的には各項目に50%の正答率を持つ被験者の能力値を基準として決められている。
:当て推量パラメータ
多肢選択形式のテストの場合に、項目iに被験者が偶然に正答できる確率を表す実数値。
基本的な考え方としては、人パラメータと、項目の難易度パラメータの差をとり、ロジスティック曲線に当てはめて、正答する確率を求めるというものである。例えば能力試験において、ある項目が被験者にとって非常に簡単であった場合、その正答率は限りなく1に近づき、逆にある項目が被験者にとって非常に難しいものであった場合、その正答率は限りなく0(パラメータcを用いる場合は)に近づく。
最も簡単な1パラメータロジスティック (1PL) モデル(ラッシュモデルとも呼ばれる)では、変数にとのみを用いる。しかし適用のための条件は厳しくなっている。このモデルでは、項目iに正答する確率は次の式で与えられる。
項目応答理論 - Wikipedia
