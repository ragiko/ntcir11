画像の検索やクラスタリング,自動アノテーションといった技術の高度化を目的として,概念間の意味的な距離(本稿ではこれを``概念間距離''と呼ぶ)をタグ付き画像の集合から算出する手法が種々検討されている.従来の概念間距離算出手法は,タグの共起性を利用するものと画像特徴を利用するものに大別される.しかし,前者には,1枚の画像に内包される2概念が必ずしもタグとして共起するとは限らないという問題,後者には,抽象的な概念において,概念の意味内容が必ずしも画像特徴とうまく対応しないという問題がある.そこで本稿では,タグ共起に基づく手法と,画像特徴に基づく手法が互いに補完されるように両者を統合することを試みる.特に,抽象度の低い概念に対しては画像特徴を重視し,抽象度の高い概念に対してはタグ共起を重視するような重み付けを行うことで概念間距離尺度の改善を目指す.実験により,タグ共起,画像特徴に基づく手法をそれぞれ単独で用いた場合よりも,提案手法の方がより良好な結果が得られることを確認した. 
In recent years, methods for calculating semantic distance between various concepts from a set of tagged images have been actively studied due to their applicability to image retrieval, clustering, annotation, and so on. 
Most of the existing distance calculation methods can be divided into two categories: the methods based on tag co-occurrence and those based on visual features extracted from the images. The former has a drawback that two similar concepts do not necessarily co-occur as text tags even if they are concurrently presented in an image. On the other hand, the latter has a drawback that visual features do not correspond directly to semantic meaning of concepts due to the semantic gap, especially in the case with abstract concepts. To overcome these drawbacks, in this paper, we propose to combine the above two types of methods by adaptively weighting each of them according to the level of abstraction for each concept. In our experiments, our proposed method outperformed the methods using only either tag co-occurrence or visual features.
研究会 - 画像情報とテキスト情報の重み付き統合による概念間距離尺度の改善
