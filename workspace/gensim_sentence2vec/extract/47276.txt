言語モデルをサブワードモデルに置換えた汎用LVCSRエンジンを利用し,対話音声中のキーワードを高い精度で抽出する方法を研究している.これまで,汎用エンジンが持つ固有言語モデルの制約を緩めると共に,認識結果の音素列に音素弁別特徴(DPF)ベクトルに基づくキーワードスポッティングを適用する方式を提案し,道案内タスク対話音声中のキーワード検出実験から,この方式が置換・脱落・付加誤りの少ないことを報告した.本報告では,日本語の全ての音節構造を考慮したサブワードモデルを利用することにより,少ない語彙数(20k辞書の1/40)で高い精度を維持することができることを示す.これによりメモリと計算負荷を大幅に低減できる.汎用エンジンの20k辞書(0-gram)との比較実験では,.最初に(a)汎用エンジン中の音節長の短い単語のみを辞書に登録(辞書サイズ1/2)することで同等の性能が得られることを示す.次に,(b)辞書中の単語から短音節単位サブワードモデルを作成することを検討し,2短音節の3-gramで同程度の性能が得られることを示す.最後に,(c)新聞記事から得られる日本語の全ての音節構造を検討し,短音節,長母音音節,發音付き音節,促音付き音節,二重母音音節をサブワードとして採用することで,20k辞書と比較し1/40の登録項目で同等の性能が得られることを示す.
This paper describes a method for spotting key-words in spontaneous speech using a general-purpose LVCSR engine with sub-word model and distinctive phonetic feature (DPF) vector. The proposed method takes advantage of the potential abilities of (1) precise phoneme recognition in the LVCSR engine and (2) coping with.the issues bf substitution, deletion and insertion errors by combining a process of conversion from a phoneme into a DPF vector and a key-word spotting process. In this report, firstly we show (a) a language model (LM) of word sequences selected from an original LM of the LVCSR engine with 20k vocabulary words and composed of within three Japanese short syllables gives equivalent performance in comparison with the 20k-words LM. Next, we design a sub-word LM using the 20k vocabulary words and show (b) a trigram LM of sub-word sequences composed of within two Japanese short syllables can hold comparative performance. Finally, we investigate all the Japanese syllable structures using a news paper corpus and show (c) a bigram LM of sub-word sequences that consists of Japanese short syllables (CV) and long syllables with long vowels (CVV), independent nasal sound (CVN), glottal stop (CVQ), and diphthongs (CV1V2). The proposed sub-word LM that contains all the Japanese syllable structures achieves high performance with only 1/40 vocabulary size of the LM in comparison with the 20k-words LM of the LVCSR engine.

