  
　しかし、上記非特許文献に記載されるような統計的手法を用いた音声合成方式では、正しいＦ０パタンが生成されず不自然な音声になる場合がある。その理由は、統計的手法を用いた音声合成方式では、主に学習データの情報量を基準として学習データ空間を部分空間に分割（クラスタリング）するため、空間内に情報量の粗密状態が発生し、学習データが少ない疎な部分空間が存在するからである。
　この問題を解決する方法の１つとして、さらに大量のデータでモデル学習するという方法が考えられる。しかし、大量の学習データを収集するのは困難であり、また、どのくらいのデータ量を収集すれば十分であるかが不明であるため、現実的ではない。
　以上より、本発明の目的は、不要に大量な学習データを収集することなく、自然性の高い音声合成を可能にする技術を提供することである。
　上記目的を達成するため、本発明の音声合成システムは、音声波形データから抽出された特徴量の集合である学習データを格納する学習用データベースと、前記学習用データベースが格納する学習データに関する空間である特徴量空間を、部分空間に分割する特徴量空間分割手段と、前記特徴量空間分割手段で分割された特徴量空間である各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生して出力する疎密状態検出手段と、前記疎密状態検出手段から出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する発音情報修正手段と、を含む。
　上記目的を達成するため、本発明の音声合成方法は、音声波形データから抽出された特徴量の集合である学習データを格納し、前記格納する学習データに関する空間である特徴量空間を、部分空間に分割し、前記分割された特徴量空間である各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生して出力し、前記出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する。
　上記目的を達成するため、本発明の記録媒体が格納するプログラムは、音声波形データから抽出された特徴量の集合である学習データを格納し、前記格納する学習データに関する空間である特徴量空間を、部分空間に分割し、前記分割された特徴量空間である各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生して出力し、前記出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する、処理をコンピュータに実行させる。
　本発明の音声合成システム、音声合成方法、および音声合成プログラムによれば、不要に大量な学習データを収集することなく、自然性の高い音声合成を可能にすることができる。
本発明の第１実施形態に係る音声合成システム１０００の構成例を示すブロック図である。 本発明の第１実施形態に係る音声合成システム１０００の動作の一例を示すフローチャートである。 本発明の第２実施形態に係る音声合成システム２０００の構成例を示すブロック図である。 特徴量空間分割部１において学習された結果として、二分木構造クラスタリングで作成された決定木構造の模式図である。 特徴量空間分割部１による学習データのクラスタリング結果を表す、特徴量空間の概念的な模式図である。 音声合成システム２０００における、韻律生成モデルを作成する準備段階の動作の一例を示すフローチャートである。 音声合成システム２０００における、実際に音声合成処理を行う音声合成段階の動作の一例を示すフローチャートである。 本発明の第３実施形態に係る音声合成システム３０００の構成例を示すブロック図である。 音声合成システム３０００における、韻律生成モデル及び波形生成モデルを作成する準備段階の動作の一例を示すフローチャートである。 音声合成システム３０００における、実際に音声合成処理を行う音声合成段階の動作の一例を示すフローチャートである。 第２実施形態に係る音声合成システム２０００を実現するハードウェア構成の一例を示すブロック図である。 
　まず、本発明の実施形態の理解を容易にするために、本発明の背景を説明する。
　非特許文献２に記載されるような統計的手法を用いた技術では、正しいＦ０パタンが生成されず不自然な音声になる場合がある。
　具体的に説明すると、例えば、「人」（２モーラ）、「単語」（３モーラ）、「音声」（４モーラ）といった数モーラ程度の学習データは十分な数が存在する。ここで、モーラとは、一定の時間的長さをもった音の文節単位であり、日本語では一般に拍とも呼ばれる。そのため、統計的手法を用いた技術は、数モーラ程度の音については正しいＦ０パタンを生成することができる。しかし、例えば「アルバートアインシュタイン医科大学」（１８モーラ）のような学習データは極端に数が少ない、あるいは存在しない恐れがある。そのため、このような単語を含むテキストが入力された場合、Ｆ０パタンが乱れてしまい、アクセント位置がずれる等の問題が発生する。
　以下に説明される本発明の実施形態によれば、疎な部分空間に属するような発音情報は修正される。そのため、本発明の実施形態によれば、学習データ不足を要因とした音声合成の不安定性を回避することができ、自然性の高い合成音声を生成することが可能となる。
　以下、本発明の実施形態について図面を参照して説明する。なお、各実施形態について、同様な構成要素には同じ符号を付し、適宜説明を省略する。また、以下の各実施形態では日本語の場合を例に説明するが、本願発明の適用は日本語の場合に限定されない。
　＜第１実施形態＞
　図１は、本発明の第１実施形態に係る音声合成システム１０００の構成例を示すブロック図である。図１を参照すると、本実施形態に係る音声合成システム１０００は、特徴量空間分割部１と、疎密状態検出部２と、発音情報修正部３と、学習用データベース４とを含む。
　学習用データベース４は、音声波形データから抽出された特徴量の集合を学習データとして格納する。学習用データベース４は、音声波形データに対応した文字列である発音情報を格納する。学習用データベース４は、時間長情報やピッチ情報等を格納していても良い。
　ここで、学習データである特徴量は、少なくとも音声波形におけるＦ０の時間変化情報であるＦ０パタンを含む。さらに、学習データである特徴量は、音声波形を高速フーリエ変換（ＦＦＴ）して求められるスペクトル情報や各音素の時間長情報であるセグメンテーション情報等を含んでも良い。
　特徴量空間分割部１は、学習用データベース４が格納する学習データに関する空間（以下、「特徴量空間」と呼ぶ。）を、部分空間に分割する。ここで特徴量空間とは、Ｎ個の所定の特徴量を軸とするＮ次元の空間である。次元の数Ｎは任意であり、例えば、スペクトル情報及びセグメンテーション情報の２つの特徴量を軸とした場合、特徴量空間は２次元の空間である。
　特徴量空間分割部１は、情報量を基準とした二分木構造クラスタリング等によって特徴量空間を部分空間に分割しても良い。特徴量空間分割部１は、部分空間に分割された学習データを疎密状態検出部２に出力する。
　疎密状態検出部２は、特徴量空間分割部１で生成された各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生する。疎密状態検出部２は発生した疎密情報を発音情報修正部３に出力する。
　ここで、疎密情報とは、学習データの情報量の疎密状態を示す情報である。疎密情報は、部分空間に属する学習データ群の特徴量ベクトルの平均値と分散値でも良い。
　発音情報修正部３は、疎密状態検出部２から出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する。
　ここで、発音情報とは、音声を合成するために必要な情報であり、発声内容を表現する音素、音節列、アクセント位置等の情報を含んでも良い。
　発音情報修正部３は、学習データが少ない（疎な）部分空間に属する特徴量で表現されるような発音情報を、学習データが多い（密な）部分空間に属する特徴量で表現される発音情報に修正する。
　図２は、本発明の第１実施形態に係る音声合成システム１０００の動作の一例を示すフローチャートである。
　図２に示すように、まず、特徴量空間分割部１は、学習用データベース４が格納する学習データに関する空間である特徴量空間を分割する（ステップＳ１）。
　次に、疎密状態検出部２は、特徴量空間分割部１で分割された特徴量空間の一部である各部分空間における学習データの情報量の疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生する（ステップＳ２）。疎密状態検出部２は、発生した疎密情報を発音情報修正部３に出力する。
　次に、発音情報修正部３は、疎密状態検出部２から出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する（ステップＳ３）。
　以上のように、本実施形態に係る音声合成システム１０００によれば、学習データ不足を要因とした音声合成の不安定性を回避することができ、自然性の高い合成音声を生成することが可能となる。その理由は、音声合成システム１０００は、疎な部分空間に属するような発音情報を修正するためである。
　＜第２実施形態＞
　続いて、本発明の第２実施形態について説明する。
　図３は、本発明の第２実施形態に係る音声合成システム２０００の構成例を示すブロック図である。図３を参照すると、本実施形態に係る音声合成システム２０００は、学習用データベース４と、音声合成学習装置２０と、韻律生成モデル格納部６と、発音情報生成用辞書７と、音声合成装置４０とを含む。
　音声合成学習装置２０は、特徴量空間分割部１と、疎密状態検出部２と、韻律学習部５とを含む。特徴量空間分割部１及び疎密状態検出部２は、第１実施形態と同様の構成である。
　なお、本実施形態では、統計的手法としてＨＭＭを、特徴量空間の分割方法として二分木構造クラスタリングを用いるものとする。統計的手法としてＨＭＭを用いる場合は、クラスタリングと学習を交互に行う場合が一般的である。そのため、本実施形態では特徴量空間分割部１と韻律学習部５を併せてＨＭＭ学習部３０とし、明示的に分割された構成を取らないものとする。しかしながら本実施形態はあくまで発明の実施態様の一例であり、ＨＭＭ以外の統計的手法を用いる場合等の発明の構成は、この限りではない。
　図３を参照すると、音声合成装置４０は、発音情報修正部３と、発音情報生成部８と、韻律生成部９と、波形生成部１０とを含む。発音情報修正部３は、第１実施形態と同様の構成である
　本実施形態において、学習用データベース４には予め十分な学習データが格納されているものとする。すなわち、学習用データベース４は多量の音声波形データから抽出した特徴量を格納している。学習用データベース４は、Ｆ０パタン、セグメンテーション情報及びスペクトル情報を音声波形データの特徴量として格納しているものとする。そしてこれらの特徴量の集合が学習データとして用いられる。また、学習データは１人の話者の音声を収集したものとする。
　本実施形態における音声合成手法は、大きく分けて、音声合成学習装置２０がＨＭＭ学習により韻律生成モデルを作成する準備段階と、音声合成装置４０が実際に音声合成処理を行う音声合成段階の２段階に分けられる。それぞれについて、順を追って説明する。
　まず、ＨＭＭ学習部３０（特徴量空間分割部１及び韻律学習部５）において、学習用データベース４を用いた統計的手法による学習が行われる。
　ＨＭＭ学習部３０において特徴量空間分割部１は、第１実施形態と同様に学習用データベース４が格納する学習データに関する特徴量空間を、部分空間に分割する。具体的には、特徴量空間分割部１は、学習用データベース４が格納する特徴量空間を、二分木構造クラスタリングにより部分空間に分割する。以下では、特徴量空間分割部１によって生成された部分空間のことをクラスタとも呼ぶ。
　図４は、特徴量空間分割部１において学習された結果として、二分木構造クラスタリングで作成された決定木構造の模式図である。図４に示すように、二分木構造クラスタリングとは、学習データを、各ノードＰ１~Ｐ６に配置された質問により２つのノードに分割する処理を繰り返し、最終的に分割された各クラスタの情報量が均等になるようにクラスタリングする手法である。
　例えば図４では、特徴量空間分割部１は、現在のノードに配置された質問に基づいて「ＹＥＳ」と「ＮＯ」のいずれに該当するかを判断して、学習データを分割する。図４の例では、特徴量空間分割部１は、最初にノードＰ１に配置された質問である「当該音素が有声音」か否かに基づいて学習データを分割する。次に、例えば「ＹＥＳ」と判断されて分割された学習データを、特徴量空間分割部１は、ノードＰ２に配置された質問である「先行音素が無声音」か否かに基づいて分割する。特徴量空間分割部１は、このような分割を繰り返して所定の学習データ数に分割された段階で、その分割された学習データを一つのクラスタとする。
　図５は、特徴量空間分割部１による学習データのクラスタリング結果を表す、特徴量空間の概念的な模式図である。図５における縦軸及び横軸は所定の特徴量を示す。
　図５では、各クラスタに属する学習データ数が４つであるような場合を示している。図５には、特徴量空間分割部１によって学習データ数が４つになるまで分割された結果、各クラスタに該当する学習データのモーラ数とアクセント核の型が、どのようになっているかが示されている。ここで、アクセント核の型とは、一つのアクセント句の中で音程が大きく下がる直前の位置を示す類型である。
　なお、図５はあくまで概念を示した模式図であり、軸は２つに限定されない。特徴量空間は、例えば１０個の特徴量を軸とした１０次元の空間でも良い。
　図５に示すように、特徴量空間分割部１は、１０モーラ以上８型以上クラスタのような学習データ数が疎である空間に、大きなクラスタを生成する。このようなクラスタは非常に学習データ数が少ない疎なクラスタとなる。
　特徴量空間分割部１は、部分空間に分割した学習データを、疎密状態検出部２及び韻律学習部５に出力する。
　ＨＭＭ学習部３０は、特徴量空間の分割とともに韻律生成モデルを作成する。
　ＨＭＭ学習部３０において韻律学習部５は、特徴量空間分割部１で分割された特徴量の空間内で、韻律モデルの学習を行い、韻律生成モデルを作成する。すなわち、韻律学習部５は、特徴量空間分割部１における学習データのクラスタリング結果（例えば図４に示す二分木構造クラスタリングの結果）を用いて韻律生成モデルを作成する。
　具体的には韻律学習部５は、クラスタ毎に学習用データベース４が格納している音声波形データに対応する発音情報に対し、どのような韻律を生成すれば良いかを統計的に学習する。韻律学習部５は、その学習の結果をモデル（韻律生成モデル）にし、各クラスタに対応させて韻律生成モデル格納部６に格納する。
　なお、学習用データベース４は時間長情報及びピッチ情報を格納しない構成とし、韻律学習部５が、入力された音声波形データから発音情報に対応する時間長情報やピッチ情報を学習する構成としても良い。
　次に、疎密状態検出部２は、特徴量空間分割部１から入力された学習データにおける各クラスタの疎密状態を検出し、該疎密状態を示す疎密情報を抽出する。疎密情報は、例えば、アクセント句のモーラ数とアクセント核の相対位置に関する分散値でも良い。このとき、例えば図５に示す３モーラ１型クラスタにおいては、全てのデータが３モーラ１型である。そのため、分散値は０となる。
　疎密状態検出部２は、抽出した各クラスタの疎密情報を、韻律生成モデルに対応付けた形で韻律生成モデル格納部６に格納する。または、疎密状態検出部２は、各クラスタの疎密情報と韻律生成モデルを対応付けた対応表等と一緒に、各クラスタの疎密情報を図示しないデータベースに格納しても良い。
　韻律生成モデル格納部６は、韻律学習部５によって作成された韻律生成モデルを格納する。また、韻律生成モデル格納部６は、疎密状態検出部２によって抽出された疎密情報を、韻律生成モデルに組み込んで格納しても良い。なお本実施形態においては、疎密情報は韻律生成モデルに組み込まれているものとする。
　以上が、音声合成学習部２０により韻律生成モデルを生成する準備段階である。続いて、音声合成段階の処理について説明する。
　発音情報生成部８は、音声合成の対象となるテキストが入力されると、発音情報生成用辞書７を用いて発音情報を生成する。
　具体的には、発音情報生成部８は、入力されたテキストに対し形態素解析等により言語解析を行う。発音情報生成部８は、言語解析結果に対しアクセント位置やアクセント句境界といった音声合成のための付加的情報を付与したり、変更したりする処理を行ことで、発音情報を生成する。
　発音情報生成用辞書７は、テキストの言語解析処理に必要なデータや規則に関する情報である言語解析情報を格納する。言語解析情報は、例えば形態素解析のためのデータや規則に関する情報である。
　発音情報生成用辞書７は、言語解析情報の他に、アクセント位置やアクセント句境界位置などの情報である、音声合成のための付加的情報の付加の方法を示す情報を含む。また、発音情報生成用辞書７は、発音情報を生成するためのスコアを格納していても良い。
　例えば、発音情報生成部８に、「アルバートアインシュタイン医科大学」という単語が含まれるテキストが入力された場合を考える。この場合、発音情報生成部８は、発音情報として、日本語読みで「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　ｉ　Ｎ　ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」という文字列を出力しても良い。なお、#65312;#12399;、アクセント位置を示している。
　発音情報生成部８は、発音情報生成用辞書７が格納するスコアを用いて発音情報毎のスコア計算を行って、スコアの高い順に第Ｎ位までの複数の発音情報の候補を生成しても良い。具体的には、発音情報生成部８は「アルバートアインシュタイン医科大学」の発音情報を生成する際に、「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　ｉ　Ｎ　ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」という文字列を発音情報の第１位の候補として生成する。発音情報生成部８は、「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」を第２位、「ａ　ｒｕ　ｂａ−　＠　ｔｏ｜ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」を第３位として、第３位までの発音情報の候補を生成しても良い。なお、#65372;#12399;アクセント句境界を意味する。
　発音情報生成部８は、生成した発音情報を発音情報修正部３に出力する。
　次に、発音情報修正部３は、韻律生成モデル格納部６が格納する各クラスタの疎密情報に基づいて発音情報を修正する。発音情報修正部３は、「発音情報に、疎なクラスタに属するアクセント句が含まれる場合、密なクラスタに属するアクセント句のみを含む発音情報を選択する」という方針で発音情報の修正を行うものとする。
　具体的には、分散値の閾値が設定され、分散値が閾値以上であるようなクラスタに属するアクセント句が修正の対象となる。例えば、６~８モーラ３型クラスタの分散値をσＡ、１０モーラ以上８型以上クラスタの分散値をσＢと仮定した場合、発音情報修正部３は、σＡ＜σＴ＜σＢを満たす分散値の閾値σＴを設定する。
　この場合、３モーラ１型クラスタは分散値が０なので、発音情報修正部３は、「僕は」「枕」といったような３モーラ１型のアクセント句については、修正を行わない。同様に、「核開発（６モーラ）」といったような６~８モーラ３型クラスタに属するアクセント句についても、σＴ＞σＡであるため、発音情報修正部３は修正を行わない。
　一方、「アルバートアインシュタイン医科大学（１８モーラ１５型）」といったような１０モーラ以上８型以上クラスタに属するアクセント句については、発音情報修正部３は、分散値が閾値以上のクラスタに属するアクセント句が含まれないように発音情報を修正する。発音情報修正部３は、発音情報生成部８が生成した他の発音情報を選択することで発音情報を修正しても良いし、発音情報生成用辞書７を参照して発音情報を分割してアクセント句を置換することで発音情報を修正しても良い。
　以下、他の発音情報を選択することにより発音情報を修正する方法を具体的に説明する。発音情報生成部８は、「アルバートアインシュタイン医科大学」という単語の発音情報を生成する際に、スコアの高い順に第Ｎ位まで発音情報の候補を、発音情報修正部３に出力する。
　ここでは、発音情報修正部３は、第３位までの発音情報の候補が入力されるものとする。候補としては上記で説明したように、第１位は「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　ｉ　Ｎ　ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」、第２位は「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」、第３位は「ａ　ｒｕ　ｂａ−　＠　ｔｏ｜ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」という発音情報であったとする。
　この場合、第１位は１８モーラ１５型であり、σＴ＜σＢである。そのため、発音情報修正部３は、第１位を候補から除外する。
　また、第２位は１２モーラ１０型と６モーラ３型であり、後部のアクセント句はσＴ＞σＡであるものの、前部のアクセント句がσＴ＜σＢである。そのため、発音情報修正部３は、２位を候補から除外する。
　次に、第３位は、５モーラ４型、７モーラ５型、６モーラ３型で構成されており、全ての分散値が閾値以下である。そのため、発音情報修正部３は、この候補を選択する。
　結果として、発音情報修正部３は、「ａ　ｒｕ　ｂａ−　＠　ｔｏ｜ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」という文字列を、修正された発音情報として韻律生成部９に出力する。
　なお、本実施形態の上記の説明では、発音情報生成部８が発音情報の複数の候補を生成し、発音情報修正部３が、第１位の発音情報の候補が疎なクラスタに属するアクセント句を含む場合、疎なクラスタに属するアクセント句を含まない他の発音情報の候補を選択することで、発音情報の修正を行った。
　他の構成として、発音情報生成部８は第１位の発音情報のみを生成するようにしても良い。その場合、発音情報に修正が必要な場合に、発音情報修正部３は発音情報生成用辞書７を参照して、発音情報が密なクラスタに属するアクセント句のみを含むようにアクセント句を置換するようにして修正を行っても良い。
　その場合、発音情報生成部８は、発音情報である「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　ｉ　Ｎ　ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」が疎なクラスタに属する場合、発音情報生成用辞書７を参照する。発音情報生成部８は、発音情報生成用辞書７を用いて上記発音情報を「ａ　ｒｕ　ｂａ−　ｔｏ　ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」に分割して置換する。まだ修正が必要であると判断すると、発音情報修正部８は、上記発音情報を「ａ　ｒｕ　ｂａ−　＠　ｔｏ｜ａ　ｉ　Ｎ　ｓｙｕ　ｔａ　＠　ｉ　Ｎ｜ｉ　ｋａ　ｄａ　＠　ｉ　ｇａ　ｋｕ」に修正して置換する。
　韻律生成部９は、発音情報修正部３により修正された発音情報に対して、韻律生成モデル格納部６が格納する韻律生成モデルを用いて韻律情報を生成する。韻律生成部９は、発音情報と、生成した韻律情報を波形生成部１０に出力する。
　波形生成部１０は、発音情報と、韻律生成部９が生成した韻律情報とを元に、音声波形を生成する。波形の生成は関連する技術に基づいて行えば良く、波形はいかなる方法で生成されても良い。波形生成部１０は、生成した音声波形を合成音声として出力する。
　次に図６及び図７を参照して、音声合成システム２０００の動作の流れを、韻律生成モデルを作成する準備段階と、実際に音声合成処理を行う音声合成段階の２段階に分けて順に説明する。
　図６は、音声合成システム２０００における、韻律生成モデルを作成する準備段階の動作の一例を示すフローチャートである。
　図６に示すように、まず、特徴量空間分割部１は、学習用データベース４が格納する学習データに関する特徴量空間を、部分空間に分割する（ステップＳ１Ａ）。
　次に、疎密状態検出部２は、特徴量空間分割部１が生成した部分空間である各クラスタの疎密状態を検出し、該疎密状態を示す疎密情報を発生する（ステップＳ２Ａ）。疎密状態検出部２は、発生した疎密情報を出力する。
　次に、韻律学習部５は、特徴量空間分割部１で分割された学習用データの空間内で、韻律モデルの学習を行い、韻律生成モデルを作成する（ステップＳ３Ａ）。なお、ステップＳ２ＡとステップＳ３Ａは逆の順序で行われても良いし、並行して行われても良い。
　次に、韻律生成モデル格納部６は、韻律学習部５によって作成された韻律生成モデルと、疎密状態検出部２から出力された疎密情報を格納する（ステップＳ４Ａ）。
　図７は、音声合成システム２０００における、実際に音声合成処理を行う音声合成段階の動作の一例を示すフローチャートである。
　図７に示すように、まず、発音情報生成部８は、音声合成の対象となるテキストが入力されると、発音情報生成用辞書７を用いて発音情報を生成する（ステップＳ５Ａ）。
　次に、発音情報修正部３は、韻律生成モデル格納部６が格納する各クラスタの疎密情報に基づいて発音情報を修正する（ステップＳ６Ａ）。
　次に、韻律生成部９は、発音情報修正部３により修正された発音情報に対して、韻律生成モデル格納部６が格納する韻律生成モデルを用いて韻律情報を生成する（ステップＳ７Ａ）。
　次に、波形生成部１０は、発音情報と、韻律生成部９が生成した韻律情報とに基づいて、音声波形を生成する（ステップＳ８Ａ）。
　以上のように、本実施形態に係る音声合成システム２０００によれば、学習データ不足を要因としたＦ０パタンの乱れを回避することができ、自然性の高い音声合成をすることが可能となる。その理由は、同一のクラスタリング結果に基づいて韻律学習と疎密情報の抽出が行われ、発音情報修正部３が該疎密情報に基づいて発音情報を修正することで、学習データが少ない発音情報が、学習データが十分な発音情報に修正されるからである。
　また、本実施形態では、学習用データベースとして、１人の話者の音声を収集したものを想定したが、複数の話者の音声を収集したものを学習用データベースとしても良い。単独話者の学習用データベースの場合は、話者の癖といった話者性を再現した合成音声を生成できるという効果がある。複数話者の学習用データベースの場合は、汎用的な合成音声が生成できるという効果がある。
　また、音声合成装置４０は、入力テキスト全体で第Ｎ位まで発音情報の候補を生成する構成としても良いし、各アクセント句境界で第Ｎ位まで発音情報の候補を生成する構成としても良い。各アクセント句境界で生成する場合、音声合成装置４０は第１位の発音情報のみを生成し、その発音情報の各アクセント句境界の候補を第Ｎ位まで生成したうえで、スコア計算などを用いたルート検索手法等により、最終的な発音情報を生成しても良い。
　＜第３実施形態＞
　続いて、本発明の第３実施形態について説明する。
　図８は、本発明の第３実施形態に係る音声合成システム３０００の構成例を示すブロック図である。
　図８を参照すると、第３実施形態に係る音声合成システム３０００は、第２実施形態に係る音声合成学習装置２０及び音声合成装置４０に代わって、音声合成学習装置２１及び音声合成装置４１を含み、さらに波形生成モデル格納部１２を含む。
　音声合成学習装置２１は、ＨＭＭ学習部３０に代わって、学習用データベース４を用いて韻律生成モデルと波形生成モデルを生成するＨＭＭ学習部３１を含む。ＨＭＭ学習部３１は、ＨＭＭ学習部３０と同様の構成に加えて、波形学習部１１をさらに含む。
　音声合成装置４１は、発音情報修正部３に代わって、付加的情報の修正を行う発音情報修正部１３を含む。また、波形生成部１０に代わって、波形生成モデル格納部１２を用いて波形を生成する波形生成部１４を含む。
　波形学習部１１は、特徴量空間分割部１で分割された特徴量の空間内で、波形モデルの学習を行い、波形生成モデルを作成する。
　波形生成モデルとは、学習用データベース内の波形のスペクトル特徴量をモデル化したものである。具体的には、特徴量はケプストラム等でも良い。なお、本実施形態においては波形生成のためのデータとして、ＨＭＭにより生成したモデルを用いる。しかし、本発明に適用する音声合成方式はこれに限定されず、別の音声合成方式、例えば波形接続方式を用いても構わない。なお、その場合、ＨＭＭ学習部３１で学習されるのは韻律生成モデルのみである。
　波形生成モデル格納部１２は、波形学習部１１によって作成された波形生成モデルを格納する。
　発音情報修正部１３は、発音情報における、アクセント位置やアクセント句境界以外の付加的情報を修正する。以下では、具体例として、発音情報修正部１３が「ポーズの挿入／削除」、および「言い回しの変更」に関する付加的情報を修正する動作を説明する。
　「ポーズの挿入／削除」に関する付加的情報の修正とは、音声が人間らしいものになるように、「自然な位置にポーズを挿入する」、「不自然な位置のポーズを削除する」といった修正である。具体的な修正内容は、例えば「１つの呼気段落がＮモーラ以下」、「接続詞の後はポーズを入れる」等である。
　また、「言い回しの変更」に関する付加的情報の修正とは、言語として標準的なテキストから生成された言語解析結果を話者特有の言い回しに変更するようなである。例えば「放送」という単語は、通常「ほーそー」という読みが付けられる。しかし話者によってはこれを「ほうそう」とはっきり読む場合がある。これを表す修正内容は、「長音を母音として読む」という内容になる。
　発音情報の修正は、第２実施形態と同様の方針で行われる。具体的には、発音情報生成部８が複数の発音情報の候補を生成する。発音情報修正部１３は、分散値が閾値以上であるようなクラスタに属する発音情報の候補を除外して、分散値が閾値以下であるようなクラスタのみで表現される候補を採用する。もちろん、前述したように、音声合成装置４１は、各アクセント句境界の候補を第Ｎ位まで出したうえでスコア計算などを行って、最良なスコアを取るルートを検索する方法により、最終的な発音情報を生成しても良い。
　具体例として、「そして、放送が開始された」というテキストが入力された場合について説明する。ここでは、発音情報生成部８は、「ｓｏ　ｓｈｉ　ｔｅ｜ＰＡＵ｜ｈｏ−　ｓｏ−　ｇａ｜ｋａ　ｉ　ｓｈｉ　ｓａ　ｒｅ　ｔａ」を第１位、「ｓｏ　ｓｈｉ　ｔｅ｜ｈｏ−　ｓｏ−　ｇａ｜ｋａ　ｉ　ｓｈｉ　ｓａ　ｒｅ　ｔａ」を第２位、「ｓｏ　ｓｈｉ　ｔｅ｜ｈｏｕ　ｓｏｕ　ｇａ｜ｋａ　ｉ　ｓｈｉ　ｓａ　ｒｅ　ｔａ」を第３位として発音情報の候補を生成したとする。なお、#65328;ＡＵ#12399;、ポーズを意味する。
　また、学習用データベース４には、「途中でポーズを入れずに話す」、「『放送』という単語を『ほーそー』ではなく『ほうそう』と発音する」という特徴を持った話者の音声波形データが格納されているとする。この場合、学習データである特徴量空間を分割すると、「『そして』の後のポーズ」というクラスタ、及び「長音化した母音の連続」というクラスタが非常に疎か、又はクラスタとして存在しないことが想定される。
　この場合、第１候補と第２候補については分散が閾値を上回ることになる。そのため発音情報修正部１３は、第３候補を採用することで発音情報を修正する。
　次に図９及び図１０を参照して、音声合成システム３０００の動作の流れを、韻律生成モデル及び波形生成モデルを作成する準備段階と、実際に音声合成処理を行う音声合成段階の２段階に分けて順に説明する。
　図９は、音声合成システム３０００における、韻律生成モデル及び波形生成モデルを作成する準備段階の動作の一例を示すフローチャートである。
　図９に示すように、まず、特徴量空間分割部１は、学習用データベース４が格納する特徴量空間を、部分空間に分割する（ステップＳ１Ｂ）。
　次に、疎密状態検出部２は、特徴量空間分割部１が生成した部分空間である各クラスタの疎密状態を検出し、該疎密状態を示す疎密情報を発生する（ステップＳ２Ｂ）。
　次に、韻律学習部５は、特徴量空間分割部１で分割された特徴量空間内で、韻律モデルの学習を行い、韻律生成モデルを作成する（ステップＳ３Ｂ）。
　次に、波形学習部１１は、特徴量空間分割部１で分割された特徴量空間内で、波形モデルの学習を行い、波形生成モデルを作成する（ステップＳ４Ｂ）。
　なお、ステップＳ２ＢとステップＳ３ＢとステップＳ４Ｂはどのような順序で行われても良いし、並行して行われても良い。
　次に、韻律生成モデル格納部６は、韻律学習部５によって作成された韻律生成モデルと、疎密状態検出部２から出力された疎密情報を格納する（ステップＳ５Ｂ）。
　次に、波形生成モデル格納部１２は、波形学習部１１によって作成された波形生成モデルと、疎密状態検出部２によって抽出された疎密情報を格納する（ステップＳ６Ｂ）。
　なお、ステップＳ５ＢとステップＳ６Ｂは逆の順序で行われても良いし、並行して行われても良い。
　図１０は、音声合成システム３０００における、実際に音声合成処理を行う音声合成段階の動作の一例を示すフローチャートである。
　図１０に示すように、まず、発音情報生成部８は、音声合成の対象となるテキストが入力されると、発音情報生成用辞書７を用いて発音情報を生成する（ステップＳ７Ｂ）。
　次に、発音情報修正部１３は、韻律生成モデル格納部６が格納する各クラスタの疎密情報に基づいて発音情報を修正する（ステップＳ８Ｂ）。
　次に、韻律生成部９は、発音情報修正部３により修正された発音情報に対して、韻律生成モデル格納部６が格納する韻律生成モデルを用いて韻律情報を生成する（ステップＳ９Ｂ）。
　次に、波形生成部１０は、発音情報と、韻律生成部９が生成した韻律情報とに基づいて、波形生成モデル格納部１２が格納する波形生成モデルを用いて音声波形を生成する（ステップＳ１０Ｂ）。
　以上のように、本実施形態によれば、発音情報修正部１３が付加的情報を修正するため、話者ごとの癖といった特徴を忠実に再現できる。また、本実施形態によれば、波形学習と、発音情報の修正に用いる疎密情報の抽出に、同一のクラスタリング結果を用いることにより、疎であるクラスタに属する波形生成モデルで波形を生成した場合、その部分の音質が劣化すると言った問題が回避できる。
　なお、波形生成にＨＭＭを用いない波形接続方式等においても、学習データが疎であるクラスタに属するデータは、対応する単位波形のデータ量も不足している。そのため、本実施形態によれば、波形接続方式等を用いた場合も、疎なクラスタに属するデータを使用しないという点で音質劣化を回避することができるという効果が得られる。
　以上、各実施形態を参照して本発明を説明したが、本発明は以上の実施形態に限定されるものではない。本発明の構成や詳細には、本発明のスコープ内で同業者が理解し得る様々な変更をすることができる。例えば、各実施形態に係る音声合成システムは、抽出した疎密情報を図示しないデータベースに格納しておき、対応表等を参照した適宜利用するようにしても良い。
　図１１は、第２実施形態に係る音声合成システム２０００を実現するハードウェア構成の一例を示すブロック図である。なお、ここでは第２実施形態を例にとって説明するが、他の実施形態に係る音声合成システムも同様のハードウェア構成によって実現されても良い。
　図１１に示すように、音声合成システム２０００を構成する各部は、ＣＰＵ（Ｃｅｎｔｒａｌ　Ｐｒｏｃｅｓｓｉｎｇ　Ｕｎｉｔ）１００と、ネットワーク接続用の通信ＩＦ２００（インターフェース２００）と、メモリ３００と、プログラムを格納するハードディスク等の記憶装置４００と、入力装置５００と、出力装置６００とを含む、コンピュータ装置によって実現される。ただし、音声合成システム２０００の構成は、図１１に示すコンピュータ装置に限定されない。
　ＣＰＵ１００は、オペレーティングシステムを動作させて音声合成システム２０００の全体を制御する。また、ＣＰＵ１００は、例えばドライブ装置などに装着された記録媒体からメモリ３００にプログラムやデータを読み出し、これにしたがって各種の処理を実行する。
　記録装置４００は、例えば光ディスク、フレキシブルディスク、磁気光ディスク、外付けハードディスク、半導体メモリ等であって、コンピュータプログラムをコンピュータ読み取り可能に記録する。記憶装置４００は、例えば、学習用データベース４や韻律生成モデル格納部６等でも良い。また、コンピュータプログラムは、通信網に接続されている図示しない外部コンピュータからダウンロードされても良い。
　入力装置５００は、例えば音声学習装置４０において、ユーザから入力テキストを受け付ける。出力装置６００は、最終的に生成した合成音声を出力する。
　なお、これまでに説明した各実施形態において利用するブロック図は、ハードウェア単位の構成ではなく、機能単位のブロックを示している。また、音声合成システム２０００の構成部の実現手段は特に限定されない。すなわち、音声合成システム２０００は、物理的に結合した一つの装置により実現されても良いし、物理的に分離した二つ以上の装置を有線又は無線で接続し、これら複数の装置により実現されても良い。その場合物理的に分離した二つの装置をそれぞれ音声合成学習装置２０及び音声合成装置４０としても良い。
　本発明のプログラムは、上記の各実施形態で説明した各動作を、コンピュータに実行させるプログラムであれば良い。
　上記の各実施の形態においては、以下に示すような音声合成装置、音声合成方法、および音声合成プログラムの特徴的構成が示されている。
（付記１）
　音声波形データから抽出された特徴量の集合である学習データを格納する学習用データベースと、
　前記学習用データベースが格納する学習データに関する空間である特徴量空間を、部分空間に分割する特徴量空間分割手段と、
　前記特徴量空間分割手段で分割された特徴量空間である各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生して出力する疎密状態検出手段と、
　前記疎密状態検出手段から出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する発音情報修正手段と、
　を含む音声合成システム。
（付記２）
　前記特徴量空間分割手段で分割された特徴量空間である部分空間内で、韻律モデルの学習を行い、韻律生成モデルを作成する韻律学習手段と、
　前記韻律学習手段によって作成された韻律生成モデルと、前記疎密状態検出手段から出力された疎密情報を格納する韻律生成モデル格納手段と、
　前記発音情報修正手段により修正された発音情報に対して、前記韻律生成モデル格納手段が格納する韻律生成モデルを用いて韻律情報を生成する韻律生成手段と、
　をさらに含む付記１に記載の音声合成システム。
（付記３）
　発音情報を生成するためのスコアを格納している発音情報生成用辞書と、
　入力されたテキストに対して、前記発音情報生成用辞書が格納しているスコアを用いて複数の発音情報の候補を生成し、スコアの高い順に第Ｎ位までの発音情報の候補を出力する発音情報生成手段と、
　をさらに含み、
　前記発音情報修正手段は、前記疎密情報に基づき、前記発音情報生成手段が生成した発音情報の候補から、密な部分空間に属するアクセント句のみからなる発音情報の候補を選択する、
　付記１又は２に記載の音声合成システム。
（付記４）
　発音情報を生成するためのスコアを格納している発音情報生成用辞書と、
　前記発音情報生成用辞書が格納しているスコアを用いて発音情報を生成して出力する発音情報生成手段と、
　をさらに含み、
　前記発音情報修正手段は、前記疎密情報に基づいて、前記発音情報生成手段が生成した発音情報に疎なクラスタに属するアクセント句が含まれる場合、前記発音情報生成用辞書を参照して密なクラスタに属するアクセント句で置換することで発音情報を修正する、
　付記１又は２に記載の音声合成システム。
（付記５）
　発音情報を生成するためのスコアを格納している発音情報生成用辞書と、
　前記発音情報生成用辞書が格納しているスコアを用いて発音情報を一つ生成し、該発音情報の各アクセント句境界の候補を第Ｎ位まで生成して出力する発音情報生成手段と、
　をさらに含み、
　前記発音情報修正手段は、前記疎密情報に基づいて、前記発音情報生成手段が生成した発音情報に疎なクラスタに属するアクセント句が含まれる場合、アクセント句を単位としたスコア計算などを用いたルート検索手法により、発音情報を修正する、
　付記１又は２に記載の音声合成システム。
（付記６）
　前記発音情報修正手段は、前記発音情報について、ポーズ挿入位置又は入力テキストの言い回し等を修正する、
　付記１~５のいずれかに記載の音声合成システム。
（付記７）
　前記特徴量空間分割手段は、情報量を基準とした二分木構造クラスタリングによって特徴量空間を部分空間に分割する、
　付記１~６のいずれかに記載の音声合成システム。
（付記８）
　前記韻律学習手段は、前記韻律モデルの学習をＨＭＭ学習により行う、
　付記２~７のいずれかに記載の音声合成システム。
（付記９）
　前記特徴量空間分割手段で分割された特徴量空間である部分空間内で、波形モデルの学習を行い、波形生成モデルを作成する波形学習手段と、
　前記波形学習手段によって作成された波形生成モデルを格納する波形生成モデル格納手段と、
　前記韻律生成手段が生成した韻律情報から、前記波形生成モデル格納手段が格納する波形生成モデルを用いて音声波形を生成し、生成した音声波形を合成音声として出力する波形生成手段と、
　をさらに含む付記１~８のいずれかに記載の音声合成システム。
（付記１０）
　音声波形データから抽出された特徴量の集合である学習データを格納し、
　前記格納する学習データに関する空間である特徴量空間を、部分空間に分割し、
　前記分割された特徴量空間である各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生して出力し、
　前記出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する、
　音声合成方法。
（付記１１）
　音声波形データから抽出された特徴量の集合である学習データを格納し、
　前記格納する学習データに関する空間である特徴量空間を、部分空間に分割し、
　前記分割された特徴量空間である各部分空間に対する疎密状態を検出し、該疎密状態を示す情報である疎密情報を発生して出力し、
　前記出力された疎密情報に基づいて、音声合成に用いる発音情報を修正する、
　処理をコンピュータに実行させるプログラムを格納する記録媒体。
　以上、実施形態を参照して本願発明を説明したが、本願発明は以上の実施形態に限定されるものではない。本願発明の構成や詳細には、本願発明のスコープ内で同業者が理解し得る様々な変更をすることができる。
　この出願は、２０１１年２月２２日に出願された日本出願特願２０１１−０３５５４２を基礎とする優先権を主張し、その開示の全てをここに取り込む。
　以上説明したように、本発明は、情報量が限定された学習データを用いた音声合成システムを構築する際に好適に適用可能である。例えば、ニュース記事や自動応答文等といったテキスト全般の読み上げシステムに好適に適用される。
　１　　特徴量空間分割部
　２　　疎密状態検出部
　３、１３　発音情報修正部
　４　　学習用データベース
　５　　韻律学習部
　６　　韻律生成モデル格納部
　７　　発音情報生成用辞書
　８　　発音情報生成部
　９　　韻律生成部
　１０、１４　波形生成部
　１１　　波形学習部
　１２　　波形生成モデル格納部
　２０、２１　音声合成学習装置
　３０、３１　ＨＭＭ学習部
　４０、４１　音声合成装置
　１００　　ＣＰＵ
　２００　　通信ＩＦ
　３００　　メモリ
　４００　　記憶装置
　５００　　入力装置
　６００　　出力装置
　１０００、２０００、３０００　音声合成システム
Patent WO2012115213A1 - 音声合成システム、音声合成方法、および音声合成プログラム - Google Patents
