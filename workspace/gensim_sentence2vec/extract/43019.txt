
第19回助教の会は情報基盤センターで助教をされています佐藤一誠さんに話をしていただきました．タイトルは「“基礎”からのBayesian Nonparametrics-点過程と機械学習の数理-」ということで，ランダム測度からはじまり機械学習で広く使われている様々な確率モデルとの関係を概観していただきました．今回の話のキモは「フビニの定理」です．今日，自然言語処理や機械学習の分野では「ノンパラメトリック」なベイズモデルが広く使われています．ここでいうノンパラメトリックとは特定のパラメトリックモデルを仮定しない広いクラス（無限次元）のモデルです．ノンパラメトリックなモデルを考えると数学的に難しい部分が出てきますが，フビニの定理を通して眺めるとすっきりするという点は重要であったと思います．
まずはその雰囲気を概観してみましょう．普通のパラメトリックモデルでのベイズモデリングでは次の「ベイズの定理」から話が始まります：
$$p(\theta|x)=\frac{p(x|\theta)\pi(\theta)}{p(x)}.$$
ここで，$\pi(\theta)$はパラメータの事前的な確からしさを表わす事前分布で，$p(x|\theta)$はパラメータ$\theta$のもとでのデータ$x$に対する当てはまりの良さを表わす尤度です．こうして得られた$p(\theta|x)$を事後分布と呼びます．しかしノンパラメトリックモデルの場合，上のように密度関数で割ったりするという操作は必ずしも自明ではありません．そこで，以下のような別の表記を使ってみましょう：
$$\int \int h(x,\theta) p(\theta|x) d\theta p(x) dx = \int \int h(x,\theta) p(x|\theta) dx \pi(\theta) d\theta,$$
ただし$h$は任意の非負関数．ここで，積分の順序が交換されていることに注意してください（内側が$x$に関する積分か$\theta$に関する積分か）．これを「フビニの定理」と呼びます．フビニの定理は無限次元の世界でも（ある条件のもと）成り立ち，確率密度関数で割る操作を陽に行わないで，事後分布を導く一つの見方を与えます．
さて，話の本筋に入りたいと思います．まずはCompletely Random Measure (CRM) から話は始まります．CRMはランダムな非負測度であり，互いに素な集合上の測度は独立になるようなものです．例えば全世界でおきる交通事故の件数の分布を考えると分かりやすいでしょう．ある地域とそれ以外の地域の交通事故の発生件数は独立であるとすると，これはCRMになります．このCRMは自動的に無限分解可能分布の構造を持ち，そのためLevy Processとして表わすことができます．さらにCRMの非負性からガウス成分はなくポアソン成分のみが残ります（Levy-Ito Decomposition）．ちょっと話が難しくなりましたが，要約しますとCRMはポアソン分布とその飛躍の大きさに関する分布で表わせます．先ほどの交通事故の例ですと，交通事故の頻度がポアソン分布に従い，その時の損害金額が飛躍の大きさと考えることができます．ここで，各地域における頻度と飛躍の大きさを表現する関数をLevy measureと呼び，これをいろいろとモデリングすれば様々なCRMを導くことができます（下図）．
例えばLevy measureとしてガンマ分布を用いると (飛躍の大きさをガンマ分布とし，頻度はbase measureで与える)，対応するCRMはガンマ過程と呼ばれます．ベイズモデリングを考えると，ガンマ過程を事前分布とした場合の事後分布を求めたくなります．たとえば交通事故による損害金額の分布を推定する際に，事前分布にガンマ過程を用いて，実際観測されたデータから事後分布を構成することを考えます．その際，役に立つのが先ほど述べましたフビニの定理です．フビニの定理を用いて次々と積分の順序交換をしてゆくことにより事後分布が自然に得られるます．さらにその操作を通じて，Chinese Restaurant Processと呼ばれるサンプリング手法も自然に導かれるとのことです．
ガンマ過程は確率測度を与えませんが（積分して1にならない），正規化することにより確率測度が得られます．ガンマ過程を正規化したものは有名なDirichlet過程になります．Dirichlet過程に関してもフビニの定理をうまく使うことにより，事後分布が自然に求まります．最後に今回話していただいた，CRMからポアソン過程→ガンマ過程→Dirichlet過程という一連の繋がりを包括した概観図を載せておきます（下図）．
数理助教の会: 1月 2013
