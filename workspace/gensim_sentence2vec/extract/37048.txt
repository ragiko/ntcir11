[研究]時刻tじゃない音声認識
去年の12月,古井先生が「なにかが足りない音声認識研究」というタイトルで発表をなさった.
現在までの音声認識研究を振り返った上で,「なにかが足りない,けどそれがなにかは知らない」という内容.
かなり刺激的なお話だったので,各地からいろんな反響(例えばhttp://d.hatena.ne.jp/tihara/20091226)があった.
「なにが足りないのか?」にはいろんな答えがあると思う.答えは一つだけではないと思う.
その上で,僕は
時刻tじゃない音声認識
が一つの答えになるのかなあ,と考えている.
以下,これまで行われてきた変化に着目した音声認識に関する研究を見ながら,自分なりの考えを書きたいと思う.
デルタ特徴量関係
デルタ特徴量は,古井先生が提案された,今やデファクトスタンダードな特徴量.
デルタ特徴量は,時系列の特徴量に対する回帰係数のことで,
具体的には時刻tのフレームの前後Nフレームをみて二乗誤差最小基準とかで回帰した係数になる.
前後を見るフレーム数Nは,HTKのデフォルトで2.
MFCCなど各フレームの特徴量を抽出するときの窓は(音声認識の場合)25ms幅,10msシフト程度のことが多いので,
結局65ms程度の単位で音の変化を見ていることになる.
デルタ特徴量のいいところは,それが手軽に使えること.
MFCCを12次元として,時刻tにおけるΔMFCCが12次元,簡単な計算で求まる.
MFCCとΔMFCCをくっつけて24次元の特徴量にしてしまえば,HMMが出力する特徴量として簡単に導入できる.
そして,簡単に率も上がる.
ΔMFCCの他に,デルタのデルタ,ΔΔMFCCも使われている.これも同様に簡単で,率も上がる.
最近では,もうちょっとNをでかくするとVAD(音声区間検出)に高い効果がある,なんて報告もある(IBMの福田さん等).
Nをでかくすると,当然音の変化を見る範囲がかわる.
Nを15とかにすれば,325ms程度の単位で音の変化を見ることになる.
どの程度の単位で音の変化を見るのがよいのか?に関しては,昔から議論があって,
だいたい60ms〜1000ms(1〜16Hz)あたりがよさそうだという報告があったりする(石川高専の金寺さん等).
ちなみに,僕がやったアフィン変換不変な局所特徴量LAIFの研究で,
LAIFはデルタと同じく時刻tの前後Nフレームから計算できるアフィン変換に不変な特徴量なのだが,
ここでもN=16あたりでもっとも性能が高くなった.
参考:アフィン変換不変性を有する局所的特徴量を用いた音声認識
http://www.gavo.t.u-tokyo.ac.jp/~mine/paper/PDF/2008/SP2008-114_p209-214_t2008-12.pdf
もう一つデルタ関連の話題として,トラジェクトリHMMの話がある.
ΔMFCCはMFCCから計算されるので,MFCCとΔMFCCには依存関係がある.
そのため,MFCC+ΔMFCCのように連結してHMMの出力する特徴量に用いると,
現状の音響モデルとしてのHMMの仮定「すべてのパラメタは直交している」が成り立たなくなってしまう.
つまり,Δは音響モデルの制約条件として導入すべきで,特徴量として連結して使うのはちょっとおかしい.
この辺をちゃんとやっているのがトラジェクトリHMMである(名工大,東芝の全さん等).
トラジェクトリHMMの他にも,声質変換において,Δを制約条件として加える方法なども提案されている(NAISTの戸田先生等).
いろいろ書いたけど,「デルタを使う」というのは今やデファクトスタンダードで,
かなり完成された技術になってきていると言えると思う.
変調スペクトルに対するバンドパスフィルタ
デルタとやや関係するが,変調スペクトル領域でバンドパスフィルタをかけよう,という技術がある.
先に書いた金寺さん等が提案されている手法で,60ms〜1000ms(1〜16Hz)の変化にヒトの聴覚が敏感だから,
その部分のみを通すバンドパスフィルタをかけてやれば,ノイズに頑健になるだろう,という手法.
この手法のオリジナルは誰の提案か正直よくわかってないのだが,
一番メジャーなのはHermanskyらが提案したRASTAだと思う.
(RASTAがやっていることは,金寺さんの手法とほぼ同じ.)
このRASTAだが,僕がちょろっとやった単語音声認識では,結構率があがる.
背景雑音ありで効果があるのはもちろん,雑音なしでもちょっと率があがる.
しかし,RASTAは,あまりデファクトスタンダードになっている感じはしない.
簡単に実装できる演算だから,CMN(ケプストラム平均正規化)
ついでにRASTAもやっちゃえばいいのに,と,ときどき思ったりもする.
音響特徴量に関する研究を除き,各種提案手法とバッティングする技術でもないんだし.
なんであまり使われないんだろう?
「あまりみんな使ってないから」「HCopyのオプションにないから」といったあたりが本音だったりするのかも.
もしそうだとするなら,あまり良くない傾向だと思う.
最近では,変調スペクトルのみならず,時間周波数領域に反応する大脳皮質の存在を理由にして,
時間周波数領域に対するフィルタを設計して特徴量として使おう,といった研究も盛んで,
ブリスベンのINTERSPEECHでスペシャルセッションがあったりした.
このあたりの研究は,効果があることは間違いないので,
今後デルタ並に広く使われるようになるといいなー,と思ったりする.
そのためには,まだあと少しだけ,いろいろ研究をやっていく必要があると思う.
(ただし,この研究が「現在の音声認識に足りない」研究ではない気も同時にする.)
離れたの音との違い
ここまで見たデルタにしろLAIFにしろRASTAにしろ,時間的に隣接した音の動的な変化を捉える手法であった.
しかし,音の変化を捉えるという意味では,別に時間的に隣接した音以外の音からの変化を見ても良い.
例えば,日本人の/r/の発音を評価したいとき,/r/の周辺を見るのも大事だけど,
やっぱり/l/の音とちゃんと区別できているか?が重要になったりする.
/r/と/l/が時間的に近接していなくても,/r/と/l/の変化(違い)を見るのは重要である.
この考え方を実現するために現在広く用いられているのが,この10年急速に発展した音響モデルの識別学習だと思う.
ものすごく簡単に言ってしまえば,
従来の生成モデル的なアプローチでは/r/そのもの,/l/そのものをモデル化していたのが,
識別学習をすれば/r/と/l/の区別がおこないやすいような/r/のモデル,/l/のモデルが得られることになる.
識別学習は,基本モデルありきで,それを音声認識に応用することで研究が進んでいる.
近年音声認識以外の分野で,識別モデル,識別学習が発展しているので,
それを輸入して音声認識用にmodifyして使うという研究が非常にやりやすくなっている.
(とはいっても頭弱い僕には難しく,この辺をしっかりやってる音声認識研究者にはいつも頭が下がります...)
このような音響モデルの識別学習の他に,特徴量レベルで/r/と/l/の違いを見ようとする手法もある.
このような研究の一つとして,Hermansky等が提案しているTANDEMアプローチがある.
これは,時刻tの前後Nフレームを特徴量xにして,context-independentな形でいったん
ニューラルネットかなにかで音素p_i(i=[1...M])の事後確率p(p_i|x)を計算する.
そうして得られたM個の事後確率を,適当に正規化して次元圧縮して,時刻tにおける特徴量とする.
それを連結ベクトルとして加えて,あとは普通のHMMを使った音声認識にかける,というもの.
各種音素の事後確率をだしているのがポイントで,
これにより,/l/とどれくらい似ていて/r/とどれくらい似ているのかが計算され,それが特徴量として含まれることになる.
resultをみると,結構,認識率もあがっている.
なお特徴量をニューラルネットで計算しなおす,といった方法は,新田先生の弁別素性関係でも有名だし,
最近ではASRU2009でD.Vasquezらが時刻tの前後NフレームのNをマルチレゾリューションにして,
Nの最大値もかなり大きくしてニューラルネットにかけることで音素認識率がかなり上がった,という発表があった.
どの発表も率はかなり上がっているので,二段構えのアプローチは実際に有効そうである.
ただし,これらの研究では,「時刻tの特徴量」に縛られてしまっている.
HMMを使って音声認識するには,「時刻tの特徴量」じゃないと使えない.
逆に言えば,「時刻tの特徴量」にしてしまえばHMMが使えるので,「時刻tの特徴量」に縛られてしまう.
(僕がやったLAIFの研究も,出発点は(後述する)音声の構造的表象的な考え方を「時刻tの特徴量」にしよう,というものだった.)
識別学習はモデルありきでそれを音声認識用にmodifyしている.
特徴量でがんばる場合にも,HMMありきなので時刻tにおける特徴量になるように工夫しなければならない.
両方,既にあるモデルありきで研究がスタートしている.
これが悪いことだとはまったく思わないけど,個人的には,そうではない研究があってもいいかと思っている.
具体的には,「時刻tの特徴量にとらわれない」音の変化を捉える特徴量を利用して,モデルはあとで考えよう,というアプローチである.
かなりな勢いで手前味噌だが,今峯松研究室でやっている音声の構造的表象を用いたアプローチが,
時刻tの特徴量にとらわれない音の変化を捉える特徴量を利用するアプローチになっている.
音声の構造的表象とは,音素のようなイベントごとにいったん音声をクラスタリングし,
各イベント間の距離,すなわち/r/と/l/の距離など,をあらゆるイベントペア間で計算して得られるものである.
ここで各イベント間距離としてf-divergenceとよばれる距離尺度を用いると,
話者の違い等に近似的に不変になる性質があるというのがセールスポイントになっている.
(ちなみにLAIFはf-divergenceを無理やり「時刻tの特徴量」化したものである)
これをつかって外国語の発音評価を行った実験では,HMMを用いるより少し精度があがっている.
参考:構造表象と多段階の重回帰を用いた外国語発音評価
http://www.gavo.t.u-tokyo.ac.jp/~mine/paper/PDF/2010/ASJ_1-P-16_t443-446_t2010-3.pdf
構造的表象の無視できない弱点は,まだ統計モデルがしっかりしていないことである.
音素HMMのように音素単位でモデル化できないので,単語音声認識まではできるけど,
大語彙音声認識に利用するのはそのままでは現状無理である.
(だから,僕の場合は外国語の発音評価を扱っている)
もちろん,構造的表象を大語彙音声認識で使うために統計モデルをしっかり作ろう,
という研究もやっているが,まだ実用化にはいたっていない.
参考:A study of Hidden Structure Model and its application of labeling sequences
http://www.gavo.t.u-tokyo.ac.jp/~mine/paper/PDF/2009/ASRU_p118-123_t2009-12.PDF
この話は,構造的表象だけの問題ではない.例えばF0の話.
日本人が自分の耳と脳で音声認識しているときに,F0を利用しているのは間違いないが,
現状の自動音声認識ではF0はほぼ用いられていない.
この理由は,F0をうまくハンドリングする時間単位でのF0モデル化の手法がないことにある(と思う).
まとまってないけどまとめ
デルタにしろRASTAにしろTANDEMアプローチにしろ,
音の変化の情報を捉えようとしている部分がとてもすばらしいと思う.
しかもこれらの手法は,これらは,すべて時刻tに対応する特徴量になるので,
それが「HMMと相性がいいから」これまで高い評価を受けているのだと思う.
モデルのことは忘れて,まず音声を見ていろいろ考える.モデルはあとから考えてもいいのではないか.
モデルのことをいったん忘れて音声を眺めると,
(あくまで個人的には)音声の構造的表象は非常に理にかなった考え方だと思うし,
F0が音声認識に使われていないのはおかしいと思う.
ヒトが音声認識するときに,すべての時刻tをすべて同一に扱っていることなんてなくて,
全体的にぼやっと捉えられている(気がする.あくまで僕の中では.).
現状,手頃な良いモデルがないので音声の構造的表象もF0をつかった音声認識も広く利用はされていないけど,
この先だれかが良いモデル作ってくれるかもしれないし,自分で思いつくかもしれない.
モデルありきで考えていると,本当に大事な音声の本質的な特徴を見逃してしまう気がする.
Permalink | コメント(2) | トラックバック(0) | 13:46   
時刻tじゃない音声認識 - SuzukiMasayuki@Hatena::Diary
