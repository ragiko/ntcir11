この投稿は現実逃避アドベントカレンダー2013の3日目の記事です。
今回の内容を3行でまとめる
前回作った分類器を利用した類似度計算器を作った
カテゴリと入力文字列の類似度を計算できるようにした
コサイン類似度とシンプソン係数を使った類似度が計算できる
Githubにコードをまとめて上げた。 https://github.com/katryo/bing_search_naive_bayes_sim
前回までのあらすじ
Bing APIを利用してWeb検索を行い
クエリをカテゴリ名として、分類器に学習させ
入力した文字列がどのカテゴリに入るか分類させる
こういうシステムを作った。
今回追加した機能
入力した文字列と各カテゴリに入れた文書との類似度計算
さらに詳しく
ベクトル(数学ガールっぽくヴェクタと呼ぶほうが好き)のコサイン類似度の計算
2つの集合のシンプソン係数による類似度計算
の2種類の類似度計算機能を追加した。
理論
2種類の類似度計算方法
コサイン類似度
2つのベクトルのコサインを計算し、コサインの値を類似度とする。ベクトルの次元数は2でも3でも100でもよい(具体例を後述)。ただし次元数が増えると当然計算コストが高くなるので次元数を減らせる工夫(tfidfで頻出すぎる語はカウントしない、とか)ができるならしたほうがいい。ちなみに今回は工夫していない。
シンプソン係数
コサイン類似度とは異なり、ベクトルではなく2つの「語の集合(= Bag of words) 」を比べ、共通して持っている語の数で類似度を計算する。頻度は関係ない。
コードを見てもらえばわかるが、1カテゴリ(あるいは1入力文字列中)に100回同じ単語が出現しても1回だけ出現しても、同じように計算する(だから頻度は関係ない!)。同じ単語が繰り返し登場しても、スコアを高くしたりはしない。
ナイーブベイズの生起確率と類似度
生起確率
ナイーブベイズである語(たとえば「診察」)があるカテゴリ(たとえば「花粉症」)に入る確率を計算するとする。
第一回でも説明したが、その確率はかなり小さくなる。普通のやり方だと0.01より小さくなる。
さらに、今回、分類における入力は語ではなく文章だ。MeCabで形態素解析をしてBag of wordsにして、語の集合として計算しているわけだから、さらに確率は低くなる。
ナイーブベイズにおいて「花粉症になったらまず耳鼻咽喉科の医院に診察してもらうといいですよ」という文が「花粉症」カテゴリに入る確率は、0.0000……1くらいだと思っていい。
だが他のカテゴリ(「骨折」や「胃もたれ」など)に入る確率よりずっと高い。相対的にだが、群を抜いて高い。だから、「花粉症になったらまず耳鼻咽喉科の医院に診察してもらうといいですよ」が「花粉症」カテゴリに入るのがいちばん尤もらしい。つまり尤度が高い。
類似度
類似度は生起確率とはまったく別の考えである。語の集合同士の類似度をどう定義し、どう計算するかは手法によって異なる。
詳しくはしょとうさんのブログ記事やデータ分析・マイニングの世界 by SASというWikiページや類似性尺度のまとめ論文あたりを読むとよいと思う。
今回はコサイン類似度とSimpson係数を使った類似度計算を行ったが、Jaccard係数やDice係数を使ったり、類似度計算には様々な手法がある。用途と計算量で使い分けよう。
コード
類似度計算器
作ったシステムに組み込んで類似度を計算
作ったコードは2つに分けられる。
1. 類似度計算器
まず以下のようなSimCalculatorクラスを作った。
import math
class SimCalculator():
def _absolute(self, vector):
# ベクトルvの長さつまり絶対値を返す
squared_distance = sum([vector[word] ** 2 for word in vector])
distance = math.sqrt(squared_distance)
return distance
def sim_cos(self, v1, v2):
numerator = 0
# v1とv2で共通するkeyがあったとき、その値の積を加算していく。2つのベクトルの内積になる。
for word in v1:
if word in v2:
numerator += v1[word] * v2[word]
denominator = self._absolute(v1) * self._absolute(v2)
if denominator == 0:
return 0
return numerator / denominator
def sim_simpson(self, v1, v2):
intersection = 0
# v1とv2で共通するkeyの数を数えている
for word in v2:
if word in v1:
intersection += 1
denominator = min(len(v1), len(v2))
# v1かv2の中身が0だったとき
if denominator == 0:
return 0
return intersection / denominator
if __name__ == '__main__':
sc = SimCalculator()
print('コサイン類似度は' + str(sc.sim_cos({'ライフハック': 1, '骨折': 2}, {'ライフハック': 2, '仕事': 1, '趣味': 1})))
print('シンプソン係数で計算した類似度は' + str(sc.sim_simpson({'ライフハック': 1, '骨折': 2}, {'ライフハック': 2, '仕事': 1, '趣味': 1})))
Python3.3で実装したナイーブベイズ分類器を利用して、文章と文字列中の語の共起頻度から、類似度を計算する - Qiita
