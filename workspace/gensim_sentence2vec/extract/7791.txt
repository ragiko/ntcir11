
Colin Beckingham はカナダのオンタリオ州東部に住むフリーランスの研究者であり、ライターであり、プログラマーでもあります。キングストンの Queen's University で学位を取得している彼は、園芸、競馬、教育、行政サービス、小売業、旅行/観光業などにも関わってきました。彼はデータベース・アプリケーションの作成者であり、数え切れないほどの新聞記事や雑誌記事、オンライン記事を執筆しており、また Linux でのオープンソース・プログラミングや VoIP、音声制御アプリケーションも研究しています。
VoxForge チュートリアルの説明に従い、HTK (Hidden Markov Model Toolkit)、Julius、CMU Sphinx
などのツールを使用すると、単純な特定話者音響モデルを容易に作成することができます (これらのツールの詳細については「参考文献」を参照)。すると 2、3 時間もかからずに「2001年宇宙の旅」の HAL 9000 コンピューターが出来上がり、皆さんのコマンドに応答して皆さんと会話するようになり、皆さんがトイレ休憩でワークステーションを離れても、部屋の鍵をかけられてしまう可能性はほとんどありません。ただし初心者の場合、最初のモデルの認識精度が受け入れがたいほど低いことに驚くことがあります。そして音声制御の実験をあきらめ、この分野はある程度の認識精度が得られる程は進歩していない、と考えてしまいがちです。しかしその考えは事実とはかけ離れています。さらに、おそらくもっと深刻な事態は、認識エラーが多ければ多いほど、また明らかに期待通りの動作をしない認識装置に合うようにマイクに向かって注意深く話そうと一生懸命になればなるほど、期待通りの結果を得ようと不自然な発声方法になり、より緊張した声になってしまう可能性が高まることです。しかし音声認識の精度を高めるためには、リラックスした声で入力するとよい正当な理由があるのです。この問題への対策として、より多くの音声サンプルを単純に追加すると効果的かもしれません。また、構成済みの不特定話者モデルを適用する方法も考えられます (その方法については VoxForge と CMU Sphinx のリソースの説明を参照してください)。あるいは第 3 の方法として、プログラミング・ツールを使用して、認識精度が低い問題に焦点を絞り、根本的な問題の修正方法を考え出すという選択肢もあります。認識精度の低さを改善する上で、プログラマーは重要な役割を果たすことが可能です。作業環境を記述するツールを利用すると、認識精度の低さの原因を特定することができ、即座に基本的な問題や潜在的なソリューションに集中して取り組めるようになります。HTK にはモデルの作成フェーズで利用できるツールが数多く用意されており、Julius は認識フェーズにおいてガイダンスとなるメッセージが表示されます。しかし、これらの方法には限界があります。例えば、HTK や Julius を作成した人達は、どのような文法をユーザーが使用するのかに関して何も想定していません。選択した文法が原因で発生するエラーの処理はユーザーが行う必要があります。これから先のセクションでは、発生しがちな特定の問題について説明し、ある特別な手段に問題の特定や解決に役立つ可能性があるかどうかについて、例と注釈を付け加えながら説明します。問題のタイプ認識精度を低下させ得るエラーのタイプについて調べてみると、エラーの原因にはさまざまなものがあることがわかります。コンピューター業界ではおなじみの GIGO (Garbage In, Garbage Out) の概念
(つまり、「入力が不適切であれば、得られる出力も不適切なものになる」という概念)
は「モデルが曖昧である」という問題につながります。音響モデルの作成プロセスに提供されるサンプル・プロンプトが明確で意味のあるものでない限り、HTK は適切なモデルを作成することができません。こうした例としては、録音された .wav ファイルと組み合わされているプロンプトが不適切な場合や、HTK は .wav ファイルを受け付けるものの、(例えば音声レベルが不適切などの理由により) うまく解釈できない場合、単語間の短い沈黙が原因で音声の一部が認識し損なわれている場合、クリック・ノイズ、ポップ・ノイズ、背景音などが挿入されてしまっている場合などがあります。この問題の解決方法としては、音声ファイルに問題がないか調べ、場合によっては録音し直します。皆さん以外の他者の声で訓練された特定話者モデルを使用しようとすると、「モデルの幅が狭い」という問題が生じます。この場合、おそらく結果はお粗末なものになります。また、皆さん自身が有線接続のヘッドセットを使用してモデルを訓練し、生成されたモデルを使用して
Bluetooth ヘッドセットでコマンドを発行しようとすると、まったく同じ声を発しているにもかかわらず、おそらく認識精度は 50%
未満になります。しかもさらに、同じヘッドセットであっても別のマシンに接続すると、やはり認識精度は期待外れの結果となります。これはモデルの幅が不適切であることによる問題とも言え、問題が発生する話者、機器、プラットフォーム専用に音声ファイルを追加することによってモデルを改善することができます。音響モデルには幅と深さの両方が必要です。同じ人が同じことを言う場合であっても、日によって感情の状態、雰囲気などが変わってくるため、言い方は異なります。動作プラットフォーム、話者、ヘッドセットに何も変更がなくても、話者が風邪を引いている場合、苛立っている場合、少し酔っている場合などは、話者の声は大幅にあるいは微妙に変わってきます。それは別の条件下で訓練されたモデルを混乱させるには十分であり、「モデルが浅い
(その
1)」という問題につながります。この問題に対しては、語彙目録を詳細に検証して単語の聞こえ方を正確に記述し、必要に応じて語彙目録のエントリーを編集または追加することで、モデルの深さを増すことができます。「モデルが浅い (その
2)」という問題は、上記のポイントと似ていますが、まったく同じではありません。同じ日に同じ条件で同じ声で発声しても、文脈やそのときの気まぐれなどによって発音が異なってくる単語もあります。例えば、Tanzania
は [Tanza-niya] と発音するのでしょうか、それとも [Tan-Zania] と発音するのでしょうか、それともその両方なのでしょうか? schedule は [sked-ule] でしょうか、それとも [shed-ule] でしょうか? status は [stay-tus] でしょうか、それとも [stattus] でしょうか?この問題に対しては、皆さん自身が一貫した発音をするように心がけることも、語彙目録にエントリーを追加することもできます。もう 1 つの微妙な問題として、音声録音の際に単語間の沈黙が長くなったり短くなったりする問題もあります。モデルのベースは「音素」です。音素は音声認識プログラムが聞き取ることを想定している音声の離散表現です。音素は語彙目録に格納されますが、音素の精度が低い場合や一貫性がない場合、それらの音素に関連付けられる音声はエラーにつながる可能性があります。語彙目録内のエントリーで問題のある音素を特定して修正することで、「使われている単語が不適切な音素に分解されたり、代替となる発音が存在しなかったりする」などの問題を軽減することができます。残念ながら、多くの言語では通常の話し方の中に音素がバランスよく含まれているわけではないため、文法内の「音素バランスは不完全である」という結果になります。言語の中で音素が頻繁に使われないために音素を適切に表現することができないような場合には、音素について訓練する機会が限られているために、問題が発生する可能性があります。私が使用している英語の文法では、[ax]、[n]、[s]、[t]
という音素の集合は頻繁に使われる傾向がある一方、[oy]、[ar]、[el]、[ur]
という音素の集合は稀にしか使われません。この問題を解決するためには、まずは問題が持つ規則性を明らかにし、それから文法を調整し、同義語を使用して、HDMan の出力を見る、あるいは最も使用頻度の低い音素を使用する非標準的な用語を独自に作成するといったことすら行います。日常的な言葉のなかで、音声認識プログラムのレベルでは区別が困難な単語を使用せざるを得ないことによって、「語彙素の音素が非常によく似ている」という問題が発生します。このため文法のなかで使われるコマンドの選択には極めて繊細な配慮が必要になります。私が作成したモデルは時々
pipe と nine を混同します。これに対して私が作成したソリューションは、pipe を複合語の pipe_symbol または vertical_bar
に変更するというものでした。
上に戻るテスト手段文法内のルールが数個しかなく、その 1 つが常に認識の問題を起こす場合には、極めて迅速にその問題にフォーカスすることができます。しかし文法が大規模な場合には、モデルの精度をシステマチックにテストする手段が必要です。テスト手段 1: 問題のある単語を特定するテスト手段 1 では、問題のある単語の組み合わせを特定し、後でそれらを検討して改善できるように保存するためのテスト・ルーチンを使用します。このルーチンを使用するメリットは、サンプルを全般的に追加するのではなく、音声認識プログラムにとって困難な文法ルールの例を追加することによって、時間を節約できることです。ここでは、マシンはプロンプト・ファイルを読み取り、プロンプト・ファイルのエントリーを配列に格納してランダムにシャッフルし、それらのプロンプトを 1 つずつ画面上に表示するか、音声で出力することによって、皆さんがそのプロンプトを認識プログラムに対して声に出して読み上げるように指示します。次にスクリプトは想定していた聞こえ方と Julius の出力とを比較します。両者が同じではない場合、スクリプトは後で分析できるようにその問題を記録し、次のプロンプトへとループ処理で進みます。このスクリプトは Python (「参考文献」を参照) を使用しており、PostgreSQL (「参考文献」を参照) でバックエンドに問題を格納します。同じことを PHP、Perl、MySQL、その他のスクリプトや DB を使用して行うこともできます。これらの選択にあたっては、作業環境に関していくつかのことを前提にしています。第 1 に、一連のテスト可能な文法ルールと、それに関連する音声ファイル名で構成された「プロンプト」のフラット・ファイルがあるものとします。音声ファイル名の後には、1 つまたは 2 つの単語によるプロンプトがあります。以下はその例です。このテスト手段では音声ファイル名を使用していないので、サンプル・プロンプトのみを含む別ファイルでも同じように機能します。
音響モデルを調整し、音声認識の精度を高める
