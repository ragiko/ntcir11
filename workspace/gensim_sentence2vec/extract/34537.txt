
自己組織化マップ(SOM)は、クラスタリングの問題にも、クラス分類の問題にも利用できます。しかしながら、日本ではこの2つの分類法の違いが正確に理解されておらず、混乱することが多々あります。
英語では、「分類」に関する単語がいろいろとあります。グルーピング(grouping)、セパレーション(separetion)、オーディネーション(ordination)、ソーテーション(sortation)、セグメンテーション(segmentation)、カテゴリゼーション(categorization)、クラシフィケーション(classfication)等々。これだけの言葉があるのは、それぞれ微妙に意味(ニュアンス)が違うからであって、だてではありません。欧米人は、「分類」について、これだけ繊細な感覚を持ってます。
一方、我々日本人はというと、「分類」は分類でしかなく、きわめて素朴です。 そのためか日本人にとっては、クラスタリングとクラシフィケーション(クラス分類)の使い分けが、なかなか難しいです。
たとえば、「SOMを用いたクラスタリングで、フィッシャーのアヤメのデータを正しくクラス分類できた」などという論文をよく見かけます。もちろん、どんなデータでもSOMで可視化してもよいですし、アヤメのデータは軽い動作確認用のデータとしては手頃です。しかしながら、これをあまり拡大解釈してはならないと思います。
SOMでアヤメのデータを分類できたとしても、「SOMは教師信号なしで正しい(絶対的・客観的)な分類法を獲得する」という結論に至るのは早すぎます。このような短絡的な論文によって、データマイニングにおけるクラスタリングの本来の目的を正しく教えられないマイナスの教育効果があります。実務に携わる者としては、とてもやりにくいです。
クラスタリングとクラス分類の一般的な説明は、
クラスタリング -- 目的変数のない(教師なしの)場合
クラス分類  -- 目的変数のある(教師ありの)場合
という分け方かと思います。とりあえず、これで違いがはっきりしているかに見えるのですが、実際のところは、その背後には厄介な哲学的問題が横たわっています。
クラスタリングとクラス分類がどう違のか?これらをどのように使い分けるべきか?あるいは、これらをどのように組み合わせるべきなのか?について述べます。
以下の説明は少々長いので、結論を急ぐ読者のために、実践的な使い方を先に述べておきます。たとえば、品質管理で良品と不良品という分け方があるわけですが、多くの人が、単純に良品・不良品を分類するモデルを作成する、という間違いを犯します。
クラスタリングというのは、既知の分類法では見えて来ないことを発見しようとすることです。
つまり、不良品にも潜在的にいくつかのパターンがあるわけで、そういうことを発見するのがクラスタリングです。不良品を減らすために、工程をどのように管理すればよいのか?(パラメータをどのように調整すればよいのか?)ということを良品・不良品という2分法でやろうとすると複雑になってしまうことがあります。これをクラスタリングによって、適当な数に問題を分割すると、問題をよりシンプルに解決できるようになります。
あるいはマーケティングでは、ある商品を購入しそうな顧客(たとえば、ウタダヒカルのCDを購入しそうな顧客)というのは、常に均質な1つのグループであるとは限りません。このような顧客を適当な数のグループに再分類することによって、より効率的なキャンペーンを実施できるようになります。
クラス分類というのは、一旦、有用な分類法が見つかれば、それを再現するモデルを作成・適用することです。
クラスタリングとは  --潜在する「集まり」を発見する
クラスタリングとは、クラスタを形成するという意味です。クラスタとは、ぶどうの房のようなイメージであり、「群れ」とか「集団」を意味します。我々の日常感覚では、そのような集団は、事実として、あるいは物理的な塊りとして存在するのですが、物理的な3次元の空間を離れて、物事の類似性を多次元の空間で考えるときは、そのような常識は通用しなくなります。
データマイニングの世界でのクラスタリングは、このような拡張された意味あいでのクラスタリングです。複数(あるいはたくさん)存在している対象をお互いに比較して、その類似性(非類似性)によって、それらがどのような集まりを形成しているか?を検出するのです。
いろいろな計算方法があるにせよ、つまりは、存在している対象同士の「距離」によってクラスタが判断される、ということになります。したがって、データマイニングにおけるクラスタリングは、まず最初に「データ空間の定義」から始まります。
対象をどの属性と、どの属性と、どの属性・・・、で比較するのか?をまず最初に決めてしまいます。実際のところ、その根拠はいったい何なのか?というあたりが大問題なのですが、とにかくそれを決めないことには何も始まりません。
とにかく属性が選択されて、それらがそれぞれ次元軸となって、多次元の空間が定義され、そこに対象がデータポイントとして位置を確定することによって、クラスタリングが可能になります。クラスタリングの計算方法は、SOM以外にもいろいろあるわけですが、どんな計算方法を採用しようと、この状況にはまったく変わりはありません。
ここで重要なことは、「クラスタリングは、属性の選択によって、どのようにでも変化するものだ」という事実です。純粋論理の上から「客観的なクラスタリング」というものは、存在しません。
しかし、日常的感覚ではこのことが受け入れにくく、つい「ありとあらゆる可能なすべての属性を考慮してクラスタリングを行なえば、客観的なクラスタリングに近づくはずだ」と考えがちです。しかし、これも間違いです、属性の数を際限なく増やしていくと、どのようなことが起きるのかというと、すべてのデータポイントが限りなく等距離に近づいて行きます。つまり、クラスタは存在しなくなります。
つまり、これがデータマイニングの専門家たちを悩ませている「次元の呪い」というものです。じつは、これと似た話は、60年代のパタン認識研究の中で、渡辺慧先生が「醜いアヒルの仔の定理」として証明しております。つまり、純粋論理の上から「類」は客観的に存在していないのです。
物事の類が存在しない、ということは、あらゆる「意味(概念)」が消失する、ということです。心理学での「ゲシュタルト崩壊」や人工知能の「フレーム問題」は、データマイニングでの「次元の呪い」と同じことだと考えることができます。
つまり、我々が日常体験している「意味のある世界」は、属性を選択することによって成り立っている、ということでもあります。哲学的には、フッサールの「志向性」やハイデガーの「気遣い(関心)」というあたりと関係してきます。脳科学的には海馬による情報選択あたりでしょうか。
結局、クラスタリングについては、「客観的なクラスタリング」は存在しておらず、「意味のある(=有用な、価値のある)クラスタリング」または「意味のない(=無用な、無価値な)クラスタリング」が存在するのみです。
ただし、誤解がないように付け加えるなら、ある多次元空間が定義されると、その定義のもとでの、限定された意味での「客観的な(正しい)クラスタリング」というものは想定することができます。実用上、我々は、そのようなクラスタリングを「自然なクラスタリング」と呼びます。
データマイニングにおけるクラスタリングの意義は、「解決しようとしている問題に対して有用な(合理的な)セグメンテーションを虚心坦懐に発見すること」にあります。あらかじめ何らかのクラスタリングを想定するべきではなく、あくまでも潜在していて見えなかったクラスタリングを「発見」することに意義があります。
例えば、対象が顧客であれば、有用な顧客セグメンテーションを発見するために、顧客データをクラスタリングするわけです。ここで、わざわざ「セグメンテーション」と言い直しているのには深い意味があります。それは「クラスタリング」とは、定義された空間における数理的な計算の結果に過ぎないからです。
クラスタリングにはSOM以外にもいろいろと方法はあります。従来の統計・多変量解析の枠組みの中で知られているクラスタ分析もクラスタリングの手法です。しかしながら、実際に有用なクラスタリングを見つける作業は、探索的なプロセスです。
何度も何度も属性選択を変えて、クラスタリングをやり直すべきなのです。実際、それはたいへんな作業です。従来のクラスタ分析では、クラスタリングの結果を評価することがまずたいへんなのです。したがって、実際に探索的にクラスタ分析を行なっている人はほとんどいないでしょう。
クラスタリングにSOMを使うことの意義は、単に「可視化できる」とか「非線形性を考慮したより高度なクラスタリングができる」というだけではなく、「統計解析と組み合わせると効率的なプロファイル分析が可能になって、たいへんだった探索的なクラスタ分析が飛躍的に効率化できる」という点にもあります。
そして、何度もクラスタリングをやり直して、良さそうなクラスタリングが得られたとして、我々はその数理的な結果を100%を受け入れなければならないのか?と言えばそうではありません。SOMの上では、クラスタリングを土台にしながら、さらに手動で「有用なセグメンテーション」を作成することさえできるのです。
(計算方法は何にせよ)数理的なクラスタリングというのは、あくまでも問題解決の手段・道具であって、最終目的でもないし、絶対的真理でもありません!
クラス分類とは --特定の分類法をより正確に再現する
一方、クラス分類は何かというと、これは「特定の分類法をより正確に再現するモデルを作成する」ということが目的です。モデルの作成の仕方としては、
方程式で表現する -- 判別分析など
ルールで表現する -- ルールベース、決定木など
確率で表現する -- ベイジアンネットワークなど
マッチングを行なう -- 自己組織化マップなど
などがあります。
どの方法を用いるにしても、まず予め正解例が提示されて、あとで正解例が提示されない場合でも、他の属性(説明変数)によって、正解の分類を再現できるようなモデルを作成するわけです。(SOMでも同じです。)
ここで重要なことは、正解例、つまり目的変数(教師信号)は、無数にある属性の中で、人間が一方的に関心を持っている属性だということです。例えば、陽性・陰性、良品・不良品、あるいはAタイプ・Bタイプ・Cタイプ・・・というようなことです。
つまり、目的変数(教師信号)は、ある1つの属性にだけ注目して、対象をカテゴリ化しています。そのグループは、はたして、均質なグループでしょうか?
アヤメの品種のような場合、同じ品種のアヤメは他の品種のアヤメと比較して、より強い類似性を持っていて、均質なグループを形成していると予想できます。クラスタリングを用いても、フィッシャーのアヤメのデータが分類できる理由はそこにあります。
しかしながら、いつでも分析しようとしているデータが、アヤメのデータのようなデータだとは限りません!
そもそも、アヤメのデータは、アヤメを分類するために必要な属性をフィッシャーが選定した結果のものです。それを使えば分類できるのは当たり前です。実際のデータマイニング・プロジェクトは、そんなものではありません。どの属性が関係あるのか?ないのか?がまだわからないたくさんの属性が与えられて、「さてどうしようか?」というのがデータマイニングの問題です。
実際のデータマイニング・プロジェクトでのクラス分類では、たくんさんの属性から分類に関係する属性を選択し、また各属性に適切な重みを与えることが、主要な課題となります。
クラス分類のモデルを問題にSOMを適用することもできます。マップ上でのクラスの分布がまだらにならないように、できるだけきれいにクラスが分割されるようなマップを作成すると、クラス属性が未知なレコードをそのマップとマッチングさせて、レコードをクラスに振り分けることができます。
マップ上のクラスの境界線とクラスタ分析による境界線は、一致していてもいいし、一致していなくても何ら問題はないのです。クラス分類用のマップの場合、分類しようとしているクラスがマップ上できれいに順序づけされているかどかがポイントです。
クラスタリングとクラス分類の違い、そして使い方
クラス分類の問題が、つねにクラスタリングと一致する保証はどこにもありません。同じクラスに分類されていても、それが人間側の勝手な興味から分けているものだとしたら(たとえば、ある商品を購入する顧客かどうか?など)、そこには共通のクラスタは存在しないかもしれないし、いくつかのクラスタに属しているものを1つのクラスに分類している可能性もあります。それが自然なものの考え方です。
クラスとクラスタは、(日本語の音では似ていますが)別物です。
クラスは、対象に付随する無数の属性の1つに着目したに過ぎないものです。データ集合に、性別、職業、地域、診断結果など複数のカテゴリ属性がある場合、それらのどれをクラス属性(目的変数)と考えるかは人間次第です。
クラス分類には人間の意識が直接働いています。クラス分類は、常に特定の関心における分類法であり、関心が変われば、それは変わります。一方、クラスタリングには人間の意識が直接には働いていません。前述したように、「どの属性を考慮するか」ということによって、間接的に働いています。
ある条件のもと、すなわち、クラス分類を再現可能な属性選択と重みづけのもとでのクラスタリングは、(人間の意図している)クラス分類と一致することもあり得ます。しかし、クラスタリングが一般的にそのように使われるものだということではありません。
あるいは、こう言えば、さらにはっきりするでしょう。すべての属性(列)が異なるカテゴリ変数で構成されているデータ集合は、それぞれの属性が異なるクラス分類を主張し合っている、と捉えることができます。このような場合、クラスタリングとは、各列が異なるクラス分類を主張しているのを統合して、aufheben(止揚)された、より高い視座に立った認識(判断)を形成していることになります。
これで、特定のクラスタリングの結果が特定のクラス分類に一致することを過大評価するのが、いかにナンセンスであるかおわかり頂けるはずです!
したがって、実際のデータマイニング・プロジェクトでは、クラスタリングを特定のクラス分類に一致させようとして使うべきではなくて、クラス・データには表現されていない潜在的なクラスを発見するために使うべきなのです。
つまり、ユーザの関心の上では、2つのクラスに分けられれば良い場合でも、実際のデータの分布はそうなっておらず、それ以上のクラスに分類することで、より高い精度で目的が達成できる、ということがあるわけです。
クラス1というクラスがあったとして、しかし、それがある定義によるデータ空間内では、異なる2つのクラスタに分かれているとしたら、そのクラスをクラス1-aとクラス1-bという具合に分けて考えると、そのデータ空間(データ集合)を用いてクラス分類するには都合がよい、ということです。何度もいいますが、このような分類法を客観的な真理だと主張するわけではありません。問題をよりスマートに(効率的に)解決するためのテクニックです。
SOM以外の手法でクラス分類問題に取り組む場合でも、まず最初にSOMでクラスタリング&rarr;セグメンテーションを行い、求めようとしているクラスそものを見直してみる、ということをお薦めします。もちろん、SOM上のマッチングによって、クラス分類を実行することも可能です。
ここでの要点は、1つのクラスでも、1つのクラスタに属するとは限らない、ということです。
2008.8.21 変更
2008.11.23 変更
ソリューション
顧客セグメンテーション
顧客スコアリング
不正検出マネジメント
製品
Viscovery SOMine
Hugin Developer
Hugin Explorer
XLSTAT-Pro
XLSTAT-3DPlot
XLSTAT-ADA
XLSTAT-Conjoint
XLSTAT-CCR
XLSTAT-DOE
XLSTAT-Dose
XLSTAT-Life
XLSTAT-MX
XLSTAT-Pivot
XLSTAT-PLS
XLSTAT-PLSPM
XLSTAT-Power
XLSTAT-Sim
XLSTAT-SPC
XLSTAT-Time
XLSTAT-Time
XLSTAT-6S
XLSTAT-Campus
XLSTAT-Medical
XLSTAT-Predict
XLSTAT-Sensory
Miner3D
｜ライセンスについて｜特定商取引に関する表示｜採用情報｜
&copy;2006-2012 Mindware Inc. All rights reserved. 
複雑な問題へのSOMの応用
