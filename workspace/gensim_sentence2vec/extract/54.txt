交差検定の k の値はどれくらいにすればいいのか
機械学習, R
分類器(識別器)のモデルを評価する手法に交差検定(クロスバリデーション)があります。
交差検定を行うには、データをいくつに分割するかを表す k の値を決めてあげなければなりません。
SVM のチューニングのしかた(1) において、交差検定の k の値を決めるとき、僕は個人的に
k = 1 + log(n)/log(2)
という式を用いていると書きました。
この式は、知っている人ならわかると思いますが、スタージェスの公式です。
スタージェスの公式は、ヒストグラムを描く際にサンプル数から階級数を決めるのに便利な公式です。
しかし、この公式を交差検定の k を決める際に使用するのは、はっきりいって根拠がありません。
そこで、今日は交差検定の k の値をどのくらいにすれば良いのかについて考えてみたいと思います。
準備(予備知識)
k の値は大きければ大きいほど、正確にモデルを評価できます。			k の最大値はサンプル数ですので、「k = サンプル数」とした場合が最も正確な評価だと言えます*1。
というわけで、できれば「k = サンプル数」でやりたいところですが、k が大きければそれだけ実行に時間がかかるので、k はなるべく小さい値にしなければなりません。
交差検定の原理上、「k = サンプル数」とした場合、モデルの評価値(正答率)は、交差検定を繰り返したとしても常に同じ値になります。
逆に、「k < サンプル数」の場合は、交差検定を何度かやると、そのたびに違った値が返ってきます。
この違いのばらつき具合(分散)は、k が小さいほど顕著になると考えられます。
そこで、k をいろいろ変えてみて、一つの k に対して交差検定を繰り返し、そのときの分散を調べてみると何かがわかるのではないかと思いました。
シミュレーション
上で書いた実験を、下記のような R のコードでシミュレーションしてみました。
library(e1071)
data(iris)
sds <- c()
means <- c()
cat("k-fold", "Mean", "SD", "\n", sep="\t")
range <- seq(5, 150, by=5)
for(k in range) {
accs <- c()
for(j in 1:100) {
model <- svm(Species ~ ., data = iris, cross=k)
accs <- c(accs, model$tot.accuracy)
}
mean <- mean(accs)
sd <- sd(accs)
cat(k, mean, sd, "\n", sep="\t")
means <- c(means, mean)
sds <- c(sds, sd)
}
データとしては以前に使った iris を使用しました。k の値を 5, 10, 15, ... というように増やしていって、150(iris のサンプル数)まで調べています。
一つの k に対して、交差検定を 100 回繰り返し、正答率の平均(mean)と標準偏差(sd)を出しています。
結果は下記のような感じで出てきます。
k-foldMeanSD
交差検定の k の値はどれくらいにすればいいのか - ほくそ笑む
