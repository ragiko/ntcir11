優先度学習を用いた文短縮手法
† †† † ††
牧野恵 平尾努 山本和英 磯崎秀樹
† ††
長岡技術科学大学電気系 日本電信電話株式会社NTTコミュニケーション科学基礎研究所E-mail:†{makino, ykaz}@nlp.nagaokaut.ac.jp
††{hirao, isozaki}@cslab.kecl.ntt.co.jp
1 はじめに
近年, ニュースの文字放送や字幕を自動的に作成する技術への需要が大きくなっている.これらは人間の読むスピードや表示する機器の大きさ等の制限により, ニュースをより圧縮したものでなくてはならない.伝統的な重要文抽出による要約では, 指定された文字数内により多くの情報を含めることが難しい.そこでより高圧縮な要約を目指し, 文短縮技術の研究が盛んに行われている[1, 2].
例えば, 堀ら[2]は文短縮を単語重要度を最大に且つ, 日本語としてできるだけ自然な部分単語列を抽出する組合せ最適化問題として定式化し, 動的計画法を用いて解く手法を提案している.一般的に, こうして得た最適解は常に最良であるとは限らず, 他にもより良い解が存在する可能性がある.そこで本稿では堀らの手法に対し, 優先度学習を適用した高性能な文短縮手法を提案する.評価実験では10位までの短縮文ランキングを優先度学習を用いて再ランキングしたことにより, 1位のBLEUスコアを約3ポイント改善できた.またBLEUスコアが最大となる順位平均も優先度学習後では約2位改善でき, 提案手法の有用性を確認した.
2 準備
堀らによると文短縮は, N個からなる入力文の単語列からM個の単語列を抽出する問題として定式化できる.いま10個の単語から成る入力文に対し, 出力文(短縮文)として5個の単語を抽出する問題を図1を用いて説明する.
横軸iは出力文(短縮文)V の単語インデックスを表し, 図1
動的計画法の探索領域
縦軸jは入力文Wの単語インデックスを表す.なお入力文Wの前後にはあらかじめ文頭記号〈s〉, 文末記号〈/s〉を挿入することにより初期状態と最終状態を明確にする.
sijはステート(単語)を表す.各ステートの重みW(sij)は単語の重要度を表し, 各ステート間(リンク)の重みは単語連接の良さを表す.重要な単語を含み且つ, 日本語としてできるだけ自然な部分単語列を抽出するには, ステートの重みとリンクの重みの和を最大にするようなパスを求める問題に帰着できる.さらに図1は文頭から文末に向い, 抽出し得る部分単語列の全ての組合せを2次元空間に示したものであり, 探索領域が図中の平行四辺形内のパスに限られることから, 動的計画法で解くことができる.よってこの問題はステート列S = s00, s1j′, ..., sM+1j′のスコアScore(S)を最大にするステート列Ŝを動的計画法を用いて求める問題となる.なおこのときj′は直前のステートから接続可能なステートの列の入力文の単語インデックス(i ≤ j′ ≤ N − M + i)を表す.
Ŝ = arg maxS Score(S) (1)
ここでScore(S)は次式で表される.
i=1
Score(S) = α W(sij) + β W(sij|si+1j′) (2)
i=0
(i + 1 ≤ j′ ≤ N − M + i + 1)
但しW(sij)はtf  idfを用いたステートsijのステートの重みを表し, W(sij|si+1j′) は単語バイグラム確率*1と係り受け確率を用いたリンクの重みを表す.またα, βはステートの重みとリンクの重みに対して与えるパラメータである.例えば図1においてスコアを最大にするステート列が「s00, s13, s24, s36, s48, s59, s611」*2であったとする.
このステート列を単語に置き換えると出力される短縮文は入力文の「〈s〉, w3, w4, w6, w8, w9, 〈/s〉」となる.図2に動的計画法を用いた前向き探索のアルゴリズムを示す.
linkf(sij)はステートsijと接続可能なステートの集合である.例えば図1でlinkf(s13)とは
linkf(s13) = {s24, s25, s26, s27} (3)
となる.なお各ステートでは初期状態からそのステートまでの最適経路の最大スコアを保持する(5, 6行目).
3 提案手法
上述の方法で得た短縮文が常に最良であるとは限らないため, 本稿では優先度学習を適用することで, より良い短縮文を得る手法を提案する.優先度学習を行うためにはい
*1堀らは単語トライグラム確率を用いているがここでは簡略化し単語バイグラム確率を用いて説明を行う.
*2図1の太線.
1 for (i = 0 ; i ≤ M + 1 ; i + +) do
2 for (j = i ; j ≤ N − M + i ; j + +) do 3 for si+1j′ ∈ linkf(sij) do
4 φ′(si+1j′)  φ(sij)+αW(si+1j′)
+βW(sij|si+1j′)
5 if φ′(si+1j′) > φ(si+1j′) then 6 φ(si+1j′)  φ′(si+1j′)7 endif 8 end 9 end 10 end
図2
動的計画法を用いた前向き探索
1 open  {sM+1N+1}2 closed  φ
3 g(sM+1N+1)  0
4 f(sM+1N+1)  h(sM+1N+1)7 while (open ≠ φ) do 8
sij  arg maxsij∈openf(S)
9
if (i = 0) then return success
10
open  open − {sij}
11
closed  closed ∪ {sij}
12
for si−1j′ ∈ linkb(sij) do
13
g′(si−1j′)  W(si−1j′| sij) + W(sij) + g(sij)
14
f′(sij, si−1j′)  g′(si−1j′) + h(si−1j′)
15
if f(si−1j′) を用いる.但し1つの短縮課題に対しリファレンスが複数存在するため, 実際にはk番目の短縮課題に対して|Tk|の数だけ訓練データが存在する.本稿では訓練データのセットを列挙し, 以下のように表す.
C(ti) = {xi1, xi2, ..., xiN+1} (7)
ti ∈ Tk
ここでxi1はリファレンスの素性ベクトルを表し, xi2
, ..., xiN+1はシステムが出力したN個の短縮文の素性ベクトルを表す.いまある素性ベクトルxが与えられたとすると, その優先度G(x)と予測ĵは次式で与えられる.
G(x) = ∑ij
αij(h(xi1
)  h(x) − h(xij
)  h(x)) (8)
ĵ = arg maxj=1...N+1G(xij) (9)
本稿での優先度学習はリファレンスが常に優先されるようにするため, 訓練において予測ĵが誤った場合には重みαijの更新を行う.つまりĵ ≠ 1となった場合, リファレンスよりもシステム出力が優先されるため誤りとみなし重みの更新を行う.図4にRanking Voted Perceptronの訓練アルゴリズムを示す.
3.2.2 素性ベクトル間の類似度
式(8)でのh(xij
)  h(x)は高次元空間における素性ベク
トルの内積である.つまりh(xij
)  h(x)はxijとxの類
1 for (i = 1; i < m; i + +) do 2 for (j = 1; j < n; j + +) do
3 G(x) = ∑ij αij(h(xi1)  h(x) − h(xij)  h(x))4 ĵ = arg maxj=1...N+1G(xij)5 if (ĵ ≠ 1) then 6 αij = αij + 17 endif 8 end 9 end
図4
Ranking Voted Perceptron
表1
実験データの詳細
訓練データ
テストデータ
短縮課題の形態素数の平均
43.0
42.8
リファレンスの形態素数の平均
25.4
25.3
要約率平均(削除率平均)
0.59(0.41)
0.59(0.41)
リファレンス個数
5
5
似度と考えてよい.よって本稿では類似度尺度を, 単語ユニグラム, スキップバイグラム, トライグラム, 品詞バイグラムの重み付き線形和とし, 次式で表す.
h(xij
)  h(x) =λ1unigram(xij, x)
+λ2skipbigramd(xij, x)+λ3trigram(xij, x)
+λ4posbigram(xij, x) (10)
但しλ1, λ2, λ3, λ4 は各項に与えるパラメータであり, unigram(xij, x)はxijとxの単語ユニグラム一致数を表す.またskipbigramd(xij, x)はd個以下のスキップを許したxij とxの単語の組合せの一致数を表し, 以下で述べる評価実験では, d = 4に設定し, 4個以下のスキップを許したスキップバイグラムを用いた.なおtrigram(xij, x)はxijとxの単語トライグラム一致数を表し, posbigram(xij, x)はxijとxの品詞バイグラムの一致数を表す.
4 評価実験4.1 実験データ
実験データには, ステートの重み, リンクの重みに対するパラメータを調整するための訓練データとして200題の短縮課題を用意した.またこれとは別の短縮課題をテストデータとしての200題用意した.訓練データとテストデータには人手で作成したリファレンス*4が1つの短縮課題に対し, 複数用意してある.なお各短縮課題にはそれぞれ指定した要約率*5があり, リファレンスもその要約率に従って作成した.表1に実験データの詳細を示す.
単語重要度や言語モデルは毎日新聞3年分(2000~2002年)を用いて構築した.本稿ではまず訓練データを使い, 前向きDPで用いるステート及び, リンクの最適な重みパラメータを設定する.その後, 得られた最適パラメータを使い, N-best解の出力及び優先度学習を行い, オープンテストを行う.なお, テストでは各短縮課題に対して10個(N-bestにおけるN=10)の出力を行い, 10分割交差検定により評価した.
*4リファレンスの作成は1人によって行った.
*5本稿では入力文中の形態素数に対する出力文中の形態素数の割合とする.
4.2 評価指標
本稿では機械翻訳の自動評価で用いられるBLEUスコア[6]とそれを要約の自動評価用に改良されたROUGEスコア[7]を使って評価を行う.
BLEUスコアはある短縮課題でシステムが出力した短縮文cとその短縮課題に対するリファレンス文の集合Rとの類似度を求めることによって評価するものである.以下にBLEUスコアについて示す.
BLEU(c, R) = BP  exp(
n=1
1
n log pn) (11)
pn =
∑
ngram Countclip(ngram)(c, R)∑
ngram′ Count(ngram′)
(12)
複数リファレンスの場合Countclip(ngram)(c, R)は次式で表される.
Countclip(ngram)(c, R) =
min(Count(ngram), Max Ref Count(ngram)) (13)式 (12) の Count(ngram′) はシステム出力の各ngramの数である.また式(13)でのCount(ngram)はシステム出力に含まれるある語の数であり, Max Ref Count(ngram)は複数リファレンスに含まれるある語の最大数である.本来, BLEUスコアではシステム出力がリファレンスよりも短かった場合, ペナルティ(BP)を与えるが, 今回は各短縮課題でリファレンスとシステム出力の長さが一致するためこのペナルティについては課さない.
ROUGEスコアはある短縮課題でシステムが出力した短縮文cとその短縮課題に対する複数リファレンス1つ1つrとの類似度を求めることによって評価するものである.
以下にROUGEスコアについて示す.
∑
Countmatch(ngram)
ngram
ROUGE−N(c, r) = ∑
(14)
Count(ngram
ngram ′)
′
式(14)のCount(ngram′)はリファレンスの各ngramの数であり, Countmatch(ngram)はリファレンスとシステム出力での一致したある語の数である.
4.3 評価結果
評価実験では各短縮課題で指定された要約率に従って文短縮を行った.評価では優先度学習によってより良い短縮文が上位に再ランキングできたかを調べるため, 優先度学習前後でのBLEUスコア, ROUGEスコアの比較を行う.ROUGEスコアではROUGE−1, ROUGE−2, ROUGE−3で評価を行った.なお複数リファレンスであるため, 各短縮課題での最大ROUGEスコアを示す.
表2, 3に優先度学習前後での評価の比較を示す.表2では優先度学習前後における1位と3位以内のBLEUスコアの平均を示し, 表3では優先度学習前後における1位のROUGEスコアの平均を示す.
表2より1位のBLEUスコア平均では約3ポイント改善でき, 3位以内でのBLEUスコア平均も改善できた.また表3よりROUGEによる評価でも優先度学習前に比べ改善できたことが分かる.なお出力した10-best中最も高いBLEUスコアの順位平均を調べたところ, 優先度学習前
表2
優先度学習前後でのBLEUスコアによる評価の比較
優先度学習前
優先度学習後
前後での差
1位
.440
.474
+0.034
3位以内
.437
.461
+0.024
表3
優先度学習前後でのROUGEスコアによる評価の比較
優先度学習前
優先度学習後
前後での差
ROUGE−1
.676
.698
+0.022
ROUGE−2
.502
.526
+0.024
ROUGE−3
.375
.404
+0.029
短縮課題:
規制緩和をめぐり、与党の行政改革プロジェクトチームが20日午後、通産省、運輸省などの官房長らを相手に異例の公開討論会を行う優先度学習前
1. 規制緩和をめぐり、プロジェクトチームが20日、相手に異例の公開討論会を行う
2. 規制緩和をめぐり、プロジェクトチームが20日、を相手に異例の討論会を行う
3. 規制緩和をめぐり、改革プロジェクトチームが20日、相手に異例の討論会を行う
優先度学習後(学習前の順位)
1. 規制緩和をめぐり、行政改革プロジェクトチームが20日、異例の公開討論会を行う(9)
2. 規制緩和をめぐり、改革プロジェクトチームが20日、相手に異例の討論会を行う(3)
3. 規制緩和をめぐり、プロジェクトチームが20日、を相手に異例の討論会を行う(2)
図5
優先度学習前後における短縮文のランキング例
が5.4位だったのに対し, 優先度学習後では3.7位となり, 2位近く改善することができた.これらの結果から, 優先度学習を適用したことで, より良い短縮文を上位に再ランキング出来たことが分かる.さらに表3よりROUGE−3の評価でも優先度学習の効果が表れていることが分かる.
これは優先度学習の類似度尺度に単語トライグラムまでを用いたことにより単語連接のより良いものを上位に再ランキング出来たためであると考える.
4.4 考察
短縮文のランキング例
参考として, 文短縮でDPスコアによりランキングした上位3位の結果と優先度学習により再ランキングした上位3位の結果の例を図5に示す.優先度学習後の括弧内の数字は優先度学習前の順位である.優先度学習前では9位だった短縮文が優先度学習後では1位になっており大きく順位が入れ替わっていることが分かる.この例では優先度学習の効果も良く分かる.
リンクの重みについて
堀らは単語連接の良さを表すリンクの重みに単語トライグラム確率を用いた.それに対し, 本稿では計算効率を考え単語バイグラム確率を用い, また優先度学習での類似度尺度に単語トライグラムやスキップバイグラムを用いることで単語連接がより良いものを上位に再ランキングしている.そこでリンクの重みに単語トライグラム確率を用いた場合と単語バイグラム確率を用いた場合で評価の比較を行う.なお単語トライグラム確率を用いた場合も訓練データでステートとリンクの重みの最適パラメータを設定し, 得
表4
リンクの重みの違いによる評価リンクの重み
1位のBLEU平均
単語トライグラム
.472
単語バイグラム(優先度学習前)
.440
単語バイグラム(優先度学習後)
.474
られた最適パラメータを用いてオープンテストを行った.
表4にリンクの重みの違いによる評価を示す.
この結果よりリンクの重みに単語トライグラム確率を用いた場合と単語バイグラム確率を用いた場合を比較すると優先度学習前では単語トライグラム確率を用いた方が良い評価が得られた.しかし優先度学習後ではより良い短縮文が上位に再ランキングされ, 堀らの単語トライグラム確率を用いた場合に匹敵する評価が得られた.よって提案手法では計算効率を抑え, さらにオンライン型の優先度学習を用いたことで単語トライグラム確率を用いた結果に匹敵する結果を得ることが出来る.また本稿では優先度学習の類似度尺度とした単語ユニグラム, スキップバイグラム, トライグラム, 品詞バイグラムを用いたが, 他により適する類似度尺度を選択できればさらに良い優先度学習が行えると期待できる.
5 おわりに
本稿では, 既存研究をベースにオンライン型の優先度学習を適用することで, より良い短縮文を再ランキングする手法を提案した.優先度学習後ではBLEUスコアによる評価が約3ポイント改善され, 提案手法の有用性を確認した.さらに優先度学習後ではリンクの重みに単語トライグラム確率を用いた場合に匹敵する結果が得られ, 計算効率を抑えた文短縮器を構成することが出来た.また今後の課題として優先度学習で用いる類似度尺度の選択やより細かなパラメータの設定などが挙げられる.
参考文献
[1] K.Kevin and M.Daniel. Summarization beyond sentence extraction:A probabilistic approach to sentence compression. In Artificial Intelligence, vol.139, pp.91-107(2002).
[2] 堀智織, 古井貞熈.単語抽出による音声要約生成法とその評価.電子情報通信学会論文誌, vol.J85-D-II, no.2, pp.200-209, (2002).
[3] 工藤拓, 松本裕治.相対的な係りやすさを考慮した日本語係り受け解析モデル.情報処理学会論文誌, vol.46, no.4, pp.1082-1092, (2005).
[4] 永田昌明.統計的言語モデルとN-best探索を用いた日本語形態素解析法.情報処理学会論文誌, vol.40, no.9, pp.3420-3431, (1999).
[5] M.Collins and N.Duffy. New ranking algorithms for parsing and tagging:Kernels over discrete structures , and voted perceptron. Proc. of the 40th ACL, pp.263-270, (2002).
[6] K.Papineni, S.Roukos, T.Ward and W.J.Zhu:BLEU:a Method for Automatic Evaluation of Machine Translation . Proc. of the 40th ACL, pp.311-318, (2002).
[7] C.Lin:Looking for a Good Metrics:ROUGE and its Evaluation, Proc.of the 4th NTCIR Workshops, pp.1-8, (2004).

