
音声認識方法
【目的】 本発明は音声認識に関するものであり、子音のように継続長が短くスペクトル変化に特徴のある部分は時間的に詳細に、母音のように時間的に定常で継続長の長い部分は時間的に粗く照合することにより情報の冗長性を省き、認識性能の高い音声認識方法を提供するものである。
【構成】 未知入力音声を音響分析部1でフレームごとにLPC分析し、特徴パラメータ抽出部2でP個(Pは正の整数)の特徴パラメータをフレームごとに求める。次に音声区間検出部3で入力音声の始端および終端フレームを音声パワー情報などを用いて検出する。次にDP照合部5で、入力音声と単音節標準パターンとの距離を求める。最後に距離比較部6で、DP照合部5で求めた距離の中で最小の値をもつ標準パターンに対応する音声名を認識結果として選択する。
【0001】
【産業上の利用分野】本発明は人間の声を機械に認識させる音声認識方法に関するものである。
【0002】
【従来の技術】近年、使用者の声を登録することなしに、誰の声でも認識できる不特定話者用の音声認識装置が実用として使われるようになった。不特定話者用の実用的な方法として、特許(特開昭61-188599号公報)を従来例として説明する。
【0003】従来例の方法は入力音声の始端、終端を求めて音声区間を決定し、音声区間を一定時間長に(Jフレーム)に線形伸縮し、これと単語標準パターンとの類似度を統計的距離尺度を用いてパターンマッチングをすることによって求め、単語を認識する方法である。
【0004】以下、従来例について図7、図8を用いて詳細に説明する。図7は従来例の音声認識方法の処理の流れを示すフローチャートである。図7において1は音響分析部、2は特徴パラメータ抽出部、3は音声区間検出部、10は時間軸線形正規化部、4は標準パターン格納部、11は距離計算部、6は距離比較部である。
【0005】図7において、入力音声が入力されると音響分析部1で分析時間(フレームと呼ぶ、本従来例では1フレーム=10ms)ごとに線形予測(LPC)分析を行なう。次に、特徴パラメータ抽出部2でP個の特徴パラメータをフレームごとに求める。特徴パラメータは、LPCメルケプストラム係数(本例ではC1-C9まで9個)、正規化残差C0、および音声対数パワーの時間差分値V0を用いる。次に音声区間検出部3で入力音声の始端フレーム、終端フレームを検出する。音声区間の検出は音声パワーを用いる方法が一番簡単であるがどのような方法を用いてもよい。検出された音声区間に対して、入力音声の特徴パラメータ時系列を時間軸線形正規化部10でJフレームに線形伸縮する。これを概念的に示したのが図8である。通常、計算量および標準パターンの推定パラメータ数削減のため、Jは実際の単語のフレーム数よりも小さく取る。これは単語の音声区間全体について等間隔にフレームを間引くことに相当する。検出された入力音声区間の始端フレームを1フレーム目、終端フレームをIフレーム目とすると、伸縮後の第jフレームと入力音声の第iフレームの関係は【0006】
【数1】【0007】となる。ただし、［］はその数を越えない最大の整数を表す。伸縮後のJフレーム分の特徴パラメータを時系列に並べ入力時系列パターンXを作成する。
【0008】
【数2】【0009】この入力時系列パターンXと標準パターン格納部4に格納されている認識対象語彙の各々の標準パターンとの距離を距離計算部11で求める。標準パターンの作成方法および距離の求めかたについては後述する。最後に距離比較部6で、距離計算部11で求めた各々の標準パターンとの距離の中で最小(類似度が最大)の値をもつ標準パターンに対応する音声名を認識結果として選択し、出力する。
【0010】以下に、単語標準パターンの作成方法、および入力時系列パターンと単語標準パターンとの距離計算の方法について述べる。
【0011】ある単語ωnの標準パターンは次のような手順で作成する。
(1)多数の人(ここでは100名)が単語ωnを発声したM個の学習用音声データを用意する。
(2)各データを(数1)を用いて線形に伸縮を行ないJフレームに正規化する。(3)第m番目の発声データに対して伸縮後の特徴パラメータを時系列に並べ、時系列パターンCmを求める。(m=1,...,M)(4)M個の時系列パターンCm(m=1,...,M)を用いてその統計量(平均値、共分散)を求めることにより標準パターンを作成する。
【0012】これをN個の認識対象語彙それぞれに対して求めておく。第m番目の発声データに対して伸縮後の特徴パラメータを時系列に並べた時系列パターンCmは次のように表される。
【0013】
【数3】【0014】これをM個の学習用音声データについて求める。時間パターンCmを一つのベクトルとして扱うことにより、パラメータのフレーム間の相関を考慮することになる。M個のJ×P次元のベクトルCm(m=1,...,M)からその平均値ベクトルμおよび共分散行列Wを求める。以下、第n番目の単語ωnに対する平均値ベクトルをμn、共分散行列をWnと表記する。
【0015】入力時系列パターンXと単語標準パターンとの距離計算は、共分散行列を共通化したベイズ判定に基づく距離を用いて計算する。
【0016】ベイズ判定に基づく距離は以下のようにして求める。(数2)で表される入力ベクトルXが観測されたときにそれが単語ωnである確率P(ωn｜X)はベイズの定理より【0017】
【数4】【0018】となる。P(X｜ωn)は事前確率で、入力がカテゴリーωnであったときに入力ベクトルXが観測される確率、P(X)は生起し得るすべての入力を考えた場合のベクトルXが観測される確率である。単語ωnの出現確率P(ωn)は各単語同じと仮定して定数とし、入力Xが一定とするとP(X)が定数となるので、事前確率P(X｜ωn)を最大とするカテゴリーωnを判定結果とすればよい。
【0019】パラメータの分布を正規分布と考えると、事前確率P(X｜ωn)は(数5)で表される。
【0020】
【数5】【0021】ここでtは転置行列を表す。両辺の対数をとって識別に不要な定数項を省略しさらに-2倍すると次式を得る。
【0022】
【数6】【0023】この式は単語ωnに対するベイズ判定に基づく距離である。計算量および推定パラメータ数削減のため、共分散行列を共通化してこの式を線形一次判別式に展開する。認識対象語彙の各々の標準パターンの共分散行列Wnを共通化し、Wとする。Wは次式のようにして求める。
【0024】
【数7】【0025】したがって【0026】
【数8】【0027】とおくことができる。これを(数6)に代入し識別に不要な定数項を省略すると、【0028】
【数9】【0029】となり、【0030】
【数10】【0031】
【数11】【0032】とおくことにより、【0033】
【数12】【0034】のような線形一次判別式になることがわかる。このようにしてAn,Bnを認識対象語彙の各々に対して求め、標準パターン格納部に格納しておく。距離計算部では上式を用いて入力時系列パターンXと、単語ωnの標準パターンとの距離Lnを求める。
【0035】
【発明が解決しようとする課題】従来例の方法は、計算量が少なく実用的な方法である。しかし従来の方法では、パラメータの推定精度の面から標準パターンのフレーム数Jを大きくすることができず、音声区間全体について等間隔にフレームを間引いて認識することになる。このため、子音のように継続長が短く詳細に照合を行なう必要がある部分の情報が欠落してしまい、十分な音声認識率が得られないという問題があった。一方、母音のように時間的に定常で継続長の長い部分の情報が冗長になってしまうという問題があった。
【0036】また、従来の方法は入力音声と標準パターンの照合の距離尺度として、音声全体を一つのベクトルとして一次判別関数で表される統計的距離尺度を用いていたため、少ない計算量で認識することができたが、近年の計算機の急速な高速化にともない、計算量が増えても認識性能を向上させる必要性がでてきた。
【0037】さらに、従来の方法は単語標準パターンを作成するために、多数の人が発声した学習用音声データが必要となるため、認識対象語彙の変更が容易ではないという問題があった。
【0038】本発明は上記従来の課題を解決するもので、その第一の目的は従来例よりも認識率を向上させる音声認識方法を提供することである。
【0039】第二の目的は、識別性能の高い距離尺度を用いて、さらに認識率を向上させる音声認識方法を提供することである。
【0040】第三の目的は、日本語のかな文字表記から単語標準パターンを作成することができる、認識対象語彙の変更が容易で高精度な音声認識方法を提供することである。
【0041】
【課題を解決するための手段】本発明では第一に、以下の手段によって上記課題を解決した。
【0042】単語音声中の子音部は基準フレームを中心にフレームを連続にとって標準パターンを作成し、母音部はフレームを線形に伸縮して標準パターンを作成する。認識の際には子音部はフレームを連続に照合し、母音部はフレームを伸縮させて照合を行なう。このようなフレームの取り方をすることにより音声認識性能を向上させることができる。
【0043】計算量および標準パターンの推定パラメータ数を増大させないために、入力音声と標準パターンの照合は、音声全体を一つのベクトルとしてフレーム間相関を考慮した一次判別関数で表される統計的距離尺度を用いる。または、計算量は2倍になるが、フレームを独立に扱い、そのかわりに特徴パラメータの時間変化量である動的特徴パラメータを併用し一次判別関数で表される統計的距離尺度を用いる。
【0044】本発明では第二に、以下の手段によって上記課題を解決した。第一の手段における入力音声と標準パターンの照合の距離尺度として二次判別関数で表される統計的距離尺度を用いる。ただし特徴パラメータの単語全体の時系列パターンを一つのベクトルとして標準パターンを作成しようとすると、共分散の推定のために膨大な学習サンプルが必要となるため、時間パターンをフレーム毎に独立のベクトルとして扱う。二次判別関数で表される統計的距離尺度を用いることによりさらに音声認識性能を向上させることができる。特徴パラメータの時間変化量である動的特徴パラメータを併用するとさらに、音声認識性能を向上させることができる。
【0045】本発明では第三に、以下の手段によって上記課題を解決した。音節、CV(子音+母音)、VC(母音+子音)、VCV(母音+子音+母音)、又はCVC(子音+母音+子音)などの単位ごとに第一、第二の手段と同様に標準パターンを作成しておき、これらを接続して任意の単語標準パターンを作成し、第一、第二の手段と同様に認識する。日本語のかな文字表記にしたがって単語標準パターンを作成することができるため、認識対象語彙の変更を容易にすることができる。
【0046】
【作用】日本語は子音と母音によって構成される。一般に、母音部はスペクトルの時間的変化が少なく定常的あり、その継続長は発声速度の相違によって伸縮しやすいという特徴がある。一方、子音部はスペクトルの時間的変化に音素を識別するための情報があり、その継続長は比較的短く発声速度が異なっても伸縮しにくいという特徴がある。
【0047】本発明は第一に、子音部は基準フレームを中心にフレームを連続にとり伸縮させずに照合を行ない、母音部はフレームを伸縮させて照合を行なうことによって、子音部の局所的なスペクトルの時間的変化の特徴と母音部の大局的なスペクトルの特徴を発声速度に影響されずに適切にとらえることができるようになり、認識性能が向上する。標準パターンの子音部を連続にとるかわりに母音部のフレームを少なくすることにより、標準パターンのフレーム数は増大しない。
【0048】音声全体を一つのベクトルとしてフレーム間相関を考慮した一次判別関数で表される統計的距離尺度を用いると、計算量および推定パラメータ数を増大させずに認識率の向上を図ることができる。フレームを独立に扱い、そのかわりに特徴パラメータの時間変化量である動的特徴パラメータを併用し一次判別関数で表される統計的距離尺度を用いると、計算量は2倍になるが、認識率の向上を図ることができる。
【0049】本発明は第二に、入力音声と標準パターンの照合の際、フレームを独立に扱い二次判別関数で表される統計的距離尺度を用いることによりさらに音声認識性能を向上させることができる。特徴パラメータの時間変化量である動的特徴パラメータを併用すると、フレームを独立に扱うことによって失われた時間変化の特徴量をとらえることができるようになるため、さらに音声認識性能を向上させることができる。
【0050】本発明は第三に、音節、CV(子音+母音)、VC(母音+子音)、VCV(母音+子音+母音)又はCVC(子音+母音+子音)などの標準パターンを接続して任意の単語標準パターンを作成し認識することにより、日本語のかな文字表記にしたがって単語標準パターンを作成することができるため、認識対象語彙の変更を容易にすることができる。
【0051】また、ワードスポッティング機能を導入することによって、騒音に対して頑強な、実用性の高い認識装置が実現できる。
【0052】
【実施例】
(実施例1)以下、本発明における第1の実施例について説明する。
【0053】第1の実施例では、日本語の発声の最小の単位である音節を単独に発声した単音節を認識対象とし、音声全体を一つのベクトルとして共分散行列を共通化したベイズ判定に基づく一次判別関数で表される統計的距離尺度を用いて入力音声と単音節標準パターンの照合を行ない認識する音声認識方法について説明する。
【0054】第1の実施例では未知入力音声の単音節区間を検出し、これとあらかじめ作成しておいた単音節標準パターンとの照合を行なうことにより単音節の認識を行なう。
【0055】日本語の単音節は子音部とそれにつづく母音部によって構成される。一般に、母音部はスペクトルの時間的変化が少なく定常的あり、その継続長は発声速度の相違によって伸縮しやすいという特徴がある。一方、子音部はスペクトルの時間的変化に音素を識別するための情報があり、その継続長は比較的短く発声速度が異なっても伸縮しにくいという特徴がある。そこで、子音部はフレーム(分析時間の単位;本実施例では1フレーム=10ms)を連続にとり伸縮させずに入力音声と標準パターンの照合を行ない、母音部はフレームを伸縮させて照合を行なう。母音部はスペクトルが定常的であるため、隣接した数フレーム分をまとめて1フレームの標準パターンにしても識別性能の低下は少ない。子音部はフレームを連続に密にとるかわりに母音部はフレームを間引いて疎にとることによって、単音節標準パターン全体のフレーム数を増大させずに認識率の向上を図ることができる。
【0056】第1の実施例について図1、図2、図3を参照しながら説明する。図1は第1の実施例の音声認識方法の処理の流れを示すフローチャートである。図1において、1は未知入力音声を分析時間(フレーム)ごとに線形予測(LPC)分析する音響分析部、2は特徴パラメータをフレームごとに求める特徴パラメータ抽出部、3は入力音声の始端フレームおよび終端フレームを検出する音声区間検出部、4は単音節標準パターンを格納する標準パターン格納部、5は入力音声と単音節標準パターンとの距離を求めるDP照合部、6はDP照合部5で求めた各々の標準パターンとの距離の中で最小(類似度が最大)の値をもつ標準パターンに対応する音声名を認識結果とする距離比較部である。
【0057】次にその動作を説明する。単音節標準パターンはあらかじめ作成して標準パターン格納部4に格納しておく。単音節標準パターンの作成方法は後述する。未知入力音声が入力されると音響分析部1で分析時間(フレーム)ごとに線形予測(LPC)分析を行なう。次に、特徴パラメータ抽出部2でP個(Pは正の整数)の特徴パラメータをフレームごとに求める。特徴パラメータは、LPCメルケプストラム係数(本例ではC1-C9まで9個)、正規化残差C0、および音声対数パワーの時間差分値V0を用いる。次に音声区間検出部3で入力音声の始端フレームおよび終端フレームを音声パワー情報などを用いて検出する。第1の実施例では音声区間の検出は音声パワーを用いるがどのような方法を用いてもよい。次にDP照合部5で、入力音声の特徴パラメータ時系列と、標準パターン格納部4に格納されているある単音節標準パターンとをDP法により動的に照合を行ない、その単音節標準パターンに対する距離を求める。これを認識対象とする全ての単音節に対して求める。DP照合および距離計算の方法は後述する。最後に距離比較部6で、DP照合部5で求めた各々の標準パターンとの距離の中で最小(類似度が最大)の値をもつ標準パターンに対応する音声名を認識結果として選択し、出力する。
【0058】以下、単音節標準パターンを作成する方法について説明する。不特定話者音声認識用の音声標準パターンは、多数の人が発声した学習用音声データを用いてその統計量(平均値、共分散)を求めることにより作成する。
【0059】日本語の単音節は子音部とそれにつづく母音部によって構成される。単音節標準パターンは、おなじカテゴリー(単音節)の各学習用音声データから非線形にフレームを抽出しこれらのフレームの特徴パラメータを時系列に並べたベクトルを求め、このベクトルの集合から作成する。非線形にフレームを抽出する方法は以下のとおりである。
【0060】子音はスペクトルの時間的変化に音素を識別するための情報があり、その継続長は比較的短く発声速度が異なっても伸縮しにくいという特徴がある。そこで子音部については、その子音の特徴を最も表している時間的な位置を基準フレームとし、学習用音声データから各基準フレームの前後数フレームを連続して抽出する。母音部はその連続した時間パターンの終端から、音声の終端フレームまでの間を線形にフレームを伸縮させて抽出する。図2がその概念図を示している。
【0061】図2において、子音の基準フレームは、子音ごとに定められている一定の基準に基づいて、目視によって学習用音声データに音素ラベル21としてラベル付けされている。本実施例では、無声破裂音(/c/,/p/,/t/,/k/)は破裂フレーム、鼻音(/m/,/n/)および無声摩擦音(/h/,/s/)は母音へのわたりの部分、有声破裂音(/b/,/d/,/g/,/r/)は破裂フレーム(バズバーの終端)、/z/は有声性から無声性へ変わる部分をそれぞれ基準フレームとしている。また単母音(「あ」,「い」,「う」,「え」,「お」)と半母音(「や」,「ゆ」,「よ」,「わ」)は語頭の音声パワー22の立ち上がりのフレームを基準フレームと定義している。そして特徴パラメータ時系列23において、この基準フレームを中心に前L1フレーム、後L2フレームを連続して抽出する。L1およびL2の値は子音ごとに異なる。L1およびL2は子音を識別するために有効なフレームを予備実験により検討して決定した。さらにこの連続した時間パターンの終端フレームから、音節の終端フレームまでの母音部を線形に伸縮して抽出することにより、時系列パターンCm24を作成する。拗音の/j/は子音から後続母音へのゆっくりとしたスペクトル遷移に特徴があり発声速度によって伸縮しやすいため、母音部と同様に線形に伸縮する。
【0062】ある単音節ωnの標準パターンは次のような手順で作成する。
(1)多数の人(ここでは100名)が単音節ωnを発声したM個の学習用音声データを用意する。
(2)各データを非線形に伸縮を行ないJフレームに正規化する。
(3)第m番目の発声データに対して伸縮後の特徴パラメータを時系列に並べ、時系列パターンCmを求める。(m=1,...,M)(4)M個の時系列パターンCm(m=1,...,M)を用いてその統計量(平均値、共分散)を求めることにより標準パターンを作成する。
【0063】第m番目の学習用音声データから、時系列パターンCmを求める方法について述べる。
【0064】標準パターンのフレーム数をJフレームとし、このうちのLフレーム(L=L1+L2+1)を連続にとるとする。第m番目の学習用音声データの｛基準フレーム-L1｝フレームを1フレーム目、音声区間の終端フレームをIフレーム目とすると、このデータの第iフレームと伸縮後の第jフレームの関係は(数13)で表される。ただし、［］はその数を越えない最大の整数を表す。第1の実施例ではJ=20、L=10とする。Jはすべての単音節について同じ値でなければならないが、Lは単音節毎に異なってもよい。
【0065】
【数13】【0066】伸縮後のJフレーム分の特徴パラメータを時系列に並べ時間パターンCmを作成する。
【0067】
【数14】【0068】これをM個の学習用音声データについて求める。時間パターンCmを一つのベクトルとして扱うことにより、パラメータのフレーム間の相関を考慮することになる。M個のJ×P次元のベクトルCm(m=1,...,M)からその平均値ベクトルμおよび共分散行列Wを求める。
【0069】さらにこれをN個の認識対象とする単音節に対してそれぞれ求める。以下、第n番目の単音節ωnに対する平均値ベクトルをμn、共分散行列をWnと表記する。
【0070】未知入力音声の特徴パラメータの時系列パターンと単音節標準パターンとの距離計算は、共分散行列を共通化したベイズ判定に基づく距離を用いて計算する。
【0071】ベイズ判定に基づく距離は以下のようにして求める。いま、未知入力音声の伸縮後の特徴パラメータをJフレーム分並べてできる入力ベクトルXを【0072】
【数15】【0073】入力ベクトルXが観測されたときにそれが単音節ωnである確率P(ωn｜X)は、従来例と同様にして求められる。ベイズの定理よりP(ωn｜X)は、【0074】
【数16】【0075】となる。P(X｜ωn)は事前確率で、入力がカテゴリーωnであったときにベクトルXが観測される確率、P(X)は生起し得るすべての入力を考えた場合のベクトルXが観測される確率である。単語ωnの出現確率P(ωn)は各単語同じと仮定して定数とし、入力Xが一定とするとP(X)が定数となるので、事前確率P(X｜ωn)を最大とするカテゴリーωnを判定結果とすればよい。
【0076】パラメータの分布を正規分布と考えると、事前確率P(X｜ωn)は(数17)で表される。
【0077】
【数17】【0078】ここでtは転置行列を表す。両辺の対数をとって識別に不要な定数項を省略しさらに-2倍すると次式を得る。
【0079】
【数18】【0080】この式は単音節ωnに対するベイズ判定に基づく距離である。ここで、計算量および推定パラメータ数削減のため、従来例と同様に共分散行列を共通化してこの式を線形判別式に展開する。各単音節標準パターンの共分散行列Wnを共通化し、Wとする。Wは次式のようにして求める。
【0081】
【数19】【0082】したがって【0083】
【数20】【0084】とおくことができる。これを(数18)に代入し識別に不要な定数項を省略すると【0085】
【数21】【0086】となり、【0087】
【数22】【0088】
【数23】【0089】とおくことにより、【0090】
【数24】【0091】のような線形一次判別式になることがわかる。このようにしてAn,Bnを認識対象とする単音節の各々に対して求め、標準パターン格納部4に格納しておく。
【0092】以下、DP照合部5で、入力音声と単音節標準パターンとを、DP法により動的に時間整合を行なって照合し、距離を求める方法について詳しく説明する。
【0093】音声区間検出部で検出された音声区間の始端フレームを第1フレーム、終端フレームを第Iフレームとする。入力音声の第iフレームの特徴パラメータをP個並べたものをxi【0094】
【数25】【0095】とする。そして、入力音声のr(1),r(2),…,r(j),…,r(J)番目のフレームのxを並べてJフレーム分の時間パターンXを作成する。これが入力ベクトルになる。
【0096】
【数26】【0097】単音節ωnの標準パターンをAn,Bnとし、Anを【0098】
【数27】【0099】と書くとき、入力ベクトルXと単音節ωnの標準パターンとの距離Lnは【0100】
【数28】【0101】であるから、【0102】
【数29】【0103】となる。そこで、Lnが最小となるようなr(j)をDP法により求めればよい。Lnが最小となるときの値をDP法によって以下のような漸化式で求める。
【0104】
【数30】【0105】ただしmはmsからmeまでの整数でms,meの値は単音節毎、標準パターンのフレームごとに異なる。j=1からj=Lまでの連続部では【0106】
【数31】【0107】とし、入力音声を伸縮させず連続的に標準パターンと照合する。伸縮部のms,meの値は、本実施例ではその単音節の標準パターンが【0108】
【数32】【0109】の間で伸縮するように決定した。これらのDPパスを連続部に関しては図3(a)に、伸縮部に関しては図3(b)に示す。
【0110】入力音声の終端フレームにおける単音節標準パターンの最終フレームの累積距離g(I,J)をBnから引いたものが、入力ベクトルXと単音節ωnの標準パターンとの距離Lnである。
【0111】
【数33】【0112】これをすべての単音節標準パターンについて求める。なお、第1の実施例では入力音声の音声区間を検出してから照合を行なう方法について説明したが、入力音声の音声区間検出をせず、ノイズを含む全入力音声区間について、【0113】
【数34】【0114】で表される漸化式によって連続DPマッチングを行ない、g(i,J)が最小となる入力フレームiを求め、そのときのフレームをIminとするとき、【0115】
【数35】【0116】を単音節ωnの標準パターンとの距離とすることによって、音声区間を検出しなくても、認識を行なうことができる。これをワードスポッティングという。
【0117】ただし、ワードスポッティングを行なう場合には事後確率化された距離尺度を用いなければならない。その方法は以下のとおりである。(数16)において、ワードスポッティングを行なう場合には異なった入力区間における入力Xについて比較しなければならないため、入力Xが一定とはならない。したがってP(X)の項を考慮した事後確率P(ωn｜X)を最大とするカテゴリーωnを判定結果とする必要がある。
【0118】P(X)は生起し得るすべての入力を考えた場合のベクトルXが観測される確率である。そこで、事後確率化のための周囲情報パターンとして、生起し得るすべての入力についての平均値ベクトルおよび共分散行列を求めておく。すなわち、認識対象とする全単音節学習用音声データの特徴パラメータ時系列に対してJフレームの時間窓を1フレームずつシフトさせながら作成したJフレームの時系列パターンから平均値ベクトルμeと共分散行列Weを求めておく。ただしノイズを含む区間から、発声された音声をスポッティングするためには、事後確率化のため周囲情報パターンにノイズ区間を含めて作成しておく必要がある。P(X)は周囲情報パターンの平均値ベクトルμe、共分散行列Weから求まる。
【0119】パラメータの分布を正規分布と考えると、事後確率P(ωn｜X)は(数36)で表される。
【0120】
【数36】【0121】ここでtは転置行列を表す。両辺の対数をとって-2倍すると次式を得る。
【0122】
【数37】【0123】この式は単音節ωnに対する事後確率化したベイズ判定に基づく距離である。ここで、計算量および推定パラメータ数削減のため、共分散行列を共通化してこの式を線形判別式に展開する。認識対象語彙の各々の標準パターンの共分散行列Wnと周囲情報パターンの共分散行列Weを共通化し、Wとする。Wは次式のようにして求める。gは周囲情報パターンを混入する割合であり、ここではg=Nとする。
【0124】
【数38】【0125】したがって、【0126】
【数39】【0127】とおくことができる。これを(数37)に代入すると【0128】
【数40】【0129】となり、【0130】
【数41】【0131】
【数42】【0132】とおくことにより、【0133】
【数43】【0134】のような線形一次判別式になることがわかる。ワードスポッティングを行なう場合には、このようにしてAn,Bnを認識対象とする単音節の各々に対して求め、標準パターン格納部4に格納しておく。
【0135】なお、無声摩擦音や、語頭のバズバーなどのようにスペクトルが定常で発声によって伸縮の激しい音素については、基準フレームを中心とした連続パターンの時間的に前の部分に母音部と同様の線形伸縮するパターンを設けてもよい。
【0136】また、第1の実施例では単音節を認識する場合の例を述べたが、単語認識も同様に行なうことができる。その場合も標準パターンは、子音部は基準フレームを中心に連続に、母音部は線形に伸縮させて全体でJフレームになるように作成する。認識する際には、連続部は伸縮させないようにしながら第1の実施例と同様にDP法により照合を行なう。
【0137】(実施例2)以下、本発明における第2の実施例について説明する。
【0138】第2の実施例では、日本語単音節を認識対象とし、ベイズ判定に基づく二次判別関数で表される統計的距離尺度を用いて、入力音声と単音節標準パターンのフレーム毎に得られる特徴パラメータベクトルと動的特徴パラメータベクトルの照合を行ない認識する音声認識方法について説明する。
【0139】第2の実施例では第1の実施例と同じく未知入力音声の単音節区間を検出し、これとあらかじめ作成しておいた単音節標準パターンとの照合を行なうことにより単音節の認識を行なう。
【0140】第2の実施例について図4を参照しながら説明する。図4は、第2の実施例の処理の流れを示すフローチャートである。
【0141】図4において1は未知入力音声をフレームごとにLPC分析を行なう音響分析部、2は特徴パラメータをフレームごとに求める特徴パラメータ抽出部、7は特徴パラメータの時間変化量を求める動的特徴パラメータ抽出部、3は入力音声の始終端フレームを検出する音声区間検出部、4は単音節標準パターンを格納する標準パターン格納部、5は入力音声と単音節標準パターンとの距離を求めるDP照合部、6はDP照合部5で求めた距離の中で最小の値をもつ標準パターンに対応する音声名を認識結果とする距離比較部である。
【0142】次にその動作を説明する。単音節標準パターンはあらかじめ作成して標準パターン格納部4に格納しておく。単音節標準パターンの作成方法は後述する。未知入力音声が入力されると音響分析部1でフレームごとにLPC分析を行ない、特徴パラメータ抽出部2でP個の特徴パラメータをフレームごとに求める。特徴パラメータは第1の実施例と同様である。そして動的特徴パラメータ抽出部7で特徴パラメータの各次元についてその時間変化量である回帰係数をフレーム毎にP個求める。次に音声区間検出部3で入力音声の始終端フレームを検出し、DP照合部5で、入力音声の特徴パラメータ時系列と、単音節標準パターンとを二次判別関数で表される統計的距離尺度を用いてDP法により動的に照合を行ない、各単音節標準パターンに対する距離を求める。最後に距離比較部6で、DP照合部5で求めた各々の標準パターンとの距離の中で最小の値をもつ標準パターンに対応する音声名を認識結果として選択し、出力する。
【0143】未知入力音声の特徴パラメータの時系列パターンと単音節標準パターンとの距離計算は、ベイズ判定に基づく距離を用いて計算する。
【0144】ベイズ判定に基づく距離は二次判別関数であり、計算量が距離を求めるベクトルの次元数の2乗に比例するため、ベクトルの次元数が大きいと計算量が爆発的に増大する。また共分散の推定のためには膨大な学習サンプルが必要となる。そこでベクトルの次元数を減らす必要がある。第1の実施例では特徴パラメータの単音節全体の時系列パターンを一つのベクトルとして入力音声と単音節標準パターンの距離を求めたが、第2の実施例では、これをフレーム毎に分割して扱う。すなわち、P個の特徴パラメータからなるP次元のベクトルをJフレーム分並べたものを標準パターンとし、それぞれのフレームと入力音声の対応するフレームとの距離をベイズ判定に基づく距離によって求め、その和を入力音声と単音節標準パターンとの距離とする。しかしこのようにフレームを独立に扱うと、特徴パラメータの動的な変化を捉らえることができなくなる。そこで特徴パラメータの時間変化量を動的特徴パラメータとして導入する。本実施例では、あるフレームの前後2フレーム(計5フレーム)分のp番目の特徴パラメータの回帰係数をそのフレームのp番目の動的特徴パラメータとする。動的特徴パラメータ抽出部7ではフレーム毎にP個の動的特徴パラメータを求める。
【0145】いま、未知入力音声の第iフレームのP個の特徴パラメータからなるベクトルを、【0146】
【数44】【0147】また、P個の動的特徴パラメータからなるベクトルを、【0148】
【数45】【0149】とする。単音節標準パターンは第1の実施例と同様にして、各学習用音声データを非線形に伸縮を行なってJフレームに正規化し、第n番目の単音節ωnに対する第jフレームの特徴パラメータの平均値ベクトルμnjおよび共分散行列Wnj、動的特徴パラメータの平均値ベクトル【0150】
【外1】【0151】および共分散行列【0152】
【外2】【0153】を、j=1-JまでJフレーム分求め、これらを標準パターン格納部4に格納しておく。
【0154】このとき入力の第iフレームと単音節ωnの第jフレームのベイズ判定に基づく距離は(数46)で表される。
【0155】
【数46】【0156】ここでtは転置行列を表す。単音節ωnに対する標準パターンの1,2,…,j,…,J番目のフレームと、入力音声のr(1),r(2),…,r(j),…,r(J)番目のフレームがそれぞれ対応するとき、入力音声と単音節ωnとの距離Lnは【0157】
【数47】【0158】とする。したがって(数46)(数47)より【0159】
【数48】【0160】となる。そこで、Lnが最小となるようなr(j)をDP法により求めればよい。Lnが最小となるときの値を第1の実施例と同様に、DP法によって以下のような漸化式で求める。
【0161】
【数49】【0162】ただしmはmsからmeまでの整数でms,meの値は第1の実施例と同様である。連続部では(数31)であり伸縮させずに照合を行なう。
【0163】入力音声の終端フレームにおける単音節標準パターンの最終フレームの累積距離g(I,J)が、入力音声と単音節ωn標準パターンとの距離Lnである。
【0164】
【数50】【0165】これをすべての単音節標準パターンについて求める。なお、第2の実施例ではフレーム毎に独立に距離計算を行なうため、標準パターンのフレーム数は、単音節毎に異なってもよい。その場合、入力音声と単音節ωnとの距離Lnは(数47)のかわりに【0166】
【数51】【0167】とする。ここでJnは単音節ωnのフレーム数である。第2の実施例では、ベイズ判定に基づく距離を用いているため、従来例に比べ計算量が多い。従来例および第1の実施例では、音声全体を一つのベクトルとして共分散行列を共通化したベイズ判定に基づく距離を用いるため、フレーム数をJ、フレームあたりのパラメータ数をP個とすると、1単音節あたりの積和の計算回数はJP回である。これはJ=20、P=11とすると220回になる。一方、ベイズ判定に基づく距離ではベクトルの次元数をPとすると積和の計算回数はP(P+3)/2回である。フレームを独立に扱い特徴パラメータベクトルと動的特徴パラメータベクトルを使用する場合、1フレームあたりの積和の計算回数はP(P+3)/2×2回となるから、JフレームではJP(P+3)回となる。これはJ=20、P=11とすると3080回になる。すなわち、第2の実施例の積和計算量は従来例の14倍になる。
【0168】なお、第2の実施例では、照合の距離尺度としてベイズ判定に基づく二次判別関数で表される統計的距離尺度を用いたが、共分散行列を共通化したベイズ判定に基づく一次判別関数で表される統計的距離尺度を用いることもできる。これにより、従来例に比べ計算量が二倍程度で従来例よりも高い認識率が得られる。
【0169】また、第2の実施例では、入力音声と単音節標準パターンのフレーム毎に得られる特徴パラメータベクトルと動的特徴パラメータベクトルの照合を行ない認識したが、特徴パラメータベクトルだけを用いてもよい。その場合には認識率はやや落ちるが、計算量が半分ですむというメリットがある。
【0170】また、第1の実施例と同様に連続DPマッチングを行なうことにより、ワードスポッティングを行なうことが可能である。ワードスポッティングを行なう場合、異なる入力区間について比較するため、距離尺度は事後確率化された距離尺度を用いる必要がある。その方法は以下のとおりである。
【0171】事後確率化のための周囲情報パターンとして、生起し得るすべての入力についての平均値ベクトルおよび共分散行列を求めておく必要がある。認識対象とする全単音節学習用音声データの全音声区間に対して作成した1フレームの特徴パラメータの平均値ベクトルμeおよび共分散行列We、動的特徴パラメータの平均値ベクトル【0172】
【外3】【0173】および共分散行列【0174】
【外4】【0175】を求めておき、これらも標準パターンとして標準パターン格納部4に格納しておく。ただしノイズを含む区間から、発声された音声をスポッティングするためには、事後確率化のため周囲情報パターンにノイズ区間を含めて作成しておく必要がある。
【0176】事後確率化されたベイズ判定に基づく距離は(数52)で表される。
【0177】
【数52】【0178】したがって、入力音声と単音節ωnとの距離Lnは(数48)のかわりに(数53)を用い、DPの漸化式は(数49)のかわりに(数54)を用いる。
【0179】
【数53】【0180】
【数54】【0181】(実施例3)以下、本発明における第3の実施例について説明する。
【0182】第3の実施例では、学習用単語音声データから音節を切りだし、第2の実施例と同様にしてフレーム毎の特徴パラメータベクトルと動的特徴パラメータベクトルから音節標準パターンを作成し、これらを連結して単語標準パターンを作成して、第2の実施例と同様にしてベイズ判定に基づく二次判別関数で表される統計的距離尺度を用いて照合を行ない単語を認識する方法について説明する。
【0183】第3の実施例について図5、図6を参照しながら説明する。図5は第3の実施例の処理の流れを示すフローチャートである。
【0184】図5において1は未知入力音声をフレームごとにLPC分析する音響分析部、2は特徴パラメータをフレームごとに求める特徴パラメータ抽出部、7は特徴パラメータの時間変化量を求める動的特徴パラメータ抽出部、3は入力音声の始終端フレームを検出する音声区間検出部、8はかな表記単語辞書、9は音節標準パターンを格納する音節標準パターン格納部、5は入力音声と各単語標準パターンとの距離を求めるDP照合部、6はDP照合部5で求めた距離の中で最小(類似度が最大)の値をもつ標準パターンに対応する音声名を認識結果とする距離比較部である。
【0185】次にその動作を説明する。音節標準パターンはあらかじめ作成して音節標準パターン格納部9に格納しておく。音節標準パターンの作成方法は後述する。未知入力音声が入力されると音響分析部1でフレームごとにLPC分析を行ない、特徴パラメータ抽出部2でP個の特徴パラメータをフレームごとに求める。特徴パラメータは第1の実施例と同様である。そして動的特徴パラメータ抽出部7で特徴パラメータの各次元についてその時間変化量である回帰係数をフレーム毎にP個求める。次に音声区間検出部3で入力音声の始終端フレームを検出する。次にかな表記単語辞書8に書かれている単語のかな文字表記にしたがって、音節標準パターン格納部9に格納されている音節標準パターンを連結し、単語標準パターンを作成する。DP照合部5で、第2の実施例と同様に入力音声の特徴パラメータ時系列と、各単語標準パターンとをDP法により動的に照合を行ない、各単語標準パターンに対する距離を求める。最後に距離比較部6で、DP照合部5で求めた各々の標準パターンとの距離の中で最小(類似度が最大)の値をもつ標準パターンに対応する音声名を認識結果として選択し、出力する。
【0186】以下、音節標準パターンを作成する方法について図6(a)を用いて説明する。音韻環境を考慮して、音韻バランスが取れた種々の単語セットを多数の人が発声した音声データを学習用音声データとして用意する。学習用音声データにはあらかじめ音節64の始終端位置と子音の基準フレームを目視によって音素ラベル61としてラベル付けを行なっておく。そして各音節の始端から終端までの音声データを切りだし、音節毎に、第2の実施例と同様に子音部は基準フレームを中心に連続に母音部は線形伸縮させて音節標準パターンの特徴パラメータ時系列63を作成する。無声摩擦音や、語頭のバズバーなどのようにスペクトルが定常で発声によって伸縮の激しい音素については、基準フレームを中心とした連続パターンの時間的に前の部分に母音部と同様の線形伸縮するパターンを設けてもよい。
【0187】入力音声を単語標準パターンとDP法により時間伸縮して照合を行なうときも第2の実施例のように、子音部は伸縮させず連続になるようにしながら単語の始端から終端まで照合を行なう。DPパスは音節毎に(数32)で表される範囲に届くようにフレーム毎に変えてもよいし、音節標準パターンの長さをその音節の平均継続長の1/2のように音節毎に変えれば伸縮部で一律にしてもよい。
【0188】なお、第3の実施例では音節単位に認識をするが、CV(子音+母音)、VC(母音+子音)、VCV(母音+子音+母音)又はCVC(子音+母音+子音)などの音声片を単位としてもよい。その場合も子音部は基準フレームを中心として連続に照合を行なう。図6(b)は認識の単位をCV-VCとしたときの切り出し方の例である。
【0189】また、第3の実施例では、照合の距離尺度としてベイズ判定に基づく二次判別関数で表される統計的距離尺度を用いたが、共分散行列を共通化したベイズ判定に基づく一次判別関数で表される統計的距離尺度を用いることもできる。これにより、少ない計算量で認識対象語彙の変更が容易な音声認識方法を実現することができる。
【0190】また、第3の実施例では、入力音声と単音節標準パターンのフレーム毎に得られる特徴パラメータベクトルと動的特徴パラメータベクトルの照合を行ない認識したが、特徴パラメータベクトルだけを用いてもよい。その場合には認識率はやや落ちるが、計算量が半分ですむというメリットがある。
【0191】また、連続DPマッチングを行なうことによって、第1、第2の実施例と同様にして、ワードスポッティングを行なうことも可能である。
【0192】第1、第2、第3の実施例の効果を確認するため、男女計150名が発声した110単音節音声および地名100単語音声を用いて認識実験を行なった。このうち100名(男女各50名)のデータを用いて音声標準パターンを作成し、残りの50名のデータを評価した。
【0193】(表1)に評価条件を示す。(表2)に従来例による110単音節認識率および地名100単語認識率、第1の実施例による110単音節認識率、第2の実施例による110単音節認識率、第3の実施例による地名100単語認識率を示す。
【0194】
【表1】【0195】
【表2】【0196】(表2)において計算量は、標準パターンのフレーム数Jを20、フレーム毎の特徴パラメータの個数Pを11とした場合の、入力音声と標準パターンの距離を求める際の積和の演算回数で従来例による方法を1としたときの比を表している。第3の実施例による方法では、地名100単語に出現する音節の総フレーム数分だけ距離計算を行なえばよいので計算量はそれほど増大しない。
【0197】このように第1の実施例による方法では、単音節認識率が従来法の47.2%に比べ68.0%と、計算量や推定パラメータ数を増大させることなく認識率を向上させることができる。
【0198】また第2の実施例による方法では、単音節認識率が第1の実施例による方法に比べ75.4%と、さらに大きく認識率を向上させることができる。
【0199】また従来法では認識対象語彙の変更が困難であったが、第3の実施例による方法では、かな表記から単語標準パターンが作成できるため認識対象語彙の変更が容易になり、認識率の面でも単語認識率が従来法の97.3%から98.9%に向上した。
【0200】本実施例はいずれも、ワードスポッティングが可能な方法でありワードスポッティングを導入することによって、騒音に対して頑強な、実用性の高い認識装置が実現できる。
【0201】
【発明の効果】本発明は第一に、子音部は基準フレームを中心に連続にフレームをとり、母音部は線形伸縮させて標準パターンを作成し、認識時には子音部は伸縮させずに照合を行ない、母音部はフレームを伸縮させて照合を行なうことによって、子音部の局所的なスペクトルの時間的変化の特徴と母音部の大局的なスペクトルの特徴を発声速度に影響されずに適切にとらえることができるようになるため、認識性能の高い音声認識方法を実現することができる。入力音声と標準パターンの照合に、音声全体を一つのベクトルとしてフレーム間相関を考慮した一次判別関数で表される統計的距離尺度を用いることにより、計算量および標準パターンの推定パラメータ数を増大させることなく、認識率を向上させることができる。また、計算量は2倍になるがフレームを独立に扱い、そのかわりに特徴パラメータの時間変化量である動的特徴パラメータを併用し一次判別関数で表される統計的距離尺度を用いることによっても、認識率を向上させることができる。
【0202】本発明は第2に、さらに、時間パターンをフレーム毎に独立のベクトルとして扱い、二次判別関数で表される統計的距離尺度を用いることにより、さらに音声認識性能を向上させることができる。また特徴パラメータの時間変化量である動的特徴パラメータを併用するとさらに、音声認識性能を向上させることができる。
【0203】本発明は第三に、さらに、音節やCV(子音+母音)、VC(母音+子音)、VCV(母音+子音+母音)又はCVC(子音+母音+子音)などの音声片を組合わせることにより、認識対象語彙の変更が容易で高精度な音声認識方法を実現することができる。
【0204】また、ワードスポッティング機能を導入することによって、騒音に対して頑強な、実用性の高い認識装置が実現できる。
【0205】このように本発明は実用上有効な方法であり、その効果は大きい。
【特許請求の範囲】
【請求項1】 入力音声に対してフレームごとにP個(Pは正の整数)の特徴パラメータを抽出し、前記入力音声とあらかじめ作成した単語音声標準パターンとを、統計的距離尺度を用いて、子音部は伸縮させず母音部は伸縮することにより時間整合して照合し、入力音声と各単語音声標準パターンの類似度を求め、前記類似度が最大となる単語音声標準パターンに対応する単語音声名を認識結果とすることを特徴とする音声認識方法。
【請求項2】 単語音声標準パターンが、認識対象とするN種(Nは正の整数)の単語音声の各々に属する学習用単語音声データの始端から終端までの間を、子音部は基準フレームを中心に連続にとり母音部は各々のデータの母音区間を線形に伸縮することにより単語全体をJフレーム(Jは正の整数)に非線形に伸縮し、各フレームごとにP個(Pは正の整数)の特徴パラメータを抽出して時間的順序に並べて得られるP×J次元のベクトルを用いて作成したものである請求項1記載の音声認識方法。
【請求項3】 単語音声標準パターンが、認識対象とするN種(Nは正の整数)の単語音声の各々に属する学習用単語音声データの始端から終端までの間を、子音部は基準フレームを中心に連続にとり母音部は各々のデータの母音区間を線形に伸縮することにより単語全体をJフレーム(Jは正の整数)に非線形に伸縮し、各フレームごとにP個(Pは正の整数)の特徴パラメータを抽出して時間的順序に並べて得られるJ個のP次元のベクトルを用いて作成したものである請求項1記載の音声認識方法。
【請求項4】 入力音声に対しフレームごとにP個(Pは正の整数)の特徴パラメータとその時間変化量であるP個の動的特徴パラメータを抽出し、入力音声区間とあらかじめ作成した単語音声標準パターンとを、統計的距離尺度を用いて、子音部は伸縮させず母音部は伸縮することにより時間整合して照合し、入力音声と各単語音声標準パターンの類似度を求め、前記類似度が最大となる単語音声標準パターンに対応する単語名を認識結果とすることを特徴とする音声認識方法。
【請求項5】 単語音声標準パターンが、認識対象とするN種(Nは正の整数)の単語音声の各々に属する学習用単語音声データの始端から終端までの間を、子音部は基準フレームを中心に連続にとり母音部は各々のデータの母音区間を線形に伸縮することにより単語全体をJフレーム(Jは正の整数)に非線形に伸縮し、各フレームごとにP個(Pは正の整数)の特徴パラメータを抽出し、さらにフレームごとに各特徴パラメータの時間変化量である動的特徴パラメータをP個求め、特徴パラメータを時間的順序に並べて得られるJ個のP次元のベクトルと動的特徴パラメータを時間的順序に並べて得られるJ個のP次元のベクトルを用いて作成したものである請求項4記載の音声認識方法。
【請求項6】 単語音声標準パターンが、音韻環境を考慮したM種(Mは正の整数)の単語セットの学習用音声データを、音節、(子音+母音)、(母音+子音)、(母音+子音+母音)又は(子音+母音+子音)などの音声片単位に切り分け、音声片ごとに、各々に属する学習用音声片データの始端から終端までの間を、子音部は基準フレームを中心に連続にとり母音部は各々のデータの母音区間を線形に伸縮することにより音声片全体をJフレーム(Jは正の整数)に非線形に伸縮し、各フレームごとにP個(Pは正の整数)の特徴パラメータを抽出し、特徴パラメータを時間的順序に並べて得られるJ個のP次元のベクトルを用いて音声片音声標準パターンを作成し、前記音声片音声標準パターンを認識対象とするN種(Nは正の整数)の単語の各々の音声片表記列にしたがって接続することにより作成したものである請求項1記載の音声認識方法。
【請求項7】 単語音声標準パターンが、音韻環境を考慮したM種(Mは正の整数)の単語セットの学習用音声データを、音節、(子音+母音)、(母音+子音)、(母音+子音+母音)、又は(子音+母音+子音)などの音声片単位に切り分け、音声片ごとに、各々に属する学習用音声片データの始端から終端までの間を、子音部は基準フレームを中心に連続にとり母音部は各々のデータの母音区間を線形に伸縮することにより音声片全体をJフレーム(Jは正の整数)に非線形に伸縮し、各フレームごとにP個(Pは正の整数)の特徴パラメータを抽出し、さらにフレームごとに各特徴パラメータの時間変化量である動的特徴パラメータをP個求め、特徴パラメータを時間的順序に並べて得られるJ個のP次元のベクトルと動的特徴パラメータを時間的順序に並べて得られるJ個のP次元のベクトルを用いて音声片音声標準パターンを作成し、前記音声片音声標準パターンを認識対象とするN種(Nは正の整数)の単語の各々の音声片表記列にしたがって接続することにより単語音声標準パターンを作成したものである請求項4記載の音声認識方法。
【請求項8】 統計的距離尺度が、共分散行列を共通化したベイズ判定に基づく距離などの一次判別関数で表されることを特徴とする請求項1、2、4、5又は7記載の音声認識方法。
【請求項9】 統計的距離尺度が、ベイズ判定に基づく距離やマハラノビス距離などの二次判別関数で表されることを特徴とする請求項3ないし7のいずれか記載の音声認識方法。
【請求項10】 日本語の単音節を認識対象とすることを特徴とする請求項1ないし9のいずれか記載の音声認識方法。
【請求項11】 母音部は動的計画法(DP法)より時間整合して照合することを特徴とする請求項1ないし10のいずれか記載の音声認識方法。
【請求項12】 事後確率を基本とした統計的距離尺度を用いて連続DPマッチングを行なうことにより、未知入力音声の音声区間検出をせず、ノイズを含む十分に長い区間から音声の部分を抽出して認識するワードスポッティング機能を持つことを特徴とする請求項1ないし11のいずれか記載の音声認識方法。
【IPC】G10L
【公開番号】特開平9-68995
【公開日】平成9年(1997)3月11日
【発明の名称】音声認識方法
【出願番号】特願平7-226173
【出願日】平成7年(1995)9月4日
【識別番号】000005821
【氏名又は名称】松下電器産業株式会社
【氏名又は名称】滝本 智之 (外1名)
音声認識方法 特開199768995
