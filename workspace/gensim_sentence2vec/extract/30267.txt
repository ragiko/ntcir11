アニメーションキャラクターなどを活用した、人間とコンピュータのより自然なインタラクション(相互のやりとり)の研究をしている成蹊大学理工学部情報科学科の中野有紀子先生の研究室を訪ね、具体的な研究内容について伺う。
中野先生はエージェント(*1参照)情報科学、とくに人工知能の分野でよく使われる言葉。この言葉自体はもともと「代理人」とか「動作主」といった意味がある。を中心としたさまざまな研究を行っている。前回は「操作説明のためのヘルプエージェント」について説明していただいた。今回は「ユーザーの態度に気づく会話エージェント」とはどのようなものなのか、具体的な内容を教えていただくことにしよう。
ユーザーの態度に気づく
会話エージェント
ユーザーの態度に気づく会話エージェントとはどのようなものか。これは、携帯電話ショップでの商品説明という状況を設定して、エージェントがユーザーの様子に対応しながら柔軟に会話を進めていくというものだ。
「アニメーションキャラクターによる情報提供システムをつくると、つまらないという反応が多いといわれます。それは、キャラクターが一方的に喋るので、ユーザーが飽きてしまうからです。そこで、ユーザーが話を聞いていないようだったら話題を変えたり、質問を促したりするようなエージェントをつくってみたいと考えたのです」
この研究は、2007年度と2008年度の2年間のプロジェクトとして行われた。ユーザーの態度を知る方法として着目したのは、人間の視線の動き。初年度は、商品説明時の人間の視線データを取ることと、視線と態度の関係を明らかにすることを中心に研究を進めた。
「人間が会話に集中しているときや飽きているとき、どのような視線の動きになるのか。それが分からないとシステムのつくりようがないので、
ウィザード・オブ・オズ(オズの魔法使い)の実験方法(*2参照)ある人工物に対して人間がどのように反応するか、どのようにインタラクションするかを知りたいときに、とりあえず見かけだけつくって、それを人間が操作し、被験者のデータを得ることを目的とした実験方法のこと。でデータを集めました」
視線の動きのパターンを分析し
会話に飽きている状態を探る
店員のアニメーションキャラクターが中央にいて、その左右に3台ずつ携帯電話が並んでいる画面を大型スクリーンに投影。ユーザー役の被験者にキャラクターの商品説明を聞いてもらい、視線がどのように動くかを計測した。計測には、瞳の動きから視線をキャッチするアイトラッカという装置を使用している。
「ユーザーのリアルな反応を調べたかったので、キャラクターも完成イメージに近いものを作成しました。キャラクターは、合成音声で商品説明をしたり、ユーザーの質問に答えたりします。姿勢も、正面のユーザーを向いているだけでなく、商品のほうに向いたり、ユーザーのほうに向き直ったりします。
これも実験段階では、キャラクターが話す内容や動きは人間が決めて操作しているのですが、被験者の方は完成したシステムだと思っているので『すごいですね』と言ってくれました(笑)」
視線の動きとユーザーが会話に飽きているかどうかの関係を明らかにするため、ユーザーには「関心低下ボタン」を持たせた。これは、会話に飽きてきたときにボタンを押すと灯りが点く。いわば自己申告だが、さらに他者の判断も加えた。
ユーザー側は鏡で、裏側からはユーザーが見えるハーフミラーを設置して、もう1人の被験者がユーザーの様子を観察。ユーザーが会話に飽きていると思ったら、関心低下ボタンを押してもらった。
どちらの関心低下ボタンもビデオで撮影して、いつボタンを押したかが分かるようにした。そして、どちらかのボタンが押されたときを関心低下状態と判定した。
「会話に集中しているときの視線パターンと関心低下状態のときの視線パターンの違いが、かなりハッキリと分かりました。会話に集中しているときは、説明している対象とエージェントに交互に視線を配ったり、対象とその周囲のものを見比べたりするような視線パターンになります。飽きているときは、説明対象以外のものやエージェントをじっと見ている視線パターンになります」
説明を中断して別の会話をしても
元の話題に戻ることが可能
実験結果の分析を踏まえて2008年度はプログラム作成に取り組み、エージェントが自律的に動くシステムを完成させた。
このシステムは、ユーザーの視線と音声を識別し、それに応じて会話や動作を自動的に変える。たとえば、エージェントがある携帯電話の説明をしているとき、ユーザーが別の携帯電話を注視していると、話題を切り替える。あるいは、説明の途中でユーザーがその携帯電話の価格を質問すると、説明を中断して価格について答え、「よろしいでしょうか」と確認してユーザーが「はい」と返事をすると、説明に戻る。文字通り、ユーザーの態度に気づくエージェントだ。
「アイトラッカで計測するユーザーの視線データと、音声認識によるユーザーの発話データは理解部というところに入ってきて、ユーザーの会話参加状態が分かるようになっています。
エージェントの動作をコントロールするのは、会話管理部です。理解部に入ってくるユーザーの情報と、予め設定しているエージェントが話すべき内容を照合しながら、エージェントの発話や動作を次々に決めていきます。そして、その発話や動作に応じた合成音声、表情、ジェスチャーが自動的に生成されます」
また、このシステムは、エージェントやユーザーが話した内容、ユーザーの視線データなどを記録するIS(インフォメーション・ステート)という機構も備えている。
「ISは、エージェントがいつ何を話したか、ユーザーがいつどのような返事や質問をしたかといった情報を一元的に管理しています。このISによって、どこまで話が進んだかが分かるので、エージェントが話を中断してほかの商品の説明をしたり、ユーザーの質問に答えたりしても、中断した話に戻ることが可能になっているのです」
中野先生は、ユーザーの態度に気づく会話エージェントの研究をライフワークの1つに位置付けている。今後は、センサーを増やして、ユーザーの視線だけでなく頭の動きや手の動きを読み取り、それをエージェントの振る舞いに反映させていくことなどをめざしている。
【用語解説】
*1 エージェント:情報科学、とくに人工知能の分野でよく使われる言葉。この言葉自体はもともと「代理人」とか「動作主」といった意味がある。
*2 ウィザード・オブ・オズ(オズの魔法使い):ある人工物に対して人間がどのように反応するか、どのようにインタラクションするかを知りたいときに、とりあえず見かけだけつくって、それを人間が操作し、被験者のデータを得ることを目的とした実験方法のこと。
《つづく》
次回は「異文化コミュニケーションを支援する会話エージェントについて」です。
研究室はオモシロイ ｜ 成蹊大学 理工学部情報科学科 ｜ ドリコムアイ.net
