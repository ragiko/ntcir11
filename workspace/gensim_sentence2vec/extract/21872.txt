自然言語処理の個々の問題を分類問題ととらえ, 帰納学習の手法により問題解決を図る場合, 最も重要な課題は, 訓練データをどのように準備するかである.ここでは具体的な問題として日本語単語分割を取り上げ, 上記課題への取り組みの1つとして, タグ付きコーパスとタグなしコーパスを相補的に利用することを試みる.具体的には, まず, 日本語単語分割を入力文の文字間に単語境界を置くか置かないかの分類問題として定式化する.次に, タグ付きコーパスから作成した訓練データを用いて, 決定リストAを作成する.次に, タグなしコーパスを既存の形態素解析システムにより単語分割し, そこから誤り付き訓練データを作成する.そこから決定リストBを作成する.そして決定リストAのある順位の規則をdefault規則ととらえ, それよりも下位の規則を省く.残された決定リストAに決定リストBを付加したものを新たな決定リストCと見る.そして, 決定リストCの精度を訓練データとアダブーストの手法を利用して高める.実験の結果, 誤り付きの訓練データを利用した効果と, ブースティングを行った効果が確認できた.
When we regard a natural language processing problem as a classification problem and solve it by an inductive learning method, the biggest problem is how to prepare correct training data. In this paper, we take up the Japanese word segmentation problem and propose the method to combine tagged and untagged corpora in the learning method to compensate for the shortage of training data. First, we regard the Japanese word segmentation problem as the classification problem to judge whether the word boundary exists between two characters or not. Next, we build the decision list'dl.A' by training data made through a tagged corpus. In other hand, we make training data with some errors through an untagged corpus, and build the decision list'dl.B'through it. We regard a rule in dl.A as the default rule and remove rules below it from dl.A. Next we attach dl. B to the left dl.A, and regard it as the decision list 'dl.C.'Finally, we improve the precision of dl.C by using Adaboost and correct training data. Through experiments, we confirmed effectiveness of boosting and use of the untagged corpus.

