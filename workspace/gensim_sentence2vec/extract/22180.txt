正凖判別分析は代表的な統計的手法として最もよく知られているが, クラス数以上の特徴が選択できないため, 少クラスの分類問題に対するその有効性には限界がある. この問題を解決するために, 新しい特徴選択手法 ( F-K-L法) を提案し, 手書き数字認識実験によりその有効性を評価する. F-K-L法は, 分散比 ( F 比) を最大化する正凖判別分析と, 全クラスの混合分布を最小2乗近似する主成分分析法 ( K-L展開) に対して, F比と2乗誤差の双方を同時に最適化する特徴選択手法である. 実験の結果, 少クラスの分類問題では, 正凖判別分析, 主成分分析, 正規直交判別ベクトル法 (ODV法) などに比べ, F-K-L法により選択された特徴量の識別力が最も高いことを示す.
Although the discriminant analysis has been most widely known as a typical statistical feature selection technique, its availability to small class classification problems is limited because the number of selectable features can not be or exceed the number of classes. In order to remove the limitation, a new feature selection technique ( F-K-L ) is proposed and tested by a handwritten numeral recognition experiment. While the discriminant analysis maximizes the variance ratio ( F-ratio ), and the principal component analysis ( K-L expansion ) minimizes the square error of representing a mixture distribution of total class, the F-K-L optimizes both the F-ratio and the square error simultaneously. The result of experiment shows that the F-K-L provides the richest features in discriminating power for the small class classification problems when compared with other techniques including the discriminant analysis, the principal component analysis, and the orthonormal discriminant vector method ( ODV ).

