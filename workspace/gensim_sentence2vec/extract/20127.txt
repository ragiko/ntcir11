【発明の詳細な説明】【0001】【産業上の利用分野】本発明は、発声された音声を高精度に認識することのできる音声認識方式に関する。【0002】【従来の技術】近年、音声を認識する方式において、音声を一定のシンボル系列に変換(これをベクトル量子化と呼ぶ)し、シンボル系列の遷移として音声をモデル化するHMM(hidden markov model)を利用した認識方式が成功を収めている。音声をシンボルに変換する際に参照するテーブルは、符号帳と呼ばれている。また、HMMは、複数の状態をもつ遷移ネットワークで表わされ、各状態ごとにシンボルの出現確率と状態間の遷移確率が埋め込まれている。【0003】符号帳が定常的な係数(例えば、スペクトルやケプストラム)を使用している場合、音声事象はHMM中に埋め込まれた状態の情報にのみ依存する(1つの状態の中では、時間関係がなくなる)。このため、Δケプストラムのような微分情報が導入されている。すなわち、音声は、スペクトル(またはケプストラム)だけでなく、それらの時間変化を考慮してシンボル系列に置換える方法が採用されている。しかし、このように多くの次元を持つ符号帳では、量子化の際の歪が非常に大きくなる。このため、パラメータ空間を分割して(上記例では、スペクトルとその時間変化情報を分離して)、次元数を減らした複数の符号帳が用いられている。【0004】これらの方法に対して、スペクトル(もしくはケプストラム)の時系列、すなわち、2次元パターンを直接、量子化する方法があり、マトリクス量子化と呼ばれている。マトリクス量子化は、音声パターンを近似なしに直接扱える長所を持つ反面、量子化歪が増大する。そこで、量子化の際に統計的手法を用いて、歪を減らす方法が提案されている。【0005】しかしこのような方法を用いても、音声を量子化する際の歪がいまだ大きく、さらに歪を低減する手段が望まれている。これを解決するには、音声スペクトル(もしくはケプストラム)をシンボルに置換えずに(量子化せずに)、直接HMMの中でこれを表現すれば良い。このような方法は、量子化を伴なう「離散HMM」に対して「連続HMM」と呼ばれている。連続HMMは、一般に厖大な計算を必要としている。これは、HMMへの入力ベクトル系列から、各状態に対応する共分散行列を求め、認識の際に入力ベクトルと共分散行列との積を計算しなければならないからである。【0006】【発明が解決しようとする課題】音声をHMMで表現する場合、その単位は音素、音節、単語、文節、あるいは文等、種々考えられるが、認識の際に入力音声とそのモデルがよく一致すること、すなわち、歪が少ないことが、全てに共通して大切なことである。上述したように、音声スペクトルの時間変化を含む2次元パターンを直接HMMの入力とする、連続HMMが、性能的に最も優れている。しかし、この方法は、厖大な計算を必要とするため実用化が難しいという問題があった。そこで、本発明は、発声された音声を高精度に認識することができ、しかも、演算処理が厖大化することもない音声認識方式を提供することを目的とする。【0007】【課題を解決するための手段】本発明の音声認識方式は、入力される音声信号を音響分析することにより特徴パラメータを求める音響分析手段と、この音響分析手段により求められた特徴パラメータと予め定められた所定の音声セグメント単位の符号帳との間でマトリクス量子化処理を行なうことにより音声セグメント類似度系列を求めるマトリクス量子化手段と、このマトリクス量子化手段により求められた音声セグメント類似度系列を音素特徴ベクトルに統合変換する統合変換手段と、この統合変換手段により統合変換された音素特徴ベクトルを一定の単位毎に作成されたHMM(hidden markov model)を用いて照合することにより認識処理を行なう認識手段とを具備している。【0008】【作用】入力される音声信号を音響分析することにより特徴パラメータを求め、この求めた特徴パラメータと予め定められた所定の音声セグメント単位の符号帳との間でマトリクス量子化処理を行なうことにより音声セグメント類似度系列を求め、この求めた音声セグメント類似度系列を音素特徴ベクトルに統合変換し、この統合変換された音素特徴ベクトルを一定の単位毎に作成されたHMMを用いて照合することにより、高精度の認識処理を行なうものである。【0009】【実施例】以下、本発明の一実施例について図面を参照して説明する。【0010】図1は、本発明に係る音声認識方式が適用される音声認識装置を概略的に示すものである。本発明では、音声学的に意味のあるセグメント(Phonetic Segment;以下PSと記述する)を量子化の単位とし、このPSの類似度(距離)系列を一旦、音素に統合変換した後、音素特徴ベクトル系列をHMM単語照合部に送る。【0011】ここまでの処理を以下に更に詳しく説明する。まず、音響分析部11にて、入力される音声信号を、例えばLPC(リニア・プレディクティブ・コーディング)分析もしくはBPF(バンドパス・フィルタ)分析する。具体的には、例えば入力音声を図示されないA/D変換器を用いて、サンプリング周波数が12KHz、12ビットで量子化した後、フレーム長が24msec、フレーム周期が8msecで、16次程度のLPC(メル)ケプストラムを求める。分析された特徴パラメータは、マトリクス量子化部12に与えられ、PS符号帳13に登録されている所定のPS単位の音声辞書との間で、時間軸方向に連続的にマッチング処理が行なわれる。マトリクス量子化部12でのPSによる連続マッチング処理は、例えば次式に示す部分空間法に基づく類似尺度を用いて行なわれる。ここで、C(PS):LPCメルケプストラム(C=｛C1 ,C2 ,…,CN ｝)φm :PSの固有ベクトル(・)は内積を、‖ ‖はノルムを示している。すなわち、音声符号帳は、各PS毎にM個の直交化された固有ベクトルで表現されている。ここで、本発明に用いられるPSを説明する。PSは、例えば次のようなものからなる。(1) 持続性セグメント ;(1-1) 母音定常部(1-2) 持続性の子音部(2) 子音セグメント ;母音への渡り(過渡部)を含む部分［半音節］(3) 音節境界セグメント;(3-1) 母音境界(3-2) 母音−子音境界(3-3) 母音−無音境界(4) その他のセグメント;母音脱落、VCV(V:母音、C:子音)等例として、100単語の音声資料に対して選定した191種の音声セグメントを次に示す。持続性セグメント:AA1A,AA2A,II1A,II2A,II3A,UU1A,UU2A,UU3A,EE1A,EE2A,OO1A,OO2A,NN1A,NN2A,NN4A,NN5A,BZ1A,MM1A,RR1A,BB1A,SS1C,SH1C,CC1C,ZZ1A,HHAB,HHIB,HHUB,HHEB,HHOB,HVAA,HVIA,HVUA,HVEA子音セグメント:QA1D,KA1E,KA2C,SA2E,TA2C,NA2B,HA2B,GA2C,DA1E,DA2B,CA1E,FA1C,FA2C,KI1E,KI2C,SI2E,NI1C,NI2B,HI1D,HI2C,MI2B,RI2B,BI1C,BI2B,PI1C,PI2C,KU1E,KU2C,SU2D,CU1E,CU2E,HU1D,RU2B,ZU2D,BU2B,QE1D,KE1E,KE2C,SE1E,SE2E,TE1D,TE2C,NE1C,NE2B,HE1D,HE2B,ME1C,ME2B,RE1C,RE2B,GE1D,GE2E,ZE1E,ZE2E,DE1C,DE2B,BE1C,BE2B,PE1C,PE2B,QO1D,KO1D,KO2C,TO1D,TO2C,NO2B,HO1D,FO1E,FO2E,MO2B,GO2C,DO2B,BO2B,PO1C,PO2B,KY1E,SY1E,CY1E,NY2D,HY2E,RY1D,RY2D,ZY2D境界セグメント:母音境界 AI1E,ANNC,INNC,IE1C,IA1E,UA1C,EI1C,EO1E,ENNC,EU1C,OI1E,OU1C,ONNC,NNOC,NNEB母音−子音境界 YA1E,YU1E,YO1E,AS1A,AN1A,AM1A,AR1A,AZ1A,AD1A,AB1A,IS1A,IN1A,IH1A,IR1A,IG1A,ID1A,IB1A,US1A,UN1A,UM1A,UD1A,UB1A,EN1A,EH1A,EF1A,EM1A,ER1A,EG1A,ON1A,OH1A,OM1A,OR1A,OG1A,OD1A,OB1A,NS1A,NH1A,NG1A,NZ1A母音−無音境界 AQ1A,IQ1A,UQ1A,EQ1A,OQ1A,NQ1Aその他のセグメント:VCV ANAC,ANEC,ARUC,AREC,IRIC,IBOC,UNEC,UDAC,UBUC,EREC,ERUC,ORIC,ORUC,母音脱落ほか KS1D,KQ1D,AUQA【0012】ここで、持続性セグメント中のAA1,AA2 は、後者がストレスの弱い母音［a］の一部から切り出されたことを示す。また、II3,UU3 は無声化したセグメントである。NN1 〜NN5 は異なる音素環境に対応している。BZ1 〜ZZ1 は子音に先立って出現する声帯音ほかの現象、HHA 〜HHO は無声の［h］、またHVA 〜HVE は有声化した［h］に対応している。【0013】次に、子音セグメント中のQA1 は語頭の母音を、またKA1,KA2 は原則として後者が語中から切り出されたものであることを示している。拗音に属する外1などは、CA1 YA1 AA1 と境界セグメントをはさんで構成している(実際の音声では、CA1 AA1 またはAA2 と遷移することもありうる)。【0014】【数1】【0015】境界セグメントとしては、母音境界(AI1)、母音−子音境界(AS1)、母音−無音境界(AQ1)などが登録されている。なお、母音境界を表わすセグメントでは、撥音はNNと記されている(ANN)。【0016】その他のセグメントには、発声速度の速い場合に観測される、子音の脱落しかけたVCV セグメント(ANA) 、母音の脱落したセグメント(KS1)などがある。PS符号帳13には、このような 191種の音声セグメントの情報が直交化辞書として格納されている。【0017】さて、このようなPSを量子化時のセグメントとする場合、セグメントの特徴パラメータの次元数(ここではLPCメルケプストラムの次数)と時間幅(フレーム数)が問題となる。すなわち、母音定常部等については、その特徴パラメータの次元数を多く必要とするが、そのフレーム数は少なくて良い。また、破裂子音等については、特徴パラメータの次元数もそのフレーム数もある程度必要である。更に、摩擦子音等にあっては、特徴パラメータの次元数は少なくて良いが、多くのフレーム数を必要とする。そこで、本発明では、各PSの特徴パラメータとフレーム数を次のように定めている。【0018】(特徴パラメータ,フレーム数);A=(16, 4)B=(14, 6)C=(12, 8)D=(10,10)E=( 8,12)の組合わせの中から選択している。先に説明したPSの種類を示す4文字のうち、最後の1文字は、この設定を表わしている。この結果、母音ではAA1Aのように特徴パラメータの次元数を「16」と大きく、またZE1Eのような摩擦子音はフレーム数を「12」と多く設定することができる。また、これによりPS全体の次元数は64〜100と、比較的近い次元数に収まり、統計的なマッチング処理(例えば部分空間法)による量子化歪の低減が可能になった。【0019】マトリクス量子化部12で求められたPS類似度系列の精度を見るため、第1位となったPSの系列を求め、このシンボル系列を(離散)HMMへ入力することで単語音声の評価実験を行なった。この実験は、不特定話者の単語音声を対象に行なわれ、結果は32単語で98.4%と、従来の単語単位のパターンマッチング法と比較して同程度の認識率であった。しかし、類似した単語の対からなる32単語では、91.0%しか得られず、第1位のシンボル系列を使用する「離散HMM」では量子化誤差が未だに大きく、HMMを連続分布として扱う必要のあることが示された。【0020】しかし、n種類のPSの類似度値からなるベクトルS=(S1,S2,… ,Sn )に対して、「連続分布HMM」を直接適用することは、厖大な計算を必要とするため得策ではない。そこで、音声セグメントの類似度空間Rnを効率良く、音素特徴空間Rm(m<<n)に統合変換した後、連続分布HMMを適用する方法を採用した。【0021】音声セグメントPSの多くは、前述したように音声中に現れる様々な環境下の音素を表現するために設計されている。このため、これらと音素との対応付けは比較的容易である。例えば、音素/r/に対応する音声セグメントは、RA1,RA2,RI1,RI2,RU1,RU2,RE1,RE2,RO1,RO2,RY1,RY2,RW1,RW2,ARA,ARI,ARU,ARE,ARO,IRA,IRI,IRU,IRE,IRO,URA,URI,URU,URE,URO,ERA,ERI,ERU,ERE,ERO,ORA,ORI,ORU,ORE,ORO,NRA,NRI,NRU,NRE,NROの44種である。ここで、セグメント名の数字は「1」が語頭を、「2」が語中を示す。また、 ARAのように前後を母音で挟まれたセグメントは、VCV型に属する。音声セグメントを音素に統合変換する方法は、種々考えられる。本実施例ではと最大値フィルタにより、その音素に属するPSを統合する。右辺の｛｝内は、PSの類似度値、左辺は統合された音素のスコアである。【0022】一般に用いられる音素には、｛o,a,e,i,u,h,j,w,r,n,m,z,s,g,k,d,t,b,p｝の19種がある。本実施例では、別にモーラ音素/N/(撥音),語頭の母音V,持続性子音部C,母音から子音への過渡部T、母音から無音への過渡部Xを加えた24種を、音素特徴として用いる。これにより、PSの類似度系列は、PS−音素統合変換部14において、上記(1)式を実行することにより、24次元の音素特徴ベクトルからなる系列へと変換され、HMM認識部15へと送られる。図2に、単語音声「堅固」に対応する音素特徴ベクトルの例を示す。【0023】次に、本発明におけるHMMを用いた単語照合について説明する。HMMではN個の状態S1 ,S2 ,…,SN を持ち、初期状態がこれらN個の状態に確率的に分布しているとする。音声では一定のフレーム周期ごとに、ある確率(遷移確率)で状態を遷移するモデルが使われる。遷移の際には、ある確率(出力確率)でラベルを出力するが、ラベルを出力しないで状態を遷移するナル遷移を導入することもある。出力ラベル系列が与えられても(状態を遷移する仕方は複数あるから)状態遷移系列は一意には決まらない。観測できるのはラベル系列だけであることから、隠れ(hidden)マルコフモデルと呼ばれている。HMMモデルMは、次の6つのパラメータから定義される。N : 状態数 (状態S1 ,S2 ,…,SN ,実験ではN=10)K : ラベル数(ラベルL=1,2,…,K,実験ではK=191)pij : 遷移確率(SiにいてSjに遷移する確率)qij(k) : SiからSjへの遷移の際にラベルkを出力する確率mi : 初期状態確率 (実験では初期状態はS1 に限定)F : 最終状態の集合(実験では最終状態はS10に限定)【0024】次に、モデルMに対して音声の特徴を反映した遷移上の制限を加える。音声では、一般に状態Siから以前に通過した状態(Si-1,Si-2,……)に戻るようなループは、時間の前後関係を乱すため許されない。上記のようなHMMの構造としては、図3のような例が代表的である。【0025】HMMを学習する際には、HMM学習部16で、ラベル系列Oを与えて、Pr(O/M)が最大となるモデルMのパラメータを推定すれば良い。この推定に用いられるアルゴリズムとしては、フォワード・バックワードアルゴリズムが知られている。【0026】また、HMMの評価(認識)では、モデルMがラベル系列O=O1 ,O2 ,…,OT を出力する確率Pr(O/M)を求める。すなわち、HMM認識部15は、各単語に対応してモデルを仮定し、Pr(O/M)が最大になるようなモデルM(単語)をヴイタービのアルゴリズムを用いて検索する。【0027】以上は、主として離散HMMを対象に説明した。連続出力確率分布HMM(以下、連続HMMと記述する)では、入力はラベル系列ではなく、ベクトル(本発明では音素特徴ベクトル)となる。これにより、上記の出力確率qij(k) (SiからSjへの遷移の際にラベルkを出力する確率)の代わりに、ベクトルの出現分布が与えられる。通常、この分布(ベクトルの各要素の分布)は正規分布もしくは、正規分布の混合として扱われる。連続HMMモデルは、次の6つのパラメータから定義される。N : 状態数 (状態S1 ,S2 ,…,SN ,実験ではN=10)pij : 遷移確率(SiにいてSjに遷移する確率)μij : SiからSjへの遷移の際に表われる平均ベクトルΣij : SiからSjへの遷移の際に表われるベクトルの共分散mi : 初期状態確率 (実験では初期状態はS1 に限定)F : 最終状態の集合(実験では最終状態はS10に限定)【0028】混合分布では、μijとΣijが複数与えられる。連続HMMの学習および評価(認識)は、離散HMMと同様に各々フォワード・バックワードアルゴリズムと、ヴィタービのアルゴリズムを使用することで行なわれる。【0029】実験では、多数の学習用データ(音素特徴ベクトル)をHMM学習部16に与えて、確率Pr(O/M)を最大にするように、32単語に対応する各モデルMのパラメータを推定した(連続HMMでは、Oはベクトル系列である)。得られたモデルのパラメータ(単語毎のμijとΣij)は、HMM単語モデルバッファ17に蓄積される。【0030】次に、認識の段階には、HMM単語モデルバッファ17に蓄積された各モデルに対して、HMM認識部15において、入力音声に対する音素特徴ベクトルの確率Pr(O/M)を求め、この確率が最大になるようなモデルMを求める。そのモデルに対応する単語が認識結果となる。本発明の評価実験は、前述した離散HMMに対する実験と同じデータ(32個の類似単語)に対して行なわれた。実験では、ベクトルの出現分布を単一の正規分布とした場合と、2つの正規分布(混合分布)からなる場合について行なった。ただし、学習データが少ないことを考慮して、共分散は対角要素のみを用いている。結果は、単一分布で91.3%、混合分布で92.4%と離散HMMの成績(91.0%)を上回り、本発明の優れていることが示された。【0031】以上説明したように上記実施例によれば、音声学的に意味のある「音声セグメント(PS)」を単位として、統計的にマトリクス量子化処理を行ない、PS類似度系列を音素特徴ベクトルに統合変換した後、HMMを用いて認識処理を実行するので、連続音声中に生じる様々な変形を効果的に吸収することが可能となり、その結果、高精度な音声認識を実現することができる。しかも、演算処理が厖大化することもない等、実用上多大な効果が得られる。【0032】なお、上記実施例では、音響分析によって求められた特徴パラメータを、音声セグメント単位の符号帳との間でマトリクス量子化処理を行なったが、この代わりに通常のベクトル量子化を用いることも可能である。また、特徴パラメータを音声セグメント単位に設定されたニューラルネットワークのような他の識別器に通し、この出力を音素特徴ベクトルに統合変換した後、連続出力確率分布HMMを通して照合する等の変形も考えられる。さらに、前記実施例では、音素特徴ベクトルへの統合変換に最大値フィルタを用いたが、音声セグメント類似度系列をニュートラルネットワークへ入力して、音素特徴ベクトルに統合変換する等の変形も考えられる。【0033】【発明の効果】以上詳述したように本発明によれば、発声された音声を高精度に認識することができ、しかも、演算処理が厖大化することもない音声認識方式を提供することができる。【図面の簡単な説明】【図1】本発明に係る音声認識方式が適用される音声認識装置の構成を概略的に示すブロック図。【図2】単語部に対応する音素特徴ベクトルの例を示す図。【図3】HMMの構造の代表例を示す図。【符号の説明】11…音響分析部、12…マトリクス量子化部、13…PS符号帳、14…PS−音素統合変換部、15…HMM認識部、16…HMM学習部、17…HMM単語モデルバッファ。
【特許請求の範囲】【請求項1】 入力される音声信号を音響分析することにより特徴パラメータを求める音響分析手段と、この音響分析手段により求められた特徴パラメータと予め定められた所定の音声セグメント単位の符号帳との間でマトリクス量子化処理を行なうことにより音声セグメント類似度系列を求めるマトリクス量子化手段と、このマトリクス量子化手段により求められた音声セグメント類似度系列を音素特徴ベクトルに統合変換する統合変換手段と、この統合変換手段により統合変換された音素特徴ベクトルを一定の単位毎に作成されたHMM(hidden markov model)を用いて照合することにより認識処理を行なう認識手段と、を具備したことを特徴とする音声認識方式。
音声認識方式
