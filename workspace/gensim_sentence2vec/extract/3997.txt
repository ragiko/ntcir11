
【注意】 このドキュメントは、W3CのSpeech Synthesis Markup Language (SSML) Version 1.1 W3C Recommendation 7 September 2010の和訳です。
このドキュメントの正式版はW3Cのサイト上にある英語版であり、このドキュメントには翻訳に起因する誤りがありえます。誤訳、誤植などのご指摘は、訳者までお願い致します。
First Update: 2012年3月10日
音声合成マークアップ言語(SSML)バージョン1.1
W3C勧告 2010年9月7日
本バージョン:
http://www.w3.org/TR/2010/REC-speech-synthesis11-20100907/
最新バージョン:
http://www.w3.org/TR/speech-synthesis11/
旧バージョン:
http://www.w3.org/TR/2010/PR-speech-synthesis11-20100223/
編集者:
Daniel C. Burnett,  Voxeo (formerly of Vocalocity and Nuance) 
双志伟 (Zhi Wei Shuang), IBM 
著者:
Paolo Baggia, Loquendo
Paul Bagshaw, France Telecom 
Michael Bodell,  Microsoft 
黄德智 (De Zhi Huang), France Telecom
楼晓雁 (Lou Xiaoyan), Toshiba 
Scott McGlashan, HP
陶建华 (Jianhua Tao), Chinese Academy of Sciences
严峻 (Yan Jun), iFLYTEK
胡方 (Hu Fang) (until 20 October 2009 while an Invited Expert)
康永国 (Yongguo Kang) (until 5 December 2007 while at Panasonic Corporation)
蒙美玲 (Helen Meng) (until 29 July 2009 while at Chinese University of Hong Kong)
王霞 (Wang Xia) (until 30 October 2006 while at Nokia)
夏海荣 (Xia Hairong) (until 2 August 2006 while at Panasonic Corporation)
吴志勇 (Zhiyong Wu) (until 29 July 2009 while at Chinese University of Hong Kong)
このドキュメントに対する正誤表を参照してください。いくつかの規範的な修正が含まれているかもしれません。
翻訳版も参照してください。
Copyright &copy; 2010 W3C&reg; (MIT, ERCIM, Keio), All Rights Reserved. W3C liability, trademark and document use rules apply.
要約
音声読み上げブラウザ・ワーキンググループは、音声対話によるウェブへのアクセスを可能にする標準の開発に取り組んできました。音声合成マークアップ言語仕様は、この標準のひとつであり、ウェブやその他のアプリケーションにおける合成音声の作成を支援するために豊かなXMLベースのマークアップ言語を提供することを目指しています。このマークアップ言語の本質的な役割は、合成可能なコンテンツの作成者に、合成に対応した様々なプラットフォームにおいて、発音、音量、ピッチ、速度などの読み上げに関する様々な側面を制御するための標準的な方法を提供することです。
このドキュメントのステイタス
この項は、このドキュメントの公開時のステイタスについて記述しています。他のドキュメントがこのドキュメントに取って代わることがありえます。現行のW3Cの刊行物およびこの技術報告の最新の改訂版のリストは、http://www.w3.org/TR/のW3C技術報告インデックスにあります。
これは、「音声合成マークアップ言語(SSML)バージョン1.1」の勧告です。音声読み上げブラウザ・アクティビティの一部である音声読み上げブラウザ・ワーキンググループによって作成されました。
コメントはwww-voice@w3.org(アーカイブ)で歓迎されます。W3Cメーリング・リストおよびアーカイブ利用ガイドラインを参照してください。
SSML 1.1の設計は広くレビューされており(コメントの処理を参照)、ワーキンググループの技術要件を満たしています。実装のリストは、関連するテスト・スイートとともにSSML 1.1実装報告に含まれています。ワーキンググループは、コメントに応じて2010年2月23日の勧告案に少しの編集上の変更を行いました。勧告案の変更は付録Gにあります。また、SSML 1.0への下位互換性に関するノートを含むSSML 1.0の変更は、付録Fにあります。
このドキュメントは、より広い自然(人間の)言語の集合をサポートするためにSSML 1.0[SSML]を強化したものです。音声合成技術にとって大きなビジネス市場や新興市場である言語のサポートという点において、SSML 1.0の開発中には母国語を話す人々の参加も専門家の参加も限られていた、あるいは、参加がなかったために、SSMLに設計上の制限があるのであれば、どのような制限なのかを判断するために、W3Cは、SSMLの国際化に関する3つのワークショップを開催しました。中国の北京で2005年10月に開催された最初のワークショップ[WS]では、主に中国語、朝鮮語および日本語に注目し、ギリシャのクレタ島で2006年5月に開催された第2回[WS2]では、主にアラビア語、インドの言語および東欧諸語に注目しました。インドのハイデラーバードで2007年1月に開催した第3回のワークショップ[WS3]では、インドおよび中東の言語に大きく注目しました。これらのワークショップ中に収集された情報は、要件ドキュメント[REQS11]を開発するために利用しました。SSML 1.0の変更は、これらの要件が動機となっています。
このドキュメントは、W3Cメンバー、ソフトウェア開発者、他のW3Cグループ、および他の利害関係者によりレビューされ、W3C勧告として管理者の協賛を得ました。これは確定済みドキュメントであり、参考資料として用いたり、別のドキュメントで引用することができます。勧告の作成におけるW3C の役割は、仕様に注意を引き付け、広範囲な開発を促進することです。これによってウェブの機能性および相互運用性が増強されます。
このドキュメントは、2004年2月5日のW3C特許方針の下で活動しているグループによって作成されました。W3Cは、このグループの成果物に関連するあらゆる特許の開示の公開リストを維持し、このページには特許の開示に関する指示も含まれています。不可欠な請求権(Essential Claim(s))を含んでいると思われる特許に関して実際に知っている人は、W3C特許方針の6項に従って情報を開示しなければなりません。
このドキュメント本体の項は、特別の定めのない限り規範的です。特別に明示されていない限り、このドキュメントの付録は参考情報です。
目次
1. はじめに 
1.1 設計コンセプト
1.2 音声合成処理のステップ
1.3 ドキュメントの作成、アプリケーションと文脈
1.4 SSMLコンテンツのプラットフォーム依存の出力
1.5 用語
2.SSMLドキュメント 
2.1 ドキュメント形式
2.2 適合性 
2.2.1 適合音声合成マークアップ言語断片
2.2.2 適合スタンドアロン音声合成マークアップ言語ドキュメント
2.2.3 他の名前空間を持つSSMLの使用
2.2.4 適合音声合成マークアップ言語プロセッサ
2.2.5 プロファイル
2.2.6 適合ユーザ・エージェント
2.3 他のマークアップ言語との統合 
2.3.1 SMIL
2.3.2 ACSS
2.3.3 VoiceXML
2.4 SSMLドキュメントの取得
3. 要素と属性 
3.1 ドキュメント構造、テキスト処理と発音 
3.1.1 「speak」ルート要素
3.1.1.1 トリミング属性
3.1.2 言語: 「xml:lang」属性
3.1.3 基底URI: 「xml:base」属性
3.1.3.1 相対URIの解決
3.1.4 識別子: 「xml:id」属性
3.1.5 辞書ドキュメント
3.1.5.1 「lexicon」要素
3.1.5.2 「lookup」要素
3.1.6 「meta」要素
3.1.7 「metadata」要素
3.1.8 テキスト構造
3.1.8.1 「p」要素と「s」要素
3.1.8.2 「token」要素と「w」要素
3.1.9 「say-as」要素
3.1.10 「phoneme」要素
3.1.10.1 発音文字レジストリ
3.1.11 「sub」要素3.1.12 「lang」要素
3.1.13 言語読み上げ失敗: 「onlangfailure」属性
3.2 韻律とスタイル 
3.2.1 「voice」要素
3.2.2 「emphasis」要素
3.2.3 「break」要素
3.2.4 「prosody」要素
3.3 その他の要素 
3.3.1 「audio」要素
3.3.1.1 トリミング属性
3.3.1.2 「soundLevel」属性
3.3.1.3 「speed"」属性
3.3.2 「mark」要素
3.3.3 「desc」要素
4. 参考文献
5. 謝辞
付録A. オーディオ・ファイル・フォーマット(規範)
付録B. 国際化(規範)
付録C. メディア・タイプとファイル拡張子(規範)
付録D. 音声合成マークアップ言語用スキーマ(規範)
付録E. SSMLの例(参考情報)
付録F. SSML 1.0以後の更新(参考情報)
付録G. 最新草案以後の更新(参考情報)
1. はじめに
このW3C仕様は、音声合成マークアップ言語仕様(SSML)として知られており、サン・マイクロシステムズ(米国カリフォルニア州)が所有するJSGFおよび/またはJSMLの仕様に基づいています。JSMLの仕様は、[JSML]にあります。
SSMLは、W3Cのオープンなプロセスにより開発された音声読み上げブラウザ用のより大きなマークアップ仕様集合の一部です。ウェブやその他のアプリケーションにおける合成音声の作成を支援するために豊かなXMLベースのマークアップ言語を提供することを目指しています。このマークアップ言語の本質的な役割は、合成可能なコンテンツの作成者に、合成に対応した様々なプラットフォームにおいて、発音、音量、ピッチ、速度などの音声出力に関する様々な側面を制御するための標準的な方法を提供することです。関連するテキスト入力の標準的なマークアップ方式を確立するための取り組みには[SABLE]があり、これは、様々なXMLベースの音声合成用マークアップを、一つの新たなマークアップに統合しようという試みです。SABLEで行われた取り組みは、音声マークアップ言語用音声合成マークアップ要件[REQS]の定義の主な出発点としても利用されました。それ以後、SABLE自身は、それ以上の開発を行っていません。
SSMLの使用目的は、合成されたコンテンツの質の改善です。マークアップ要素の違いは、合成処理の異なる局面に影響を及ぼします(1.2項を参照)。マークアップは、例えば、XHTMLドキュメントのXSLTやCSS3で自動的に作成するか、人手によるオーサリングで作成できます。マークアップは、完全なSSMLドキュメント(2.2.2項を参照)内に記述したり、別の言語に埋め込まれた部分的な断片(2.2.1項を参照)として記述したりすることができます。ただし、他の言語との相互作用をSSML自身の一部として規定することはできません。SSMLに含まれているマークアップの多くは、大半のコンテンツ開発者による利用に適していますが、音素や韻律(例えば音声曲線設計用)のような一部の拡張機能には専門知識が必要かもしれません。
1.1 設計コンセプト
設計と標準化のプロセスは、音声マークアップ言語用音声合成マークアップ要件[REQS]から引き継ぎました。
主な設計上の基準は、次の事項でした。
整合性: 複数のプラットフォームや音声合成の実装にまたがって音声出力の制御を予測可能とすること。
相互運用性: VoiceXML、ACSS(aural Cascading Style Sheets)やSMILを含む(しかし、これらに限らない)、他のW3C仕様との併用をサポートすること。
汎用性: 様々な音声コンテンツを備えた広範囲なアプリケーションの音声出力をサポートすること。
国際化: ドキュメント内あるいはドキュメント間にまたがる多くの言語による音声出力を実現すること。
作成と可読性: ドキュメントの自動作成および手作業によるオーサリングをサポートすること。ドキュメントは、人間が読めるものであるべき。
実装可能性: 仕様は、既存の一般的に利用可能な技術を用いて実装可能であり、オプション機能の数は最小限であるべき。
1.2 音声合成処理のステップ
SSMLをサポートしたTTS(Text-To-Speech)システム(合成プロセッサ)は、ドキュメントを音声出力として再生し、マークアップに含まれている情報を用いて、作成者の意図したとおりにドキュメントを表現することに責任を負います。
ドキュメントの作成: 合成プロセッサに入力されるテキスト・ドキュメントは、自動的に、または、人手によるオーサリングによって、もしくは、これらの方式の組み合わせによって作成できます。SSMLは、ドキュメントの形式を定義しています。
ドキュメントの処理: 下記は、マークアップしたテキストの入力データを自動的に音声出力データに変換し作成するために合成プロセッサが実行する6つの主な処理ステップです。このマークアップ言語は、ドキュメントの作成者(人間またはマシン)が最終的な音声出力を制御できるように、下記の各ステップの制御を可能とするために、十分にリッチであることを目指しています。下記の各ステップは、「マークアップ」と「非マークアップ」に分けていますが、実際には、通常はこれら2つをミックスしたものであり、タグによって異なります。プロセッサは、作成するデータが発音可能である(かつ、理想的には、分かりやすい)ことを保証する最終的な権限を有しています。一般的に、マークアップは、著者が韻律やその他の情報(通常は、プロセッサが独自に取得できない情報)をプロセッサが利用できるようにする方法を提供します。その後の情報の採否や使用方法の判断は、プロセッサ次第です。
XML解析: XMLパーザは、入力されたテキスト・ドキュメントからドキュメン・ツリーとコンテンツを抽出するために用います。このステップで得られる構造、タグ、属性は、次の各ステップに影響を及ぼします。
構造分析: ドキュメントの構造は、ドキュメントを読むべき方法に影響を及ぼします。例えば、段落や文に共通する読み上げパターンが存在したりします。
マークアップ: SSMLで定義されているp要素とs要素により、音声出力に影響を与えるドキュメント構造を明示します。
非マークアップ: これらの要素が用いられていないドキュメントやドキュメントの部分では、合成プロセッサは、テキストの自動解析によって構造を推論する責任があり、しばしば、句読点やその他の言語固有のデータが用いられます。
テキストの正規化: すべての記述言語には、記述形式(表記形式)を会話形式に変換する必要がある特殊な要素があります。テキストの正規化とは、この変換を行なう合成プロセッサの自動処理です。例えば、英語の場合、ドキュメントに「$200」とあるとき、会話では「two hundred dollars」と読み上げられる可能性があります。同様に、「1/2」は、「half」、「January second」、「February first」などと読み上げられるかもしれません。このステップが終了するまでに、読み上げられるテキストは完全にトークンに変換されます。トークンが何で構成されるかの詳細は、言語によって異なります。英語では通常、トークンはスペースで区切られており、それは通常は単語です。トークン化の性質がこれとは異なる言語の場合、この仕様の「単語」という用語は、これに相当する単位を意味します。token要素とw要素内を除き、SSMLのトークンがアークアップ・タグに及ぶことはできません。英語での簡単な例は、「cup<break/>board」で、合成プロセッサは、token要素とw要素の記述の外では、これを、間に休止がある1つのトークン(単語)としてではなく、「cup」と「board」の2つのトークンとして扱うでしょう。この方法で1つのトークンを複数のトークンに分解すると、プロセッサがそれを扱う方法に恐らく影響するでしょう。
マークアップ: say-as要素を入力ドキュメントで用いると、これらの構成子の存在と種類を示して曖昧さを解消できます。マークアップ可能な構成子はまだ定義されていませんが、日付、時間、数、頭字語、金額などが含まれるかもしれません。頭字語や略語の多くは、著者が直接テキストを置換したり、sub要素を用いて扱えることに注意してください。例えば、「BBC」は「B B C」と記述でき、「AAA」は「triple A」と記述できます。この置き換えられた記述形式により、恐らく、元の頭字語は、発音して欲しいと思うとおりに発音されるでしょう。日本語のテキストの場合には、漢字と仮名の両方をサポートする合成プロセッサがあれば、sub要素を用いて、「今日は」が「きょうは」(「kyou wa」=「today」)と読み上げるべきか、「こんにちは」(「konnichiwa」=「hello」)と読み上げるべきかを区別できます。
非マークアップ: say-as要素でマークアップされていないテキストの場合、合成プロセッサがこれらの構成子を自動的に見つけ出し、読み上げに適した形に変換するにはかなりの労力が必要です。内在する曖昧さ(上記の「1/2」の例のような)のため、また、ある言語に想定される構成子の範囲が広いため、この処理によって音声出力にエラーが生じるかもしれないし、同じドキュメントに対して異なるプロセッサが異なる表現を行う原因となるかもしれません。
テキストから音素への変換: 合成プロセッサがトークンを読み上げる場合には、トークンごとの発音を基にするはずです。発音は、便宜上、音素の列として表現され、これは、ある単語を別の単語と区別する機能を果たす単語の音の単位です。各言語(ある言語の異なる国の言葉や方言の場合もある)は、独自の音素を持っています。例えば、ほとんどのアメリカ英語方言には約45の音素があり、ハワイ語には12から18(誰に尋ねるかによる)、一部の言葉には100以上もあります!
この変換は、多くの問題によって複雑になっています。問題のひとつは、言語の記述形式と会話形式に違いがあるということで、この違いによって、記述された単語の発音が確定できなかったり曖昧になる場合があります。例えば、ヘブライ語とアラビア語の単語は通常、その会話形式と比較して、母音が記述されなかったり、ほんの一部の母音が記述されるだけだったりします。多くの言語では、記述された一つの単語に多くの読み上げ方がありえます。例えば、英語の場合、「read」は「リード(reed)」(I will read the book)と読んだり、「レッド(red)」(I have read the book)と読んだりします。人間も合成プロセッサも、これらの単語を文脈に基づいて正確に発音できますが、文脈がない場合には困難なことがあります(下記の「非マークアップ」を参照)。もう一つの問題は、標準的でない綴りや発音を持つ単語の扱いです。例えば、英語の合成プロセッサは、「Caius College」(「keys college」と発音する)やTito(「sutto」と発音する)大統領、Kiribati(「kiribass」と発音する)共和国の大統領など、一部の英語由来でない名前の読み上げ方を決める際にしばしば苦労するでしょう。
マークアップ: phoneme(音素)要素によって、任意のトークンやトークンの列に音素の列を付与することができます。これにより、コンテンツの作成者は、発音を明確に制御できます。テキストが固有名詞であり、合成プロセッサが特別な規則を適用してその発音を決定できることを示すためにsay-as要素を用いることもありえます。lexicon要素とlookup要素は、発音の外部定義を参照するために使用できます。これらの要素は特に、プロセッサが自身のテキストの正規化では解決できず、テキストを直接置換したりsub要素を用いても対処できない頭字語や略語に役立ちます(上記の第3段落を参照)。
非マークアップ: phoneme要素が記述されていない場合には、合成プロセッサは、自動的に発音を決定する機能を適用しなければなりません(MUST)。これは通常、発音辞書(ある言語に依存するかもしれない)でトークンを調べ、他の発音を決定する規則を適用することで達成されます。合成プロセッサは、ほとんどのドキュメントのほとんどの単語を自動的に扱えるようなテキストの音素変換を実行できるように設計されています。作成者は、プロセッサに頼るのではなく、SSMLでコード化する前に一部の変換自身を行なうことも選択できます。発音が不確定または曖昧な書き言葉を、明確な発音の言葉に置き換えることができるかもしれません。例えば「read」の場合、「I will reed the book」にするなどが考えらえます。しかし、作成されるSSMLドキュメントは、視覚表示には不向きでありえることを作成者は知っているべきです。
韻律分析: 韻律は、ピッチ(イントネーションやメロディーとも呼ばれる)、タイミング(またはリズム)、休止、読み上げ速度、単語の強調やその他の多くの特性を含む音声出力特性の集合です。人間に近い韻律を作り出すことは、自然な読み上げ音声を生成したり、読み上げられた言葉の意味を正確に伝えるために重要です。
マークアップ: ドキュメントの作成者は、合成プロセッサが音声出力時に適切な韻律特性を生成できるようにするために、emphasis(強調)、break(休止)、prosody(韻律)の要素のすべてを使用できます。
非マークアップ: これらの要素が記述されていない場合には、合成プロセッサは、自動的に適切な韻律を生成することに長けています(しかし完全ではない)。これは、入力されたテキストから推測できるドキュメントの構造、文法やその他の情報の解析により達成されます。
SSMLのほとんどの要素は、読み上げ用のコンテンツか形式的な論理記述かのどちらかを提供するという点において、高レベルであると考えることができます。しかし、上記のbreak要素とprosody要素は、より後の処理で実行されるため、emphasis要素の使用との共存と、プロセッサ独自の韻律との共存の両方を行わなければなりません。しかるべき項で指定されていない場合には、プロセッサ独自の決定と、このレベルで著者が提供する記述との相互関係の詳細は、プロセッサによって異なります。作成者は、これらの2つのレベルの制御を偶然あるいは恣意的に組み合わせないようにしてください。
波形の作成: 合成プロセッサは、オーディオの波形を作成する際に、音素と韻律の情報を用います。この処理段階には多くのアプローチがあるため、プロセッサ独自のバリエーションがかなりありえます。
マークアップ: voice(音声)要素により、ドキュメントの作成者は、特殊な音声や特定の音声品質(例えば、若い男声)を要求することが可能となります。audio(オーディオ)要素により、録音の時間、音響レベル、再生速度に対するオプション制御を含む、録音されたオーディオ・データを出力ストリームに挿入することが可能となります。speak要素でトリミング属性を用いれば、ドキュメントの一部の再生に制限することができます。
非マークアップ: デフォルトの音量/音響レベル、速度、ドキュメント内の声と録音されたオーディオの両方は、それらが音声か録音かを問わず、未処理の波形のピッチ/周波数となります。
1.3 ドキュメントの作成、アプリケーションと文脈
合成プロセッサが読み上げるマークアップ・ドキュメントの作成者には様々な人がいます。ドキュメントの作成者(人間とマシンを含む)がすべて、すべての要素または前項で述べた各処理ステップで使用できる情報にアクセスできるとは限りません。下記は、一部の一般的な例です。
ドキュメントの作成者は、テキストをマークアップするための情報にアクセスできません。合成プロセッサ内のすべての処理ステップは、生のテキスト上で全自動で行なわれなければなりません。ドキュメントにspeak要素を記述するだけでコンテンツが読み上げ可能であることを示すことができます。
テキストのマークアップをプログラムで行う場合には、その作成プログラムは、ドキュメントの一部またはすべての構造および/または特殊なテキスト構成子に関して特定の知識を持っているかもしれません。例えば、電子メール・リーダーは、電子メールの受信日時の箇所をマークアップできます。このようなアプリケーションは、構造、テキストの正規化、韻律および恐らくテキストから音素への変換に影響を与える要素を使用できます。
ドキュメントの作成者のなかには、プラットフォームの全体で一貫した読み上げ品質を保証し、より正確に出力品質を定められるように、出来る限り詳細にドキュメントを記述しようと相当な努力を行う人もいます。この場合、音声出力をしっかりと管理するために、利用可能な要素の一部またはすべてをマークアップに使用できます。例えば、テレフォニー(telephony)や音声読み上げブラウザのアプリケーションが作成したメッセージを調整して、システム全体の有効性を最大限に高めることができます。
最も高度なドキュメントの作成者は、より高いレベルのマークアップ(構造、テキストの正規化、テキストから音素への変換、韻律解析)をスキップし、ドキュメントの部分や全体に対し、低レベルの音声合成マークアップを作成するかも知れません。通常これには、音素の列を作成するツールに加え、ピッチとタイミングの情報が必要です。例えば、「コピー合成」や「韻律の移植」を行うツールは、録音データの特性をコピーして人間のスピーチを模倣しようとします。
下記は、マークアップした合成ドキュメントを作成するアーキテクチャや設計の重要な実例です。この言語の設計は、これらの各アプローチの促進を目的としています。
対話言語: 音声読み上げブラウザ・ワーキンググループが作成する対話記述ドキュメントに、SSMLでマークアップされたドキュメントを含めることができるべき(SHOULD)であることが要求されます。
オーラルCSS(ACSS)との相互運用性: オーラルCSSに対応したHTMLプロセッサは、SSMLを作成できます。ACSSについては、CSS2(Cascading Style Sheets, level 2)仕様の19項[CSS2 19項]で取り上げています。このように音声合成を用いることによって、既存のHTMLとXHTMLコンテンツのアクセシビリティの改善が促進されます。
アプリケーション固有のスタイル・シートの処理: 上記のとおり、読み上げるテキストの内容について知識を持っているアプリケーションにはいくつかの種類があり、それを音声合成のマークアップに組み込んで、ドキュメントの表現を強化することができます。多くの場合、アプリケーションは、スタイル・シートを用いて既存のXMLドキュメントをSSMLに変換すると予想されます。これは、HTMLにACSSを用いるのと等しく、ここでも、SSMLは作成された表現として合成プロセッサに渡されることになります。その意味で、SSMLは、空間オーディオを除き、ACSS[CSS2 19項]の上位集合と見なせます。
1.4 SSMLコンテンツのプラットフォーム依存の出力
SSMLは、発音、音量、ピッチ、速度などの合成音声作成の全体的な特性を指定する標準的な方法を提供します。しかし、異なる種類のプロセッサにまたがる合成音声出力に関する厳密な仕様は、このドキュメントの範囲外です。
明示されていない場合には、マークアップの値は、絶対的な値ではなく単なる指示です。例えば、作成者はテキストの断片の時間を明示でき、さらにそのテキストの断片の部分集合の時間を明示すこともできます。この2つの時間によって、合成プロセッサが合理的に表現できないテキストの断片が生じる場合には、プロセッサは、そのテキストの断片の表現に必要な時間に変更することが認められています。
1.5 用語
必要条件に関する用語
このドキュメントの「しなければならない(MUST)」「してはならない(MUST NOT)」「必須である/要求される(REQUIRED)」「することになる(SHALL)」「することはない(SHALL NOT)」「すべきである/する必要がある(SHOULD)」「すべきでない/する必要がない(SHOULD NOT)」「推奨される(RECOMMENDED)」「することができる/してもよい(MAY)」「選択できる/任意である(OPTIONAL)」というキーワードは、[RFC2119]で記述されているように解釈されるべきです。ただし、この仕様では、読みやすさのために、これらの用語をすべて大文字で表しているとは限りません。
ユーザ・オプション
適合合成プロセッサは、記述されているとおりに動作してもよく(MAY)、または、動作しなければなりません(MUST)(文の法動詞に依存する)。実行時には、記述されている動作を有効または無効にする方法をユーザに提供しなければなりません(MUST)。
エラー
結果は未定義です。適合合成プロセッサは、エラーを検知して報告でき(MAY)、それを元に戻すことができます(MAY)。
メディア・タイプ
メディア・タイプ([RFC2045]および[RFC2046]で定義されている)は、リンクしている資源の性質を指定します。メディア・タイプは、大文字と小文字を区別しません。公認のメディア・タイプのリストをダウンロードできます[TYPES]。SSMLのメディア・タイプに関する情報については、付録Cを参照してください。
音声合成
プレーン・テキスト、マークアップされたテキスト、バイナリ・オブジェクトを含んでいる可能性のある入力データを基にした音声出力データの自動作成処理。
合成プロセッサ
SSMLドキュメントを入力データとして受け入れ、それを読み上げ出力データとして表現するText-To-Speechシステム。
Text-To-Speech
テキストまたは注釈付きテキストの入力データからの音声出力データの自動作成処理。
URI(Uniform Resource Identifier)
ウェブ環境におけるグローバルな識別子[WEB-ARCH]。XMLスキーマ パート2:データ型[SCHEMA2 3.2.17項]のとおり、URIは、任意の正当なanyURIプリミティブであると定義されています。参考までに、[RFC3986]と[RFC2732]は、構造、フォーマットやURIの使用について理解するのに役立つかもしれません。IRI([RFC3987]を参照)が上記のURIの定義の範囲内で認められていることに注意してください。相対URI参照は、3.1.3.1項で示している規則によって解決されなければなりません(MUST)。この仕様では、例えばaudio要素とlexicon要素の場合のように、URIを要素の属性として指示します。
音声読み上げブラウザ
(音声)マークアップ言語を解釈し、音声出力データを作成でき、かつ/または、音声入力データを解釈でき、可能であればその他の入出力の方式を解釈・作成できる装置。
2. SSMLドキュメント
2.1 ドキュメント形式
正当なスタンドアロンの音声合成マークアップ言語ドキュメントには、正当なXMLプロローグ[XML 1.0または必要に応じてXML 1.1 2.8項]がなければなりません(MUST)。
XMLプロローグの次にルートのspeak要素が来ます。この要素の詳細については、3.1.1項を参照してください。
speak要素では、SSML名前空間を指定しなければなりません(MUST)。これは、xmlns属性または接頭辞「xmlns」を持つ属性の宣言により達成できます。詳細は[XMLNS 1.0または必要に応じてXMLNS 1.1 2項]を参照してください。xmlns属性のみを用いた場合、それが出現する要素と子要素に対し、デフォルトの名前空間が設定されることに注意してください。SSMLの名前空間は、http://www.w3.org/2001/10/synthesisであると定義されています。
[SCHEMA1 2.6.3項]にあるxsi:schemaLocation属性を用いて、speak要素で適切なSSMLスキーマ(付録Dを参照)の位置も指し示すことを推奨します(RECOMMENDED)。この指示は必須ではありませんが、このドキュメントでは、これを促進するために、すべての例に対してそのような指示を行っています。この属性が付与されていない場合には、コア・プロファイル[2.2.5項]を前提としなければなりません(MUST)。
下記は、2つの正当なSSMLヘッダの例です。
<?xml version="1.0"?>
<speak version="1.1" xmlns="http://www.w3.org/2001/10/synthesis"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
http://www.w3.org/TR/speech-synthesis11/synthesis.xsd"
xml:lang="en-US">
<?xml version="1.0"?>
<speak version="1.1" xmlns="http://www.w3.org/2001/10/synthesis"
xml:lang="en-US">
ルートのspeak要素内にその他のすべての要素やテキストを記述する前に、meta、metadata、lexiconの要素を記述しなければなりません(MUST)。この仕様では、要素の順序に関し、その他の制約はありません。
2.2. 適合性
2.2.1 適合音声合成マークアップ言語断片
2.2.1.1 適合コア音声合成マークアップ言語断片
次の場合、ドキュメントの断片は適合コア音声合成マークアップ言語断片です。
下記を実行した後に、適合スタンドアロン・コア音声合成マークアップ言語ドキュメントの基準に適合している場合。
xml:langとxml:baseを除き、すべての非合成名前空間要素と属性、そして非合成名前空間要素を参照するすべてのxmlns属性をドキュメントから除外する。
また、speak要素において、xmlns属性を用いて合成名前空間をまだ指定していない場合には、xmlns="http://www.w3.org/2001/10/synthesis"を要素に追加する。
2.2.1.2 適合拡張音声合成マークアップ言語断片
次の場合、ドキュメントの断片は適合拡張音声合成マークアップ言語断片です。
下記を実行した後に、適合スタンドアロン拡張音声合成マークアップ言語ドキュメントの基準に適合している場合。
xml:langとxml:baseを除き、すべての非合成名前空間要素と属性、そして非合成名前空間要素を参照するすべてのxmlns属性をドキュメントから除外する。
また、speak要素において、xmlns属性を用いて合成名前空間をまだ指定していない場合には、xmlns="http://www.w3.org/2001/10/synthesis"を要素に追加する。
2.2.2 適合スタンドアロン音声合成マークアップ言語ドキュメント
2.2.2.1 適合スタンドアロン・コア音声合成マークアップ言語ドキュメント
次の両方の条件を満たす場合、ドキュメントは適合スタンドアロン・コア音声合成マークアップ言語ドキュメントです。
XML(1.0[XMLNS 1.0]または1.1[XMLNS 1.1])の名前空間に適合した整形式のXMLドキュメント[それぞれ、XML 1.0またはXML 1.1 2.1項]である。
コア・スキーマ(付録Dを参照)で表された制約を含み、2.1項で定められているXMLプロローグとspeakルート要素を有するこのドキュメント(音声合成マークアップ言語仕様)で記述している仕様に従った妥当なXMLドキュメント[XML 1.0またはXML 1.1 2.8項]である。
2.2.2.2 適合スタンドアロン拡張音声合成マークアップ言語ドキュメント
次の両方の条件を満たす場合、ドキュメントは適合スタンドアロン拡張音声合成マークアップ言語ドキュメントです。
XML(1.0[XMLNS 1.0]または1.1[XMLNS 1.1])の名前空間に適合した整形式のXMLドキュメント[それぞれ、XML 1.0またはXML 1.1 2.1項]である。
拡張スキーマ(付録Dを参照)で表された制約を含み、2.1項で定められているXMLプロローグとspeakルート要素を有するこのドキュメント(音声合成マークアップ言語仕様)で記述している仕様に従った妥当なXMLドキュメント[XML 1.0またはXML 1.1 2.8項]である。
SSMLの仕様やこれらの適合基準は、合成ドキュメントのいかなる側面に対してもサイズの制限を定めません。属性値の要素数、文字のデータ量、文字数に上限値はありません。
2.2.3 他の名前空間を持つSSMLの使用
合成名前空間は、XML勧告の適切な名前空間に従った他のXML名前空間(使用されているXMLのバージョンにより1.0[XMLNS 1.0]あるいは1.1[XMLNS 1.1])と共に使用することもできます(MAY)。W3Cによる取り組みにより、将来的には、複数の名前空間を含むドキュメントの適合性を指定する方法が出現するでしょう。言語固有(つまり、非SSML)の要素と属性は、適切な名前空間を用いて、SSMLに挿入できます。しかし、このようなコンテンツを表現できるのは、特製のマークアップをサポートした合成プロセッサのみでしょう。以下に、SSMLにルビ[RUBY]要素を挿入する方法の一例を示します。
<?xml version="1.0" encoding="UTF-8"?>
<speak version="1.1"
xmlns="http://www.w3.org/2001/10/synthesis"
xmlns:xhtml="http://www.w3.org/1999/xhtml"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
http://www.w3.org/TR/speech-synthesis11/synthesis.xsd"
xml:lang="ja">
<!-- It's 20 July today. -->
<s>今日は七月
<xhtml:ruby>
<xhtml:rb>二十日</xhtml:rb>
<xhtml:rt role="alphabet:x-JEITA">ハツカ</xhtml:rt>
</xhtml:ruby>
です。
</s>
<!-- It's 20 July today. -->
<s>今日は七月
<xhtml:ruby>
<xhtml:rb>二十日</xhtml:rb>
<xhtml:rt role="alphabet:x-JEITA">ニジューニチ</xhtml:rt>
</xhtml:ruby>
です。
</s>
</speak>
2.2.4 適合音声合成マークアップ言語プロセッサ
適合音声合成マークアップ言語プロセッサでは、XMLパーサは、XML 1.0[XML 1.0]、XML 1.1[[XML 1.1]および対応するXML(1.0[XMLNS 1.0]と1.1[XMLNS 1.1])の名前空間のバージョンで定義されているすべてのXML構成子を解析し処理できなければなりません(MUST)。このXMLパーサは、そのスキーマやDTDを用いてSSMLドキュメントの検証を行なう必要はありません。これは、SSMLドキュメントの処理中に、外部のDTDで定義されている外部エンティティー参照を適用または拡張するか否かは任意である(OPTIONAL)ことを示唆しています。
適合音声合成マークアップ言語プロセッサは、自然(人間の)言語を扱うために、次の要件を満たさなければなりません(MUST)。
適合音声合成マークアップ言語プロセッサが、正当な自然言語の宣言をすべてうまく解析することは必須です(REQUIRED)。
適合音声合成マークアップ言語プロセッサは、複数の自然言語を参照しているマークアップ言語のセマンティクスを適用できるかもしれません。プロセッサが集合内の個々の自然言語をサポートできるけれども、それらを同時に扱うことはできない場合には、ホスティング環境に通知すべきです(SHOULD)。プロセッサがサポートしていない複数の自然言語が集合に含まれている場合には、ホスティング環境に通知すべきです(SHOULD)。
適合音声合成マークアップ言語プロセッサは、ドキュメント化されたプロセッサ固有の挙動に従って、類似物を代用することによって自然言語を実装することができます(MAY)。例えば、アメリカ英語用の合成プロセッサは、イギリス英語の入力データを処理できます。
音声合成マークアップ言語プロセッサの性能特性に関する適合要件はありません。例えば、プロセッサが作成する読み上げの正確さ、速度やその他の特性に関するステートメントは必須ではありません。音声合成マークアップ言語プロセッサがサポートしなければならない入力データのサイズに関するステートメントは作成されません。
2.2.4.1 適合コア音声合成マークアップ言語プロセッサ
コア音声合成マークアップ言語プロセッサは、適合スタンドアロン・コア音声合成マークアップ言語ドキュメントを解析し処理できる適合音声合成マークアップ言語プロセッサです。
適合コア音声合成マークアップ言語プロセッサは、コア・プロファイルの要素と属性のセマンティクスをこのドキュメントで記述しているとおりに正確に理解し適用しなければなりません(MUST)。
適合コア音声合成マークアップ言語プロセッサがコア・プロファイルに含まれている以外の要素や属性に遭遇した場合、次のとおりにすることができます(MAY)。
非標準の要素および/または属性を無視する。
または、非標準の要素および/または属性を処理する。
または、これらの要素および/または属性が含まれているドキュメントを拒否する。
2.2.4.2 適合拡張音声合成マークアップ言語プロセッサ
拡張音声合成マークアップ言語プロセッサは、適合スタンドアロン拡張音声合成マークアップ言語ドキュメントを解析し処理できる適合音声合成マークアップ言語プロセッサです。
適合拡張音声合成マークアップ言語プロセッサは、拡張プロファイルの要素と属性のセマンティクスをこのドキュメントで記述しているとおりに正確に理解し適用しなければなりません(MUST)。
適合拡張音声合成マークアップ言語プロセッサが拡張プロファイルに含まれている以外の要素や属性に遭遇した場合、次のとおりにすることができます(MAY)。
非標準の要素および/または属性を無視する。
または、非標準の要素および/または属性を処理する。
または、これらの要素および/または属性が含まれているドキュメントを拒否する。
2.2.5 プロファイル
SSMLプロファイルは、SSMLの要素と属性の集合です。このドキュメントには、定義済みのプロファイルが2つだけあります。
コア・プロファイル
コア・プロファイルは、audio要素のclipBegin、clipEnd、repeatCount、repeatDur、soundLevel、speedの属性以外の、この仕様で定義されているすべての要素と属性で構成されます。
拡張プロファイル
拡張プロファイルは、この仕様で定義さているすべての要素と属性で構成されます。
2.2.6 適合ユーザ・エージェント
適合ユーザ・エージェントは、SSMLドキュメントを入力データとして受け入れ、著者が意図するとおりにドキュメントを表現するために、マークアップに含まれている情報を用いて読み上げ出力データを作成できる適合音声合成マークアップ言語プロセッサです。適合ユーザ・エージェントは、少なくとも1つの自然言語をサポートしなければなりません(MUST)。
出力データが、入力データに含まれているすべてのマークアップを正確に表現したものであることを保証することはできないため、正確さに関する適合要件はありません。しかし、適合テストでは、適合性を判断するために、参照ドキュメントの正確な合成の例をいくつか要求することができます(MAY)。
2.3 他のマークアップ言語との統合
2.3.1 SMIL
SMIL(Synchronized Multimedia Integration Language、「スマイル」と発音)[SMIL3]は、シンプルな対話型視聴覚表現のオーサリングを可能とします。一般的にSMILは、ストリーミングのオーディオやビデオを画像やテキスト、その他のメディア・タイプと統合させた「リッチ・メディア」/マルチメディアの表現に用いられます。SMILは、HTMLのように容易に学べる言語で、SMILによる表現の多くは、単純なテキスト・エディターで記述されます。付録EのSMIL/SSMLの統合例を参照してください。
2.3.2 ACSS
ACSS(Aural Cascading Style Sheets)[CSS2 19項]は、テキストをオーディオに合成する際に役立つ要素を加えることで、ドキュメント(HTMLのような)の標準的な視覚形式を強化するために用いられます。SSMLと比較して、ACSSで作成されるドキュメントは、音源の三次元位置の指定を含むより複雑なオーディオ・シーケンスの指定が可能です。他のACSS要素の多くは、特に音声の種類/質の仕様に関して、SSML機能性と重複しています。SSMLは、空間オーディオを除き、ACSSの性能上の上位集合と見なせます。
2.3.3 VoiceXML
VoiceXML(Voice Extensible Markup Language)[VXML]は、ウェブ・ベースの対話型音声応答アプリケーションの開発とコンテンツの提供を可能とします(音声読み上げブラウザを参照)。VoiceXMLは、音声合成、ディジタル化されたオーディオの録音・再生、音声認識、DTMF入力、テレフォニー・コール制御、フォームによる混合主導型対話をサポートしています。VoiceXML 2.0は、SSMLを拡張し、テキストのマークアップを合成できるようにします。VoiceXMLとSSMLとの統合の例に関しては、付録Fを参照してください。
2.4 SSMLドキュメントの取得
SSMLドキュメントの取得とキャッシングは、合成プロセッサが作動する環境によって規定されます。例えば、VoiceXMLインタープリターの環境では、キャッシング・ポリシーは、VoiceXMLインタープリターによって決まります。
3. 要素と属性
この仕様では、次の要素と属性を定義しています。
3.1 ドキュメント構造、テキスト処理と発音 
3.1.1 「speak」ルート要素
3.1.1.1 トリミング属性
3.1.2 言語: 「xml:lang」属性
3.1.3 基底URI: 「xml:base」属性
3.1.3.1 相対URIの解決
3.1.4 識別子: 「xml:id」属性
3.1.5 辞書ドキュメント
3.1.5.1 「lexicon」要素
3.1.5.2 「lookup」要素
3.1.6 「meta」要素
3.1.7 「metadata」要素
3.1.8 テキスト構造
3.1.8.1 「p」要素と「s」要素
3.1.8.2 「token」要素と「w」要素
3.1.9 「say-as」要素
3.1.10 「phoneme」要素
3.1.10.1 発音文字レジストリ
3.1.11 「sub」要素
3.1.12 「lang」要素
3.1.13 言語読み上げ失敗: 「onlangfailure」属性
3.2 韻律とスタイル 
3.2.1 「voice」要素
3.2.2 「emphasis」要素
3.2.3 「break」要素
3.2.4 「prosody」要素
3.3 その他の要素 
3.3.1 「audio」要素
3.3.1.1 トリミング属性
3.3.1.2 「soundLevel」属性
3.3.1.3 「speed」属性
3.3.2 「mark」要素
3.3.3 「desc」要素
3.1 ドキュメント構造、テキスト処理と発音
3.1.1 speakルート要素
音声合成マークアップ言語は、XMLアプリケーションです。ルート要素はspeakです。
xml:langは、ルート・ドキュメントの言語を指定する必須の(REQUIRED)属性です。
xml:baseは、ルート・ドキュメントの基底URIを指定する任意の(OPTIONAL)属性です。
onlangfailureは、読み上げに失敗したときの望ましい挙動を指定する任意の(OPTIONAL)属性です。
version属性は、ドキュメントに用いる仕様のバージョンを示す必須の(REQUIRED)属性で、「1.1」という値でなければなりません(MUST)。
トリミング属性に関しては、以下の小項目で定めています。
合成プロセッサは、speak要素の実行前にデフォルトの音声を選択しなければなりません(MUST)。デフォルトの音声ではテキストの言語を読み上げられない場合には、最初のテキストに遭遇するとすぐに読み上げ失敗(3.1.13項を参照)が発生することに注意してください。もちろん、これは、テキストに遭遇する前に音声が変更されていないことが前提となります。
<?xml version="1.0"?>
<speak version="1.1"
xmlns="http://www.w3.org/2001/10/synthesis"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.w3.org/2001/10/synthesis
http://www.w3.org/TR/speech-synthesis11/synthesis.xsd"
xml:lang="en-US">
... the body ...
</speak>
speak要素には、表示用テキストとaudio、break、emphasis、lang、lexicon、lookup、mark、meta、metadata、p、phoneme、prosody、say-as、sub、s、token、voice、wの要素のみを含むことができます。
3.1.1.1 トリミング属性
トリミング属性は、ドキュメントの再生範囲を定義します。speakコンテンツ内の範囲の開始と終了は、両方ともマークを用いて指定できます。
speakには、次のトリミング属性が定義されています。
名前
必須
タイプ
デフォルト値
説明
音声合成マークアップ言語(SSML)バージョン1.1
