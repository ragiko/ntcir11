  
　従来の電子機器の中には、ユーザによる動画コンテンツの選択を支援する機能として、各コンテンツのダイジェストを提示する機能を備えたものがある。動画コンテンツの「ダイジェスト」とは、そのコンテンツが表す映像の冒頭部分等、その映像全体の中から抜粋された映像部分、又はその映像部分を表すデータをいう。従来の電子機器は例えば、ユーザが選択肢の動画コンテンツを識別しやすい環境として、それらのダイジェストがサムネイル表示された画面を提示する。しかし、近年、全番組録画が可能なレコーダの登場、及びスマートフォンの爆発的な普及が、各家庭に蓄積される動画コンテンツの増加のペースを更に加速している。それに伴い、ダイジェストでさえも、ユーザがそれらを隈無くチェックするには多過ぎるようになりつつある。従って、ユーザに、膨大な数のダイジェストの中から、自分の嗜好に合ったものを手早く選択させるための工夫が更に必要である。
　そのような工夫の１つとしては、電子機器に自動的に、動画コンテンツが表す映像の中から、ユーザの嗜好に合った映像をダイジェストとして抽出させることが考えられる。その場合、動画コンテンツの数は膨大であっても、ダイジェストの種類は、ユーザの嗜好に合ったものに絞られるので、ユーザがチェックすべきダイジェストの数は動画コンテンツの数よりも少なくてすむ。また、いずれのダイジェストが表す映像もユーザの嗜好に合っているので、ユーザはそれらの映像を比較的迅速にチェックできる。しかし、映像そのものの特徴でユーザの嗜好を表現するのは難しいので、ユーザの嗜好に合う／合わないの判断基準を映像の特徴ベクトルで設定するのは難しい。また、仮にその基準を映像の特徴ベクトルで設定できたとしても、映像の解析に必要な計算量は一般に大きいので、その基準に合うダイジェストを動画コンテンツから抽出する処理には時間がかかる。従って、動画コンテンツの数又はサイズが膨大であれば、ダイジェストの生成に必要な時間を実用的な範囲に収めることが難しい。
　本発明の目的は上記の課題を解決することにあり、特に、動画コンテンツのダイジェストを自動的に、迅速に、かつ基準に対して的確に生成することのできる装置を提供することにある。
　本発明の１つの観点によるダイジェスト生成装置は、動画コンテンツからダイジェストを生成するための装置であり、区間分類部とダイジェスト抽出部とを備えている。区間分類部は、１つの動画コンテンツに含まれる複数の区間のそれぞれが表す音声又は字幕における単語別の出現回数からその区間の特徴ベクトルを構成し、異なる区間の間での特徴ベクトルの類似度に基づいて、複数の区間を複数のグループに分類する。ダイジェスト抽出部は、複数のグループのそれぞれが表す音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性を評価し、評価された値が所定の閾値以上であるグループをダイジェストとして動画コンテンツから抽出する。
　本発明の上記の観点によるダイジェスト生成装置は動画コンテンツの区間をグループ分けする際、映像の特徴に代えて、音声又は字幕における単語の出現回数を利用する。それにより、この装置は各グループの特徴を自動的に、的確に、かつ迅速に分けることができる。更にこの装置は、ダイジェストとして抽出されるべきグループを、音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性に基づいて選択する。その結果、この装置は動画コンテンツのダイジェストを自動的に、迅速に、かつ基準に対して的確に生成することができる。
本発明の実施形態によるホーム・ビデオ・ネットワーク・システムを示す模式図である。 図１に示されているシステムにおけるホーム・ビデオ・サーバ、すなわちＮＡＳのハードウェア構成を示すブロック図である。 図１に示されているシステムにおけるホーム・ビデオ・サーバ、すなわちＮＡＳの機能ブロック図である。 ＭＰＥＧ－２　ＴＳ形式を採用した動画コンテンツのデータ構造を示す模式図である。 テキスト字幕ストリームのデータ構造を示す模式図である。 図３に示されている区間分類部の機能ブロック図である。 図６に示されている区間分類部による処理のフローチャートである。 図６に示されている区間分類部がオーディオ・ストリームから単語を抽出する処理を示す模式図である。 図７に示されているステップＳ７０６において、字幕を表すテキスト文字列を動画コンテンツの区間ごとに連結する処理のフローチャートである。 図６に示されている特徴ベクトル構成部がテキスト文字列から単語を抽出する処理を示す模式図である。 （ａ）は、図６に示されている特徴ベクトル構成部が構成した特徴ベクトルに関する情報の一覧表である。（ｂ）は、その特徴ベクトルを幾何学的に表す模式図である。 図７に示されているステップＳ７０９においてシーンを構成する処理のフローチャートである。 （ａ）、（ｂ）は、図１２に示されている処理によるシーンの構成を示す模式図である。（ｃ）は、図６に示されているシーン境界設定部が作成したシーン情報を示す表である。 図３に示されている関心情報収集部の機能ブロック図である。 図１４に示されている関心情報収集部による処理のフローチャートである。 図１４に示されている基準単語表管理部によって管理される基準単語表を示す表である。 図３に示されているダイジェスト抽出部の機能ブロック図である。 図１７に示されているダイジェスト抽出部による処理のフローチャートである。 （ａ）、（ｂ）はそれぞれ、図３に示されているクライアントの１つが視聴対象の動画コンテンツの選択画面に表示するダイジェストのレイアウトの一例を示す模式図である。 
　以下、本発明の実施形態について、図面を参照しながら説明する。
　［ホーム・ビデオ・ネットワーク・システムの構成］
　図１は、本発明の実施形態によるホーム・ビデオ・ネットワーク・システム100を示す模式図である。図１を参照するに、このシステム100は、ルータ110、ネットワーク・ストレージ（ＮＡＳ：Networkttachedtorage）120、デジタル・スチル・カメラ121、デジタル・ビデオ・カメラ122、録画装置130、表示装置140、141、パーソナル・コンピュータ（ＰＣ）150、及びモバイル機器160を含む。
　ルータ110は、システム100内の他の電子機器120、130、#12289;160と有線ＬＡＮ（ＩＥＥＥ８０２．３）又は無線ＬＡＮ（ＩＥＥＥ８０２．１１）を通して通信する機能、及び、インターネットWWWにＷＡＮを通して接続する機能を備えている。ルータ110はそれらの機能を利用して、他の電子機器120、#12289;160の相互間、及び、それらの電子機器とインターネットWWWとの間でのデータ交換を中継する。
　ＮＡＳ120は、ハードディスク・ドライブ（ＨＤＤ）又は半導体メモリ・ドライブ（ＳＳＤ）等の大容量記憶装置を利用して大量の映像・音声（ＡＶ）データを保管する機能、有線ＬＡＮ又は無線ＬＡＮ（以下、ＬＡＮと略す。）を通してルータ110と通信する機能、及び、外部インタフェースを通して別の電子機器から直接、データを取り込む機能を備えている。ＮＡＳ120はそれらの機能を利用して、システム100内の中心的役割、すなわちホーム・ビデオ・サーバとしての役割を果たす。具体的には、ＮＡＳ120はルータ110又は外部インタフェースを利用して、システム100内の他の電子機器121、122、130、#12289;160から様々な動画コンテンツを受け付けて記憶装置に格納する。一方、ＮＡＳ120はそれらの電子機器からの要求に応じて、記憶装置に保存されている動画コンテンツの一覧として、それらのダイジェストを生成して返信する。その後、それらの電子機器から特定の動画コンテンツのダウンロードを要求された場合、ＮＡＳ120はその動画コンテンツを記憶装置から検索して要求元の電子機器へ返信する。
　デジタル・スチル・カメラ121とデジタル・ビデオ・カメラ122とは、ユーザの操作に従って静止画（すなわち写真）又は動画（すなわちホームビデオ）を撮影する機能、及び、ＮＡＳ120の外部インタフェースへＡＶデータを転送する機能を備えている。各デジタル・カメラ121、122はそれらの機能を利用して、写真の映像データとホームビデオのＡＶデータとをＮＡＳ120へ転送する。
　録画装置130はハードディスク・レコーダ又は光ディスク・レコーダである。録画装置130は、ユーザから録画予約を受け付ける機能、地上デジタル放送波、衛星デジタル放送波、又はケーブル・テレビ放送波（以下、放送波と略す。）を受信してその放送波から録画対象の番組のＡＶデータを抽出する機能、ハードディスク又は光ディスク等の記録媒体へＡＶデータを記録する機能、その記録媒体からＡＶデータを再生する機能、及び、ＬＡＮを通してルータ110と通信する機能を備えている。録画装置130はそれらの機能を利用して、ユーザに指定された放送番組を予約録画する一方、私的に録画された放送番組又は市販の映画等の動画コンテンツを記録媒体から再生してＮＡＳ120へ転送する。
　表示装置140、141は、液晶ディスプレイ、プラズマ・ディスプレイ、又は有機ＥＬディスプレイ等のフラット・パネル・ディスプレイである。表示装置140、141は、放送波を受信して、その放送波から所望の番組の映像を画面に再現し、かつ、その音声を再生する機能、ＬＡＮを通してルータ110と通信する機能、及び、ブラウザを用いてＷｅｂページ又は動画コンテンツを画面に表示する機能を備えている。ＰＣ150も同様な機能を備えている。表示装置140、141とＰＣ150とはそれらの機能を利用して、所望の放送番組をリアルタイムでユーザに視聴させ、所望の動画コンテンツをＮＡＳ120若しくはインターネットWWWからダウンロードしてユーザに視聴させ、又は、所望の動画コンテンツを録画装置130に記録媒体から再生させてユーザに視聴させる。ＰＣ150はその他に、インターネットWWWからダウンロードした動画コンテンツをＮＡＳ120へアップロードする。
　モバイル機器160は、スマートフォン等の携帯電話、携帯情報端末、又はタブレット型ＰＣである。モバイル機器160は、携帯電話回線を通してインターネットWWWにアクセスする機能、ＬＡＮを通してルータ110と通信する機能、ブラウザを用いてＷｅｂページ又は動画コンテンツを画面に表示する機能、ワンセグ放送波を受信して、その放送波から所望の番組の映像を画面に再現し、かつ、その音声を再生する機能、及び、デジタル・カメラ121、122と同様な写真・ホームビデオの撮影機能を備えている。モバイル機器160はそれらの機能を利用して、所望の動画コンテンツをＮＡＳ120若しくはインターネットWWWからダウンロードしてユーザに視聴させ、所望の放送番組をリアルタイムでユーザに視聴させ、所望の動画コンテンツを録画装置130に記録媒体から再生させてユーザに視聴させ、又は、インターネットWWWからダウンロードした動画コンテンツ若しくは写真・ホームビデオをＮＡＳ120へアップロードする。
　［ホーム・ビデオ・サーバの特徴の概要］
　ＮＡＳ120にはシステム100内の他の電子機器121、122、130、#12289;160から、多種多様な動画コンテンツが数多く集められて蓄積される。ユーザは、ＮＡＳ120に保存されている動画コンテンツを表示装置140等に表示させて視聴する場合、ＮＡＳ120に蓄積された多数の動画コンテンツの中から視聴対象を選択しなければならない。ＮＡＳ120はその選択を支援する機能として、各動画コンテンツのダイジェストを生成する機能を備えている。以下、ＮＡＳ120の構成のうち、この機能を実現する部分を「ダイジェスト生成装置」と呼ぶ。本発明の実施形態によるダイジェスト生成装置は、以下に述べるようにして、特にユーザの嗜好に合ったダイジェストを各動画コンテンツから自動的に生成する。
　ダイジェスト生成装置はまず、ＮＡＳ120を始め、システム100内の各電子機器からルータ110を通してユーザに関する関心情報を取得する。「関心情報」とは、特定のユーザが各電子機器を操作して視聴した情報をいう。ユーザが複数であれば、関心情報はユーザ別に収集される。例えばユーザが録画装置130又はＰＣ150を操作して放送番組を予約録画した場合、その放送番組の番組情報が関心情報として録画装置130等から取得される。ユーザがＰＣ150又はモバイル機器160を操作して情報をインターネットから検索した場合、その情報、又はその検索に用いられたキーワードが関心情報としてＰＣ150等から取得される。ユーザが表示装置140、141、ＰＣ150、又はモバイル機器160のブラウザを操作してＷｅｂページを閲覧した場合、そのＷｅｂページが関心情報として表示装置140等から取得される。ユーザが表示装置140、141、ＰＣ150、又はモバイル機器160を操作して、放送局から配信され、又はＮＡＳ120からダウンロードされる動画コンテンツを視聴した場合、その動画コンテンツに含まれるタイトル、番組情報、音声データ、又は字幕データが関心情報としてＮＡＳ120から取得される。
　ダイジェスト生成装置は次に、取得された関心情報が表す音声又は文字列を解析し、その中に含まれる単語の集合を基準の単語の集合として設定する。ここで、「単語」とは、名詞、動詞等、単独で意味がわかる自立語を意味し、単独では意味がわからない付属語、すなわち助詞と助動詞とを除く。基準の単語の集合は、「ユーザが関心を示した情報に含まれていた単語の集合である」という意味で、そのユーザの嗜好を表すキーワードの集合とみなすことができる。
　ダイジェスト生成装置は続いて、ＮＡＳ120に保存されている各動画コンテンツの区間をグループ分けすることにより、複数のシーンを構成する。ここで、動画コンテンツの「区間」とは、その動画コンテンツが表す映像全体の表示期間をその開始時点から一定の時間間隔で複数の期間に分けた場合、それらの期間のうちの１つに表示されるべき映像部分を表すその動画コンテンツの部分をいう。また、「シーン」とは、動画コンテンツの中で連続する区間のグループ、又はそのグループが表す一連の映像、音声、及び字幕等をいう。ダイジェスト生成装置はまず、動画コンテンツの各区間が表す音声又は字幕を解析し、その音声又は字幕における単語別の出現回数からその区間の特徴ベクトルを構成する。ダイジェスト生成装置は次に、異なる区間の間で特徴ベクトルの類似度を算定し、その類似度に基づいて、それらの区間を同じシーンに分類すべきか否かを判断する。こうして、その動画コンテンツから複数のシーンが構成される。具体的には、各シーンの表示期間と、そのシーンが表す音声又は字幕における単語別の出現回数との組み合わせが、その動画コンテンツに関するシーン情報として記録される。
　動画コンテンツでは、音声データ及び字幕データはいずれも映像データよりもサイズが大幅に小さい。従って、動画コンテンツの各区間の特徴ベクトルを、音声又は字幕における単語別の出現回数から構成して比較する処理は、映像の特徴量から構成して比較する処理よりも計算量が大幅に少ない。従って、このダイジェスト生成装置は、ＮＡＳ120に多数の動画コンテンツが蓄積されていても、各動画コンテンツからシーンを構成する処理に必要な時間を実用的な範囲に収めることができる。また、映像と共に流れる音声及び字幕はその映像の特徴を言葉で表現している場合が多いので、音声又は字幕における単語別の出現回数で構成された特徴ベクトルが映像の特徴を的確に反映している可能性は高い。それらの結果、このダイジェスト生成装置は各動画コンテンツから、互いに特徴の異なる複数のシーンを自動的に、的確に、かつ迅速に構成することができる。
　ダイジェスト生成装置はシーン情報を利用して、動画コンテンツからダイジェストを次のように生成する。まず、シーン情報を参照して、各シーンが表す音声又は字幕に出現する単語の集合を形成する。次に、その単語の集合と基準の単語の集合との間の類似性を評価する。その評価には例えば、両集合の共通部分に属する単語の数が利用される。続いて、評価された値が所定の閾値以上であるシーンをダイジェストとして抽出する。この閾値は、「評価値がそれ以上であれば、シーンがユーザの嗜好に合うとみなせる」という条件を満たすように決定されている。実際、評価値が高いシーンほど、音声又は字幕に出現する単語の多くが基準の単語の集合にも属している。従って、ダイジェストは、ユーザの嗜好に合う可能性が高いシーンのみを含む。こうして、ダイジェスト生成装置は動画コンテンツのダイジェストを自動的に、迅速に、かつ「ユーザの嗜好に合う」という基準に対して的確に抽出することができる。
　ＮＡＳ120は表示装置140等からの要求に応じ、保存されている動画コンテンツの一覧としてそれらのダイジェストを生成して要求元の電子機器へ提供する。その電子機器は例えば、それらのダイジェストを画面にサムネイル表示して、ユーザに視聴対象の動画コンテンツを選択させる。ここで、ＮＡＳ120に膨大な数の動画コンテンツが保存されていても、ダイジェストの種類は、ユーザの嗜好に合ったものに絞られるので、ユーザがチェックすべきダイジェストの数は一般には、動画コンテンツの数よりもずっと少ない。また、いずれのダイジェストも、ユーザの嗜好に合ったシーンから構成されているので、ユーザはそれらを比較的迅速にチェックできる。それらの結果、ユーザは視聴対象の動画コンテンツを手早く選択できる。
　［ホーム・ビデオ・サーバのハードウェア構成］
　図２は、システム100におけるホーム・ビデオ・サーバ、すなわちＮＡＳ120のハードウェア構成を示すブロック図である。図２を参照するに、ＮＡＳ120は、ダイジェスト生成装置200、記憶部210、外部インタフェース220、及びコネクタ221、222を含む。ダイジェスト生成装置200は、ＣＰＵ201、メモリ部202、ハードウェア・デコーダ203、ネットワーク・インタフェース204、記憶部インタフェース205、及びバス206を含む。ダイジェスト生成装置200と外部インタフェース220とは、ＬＳＩ等、単一の集積回路に実装されている。
　記憶部210は、ＮＡＳ120に内蔵又は外付けされた大容量記憶装置であり、具体的にはＨＤＤ又はＳＳＤである。ＣＰＵ201は、ファームウェアに列記された命令群に従い、ＮＡＳ120内の他のハードウェア要素を制御する。それにより、ＣＰＵ201はそれらの要素と協働してＮＡＳ120の様々な機能、特にダイジェスト生成装置200の機能を実現する。メモリ部202はＲＯＭとＲＡＭとを含む。ＲＯＭは、ＣＰＵ201に実行されるべきファームウェア群を、ＮＡＳ120の停止期間中も安定に保持する。ＲＡＭはＮＡＳ120の動作期間中、パラメータの一時的な保管場所又はフレーム・バッファ等の作業領域をＣＰＵ201とハードウェア・デコーダ203とに提供する。ハードウェア・デコーダ203は、ＡＶデータの復号処理に特化した集積回路であり、特にその復号処理のアクセラレータ機能を備えている。ネットワーク・インタフェース204は、ＩＥＥＥ８０２．３又はＩＥＥＥ８０２．１１に準拠したインタフェースであり、ルータ110とバス206との間のデータ通信を有線又は無線で実現する。記憶部インタフェース205は、ＡＴＡ又はＳＣＳＩに準拠したインタフェースであり、バス206と記憶部210との間のデータ通信を実現する。バス206は、ＮＡＳ120内のハードウェア要素間を接続する配線及びチップセットの組み合わせであり、それらの要素間でのデータ通信に共通の伝送経路として利用される。外部インタフェース220は、ＤＶ、ＨＤＭＩ（登録商標）、ＵＳＢ、ＩＥＥＥ１３９４、又はＢｌｕｅｔｏｏｔｈ（登録商標）等に準拠のインタフェースであり、コネクタ221、222を通して外部の電子機器からバス206へＡＶデータを中継する。コネクタ221、222は、外部インタフェース220と同じ規格に準拠の接続端子である。コネクタ221、222にはデジタル・カメラ121、122が接続可能である。
　［ホーム・ビデオ・サーバの機能］
　図３は、システム100におけるホーム・ビデオ・サーバ、すなわちＮＡＳ120の機能ブロック図である。図３を参照するに、ＮＡＳ120の機能部は、動画データベース301、関心情報データベース302、動画管理部303、及びダイジェスト生成装置200の機能部を含む。ダイジェスト生成装置200の機能部は、区間分類部311、ダイジェスト抽出部312、ダイジェスト提示部313、ユーザ識別部314、及び関心情報収集部315を含む。これらの機能部は、ＣＰＵ201がファームウェアの命令群に従って、図２に示されているハードウェア要素を制御することにより実現される。
　動画データベース301と関心情報データベース302とは、図２に示されている記憶部210によって実現される。動画データベース301には、外部の動画源VSRからＬＡＮ又は外部インタフェース220を通して動画コンテンツが登録される。図１に示されているシステム100における動画源VSRは、デジタル・カメラ121、122、録画装置130、表示装置140、141、ＰＣ150、及びモバイル機器160を含む。動画データベース301にはまた、それらの動画コンテンツに関するシーン情報が区間分類部311によって登録される。関心情報データベース302には、外部の関心情報源ITSからＬＡＮを通してユーザに関する関心情報が登録される。システム100における関心情報源ITSは、録画装置130、表示装置140、141、ＰＣ150、及びモバイル機器160を含む。関心情報データベース302にはまた、各ユーザに関する基準単語表が関心情報収集部315によって登録される。各ユーザに関する「基準単語表」とは、そのユーザに関する基準の単語の集合に属する単語の一覧表である。
　動画管理部303はネットワーク・インタフェース204を利用して、外部の動画源VSRからＮＡＳ120宛に送られた動画コンテンツのアップロード要求を検出する。動画管理部303はまた、外部インタフェース220を利用して、コネクタ221、222へのデジタル・カメラ121、122の接続を検出する。それらの検出に応じて、動画管理部303は動画源VSRとの間の接続を確立し、動画源VSRから動画コンテンツを取得して動画データベース301に登録する。
　一方、動画管理部303はネットワーク・インタフェース204を利用して、外部のクライアントCLTからＮＡＳ120宛に送られた動画コンテンツのダウンロード要求を検出する。システム100におけるクライアントCLTは、録画装置130、表示装置140、141、ＰＣ150、及びモバイル機器160を含む。動画管理部303はダウンロード要求の検出に応じてクライアントCLTとの間の接続を確立し、クライアントCLTに要求された動画コンテンツを動画データベース301から検索してクライアントCLTへ供給する。
　関心情報収集部315はネットワーク・インタフェース204を利用して、ＬＡＮに接続されている関心情報源ITSを検出する。それにより、関心情報収集部315は、ＬＡＮへ新たな関心情報源ITSが接続される度に、その関心情報源ITSに対して、各ユーザに関する関心情報を要求する。関心情報収集部315はまた、ＬＡＮに既に接続されている関心情報源ITSに対しては定期的に、各ユーザに関する関心情報を要求する。関心情報収集部315はその他に、動画管理部303がクライアントCLTに動画コンテンツを動画データベース301からダウンロードさせる度に、動画管理部303に対して、そのクライアントCLTのユーザに関する関心情報を要求する。それらの要求に応じ、関心情報源ITS及び動画管理部303からは関心情報の最新の履歴が返信される。例えば、録画装置130とＰＣ150とからは録画予約の履歴が返信され、表示装置140、141、ＰＣ150、及びモバイル機器160からは、インターネットでの検索履歴、Ｗｅｂページの閲覧履歴、及び放送番組の視聴履歴が返信され、動画管理部303からは動画コンテンツの視聴履歴が返信される。関心情報収集部315はそれら関心情報の履歴を取得して、各関心情報が表す音声又は文字列を解析する。それにより、それらの音声又は文字列の中から単語が抽出される。関心情報収集部315は、抽出された単語群をユーザ別に分類し、関心情報データベース302に登録されている基準単語表のうち、対応するユーザに関するものに追記する。対応するユーザに関する基準単語表が未登録である場合、関心情報収集部315は、そのユーザに関する基準単語表を新たに作成して関心情報データベース302に登録する。こうして、各ユーザに関する基準単語表が更新又は設定される。
　区間分類部311は、動画データベース301に登録されている各動画コンテンツから複数のシーンを次のように構成する。区間分類部311はまず、記憶部インタフェース205を利用して動画データベース301から動画コンテンツを１つずつ読み出し、ハードウェア・デコーダ203により各動画コンテンツから音声データ又は字幕データを復号する。区間分類部311は次に、音声データをテキスト・データに変換し、又は字幕データからテキスト・データを抽出し、それらのテキスト・データを解析する。それにより、そのテキスト・データが表す文字列から単語が抽出され、動画コンテンツの各区間における単語別の出現回数が求められる。区間分類部311は続いて、それらの出現回数からその区間の特徴ベクトルを構成する。この特徴ベクトルは、その区間における単語別の出現回数を成分とするベクトルであり、動画コンテンツに出現する単語の総数と等しい次元の空間（以下、特徴空間という。）に属するものとみなすことができる。区間分類部311は更に、異なる区間の間で特徴ベクトルの類似度を算定し、その類似度に基づいて、それらの区間を同じシーンに分類すべきか否かを判断する。具体的には、異なる区間の特徴ベクトル間でのコサイン距離が類似度として計算され、その類似度が許容下限以上であれば、それら異なる区間が同じシーンに分類される。こうして、区間分類部311は基本的には、１つの動画コンテンツの中で隣接する区間の対の全てについて、それらの対を同じシーンに分類すべきか否かを判断する。その結果、その動画コンテンツから複数のシーンが構成される。ここで、２つの特徴ベクトル間のコサイン距離が最大値１に近いほど、それら２つの特徴ベクトルは向きが近い。従って、各シーンでは基本的に、隣接する区間の対のそれぞれで特徴ベクトルがほぼ同じ向きに揃っている。すなわち、シーンの違いが、それらの間での音声又は字幕の特徴の違いを的確に反映している。
　その後、区間分類部311は、各動画コンテンツ内の各シーンの表示期間と、そのシーンが表す音声又は字幕における単語別の出現回数との組み合わせから、その動画コンテンツに関するシーン情報を作成する。すなわち、シーン情報は、各シーンの表示期間の開始時刻と終了時刻、及び、そのシーンにおける特徴ベクトルの合成を表す。区間分類部311は記憶部インタフェース205を利用して、各動画コンテンツに関するシーン情報を動画データベース301に登録する。
　ユーザ識別部314はネットワーク・インタフェース204を利用して、外部のクライアントCLTからＮＡＳ120宛に送られた動画コンテンツの一覧のダウンロード要求を検出する。ユーザ識別部314はその検出に応じてそのクライアントCLTの認証を行い、その認証に成功した場合、そのクライアントCLTにユーザの識別情報を要求する。その後、そのクライアントCLTからユーザの識別情報が届いた場合、ユーザ識別部314はユーザの認証を行う。更にその認証に成功した場合、ユーザ識別部314はそのクライアントCLTとユーザとの識別情報をダイジェスト抽出部312へ渡す。
　ダイジェスト抽出部312はユーザ識別部314からクライアントCLTとユーザとの識別情報を受信し、それに応じて記憶部インタフェース205を用い、まず、そのユーザに関する基準単語表を関心情報データベース302から検索する。ダイジェスト抽出部312は次に、動画データベース301に登録されている動画コンテンツの中から、受信された識別情報が示すクライアントCLTによって表示可能なものを選択し、それらに関するシーン情報を動画データベース301から検索する。例えば、クライアントCLTの識別情報が表示装置140を示す場合にはフルＨＤ（解像度１９２０#65297;０８０）の動画コンテンツが選択され、スマートフォン160を示す場合にはｑＨＤ（解像度９６０ラ５４０）又はＨＤ（解像度１２８０ラ７２０）の動画コンテンツが選択される。また、クライアントCLTの識別情報が３Ｄ映像対応の表示装置を示す場合には３Ｄ映像の動画コンテンツが選択され、３Ｄ映像非対応の表示装置を示す場合には２Ｄ映像の動画コンテンツが選択される。各クライアントCLTによって表示可能な動画コンテンツの種類の一覧は、ダイジェスト抽出部312又は動画データベース301に予め保存されている。その他に、動画データベース301に、動画コンテンツと共に、それを表示可能なクライアントCLTの一覧が登録されていてもよい。ダイジェスト抽出部312はそれらの一覧を動画コンテンツの選択に利用する。
　ダイジェスト抽出部312は続いて、各動画コンテンツに関するシーン情報から、各シーンが表す音声又は字幕に出現する単語を抽出し、基準単語表に登録されている単語と照合する。それにより、ダイジェスト抽出部312は、各シーンが表す音声又は字幕に出現する単語の集合と基準の単語の集合との共通部分に属する単語の数を求め、そのシーンに関する両集合間の類似性の評価値をその単語の数に設定する。ダイジェスト抽出部312は更に、各シーンに関する評価値を上記の閾値と比較し、評価値がその閾値以上であるシーンを特定する。ダイジェスト抽出部312はその後、ハードウェア・デコーダ203を用いて動画データベース301から各動画コンテンツを読み出し、特定されたシーンをその動画コンテンツから抽出して復号する。ダイジェスト抽出部312は、１つの動画コンテンツから複数のシーンを抽出した場合、それらのシーンを１つのダイジェストに連結する。こうして、ダイジェスト抽出部312は、動画データベース301に登録されている各動画コンテンツから１つのダイジェストを生成してダイジェスト提示部313へ渡す。
　ダイジェスト抽出部312はまた、各ダイジェストの最高評価値と最頻出単語とをクライアントCLTの識別情報と共にダイジェスト提示部313へ通知する。ここで、各ダイジェストの「最高評価値」とは、そのダイジェストを構成するシーンの間で最も高い類似性の評価値をいい、「最頻出単語」とは、類似性の評価値が最高評価値に等しいシーンが表す音声又は字幕に出現する単語の集合と基準の単語の集合との共通部分に属する単語の中で、その音声又は字幕に最も多く出現するものをいう。
　ダイジェスト提示部313はダイジェスト抽出部312から、ダイジェスト、最高評価値、及び最頻出単語を受信し、それらのデータから動画コンテンツの一覧情報を作成する。具体的には、ダイジェスト提示部313はそれらのダイジェストを符号化し、それらの符号化データに、最高評価値、最頻出単語、及び動画コンテンツの識別情報を所定の形式で組み込み、それにより得られたデータをその一覧情報として定める。ここで、その所定の形式は、ユーザ識別部314によって検出されたダウンロード要求の送信元、すなわち、ダイジェスト抽出部312から受信した識別情報の示すクライアントCLTがその一覧情報から、符号化データと、それに組み込まれるパラメータとの間の対応関係を把握できるように選択される。例えばユーザ識別部314がそのクライアントCLTに、そのダウンロード要求そのもの、又はその要求を送信する際のプロトコルを通じて、その所定の形式とダイジェストの符号化形式とを指定させ、指定された形式を示すデータをそのクライアントCLTの識別情報に組み込む。ダイジェスト提示部313は一覧情報の作成に、そのデータが示す形式を採用する。ダイジェスト提示部313は更にネットワーク・インタフェース204を利用して、そのクライアントCLTへ一覧情報を送信する。
　［区間分類部の詳細］
　区間分類部311は上記のとおり、動画コンテンツが音声データ又は字幕データを含むことを利用して、その動画コンテンツからシーンを構成する。従って、区間分類部311の詳細を説明する前に、その処理対象である動画コンテンツのデータ構造を決めておく方が、区間分類部311の詳細を理解しやすいであろう。
　　　－動画コンテンツのデータ構造－
　動画コンテンツには、映像と音声とを表すストリーム・データが多重化されており、更に多くの場合、字幕を表すストリーム・データも多重化されている。図１に示されているシステム100は動画コンテンツの主な多重化形式に対応している。特に代表的な多重化形式としては、ＭＰＥＧ－２　トランスポート・ストリーム（ＴＳ）形式が挙げられる。例えば、現行のデジタル放送にはこの多重化形式が採用されている。以下に述べる区間分類部311の詳細についての説明では便宜上、動画コンテンツがこの多重化形式である場合を想定する。尚、その説明を、ＭＰＥＧ－２　プログラム・ストリーム形式等、他の多重化形式の動画コンテンツに当てはまるように変更することは、当業者であれば容易であろう。
　図４は、ＭＰＥＧ－２　ＴＳ形式を採用した動画コンテンツのデータ構造を示す模式図である。ＭＰＥＧ－２　ＴＳ形式では通常、エレメンタリ・ストリームと呼ばれるストリーム・データが複数、多重化されて１つのストリーム・ファイルを構成する。図４を参照するに、この動画コンテンツ400には、ビデオ・ストリーム401、オーディオ・ストリーム402、プレゼンテーション・グラフィックス（ＰＧ）ストリーム403、及びテキスト字幕ストリーム804が多重化されている。ビデオ・ストリーム401は、映像を表すエレメンタリ・ストリームであり、ＭＰＥＧ－２、Ｈ．２６４／ＭＰＥＧ－４　ＡＶＣ、又はＳＭＰＴＥ　ＶＣ－１等の方式で圧縮されている。オーディオ・ストリーム402は、音声を表すエレメンタリ・ストリームであり、ＡＣ－３、ドルビー・デジタル・プラス（Dolbyigitallus：「ドルビー・デジタル」は登録商標）、ＭＬＰ（Meridianosslessacking：登録商標）、ＤＴＳ（Digitalheaterystem：登録商標）、ＤＴＳ－ＨＤ、又はリニアＰＣＭ（Pulseodeodulation）等の方式で圧縮されている。ＰＧストリーム403は、グラフィックス映像を表すエレメンタリ・ストリームである。そのグラフィックス映像は、グラフィックスによる字幕等、ビデオ・ストリーム401が表す映像に重ねて表示されるべきものである。テキスト字幕ストリーム404は、字幕をテキスト文字列で表すエレメンタリ・ストリームである。「テキスト文字列」は、字幕の各文字を特定の符号（キャラクタ・コード）で表したデータ列である。
　ビデオ・ストリーム401はオーディオ・ストリーム402とＰＧストリーム403との組み合わせで１つのストリーム・ファイルを構成する。一方、テキスト字幕ストリーム404は単独で１つのストリーム・ファイルを構成する。一般に１つのストリーム・ファイルには、ビデオ・ストリーム以外のエレメンタリ・ストリームが種類ごとに最大３２本まで多重化可能である。例えばオーディオ・ストリームとして、二カ国以上の言語を表すものが含まれていてもよく、主音声を表すものの他に、副音声を表すものが含まれていてもよい。
　各エレメンタリ・ストリーム401、#12289;404には固有のパケット識別子（ＰＩＤ）が割り当てられている。例えば、ビデオ・ストリーム401、オーディオ・ストリーム402、ＰＧストリーム403、及びテキスト字幕ストリーム404にはそれぞれ、ＰＩＤとして１６進数値０ｘ１０１１、０ｘ１１００－０ｘ１１１Ｆのいずれか、０ｘ１２００－０ｘ１２１Ｆのいずれか、及び０ｘ１８００が割り当てられている。
　図４には更に、動画コンテンツ400内における各エレメンタリ・ストリーム401、402、403、404の配置が模式的に示されている。例えばビデオ・ストリーム401はまず、ピクチャ401Aごとに１つのＰＥＳ（Packetizedlementarytream）パケット411に格納される。各ＰＥＳパケットのヘッダにはＰＴＳ（Presentationime－Stamp）が格納される。ＰＴＳは、デコーダに対して、そのパケットに格納されたピクチャを復号後にフレーム・バッファへ書き込むべきタイミングを示すパラメータである。次に、各ＰＥＳパケット411が一般に複数の部分に分割され、各部分が異なるＴＳパケット421に格納される。ＴＳパケット421は１８８バイト長のパケットであり、先頭の４バイトにヘッダを含み、残りの１８４バイトにＰＥＳパケットの一部を含む。ＴＳパケット421のヘッダには、そのパケットに格納されたビデオ・ストリーム401のＰＩＤが格納される。同様に、オーディオ・ストリーム402、ＰＧストリーム403、及びテキスト字幕ストリーム404がそれぞれ、適当なデータ単位でＰＥＳパケット412、413、414に格納され、各ＰＥＳパケットが複数のＴＳパケット422、423、424に格納される。最後に、各エレメンタリ・ストリーム401、#12289;404から得られた複数のＴＳパケット421、#12289;424が一連のパケット列400に時分割で多重化される。
　図４を更に参照するに、ＴＳパケット列400は、エレメンタリ・ストリームを格納したＴＳパケット421、#12289;424以外にも、ＰＡＴ（Programssociationable）431、ＰＭＴ（Programapable）432、及びＰＣＲ（Programlockeference）433を格納したＴＳパケットを含む。ＰＭＴ432は、一連のＴＳパケット列400が複数の動画コンテンツを含む場合に各動画コンテンツに１つずつ割り当てられ、その動画コンテンツを構成するエレメンタリ・ストリームのＰＩＤとその属性情報との一覧、及びＰＣＲ433のＰＩＤを示す。エレメンタリ・ストリームの属性情報には、例えば、そのエレメンタリ・ストリームの圧縮に利用されたコーデックの識別情報、及びフレーム・レートとアスペクト比とが含まれる。ＰＡＴ431は、一連のＴＳパケット列400に含まれるＰＭＴ432それぞれのＰＩＤを示す。ＰＡＴ431自身のＰＩＤは０である。ＰＣＲ433は、デコーダに対してＳＴＣ（Systemimelock）の値を示すパラメータであり、単一のＴＳパケットに格納される。「ＳＴＣ」とは、デコーダが、ＰＴＳの示すタイミングの計測に利用するクロックをいう。ＰＣＲ433は動画コンテンツのＴＳパケット列400の中に所定の時間間隔、例えば１００ｍ秒間隔で挿入される。デコーダはＰＣＲ433を検出する度にＳＴＣの値を、そのＰＣＲ433が示す値に揃える。
　図５は、テキスト字幕ストリームのデータ構造を示す模式図である。図５を参照するに、テキスト字幕ストリーム500はテキスト・データ・エントリ510の一次元配列を含む。各テキスト・データ・エントリ510はスタイル情報511とテキスト情報512との対から構成されている。テキスト情報512は、１枚のピクチャに重ねて表示されるべき字幕を表すテキスト文字列を示す。スタイル情報511は、そのテキスト文字列を文字列の映像データに変換する際に必要な情報を示す。具体的には、図５に示されているとおり、スタイル情報511は、ＰＴＳ501、表示位置502、フォントＩＤ503、表示スタイル504、及びフォント・サイズ505を含む。ＰＴＳ501は、デコーダに対し、テキスト文字列から変換した文字列の映像データをフレーム・バッファへ書き込むべきタイミングを示す。表示位置502は、その映像データが表す文字列が表示されるべき画面上の位置を示す。フォントＩＤ503は、そのテキスト文字列が文字列の映像データに変換される際に利用されるべきフォント・セットの識別情報を示す。表示スタイル504は、その映像データが表す文字列が画面に表示される際の字体を示す。フォント・サイズ505は、その文字列が画面に表示される際の大きさを示す。
　　　－区間分類部の機能－
　図６は、区間分類部311の機能ブロック図である。図６を参照するに、区間分類部311は、ＰＩＤフィルタ610、音声デコーダ620、テキスト字幕デコーダ630、音声認識部640、特徴ベクトル構成部650、及びシーン境界設定部660を含む。ＰＩＤフィルタ610と２種類のデコーダ620、630とはハードウェア・デコーダ203に実装され、他の機能部640、650、660はＣＰＵ201によってソフトウェア的に実現される。
　ＰＩＤフィルタ610は動画データベース301から動画コンテンツのＴＳパケット列を読み出し、各ＴＳパケットからＰＩＤを検出する。それにより、まず、ＰＩＤ＝０のＴＳパケットが集められ、それらからＰＡＴ431が復元される。ＰＩＤフィルタ610はそのＰＡＴ431からＰＭＴ432のＰＩＤを読み出し、そのＰＩＤをヘッダに含むＴＳパケットをＴＳパケット列から抽出して、それらからＰＭＴ432を復元する。ＰＩＤフィルタ610は続いて、そのＰＭＴ432からオーディオ・ストリームのＰＩＤとテキスト字幕ストリームのＰＩＤとを読み出し、各ＰＩＤをヘッダに含むＴＳパケットをＴＳパケット列から抽出して、そのＰＩＤに対応するエレメンタリ・ストリームの復号に適したデコーダ620、630へ転送する。すなわち、ＰＩＤが０ｘ１１００－０ｘ１１１ＦのいずれかであるＴＳパケットは音声デコーダ620へ転送され、ＰＩＤが０ｘ１８００であるＴＳパケットはテキスト字幕デコーダ630へ転送される。
　音声デコーダ620は、図６に示されているように、トランスポート・ストリーム・バッファ（ＴＢ：Transporttreamuffer）621、多重化バッファ（ＭＢ：Multiplexinguffer）622、エレメンタリ・ストリーム・バッファ（ＥＢ：Elementarytreamuffer）623、及び圧縮音声デコーダ（ＤＥＣ）624を含む。ＴＢ621、ＭＢ622、及びＥＢ623はいずれもバッファ・メモリであり、それぞれが、音声デコーダ620に内蔵されたメモリ素子の一領域を利用する。ＴＢ621は、ＰＩＤフィルタ610から受信されたＴＳパケットをそのまま蓄積する。ＭＢ622は、ＴＢ621に蓄積されたＴＳパケットからヘッダを除去し、残りのデータからＰＥＳパケットを復元して蓄積する。ＥＢ623は、ＭＢ622に蓄積されたＰＥＳパケットから圧縮音声データとそのＰＴＳとを抽出して蓄積する。ＤＥＣ624は、圧縮音声データの復号処理に特化したハードウェア・デコーダである。ＤＥＣ624は、ＴＳパケットからオーディオ・ストリームの圧縮符号化方式とその属性とを特定し、それらに合った方法で、ＭＢ622に蓄積された圧縮音声データを復号する。ＤＥＣ624は更に、復号された非圧縮の音声データを、そのＰＴＳと共に音声認識部640へ転送する。
　音声認識部640は、音声デコーダ620から転送された非圧縮の音声データを解析して、それが示す音声に含まれる単語（ここでは自立語と付属語との両方である。）を認識する。具体的には音声認識部640は、非圧縮の音声データの示す音声の周波数スペクトルを調べ、その時間変化のパターンの中から「所定の音素列を示すパターンである」と統計学的に認められる部分を探す。この音素列は、特定の単語を表す音声を構成する。従って、その音素列を示すパターンが検出されれば、その音声データの示す音声がその特定の単語を含むとみなすことができる。音声認識部640は更に、認識された単語を表すテキスト・データをＰＴＳと共に特徴ベクトル構成部650へ渡す。
　テキスト字幕デコーダ630は、ＰＩＤフィルタ610から受信された各ＴＳパケットからヘッダを除去し、残りのデータからテキスト・データ・エントリ510を復元する。テキスト字幕デコーダ630は更に、そのエントリ510内のスタイル情報511からＰＴＳを読み出し、テキスト情報512からは、字幕を表すテキスト文字列を読み出して、そのＰＴＳとテキスト文字列との対を特徴ベクトル構成部650へ渡す。
　特徴ベクトル構成部650はまず、音声認識部640とテキスト字幕デコーダ630とのそれぞれから受信したＰＴＳを利用して、それらと共に受信したテキスト・データのそれぞれが属する動画コンテンツの区間を特定する。特徴ベクトル構成部650は次に、動画コンテンツの各区間に属するテキスト・データが表す（自然言語の）文字列に対して形態素解析を行い、その文字列から自立語、特に名詞を「単語」として抽出する。それと同時に、特徴ベクトル構成部650は動画コンテンツの各区間における単語別の出現回数を求める。特徴ベクトル構成部650は続いて、それらの出現回数からその区間の特徴ベクトルを構成する。ここで、動画コンテンツのいずれの区間も少なくとも音声データは含む。従って、動画コンテンツのいずれの区間に対しても特徴ベクトルが構成される。特徴ベクトル構成部650は、動画コンテンツの全ての区間に対して特徴ベクトルを構成した後、各区間の特徴ベクトルを、その区間の境界のＰＴＳと共にシーン境界設定部660へ渡す。
　シーン境界設定部660は、異なる区間の間での特徴ベクトルの類似度として、それらの区間の特徴ベクトル間のコサイン距離を計算する能力を持つ。具体的には、ｊ番目（文字ｊは１以上の整数である。）の区間の特徴ベクトルFV[j]＝(w1[j],2[j],,Nwd[j])と（ｊ＋ｋ）番目（文字ｋは１以上の整数である。）の区間の特徴ベクトルFV[j+k]＝(w1[j+k],2[j+k],,Nwd[j+k])との間のコサイン距離が、両区間間での特徴ベクトルの類似度SML(j,j+k)として次式（１）で計算される：
　ここで、特徴空間の次元Nwdは、動画コンテンツに出現する単語の総数に等しい。また、各特徴ベクトルFV[j]、FV[j+k]のｉ番目（文字ｉは１以上定数Ｎｗｄ以下の整数である。）の成分wi[j]、wi[j+k]は、動画コンテンツに出現するｉ番目の単語がｊ番目、（ｊ＋ｋ）番目の各区間に出現する回数である。式（１）から明らかなとおり、類似度SML(j,j+k)は－１以上＋１以下であり、最大値１に近いほど、２つの特徴ベクトルFV[j]、FV[j+k]は向きが近い。すなわち、ｊ番目と（ｊ＋ｋ）番目との区間では、音声又は字幕に出現する単語の分布パターンが似ている。その意味で、「類似度SML(j,j+k)が高いほど、両区間は特徴が似ている」と言える。
　シーン境界設定部660は、異なる区間間での特徴ベクトルの類似度に基づいて、それらの区間を同じシーンに分類すべきか否かを判断する。具体的には、シーン境界設定部660は先頭の区間から順番に、その区間と次の区間との間で特徴ベクトルの類似度を算定して許容下限と比較する。その類似度が許容下限以上であれば、「それら２つの区間は特徴が十分に似ている」とみなせる。従って、その類似度が許容下限以上である場合には、シーン境界設定部660はそれら２つの区間を同じシーンに分類し、次の区間について以上の処理を繰り返す。
　一方、ｊ番目と（ｊ＋１）番目との区間間での特徴ベクトルの類似度が許容下限未満である場合、シーン境界設定部660は（ｊ＋２）番目の区間から順番に、（ｊ＋ｋ）番目（ｋ＝２、３、４、#65289;とｊ番目との区間の間で特徴ベクトルの類似度を更に算定して許容下限と比較する。
　整数ｋが２以上の定数ＧＰを超える前に、更に算定された類似度が許容下限以上に達すれば、ｊ番目の区間と音声又は字幕の特徴があまり似ていない区間は、（ｊ＋１）番目の区間から数えて、定数ＧＰよりも少ない数ｋ－１しか連続していないことがわかる。ここで、定数ＧＰは、次の条件を満たすように予め設定されている：「直前の区間とは音声又は字幕の特徴が異なる区間が、定数ＧＰよりも少ない数しか連続していなければ、その連続区間における特徴の変化は一時的なものに過ぎず、その連続区間の後、それ以前の区間と特徴が似た区間が再び連続することが十分に期待できる。」従って、シーン境界設定部660はｊ番目から（ｊ＋ｋ）番目までの区間を同じシーンに分類し、（ｊ＋ｋ）番目の区間から順番に、その区間と次の区間との間での特徴ベクトルの類似度と許容下限との比較を再開する。
　整数ｋが２から定数ＧＰまでのいずれの値であっても、更に算定された類似度が許容下限に満たなければ、ｊ番目の区間と音声又は字幕の特徴があまり似ていない区間は、（ｊ＋１）番目の区間から数えて、少なくとも定数ＧＰに等しい数、連続していることがわかる。その場合、「ｊ番目以前の区間と（ｊ＋１）番目以降の区間とでは、音声又は字幕の特徴は本質的に異なる」という可能性が高い。従って、シーン境界設定部660はｊ番目と（ｊ＋１）番目との区間の間にシーンの境界を設定する。その後、シーン境界設定部660は（ｊ＋１）番目の区間から順番に、その区間と次の区間との間での特徴ベクトルの類似度と許容下限との比較を再開する。
　以上の処理を、シーン境界設定部660は動画コンテンツの全ての区間について行う。その結果、その動画コンテンツから複数のシーンが構成される。各シーンでは特徴ベクトルがほぼ同じ向きに揃っており、その向きとは特徴ベクトルの向きが大きく異なる部分が含まれていたとしても、その部分は、定数ＧＰよりも少ない数の区間全体の長さしか連続していない。一方、異なるシーンの間では特徴ベクトルの向きが大きく異なる。このように、シーンの違いが、それらの間での音声又は字幕の特徴の違いを的確に反映している。
　各動画コンテンツから複数のシーンを構成した後、シーン境界設定部660は、各シーンの表示期間と、そのシーンが表す音声又は字幕における単語別の出現回数とから、その動画コンテンツに関するシーン情報を作成する。具体的には、シーン境界設定部660は、特徴ベクトル構成部650から受信した各区間の境界のＰＴＳに基づいて、各シーンの表示期間の開始時刻と終了時刻とのそれぞれを表すＰＴＳを求め、かつ、そのシーンに含まれる区間全体で特徴ベクトルの合成を求め、得られた値をシーン情報に組み込む。その後、シーン境界設定部660は各動画コンテンツに関するシーン情報を動画データベース301に登録する。
　　　－区間分類部の動作－
　図７は、区間分類部311による処理のフローチャートである。この処理は、動画管理部303が動画データベース301に新たな動画コンテンツを登録した時点に開始される。
　ステップＳ７０１では、区間分類部311が新たな動画コンテンツを処理対象に選択し、そのＴＳパケット列を動画データベース301からＰＩＤフィルタ610へ転送する。ＰＩＤフィルタ610はそのＴＳパケット列から、まずＰＡＴを検出し、それが示すＰＩＤを利用して、次にＰＭＴを検出する。区間分類部311は、ＰＭＴの示すＰＩＤの一覧にテキスト字幕ストリームのＰＩＤ＝０ｘ１８００が有るか否かを判断する。もし有れば処理はステップＳ７０２へ進み、無ければ処理はステップＳ７０４へ進む。
　ステップＳ７０２では、ＰＩＤフィルタ610が処理対象のＴＳパケット列からテキスト字幕ストリームのＴＳパケットを抽出して、それらのＴＳパケットをテキスト字幕デコーダ630へ送る。テキスト字幕デコーダ630はそれらのＴＳパケットからテキスト・データ・エントリ510を復元し、その中からＰＴＳとテキスト文字列とを読み出して特徴ベクトル構成部650へ渡す。その後、処理はステップＳ７０３へ進む。
　ステップＳ７０３では、区間分類部311は、テキスト字幕デコーダ630によって読み出された一連のＰＴＳの中から不連続な部分を探すことにより、処理対象の動画コンテンツの中から、字幕を含まない区間を探す。その区間が検出されれば処理はステップＳ７０４へ進み、検出されなければ処理はステップＳ７０６へ進む。
　ステップＳ７０４では、処理対象の動画コンテンツの少なくとも一部の区間が字幕を含まない。従って、区間分類部311はＰＩＤフィルタ610に、処理対象のＴＳパケット列の中からオーディオ・ストリームのＴＳパケットを抽出させる。それらのＴＳパケットはＰＩＤフィルタ610から音声デコーダ620へ送られる。音声デコーダ620はまず、それらのＴＳパケットから圧縮音声データとそのＰＴＳとを復元する。音声デコーダ620は次に、復元されたＰＴＳを利用して、圧縮音声データのうち、少なくとも、字幕を含まない区間に属するものを復号する。復号された非圧縮の音声データはそのＰＴＳと共に音声認識部640へ転送される。その後、処理はステップＳ７０５へ進む。
　ステップＳ７０５では、音声認識部640が、非圧縮の音声データが表す音声に含まれる単語を認識する。音声認識部640は更に、認識された単語を表すテキスト・データをＰＴＳと共に特徴ベクトル構成部650へ渡す。こうして、処理対象の動画コンテンツのうち、字幕を含まない区間については音声データがテキスト化される。その後、処理はステップＳ７０６へ進む。
　ステップＳ７０６では、特徴ベクトル構成部650がＰＴＳを利用してテキスト・データを動画コンテンツの区間別に分ける。その後、処理はステップＳ７０７へ進む。ここで、テキスト・データを区間別に分ける処理は、具体的には次のように実行される。
　音声については、特徴ベクトル構成部650はまず、ステップＳ７０３で特定された「字幕を含まない区間」の表示期間において、ステップＳ７０５で各単語として認識された音素列が出現する時間的な位置をＳＴＣの値で表す。特徴ベクトル構成部650は次に、そのＳＴＣの値と、各区間の表示期間間の境界を表すＰＴＳとを比較することにより、その単語を表すテキスト・データの所属先の区間を特定する。
　字幕については、特徴ベクトル構成部650はまず、各テキスト文字列が表す字幕の表示期間を、そのテキスト文字列と同じテキスト・データ・エントリ510に含まれていたＰＴＳから割り出す。特徴ベクトル構成部650は次に、先頭のテキスト文字列から順番に、連続するテキスト文字列のそれぞれが表す字幕の表示期間の長さを加算する。得られた和が１区間当たりの表示時間に達した場合、特徴ベクトル構成部650はそれら連続するテキスト文字列を１つに連結し、残りのテキスト文字列から分ける。以上の操作を残りのテキスト文字列の先頭から順に繰り返すことにより、特徴ベクトル構成部650は全てのテキスト文字列を区間別に分ける。
　ステップＳ７０７では、特徴ベクトル構成部650は形態素解析を用いて、処理対象の動画コンテンツの各区間に属するテキスト・データが表す文字列から単語を抽出する。それと同時に、特徴ベクトル構成部650は各区間における単語別の出現回数を求める。その後、処理はステップＳ７０８へ進む。
　ステップＳ７０８では、特徴ベクトル構成部650は処理対象の動画コンテンツの各区間の特徴ベクトルを、その区間における単語別の出現回数から構成する。いずれの区間も少なくとも音声データは含むので、全ての区間について特徴ベクトルが構成される。特徴ベクトル構成部650は各区間の特徴ベクトルを、その区間の境界のＰＴＳと共にシーン境界設定部660へ渡す。その後、処理はステップＳ７０９へ進む。
　ステップＳ７０９では、シーン境界設定部660がまず、式（１）を用いて、隣接する２つの区間間での特徴ベクトルの類似度SML(j,j+1)を計算する。シーン境界設定部660は次に、その類似度SML(j,j+1)を許容下限と比較し、その類似度SML(j,j+1)が許容下限以上である場合には、それら２つの区間を同じシーンに分類する。一方、その類似度SML(j,j+1)が許容下限未満である場合には、シーン境界設定部660は（ｊ＋２）番目の区間から順番に、その区間とｊ番目の区間との間での特徴ベクトルの類似度を更に算定して許容下限と比較することを繰り返す。ｊ番目の区間との特徴ベクトルの類似度SML(j,・)が許容下限未満である区間が、（ｊ＋１）番目の区間から数えて、定数ＧＰよりも少ない数しか連続していない場合、シーン境界設定部660はそれらの連続区間をｊ番目の区間と同じシーンに分類する。（ｊ＋１）番目から（ｊ＋ＧＰ）番目までのいずれの区間もｊ番目の区間との特徴ベクトルの類似度SML(j,・)が許容下限未満である場合、シーン境界設定部660はｊ番目と（ｊ＋１）番目との区間の間にシーンの境界を設定する。こうして、区間分類部311は処理対象の動画コンテンツから複数のシーンを構成して、処理を終える。
　　　－音声に含まれる各単語の属する区間の特定－
　図８は、区間分類部311がオーディオ・ストリームから単語を抽出する処理を示す模式図である。図８を参照するに、ビデオ・ストリームから再生されるフレーム列FRSの全体の表示期間は一定の時間間隔で動画コンテンツの各区間の表示期間SC1、SC2、#12434;含む。一方、オーディオ・ストリームの表す音声SNDはフレーム列FRSの再生に同期して再生され、一般には、隣接する区間の表示期間SC1、SC2の間の境界を跨いで連続して変化する。区間分類部311は、その音声SNDに含まれる各単語の音素列の時間的な位置をＳＴＣの値WT1、WT2、#12391;表し、その値と、各区間の表示期間間の境界を表すＰＴＳとを比較することにより、その単語の所属先の区間を特定する。図８の例では、単語「７時」、「ニュース」の音素列の先頭の位置を表すＳＴＣの値WT1、WT2が、第１区間の表示期間SC1の開始時刻を表す第１ＰＴＳP0から、終了時刻を表す第２ＰＴＳP1までの範囲に属しているので、それらの単語が第１区間に分類される。単語「衆院」の音素列は第１区間の表示期間SC1と第２区間の表示期間SC2との間の境界を跨いでいるが、その先頭の位置を表すＳＴＣの値WT5が第２ＰＴＳP1よりも小さいので、その単語「衆院」は第１区間に分類される。単語「本会議」の音素列の先頭の位置を表すＳＴＣの値WT6は第２ＰＴＳP1よりも大きいので、その単語「本会議」は第２区間に分類される。
　　　－字幕を表すテキスト文字列の連結－
　図９は、図７に示されているステップＳ７０６において、字幕を表すテキスト文字列を動画コンテンツの区間ごとに連結する処理のフローチャートである。この処理は、特徴ベクトル構成部650がテキスト字幕デコーダ630からテキスト文字列を渡されることによって開始される。
　ステップＳ９０１では、特徴ベクトル構成部650は整数値変数ｊの値を１に初期化する。その後、処理はステップＳ９０２へ進む。
　ステップＳ９０２では、特徴ベクトル構成部650は、テキスト字幕デコーダ630から受信したテキスト文字列のうち、ｊ番目のものに対する表示期間を、そのテキスト文字列と共に受信したＰＴＳから割り出す。ここで、「テキスト文字列に対する表示期間」とは、そのテキスト文字列の表す字幕が画面に表示される期間をいい、具体的には、その期間の開始時刻と終了時刻とを表すＰＴＳの対で定義される。ｊ番目のテキスト文字列に対する表示期間を表すＰＴＳの対は、変数ＤＳＰに代入される。その後、処理はステップＳ９０３へ進む。
　ステップＳ９０３では、特徴ベクトル構成部650は、テキスト字幕デコーダ630から受信したテキスト文字列の中に（ｊ＋１）番目のものが有るか否かを確認する。もし有れば処理はステップＳ９０４へ進み、無ければ処理はステップＳ９０９へ進む。
　ステップＳ９０４では、特徴ベクトル構成部650は表示期間ＤＳＰの長さを基準値と比較する。ここで、「表示期間ＤＳＰの長さ」とはその表示期間の開始時刻から終了時刻までの時間長をいい、具体的には、変数ＤＳＰが表す２つのＰＴＳの間の差で定義される。また、基準値としては動画コンテンツの１区間当たりの表示時間、例えば３０秒、１分、５分、又は１０分が採用される。表示期間ＤＳＰの長さが基準値よりも小さい場合には処理はステップＳ９０５へ進み、基準値以上である場合には処理はステップＳ９０７へ進む。
　ステップＳ９０５では、表示期間ＤＳＰの長さがまだ、動画コンテンツの１区間当たりの表示時間には達していないので、特徴ベクトル構成部650は、次のテキスト文字列に対する表示期間だけ表示期間ＤＳＰを延長することを試みる。その準備として、特徴ベクトル構成部650は整数値変数ｊの値を１だけ増やす。その後、処理はステップＳ９０６へ進む。
　ステップＳ９０６では、特徴ベクトル構成部650はｊ番目のテキスト文字列に対する表示期間を、テキスト字幕デコーダ630から受信したＰＴＳから割り出して、その表示期間だけ表示期間ＤＳＰを延長する。その後、処理はステップＳ９０３から繰り返される。
　ステップＳ９０７では、表示期間ＤＳＰの長さが既に、動画コンテンツの１区間当たりの表示時間以上に達している。従って、特徴ベクトル構成部650はまず、その表示期間ＤＳＰに画面に表示される字幕を表すテキスト文字列を一連のテキスト・データとして連結する。特徴ベクトル構成部650は次に、その表示期間ＤＳＰに画面に表示される映像を表す部分を含む動画コンテンツの１区間を特定し、連結後のテキスト・データをその区間に分類する。その後、処理はステップＳ９０８へ進む。
　ステップＳ９０８では、特徴ベクトル構成部650は整数値変数ｊの値を１だけ増やす。その後、処理はステップＳ９０２から繰り返される。
　ステップＳ９０９では、テキスト字幕デコーダ630から特徴ベクトル構成部650へ受信したテキスト文字列のうち、最後のものに対する表示期間が表示期間ＤＳＰに含まれる。従って、特徴ベクトル構成部650はまず、その表示期間ＤＳＰに画面に表示される字幕を表すテキスト文字列を一連のテキスト・データとして連結する。特徴ベクトル構成部650は次に、その表示期間ＤＳＰに画面に表示される映像を表す部分を含む動画コンテンツの１区間を特定し、連結後のテキスト・データをその区間に分類する。こうして、全てのテキスト文字列が区間別に分けられる。その後、処理はステップＳ７０７へ進む。
　図１０は、特徴ベクトル構成部650がテキスト文字列から単語を抽出する処理を示す模式図である。図１０の上部には、テキスト字幕ストリームの表す情報として、動画コンテンツの識別情報1001、各テキスト文字列に対する表示期間の開始時刻と終了時刻とを表すＰＴＳの対、及びそのテキスト文字列が表す字幕が表示されている。特徴ベクトル構成部650はまず、各テキスト文字列が表す字幕の表示期間の長さを、その表示期間の開始時刻と終了時刻とを表すＰＴＳ間の差から求める。特徴ベクトル構成部650は次に、先頭のテキスト文字列から順番に、連続するテキスト文字列のそれぞれが表す字幕の表示期間の長さを変数ＤＳＰに加算する。図１０の例では、開始時刻0：48：48,119#12363;ら終了時刻0：48：51,890#12414;での期間に表示されるべき字幕SB1の表示期間の長さが変数ＤＳＰに加算されると、その変数ＤＳＰの値が１区間当たりの表示時間＝60秒を超える。従って、特徴ベクトル構成部650はその字幕SB1と、それ以前に表示される字幕とのそれぞれを表すテキスト文字列を１つに連結して１つの区間SC42に分類する。特徴ベクトル構成部650は更に、開始時刻0：48：51,890#12363;ら表示されるべき字幕SB2を表すテキスト文字列を次の区間SC43に分類し、変数ＤＳＰの値をその字幕SB2の表示期間の長さにリセットする。その結果、終了時刻0：48：51,890#12395;表示が終了されるべき字幕SB1以前の字幕に出現する単語「天気図」、「明日」、#12289;「間隔」、「北海道」は前の区間SC42に分類され、開始時刻0：48：51,890#12363;ら表示が開始されるべき字幕SB2以降の字幕に出現する単語「明日」、「明け方」、#12399;次の区間SC43に分類される。
　　　－動画コンテンツの各区間の特徴ベクトル－
　図１１の（ａ）は、特徴ベクトル構成部650が構成した特徴ベクトルに関する情報の一覧表である。図１１の（ａ）を参照するに、その情報は、動画コンテンツの識別情報1101に、各区間の開始時刻と終了時刻とを表すＰＴＳの対、及びその区間の特徴ベクトルを対応付けている。各区間の特徴ベクトルは、その区間が表す音声又は字幕における単語別の出現回数を成分とする。例えば、第１区間の特徴ベクトルは、単語「ニュース」、「温泉」、「天気」の各出現回数が#65297;#12289;#65299;#12289;#65298;#12391;あることを示し、第２区間の特徴ベクトルは、単語「年金」、「厚生労働省」、「消費税」の各出現回数が#65300;#12289;#65299;#12289;#65298;#12391;あることを示す。
　図１１の（ｂ）は、特徴ベクトル構成部650が構成した特徴ベクトルを幾何学的に表す模式図である。図１１の（ｂ）を参照するに、この特徴ベクトルは幾何学的には、多次元の特徴空間の中で一方向に延びている。この特徴空間は、動画コンテンツに出現する単語の総数と次元が等しく、各次元の座標軸が１つの単語を表し、その軸における座標がその単語の出現回数を表す。図１１の（ｂ）には、（ａ）に示された第２区間の特徴ベクトルが示されている。各区間が表す音声又は字幕の特徴は、「その区間の特徴ベクトルが特徴空間のどの向きに、どれだけの長さで延びているか」で表現される。特定の区間の特徴ベクトルと向き及び長さが近い特徴ベクトルを持つ区間ほど、それが表す音声又は字幕の特徴が、その特定の区間が表すものに似ているとみなすことができる。このように、特徴ベクトルを用いれば、各区間が表す音声又は字幕の特徴を幾何学的に表現することができる。
　　　－特徴ベクトルの類似度に基づくシーンの構成－
　図１２は、図７に示されているステップＳ７０９においてシーンを構成する処理のフローチャートである。この処理は、シーン境界設定部660が特徴ベクトル構成部650から各区間の特徴ベクトルを渡されることによって開始される。
　ステップＳ１２０１では、シーン境界設定部660は整数値変数ｊの値を１に初期化する。その後、処理はステップＳ１２０２へ進む。
　ステップＳ１２０２では、シーン境界設定部660は整数値変数ｋの値を１に初期化する。その後、処理はステップＳ１２０３へ進む。
　ステップＳ１２０３では、シーン境界設定部660は、処理対象の動画コンテンツに（ｊ＋ｋ）番目の区間が有るか否かを確認する。もし有れば処理はステップＳ１２０４へ進み、無ければ処理はステップＳ１２１１へ進む。
　ステップＳ１２０４では、処理対象の動画コンテンツには、（ｊ＋ｋ）番目の区間が有る。シーン境界設定部660は式（１）を用いて、ｊ番目の区間の特徴ベクトルFV[j]と（ｊ＋ｋ）番目の区間の特徴ベクトルFV[j+k]との間のコサイン距離、すなわち両区間間での特徴ベクトルの類似度SML(j,j+k)を算定する。その後、処理はステップＳ１２０５へ進む。
　ステップＳ１２０５では、シーン境界設定部660はｊ番目と（ｊ＋ｋ）番目との区間間での特徴ベクトルの類似度SML(j,j+k)を許容下限と比較する。その類似度SML(j,j+k)が許容下限以上であれば処理はステップＳ１２０６へ進み、未満であれば処理はステップＳ１２０８へ進む。
　ステップＳ１２０６では、ｊ番目と（ｊ＋ｋ）番目との区間間での特徴ベクトルの類似度SML(j,j+k)が許容下限以上である。従って、シーン境界設定部660はｊ番目から（ｊ＋ｋ）番目までの区間を同じシーンに分類する。その後、処理はステップＳ１２０７へ進む。
　ステップＳ１２０７では、シーン境界設定部660は整数値変数ｊの値を変数ｋの値だけ増やす。その後、処理はステップＳ１２０２から繰り返される。それにより、ステップＳ１２０６で同じシーンに分類された区間の中で最後のものとその次の区間（もし有れば）との間で特徴ベクトルの類似度が算定され、許容下限と比較される。
　ステップＳ１２０８では、ｊ番目と（ｊ＋ｋ）番目との区間間での特徴ベクトルの類似度SML(j,j+k)が許容下限未満である。その場合、シーン境界設定部660は変数ｋの値を定数ＧＰと比較する。変数ｋの値が定数ＧＰよりも小さい場合、処理はステップＳ１２０９へ進み、定数ＧＰ以上である場合、処理はステップＳ１２１０へ進む。
　ステップＳ１２０９では、ｊ番目と（ｊ＋ｋ）番目との区間間での特徴ベクトルの類似度SML(j,j+k)が許容下限未満であり、かつ変数ｋの値が定数ＧＰよりも小さい。従って、シーン境界設定部660は変数ｋの値を１だけ増やし、その後、処理をステップＳ１２０３から繰り返す。
　ステップＳ１２１０では、ｊ番目と（ｊ＋ｋ）番目との区間間での特徴ベクトルの類似度SML(j,j+k)が許容下限未満であり、かつ変数ｋの値が定数ＧＰ以上である。その場合、ｊ番目の区間と音声又は字幕の特徴があまり似ていない区間は、（ｊ＋１）番目の区間から数えて、少なくとも定数ＧＰに等しい数、連続していることがわかる。従って、シーン境界設定部660はｊ番目と（ｊ＋１）番目との区間間にシーンの境界を設定する。その後、処理はステップＳ１２１１へ進む。
　ステップＳ１２１１では、シーン境界設定部660は整数値変数ｊの値を１だけ増やす。その後、処理はステップＳ１２０２から繰り返される。それにより、音声又は字幕の特徴が直前の区間のものから大きく変化した区間から改めて、その区間とその次の区間（もし有れば）との間での特徴ベクトルの類似度と許容下限との間の比較が再開される。
　ステップＳ１２１２では、処理対象の動画コンテンツに（ｊ＋ｋ）番目の区間が無い。すなわち、（ｊ＋ｋ－１）番目の区間がその動画コンテンツの最後の区間である。従って、シーン境界設定部660はｊ番目から（ｊ＋ｋ－１）番目までの区間を同じシーン、すなわちその動画コンテンツの最後のシーンに分類する。その後、処理はステップＳ１２１２へ進む。
　ステップＳ１２１３では、シーン境界設定部660がまず、特徴ベクトル構成部650から受信した各区間の境界のＰＴＳに基づいて、各シーンの表示期間の開始時刻と終了時刻とのそれぞれを表すＰＴＳを求める。シーン境界設定部660は次に、各シーンに含まれる区間全体で特徴ベクトルの合成を求める。こうして得られた、各シーンの表示期間を表すＰＴＳの対と、そのシーンが表す音声又は字幕における単語別の出現回数とから、シーン境界設定部660は処理対象の動画コンテンツに関するシーン情報を作成して動画データベース301に登録する。その後、処理は終了する。
　図１３の（ａ）、（ｂ）は、図１２に示されている処理によるシーンの構成を示す模式図である。図１３の（ａ）、（ｂ）を参照するに、シーン境界設定部660は先頭の区間SC1から順番に、その区間SCj（j＝1、2、3）と次の区間SC(j+1)との間で特徴ベクトルの類似度SML(j,j+1)、すなわち特徴ベクトルFV[j]、FV[j+1]間のコサイン距離を算定して許容下限Thと比較する。先頭の区間SC1と２番目の区間SC2との間の類似度SML(1,2)、及び２番目の区間SC2と３番目の区間SC3との間の類似度SML(2,3)がいずれも許容下限Th以上であるので、シーン境界設定部660は先頭の区間SC1から３番目の区間SC3までを第１シーンSN1に分類する。一方、３番目の区間SC3と４番目の区間SC4との間の類似度SML(3,4)は許容下限Th未満であるので、シーン境界設定部660は更に５番目の区間SC5から順番に、３番目の区間SC3との間の類似度SML(3,3+k)（k＝2、3、#65289;を算定する。
　図１３の（ａ）では、３番目の区間SC3と５番目の区間SC5との間の類似度SML(3,5)は許容下限Th未満であるが、３番目の区間SC3と６番目の区間SC6との間の類似度SML(3,6)は許容下限Th以上である。ここで、定数ＧＰが#65300;#12391;ある場合を想定すると、整数ｋが、定数ＧＰよりも小さい#65299;#12395;達したときに、更に算定された類似度SML(3,6)が許容下限Th以上に達する。すなわち、３番目の区間SC3の特徴ベクトルFV3と向きが大きく異なる特徴ベクトルを持つ区間は、４番目の区間SC4から数えて、定数ＧＰよりも少ない数ｋ－1＝２しか連続していない。従って、シーン境界設定部660は３番目の区間SC3から５番目の区間SC5までを同じシーンSN1に分類し、６番目の区間SC6から順番に、その区間と次の区間との間での特徴ベクトルの類似度と許容下限との比較を再開する。６番目の区間SC6と７番目の区間SC7との間の類似度SML(6,7)は許容下限Th以上であるので、シーン境界設定部660は６番目の区間SC6と７番目の区間SC7とを第２シーンSN2に分類する。
　図１３の（ｂ）では、５番目の区間SC5から７番目の区間SC7までのいずれも、３番目の区間SC3との間の類似度SML(3,3+k)（k＝2、3、4）が許容下限Th未満である。すなわち、３番目の区間SC3の特徴ベクトルFV3と向きが大きく異なる特徴ベクトルを持つ区間が、４番目の区間SC4から数えて、少なくとも定数ＧＰ＝４に等しい数、連続している。従って、シーン境界設定部660は３番目の区間SC3と４番目の区間SC4との間にシーンの境界BNDを設定する。その後、シーン境界設定部660は４番目の区間SC4から順番に、その区間と次の区間との間での特徴ベクトルの類似度と許容下限との比較を再開する。４番目の区間SC4から７番目の区間SC7までは、隣接する区間間の類似度SML(j,j+1)（j＝4、5、6、7）がいずれも許容下限Th以上であるので、シーン境界設定部660はそれらの区間SC4、#12289;SC7を第２シーンSN1に分類する。
　図１３の（ｃ）は、シーン境界設定部660が作成したシーン情報を示す表である。図１３の（ｃ）を参照するに、シーン情報は、動画コンテンツの識別情報1301に、各シーンの表示期間の開始時刻と終了時刻とを表すＰＴＳの対、及び、そのシーンに含まれる区間全体での特徴ベクトルの合成を対応付けている。この合成ベクトルは、そのシーンを構成する区間全体が表す音声又は字幕における単語別の出現回数を示す。すなわち、同じシーンに属する異なる区間に共通の単語が出現する場合、それらの区間でのその単語の出現回数の総和をその合成ベクトルは成分として含む。
　［関心情報収集部の詳細］
　　　－関心情報収集部の機能－
　図１４は、関心情報収集部315の機能ブロック図である。図１４を参照するに、関心情報収集部315は、情報源監視部1401、関心情報取得部1402、文字情報解析部1403、ＡＶデータ解析部1404、単語抽出部1405、及び基準単語表管理部1406を含む。ＡＶデータ解析部1404は、デマルチプレクサ1441、音声デコーダ1442、字幕デコーダ1443、及び音声認識部1444を含む。デマルチプレクサ1441と２種類のデコーダ1442、1443とはハードウェア・デコーダ203に実装され、他の機能部1401、1402、1403、1444、1405、1406はＣＰＵ201によってソフトウェア的に実現される。
　情報源監視部1401はネットワーク・インタフェース204を利用して、ＬＡＮに接続されている関心情報源ITSを検出する。それにより、情報源監視部1401は、ＬＡＮへ新たな関心情報源ITSが接続される度に、その関心情報源ITSに対して、各ユーザに関する関心情報を要求する。情報源監視部1401はまた、ＬＡＮに既に接続されている関心情報源ITSに対しては定期的に、各ユーザに関する関心情報を要求する。情報源監視部1401はその他に、動画管理部303がクライアントCLTに動画コンテンツを動画データベース301からダウンロードさせる度に、動画管理部303に対して、そのクライアントCLTのユーザに関する関心情報を要求する。
　関心情報取得部1402はネットワーク・インタフェース204を利用して、情報源監視部1401の要求に応じて関心情報源ITS及び動画管理部303から返信される関心情報の最新の履歴を取得する。取得される履歴には例えば、録画装置130等からの録画予約の履歴；表示装置140等からのインターネットでの検索履歴、Ｗｅｂページの閲覧履歴、及び放送番組の視聴履歴；並びに、動画管理部303からの動画コンテンツの視聴履歴がある。録画予約の履歴は、録画予約がされた放送番組の番組情報を含み、インターネットでの検索履歴は、検索された情報、又はその検索に用いられたキーワードを含み、Ｗｅｂページの閲覧履歴は、閲覧されたＷｅｂページを含み、放送番組の視聴履歴は、視聴された放送番組のタイトル、番組情報、音声データ、又は字幕データを含む。動画コンテンツの視聴履歴は、動画データベース301に登録されたその動画コンテンツのシーン情報を含む。関心情報取得部1402は更に、取得された関心情報を、文字情報、ＡＶデータ、及びシーン情報に分別し、文字情報は文字情報解析部1403へ渡し、ＡＶデータはＡＶデータ解析部1404へ渡し、シーン情報は基準単語表管理部1406へ渡す。一方、関心情報取得部1402は各関心情報から、その情報を視聴したユーザの識別情報と日時とを特定し、関心情報、ユーザ、及び視聴日時の間の対応関係を基準単語表管理部1406へ通知する。
　文字情報解析部1403は、関心情報取得部1402から受信した文字情報を解析し、その情報からテキスト・データを抽出する。文字情報は例えば、放送番組のタイトルと番組情報、インターネットで検索された文書、その検索に用いられたキーワード、Ｗｅｂページを含む。文字情報解析部1403は更に、抽出されたテキスト・データを単語抽出部1405へ渡す。
　ＡＶデータ解析部1404は、関心情報取得部1402から受信したＡＶデータの中から音声データ又は字幕データを抽出する。例えばＡＶデータがＭＰＥＧ－２　ＴＳ形式である場合、デマルチプレクサ1441、音声デコーダ1442、及び字幕デコーダ1443はそれぞれ、図６に示されているＰＩＤフィルタ610、音声デコーダ620、及びテキスト字幕デコーダ630と同等である。デマルチプレクサ1441は、ＡＶデータのヘッダ等に記載された情報に基づいて、そのＡＶデータから音声データ又は字幕データを抽出する。デマルチプレクサ1441は更に、音声データを音声デコーダ1442へ転送し、字幕データを字幕デコーダ1443へ転送する。音声デコーダ1442は、音声データのヘッダ等から圧縮符号化方式とその属性とを特定し、それらに合った方法で音声データを復号する。音声デコーダ1442は更に、復号された非圧縮の音声データを音声認識部1444へ転送する。字幕デコーダ1443は字幕データから、字幕の文字列を表すテキスト・データを復号して単語抽出部1405へ渡す。音声認識部1444は、図６に示されている音声認識部640と同様に、非圧縮の音声データを解析して、それが示す音声に含まれる単語を認識する。音声認識部1444は更に、認識された単語を表すテキスト・データを単語抽出部1405へ渡す。
　単語抽出部1405は、文字情報解析部1403、音声認識部1444、及び字幕デコーダ1443のそれぞれから受信したテキスト・データが表す（自然言語の）文字列に対して形態素解析を行い、その文字列から自立語、特に名詞を「単語」として抽出する。それと同時に、単語抽出部1405は各テキスト・データにおける単語別の出現回数を求め、基準単語表管理部1406へ渡す。
　基準単語表管理部1406は、単語抽出部1405から受信した単語別の出現回数と、関心情報取得部1402から通知された、関心情報、ユーザ、及び視聴日時の間の対応関係とに基づいて、関心情報から抽出された単語群をユーザ別に分類し、かつ各単語の出現日時を特定する。基準単語表管理部1406は続いて、それらの単語群と出現日時とを、関心情報データベース302に登録されている基準単語表のうち、対応するユーザに関するものに追記する。対応するユーザに関する基準単語表が未登録である場合、基準単語表管理部1406は、そのユーザに関する基準単語表を新たに作成して関心情報データベース302に登録する。
　　　－関心情報収集部の動作－
　図１５は、関心情報収集部315による処理のフローチャートである。この処理は、ＮＡＳ120がＬＡＮに接続された時点に開始される。
　ステップＳ１５０１－Ｓ１５０４では、情報源監視部1401が電子機器によるＬＡＮへの接続を監視して、ＬＡＮに接続されている関心情報源ITSを検出する。情報源監視部1401は更に、検出された関心情報源ITSに対して各ユーザに関する関心情報を要求する。その要求に応じて関心情報源ITSから返信される関心情報の最新の履歴を関心情報取得部1402が取得する。関心情報取得部1402は更に、取得された関心情報を文字情報とＡＶデータとに分別し、文字情報は文字情報解析部1403へ渡し、ＡＶデータはＡＶデータ解析部1404へ渡す。関心情報取得部1402はまた、各関心情報から、その情報を視聴したユーザの識別情報と日時とを特定し、それらの間の対応関係を基準単語表管理部1406へ通知する。
　ステップＳ１５０１では、ＬＡＮに接続されている録画装置130又はＰＣ150を情報源監視部1401が検出し、それらに対して各ユーザに関する関心情報を要求する。その要求に応じて録画装置130又はＰＣ150から録画予約の最新の履歴が返信された場合、関心情報取得部1402がその履歴から、録画予約がされた放送番組の番組情報を読み取って文字情報解析部1403へ渡す。その後、処理はステップＳ１５０２へ進む。
　ステップＳ１５０２では、ＬＡＮに接続されている表示装置140、141、ＰＣ150、又はモバイル機器160を情報源監視部1401が検出し、それらに対して各ユーザに関する関心情報を要求する。それに応じて表示装置140等からインターネットでの最新の検索履歴が返信された場合、関心情報取得部1402はその履歴から、検索された情報、又はその検索に用いられたキーワードを読み取る。関心情報取得部1402は更に、検索された情報がＡＶデータを含む場合はそのＡＶデータをＡＶデータ解析部1404へ渡し、その他の場合は、検索された情報を文字情報解析部1403へ渡す。その後、処理はステップＳ１５０３へ進む。
　ステップＳ１５０３では、ＬＡＮに接続されている表示装置140、141、ＰＣ150、又はモバイル機器160を情報源監視部1401が検出し、それらに対して各ユーザに関する関心情報を要求する。それに応じて表示装置140等からＷｅｂページの最新の閲覧履歴が返信された場合、関心情報取得部1402はその履歴から、閲覧されたＷｅｂページを読み取る。関心情報取得部1402は更に、そのＷｅｂページがＡＶデータを含む場合はそのＡＶデータをＡＶデータ解析部1404へ渡し、その他の場合はそのＷｅｂページを文字情報解析部1403へ渡す。その後、処理はステップＳ１５０４へ進む。
　ステップＳ１５０４では、ＬＡＮに接続されている表示装置140、141、ＰＣ150、又はモバイル機器160を情報源監視部1401が検出し、それらに対して各ユーザに関する関心情報を要求する。それに応じて表示装置140等から放送番組の最近の視聴履歴が返信された場合、関心情報取得部1402はその履歴から、視聴された放送番組のタイトル、番組情報、音声データ、又は字幕データを読み取る。関心情報取得部1402は更に、その音声データ又は字幕データをＡＶデータ解析部1404へ渡し、その他の情報を文字情報解析部1403へ渡す。その後、処理はステップＳ１５０５へ進む。
　ステップＳ１５０５では、動画データベース301からの動画コンテンツのダウンロードを情報源監視部1401が検出し、動画管理部303に対してダウンロード先のクライアントCLTのユーザに関する関心情報を要求する。それに応じて動画管理部303から動画コンテンツの最新の視聴履歴が返信された場合、関心情報取得部1402はその履歴からシーン情報を読み取って単語表管理部1406へ渡す。その後、処理はステップＳ１５０６へ進む。
　ステップＳ１５０６では、基準単語表管理部1406が、単語別の出現回数と、関心情報、ユーザ、及び視聴日時の間の対応関係とに基づいて、関心情報から抽出された単語群と各単語の出現日時とを、関心情報データベース302に登録されている各ユーザに関する基準単語表に追記し、又は新たな基準単語表に記入する。その後、処理は終了する。
　図１６は、基準単語表管理部1406によって管理される基準単語表を示す表である。図１６を参照するに、基準単語表は各ユーザの識別情報1401、1402に、そのユーザに関する関心情報から抽出された各単語、現在までに収集された関心情報におけるその単語の出現回数、及びその出現日時の一覧を対応付けている。
　［ダイジェスト抽出部の詳細］
　　　－ダイジェスト抽出部の機能－
　図１７は、ダイジェスト抽出部312の機能ブロック図である。図１７を参照するに、ダイジェスト抽出部312は、類似性評価部1710、復号部1720、及びシーン連結部1730を含む。復号部1720は、ＭＰＥＧ－２　ＴＳ形式に対応したデコーダであり、ＰＩＤフィルタ1721、ＳＴＣカウンタ1722、映像デコーダ1723、ＰＧデコーダ1724、テキスト字幕デコーダ1725、音声デコーダ1726、映像プレーン・メモリ1727、ＰＧプレーン・メモリ1728、音声ミキサ1729、及びプレーン加算部172Aを含む。類似性評価部1710とシーン連結部1730とはＣＰＵ201によってソフトウェア的に実現され、復号部1720はハードウェア・デコーダ203に実装される。
　類似性評価部1710はユーザ識別部314からクライアントCLTとユーザとの識別情報を受信し、そのユーザの識別情報を利用してそのユーザに関する基準単語表を関心情報データベース302から検索する。一方、類似性評価部1710はそのクライアントCLTの識別情報を利用して、動画データベース301に登録された動画コンテンツの中から処理対象を選択し、その処理対象に関するシーン情報を動画データベース301から検索する。ここで、その処理対象は、そのクライアントCLTによって表示可能な動画コンテンツである。類似性評価部1710は続いて、検索されたシーン情報から、各シーンが表す音声又は字幕に出現する単語を抽出し、基準単語表に登録された基準の単語と照合する。それにより、類似性評価部1710は、各シーンが表す音声又は字幕に出現する単語の集合と基準の単語の集合との共通部分に属する単語の数を決定し、そのシーンに関する類似性の評価値をその単語の数に設定する。類似性評価部1710は更に、各シーンに関する評価値を上記の閾値と比較して、評価値がその閾値以上であるシーンを特定する。処理対象の動画コンテンツに含まれる全てのシーンに関する評価値を閾値と比較し終えた後、類似性評価部1710は、特定されたシーンそれぞれの表示期間を表すＰＴＳの対をシーン情報から読み出して、その動画コンテンツの識別情報と共に復号部1720へ渡す。類似性評価部1710はまた、特定されたシーンに関する評価値の中から最高評価値を選択し、その最高評価値と評価値が等しいシーンにおける最頻出単語をシーン情報に基づいて決定し、その最高評価値と最頻出単語とをクライアントCLTの識別情報と共にダイジェスト提示部313へ通知する。
　ＰＩＤフィルタ1721は、類似性評価部1710から受信した動画コンテンツの識別情報を用いて動画データベース301からその動画コンテンツのＴＳパケット列を検索し、図６に示されているもの610と同様に、それらのＴＳパケットをＰＩＤ別に分別する。すなわち、ＰＩＤフィルタ1721はまず、ＰＩＤ＝０のＴＳパケットからＰＡＴ431を復元し、次に、そのＰＡＴ431の示すＰＩＤを利用してＰＭＴ432を復元する。ＰＩＤフィルタ1721は続いて、そのＰＭＴ432から各エレメンタリ・ストリームのＰＩＤを読み出し、そのＰＩＤを含むＴＳパケットを、そのエレメンタリ・ストリームの復号に適したデコーダ1723、1724、1725、1726へ転送する。具体的には、ＰＩＤが、０ｘ１０１１、０ｘ１１００－０ｘ１１１Ｆのいずれか、０ｘ１２００－０ｘ１２１Ｆのいずれか、０ｘ１４００－０ｘ１４１Ｆのいずれか、０ｘ１８００であるＴＳパケットはそれぞれ、映像デコーダ1723、音声デコーダ1726、ＰＧデコーダ1724、及びテキスト字幕デコーダ1725へ転送される。ＰＩＤフィルタ1721はまた、ＰＭＴ432の示すＰＣＲ433のＰＩＤを利用してＰＣＲ433を検出し、その検出時にＳＴＣカウンタ1722の値を、そのＰＣＲ433が示す値に揃える。
　ＳＴＣカウンタ1722は、２７ＭＨｚクロックのパルスを数えるカウンタであり、そのカウント値が各デコーダ1723、#12289;1726によってＳＴＣとして利用される。具体的には、各デコーダは、ＴＳパケットからＰＥＳパケットを復元してそのヘッダからＰＴＳを読み取り、そのＰＴＳに従って、そのＰＥＳパケットの含むデータを復号すべきタイミングを決める。
　映像デコーダ1723は、ＴＢ1701、ＭＢ1702、ＥＢ1703、圧縮映像デコーダ（ＤＥＣ）1704、及び復号ピクチャ・バッファ（ＤＰＢ：Decodedictureuffer）1705を含む。ＴＢ1701、ＭＢ1702、ＥＢ1703、及びＤＰＢ1705はいずれもバッファ・メモリであり、それぞれが、映像デコーダ1723に内蔵されたメモリ素子の一領域を利用する。ＴＢ1701はＰＩＤフィルタ1721からのＴＳパケットをそのまま蓄積する。ＭＢ1702は、ＴＢ1701に蓄積されたＴＳパケットからヘッダを除去し、残りのデータからＰＥＳパケットを復元して蓄積する。ＥＢ1703は、ＭＢ1702に蓄積されたＰＥＳパケットから圧縮ピクチャとそのＰＴＳとを抽出して格納する。ＤＥＣ1704は、圧縮ピクチャの復号処理に特化したハードウェア・デコーダであり、特にその復号処理のアクセラレータ機能を備えている。ＤＥＣ1704は、ＥＢ1703に蓄積された圧縮ピクチャのヘッダから圧縮符号化方式とその属性とを特定し、それらに合った方法でその圧縮ピクチャを復号する。ＤＥＣ1704は更に、復号された非圧縮のピクチャをＤＰＢ1705へ転送する。ＤＰＢ1705はその非圧縮のピクチャを一時的に保持し、ＤＥＣ1704からの指示に応じて、保持しているピクチャを参照ピクチャとしてＤＥＣ1704へ提供する。ＤＰＢ1705は更に、ＥＢ1703に蓄積されたＰＴＳのうち、類似性評価部1710から受信したＰＴＳの対の間にあるものを検索し、検索された各ＰＴＳが示すタイミングで、そのＰＴＳに対応するピクチャを映像プレーン・メモリ1727へ書き込む。
　ＰＧデコーダ1724はまず、ＰＩＤフィルタ1721からＴＳパケットを受信して、それらからＰＥＳパケットを復元する。ＰＧデコーダ1724は次に、そのＰＥＳパケットからグラフィックス・オブジェクトを復号すると共に、そのＰＥＳパケットからＰＴＳを読み取る。ＰＧデコーダ1724は更に、そのＰＴＳが、類似性評価部1710から受信したＰＴＳの対の間にある場合、そのＰＴＳが示すタイミングでグラフィックス・オブジェクトをＰＧプレーン・メモリ1728へ書き込む。
　テキスト字幕デコーダ1725は、テキスト・デコーダ（ＤＥＣ）1708とビットマップ・バッファ1709とを含む。ＤＥＣ1708は、テキスト文字列の復号処理とレンダリング処理とに特化したハードウェア・デコーダであり、特にそれらの処理のアクセラレータ機能を備えている。ＤＥＣ1708はまず、ＰＩＤフィルタ1721から受信されたＴＳパケット群からテキスト・データ・エントリを復号し、そのスタイル情報の示すフォント・セットとＰＴＳとを特定する。ＤＥＣ1708は次に、そのフォント・セットを利用して、同じテキスト・データ・エントリ内のテキスト情報の示すテキスト文字列をビットマップ・データへ変換し、そのデータをビットマップ・バッファ1709へ書き込む。ビットマップ・バッファ1709は、テキスト字幕デコーダ1725に内蔵されたメモリ素子の一領域である。ビットマップ・バッファ1726は、ＤＥＣ1708によって特定されたＰＴＳが、類似性評価部1710から受信したＰＴＳの対の間にある場合、そのＰＴＳが示すタイミングでビットマップ・データをＰＧプレーン・メモリ1728へ転送する。
　音声デコーダ1726は、図６に示されている音声デコーダ620と同様に、ＰＩＤフィルタ1721から受信されたＴＳパケット群を非圧縮の音声データに復号する。音声デコーダ1726は更に、その音声データの出力タイミングを示すＰＴＳが、類似性評価部1710から受信したＰＴＳの対の間にある場合、そのＰＴＳが示すタイミングでその音声データを音声ミキサ1729へ渡す。
　音声ミキサ1729は、音声デコーダ1726から受信される非圧縮の音声データに、主音声を表すものの他に、副音声を表すものが含まれている場合、それらの音声データを用いてミキシングを行う。音声ミキサ1729は更に、そのミキシングで得られた合成音のデータをシーン連結部1730へ渡す。
　映像プレーン・メモリ1727とＰＧプレーン・メモリ1728とはいずれも、復号部1720に内蔵されたメモリ素子の一領域であり、少なくとも１フレームの画素データ、すなわちプレーン・データを格納可能である。「プレーン・データ」とは、画素データの２次元配列であり、その要素数が１フレームの解像度（例えば、ＨＤでは１９２０#65297;０８０）に等しいものをいう。その配列の各要素、すなわち画素データは、色座標値とα値（不透明度）との組み合わせから成る。色座標値はＲＧＢ値又はＹＣｒＣｂ値で表される。映像プレーン・メモリ1727では、映像デコーダ1723が非圧縮のピクチャを書き込むことにより、映像プレーンが生成される。ＰＧプレーン・メモリ1728では、ＰＧデコーダ1724がグラフィックス・オブジェクトを書き込むことによってＰＧプレーンが生成され、テキスト字幕デコーダ1725がビットマップ・データを書き込むことによって字幕プレーンが生成される。ＰＧプレーンと字幕プレーンとはいずれもグラフィックス・プレーンであり、グラフィックス映像を表す。
　プレーン加算部172Aは、映像プレーン・メモリ1727とＰＧプレーン・メモリ1728とのそれぞれから、同じＰＴＳが示すタイミングで書き込まれたプレーン・データを読み出し、それらを互いに重畳して１枚のビデオ・フレームに合成する。プレーン加算部172Aは更にそのフレームをシーン連結部1730へ渡す。
　シーン連結部1730は、プレーン加算部172Aから受信したフレームを蓄積して一連のフレーム列を構成する。シーン連結部1730は更に、音声ミキサ1729から受信した音声データをそのフレーム列に多重化してダイジェストを構成する。こうして、復号部1720によって動画データベース301から読み出された動画コンテンツのうち、類似性評価部1710から復号部1720へ受信したＰＴＳの対が示す表示期間の映像を表す部分、すなわち、類似性評価部1710によって特定されたシーンの１つからダイジェストが構成される。シーン連結部1730はその後、同じ動画コンテンツから別のシーンを抽出した場合、そのシーンをダイジェストに連結する。類似性評価部1710から復号部1720へ受信したＰＴＳの対が示す動画コンテンツの部分の全て、すなわち、類似性評価部1710によって特定されたシーンの全てからダイジェストを構成し終えた後、シーン連結部1730はそのダイジェストをダイジェスト提示部313へ渡す。
　　　－ダイジェスト抽出部とダイジェスト提示部との動作－
　図１８は、ダイジェスト抽出部312による処理のフローチャートである。この処理は、クライアントCLTから届いたユーザの識別情報をユーザ識別部314がダイジェスト抽出部312へ渡すことによって開始される。
　ステップＳ１８０１では、類似性評価部1710が、ユーザ識別部314から受信したユーザの識別情報を利用してそのユーザに関する基準単語表を関心情報データベース302から検索する。その後、処理はステップＳ１８０２へ進む。
　ステップＳ１８０２では、類似性評価部1710が、ユーザ識別部314から受信したクライアントCLTの識別情報を利用して、動画データベース301に登録されている動画コンテンツの中から、そのクライアントCLTによって表示可能なものを１つ、処理対象として選択する。類似性評価部1710は更に、その処理対象に関するシーン情報を動画データベース301から検索する。その後、処理はステップＳ１８０３へ進む。
　ステップＳ１８０３では、類似性評価部1710が整数値変数ｊの値を１に初期化する。その後、処理はステップＳ１８０４へ進む。
　ステップＳ１８０４では、ステップＳ１８０２で検索されたシーン情報から、ｊ番目のシーンが表す音声又は字幕に出現する単語を類似性評価部1710が抽出する。類似性評価部1710は続いて、抽出された単語から成る集合を、ステップＳ１８０１で検索された基準単語表に登録された基準の単語の集合と照合する。それにより、類似性評価部1710は、両集合の共通部分に属する単語の数を求めて、両集合間の類似性の評価値をその単語の数に設定する。類似性評価部1710はまた、両集合の共通部分に属する単語の中から最頻出単語をシーン情報に基づいて決定する。その後、処理はステップＳ１８０５へ進む。
　ステップＳ１８０５では、類似性評価部1710がｊ番目のシーンに関する類似性の評価値を上記の閾値と比較する。その評価値がその閾値以上である場合、処理はステップＳ１８０６へ進み、その閾値未満である場合、処理はステップＳ１８０７へ進む。
　ステップＳ１８０６では、ｊ番目のシーンに関する類似性の評価値が上記の閾値以上である。その場合、その閾値の定義から「ｊ番目のシーンはユーザの嗜好に合う」とみなされる。類似性評価部1710は、ｊ番目のシーンの表示期間を示すＰＴＳの対を、ステップＳ１８０２で検索されたシーン情報から読み出して、ｊ番目のシーンに関する類似性の評価値と、ステップＳ１８０４で決定された最頻出単語と共に記憶する。その後、処理はステップＳ１８０７へ進む。
　ステップＳ１８０７では、類似性評価部1720は、ステップＳ１８０２で検索されたシーン情報に記載されたシーンの中に未処理のものが残っているか否かをチェックする。未処理のシーンが残っていれば、処理はステップＳ１８０８へ進み、残っていなければ、処理はステップＳ１８０９へ進む。
　ステップＳ１８０８では、ステップＳ１８０２で検索されたシーン情報に記載されたシーンの中に未処理のものが残っている。従って、類似性評価部1710は未処理のシーンの１つを処理対象に設定することを目的として、整数値変数ｊの値を１だけ増やす。その後、処理はステップＳ１８０４から繰り返される。
　ステップＳ１８０９では、ステップＳ１８０２で検索されたシーン情報に記載されたシーンの全てに対する処理が終わっている。従って、類似性評価部1710は、ステップＳ１８０６で記憶されたＰＴＳの対を全て、ステップＳ１８０２で特定された動画コンテンツの識別情報と共に復号部1720へ渡す。類似性評価部1710は更に、ステップＳ１８０６で記憶された評価値の中から最高評価値を選択し、その最高評価値と共に記憶された最頻出単語を特定する。類似性評価部1710はその最高評価値と最頻出単語とを、ユーザ識別部314から受信したクライアントCLTの識別情報と共にダイジェスト提示部313へ通知する。
　一方、復号部1720は、類似性評価部1710から受信した識別情報が示す動画コンテンツを動画データベース301から検索する。復号部1720は更に、検索された動画コンテンツの中から、類似性評価部1710から受信したＰＴＳの対が示す表示期間の映像を表す部分、すなわち類似性評価部1710によって特定されたシーンを全て復号し、１つのダイジェストに連結する。こうして構成されたダイジェストを復号部1720はダイジェスト提示部313へ渡す。その後、処理はステップＳ１８１０へ進む。
　ステップＳ１８１０では、動画データベース301に登録されている動画コンテンツの中に、クライアントCTLによって表示可能であるが、ダイジェストはまだ生成されていないものが残っているか否かを類似性評価部1710がチェックする。残っていれば、処理はステップＳ１８０２から繰り返され、残っていなければ、処理はステップＳ１８１１へ進む。
　ステップＳ１８１１では、ダイジェスト提示部313が、ダイジェスト抽出部312から受信した各動画コンテンツのダイジェスト、及びそのダイジェストの最高評価値と最頻出単語にその動画コンテンツの識別情報を組み合わせて動画コンテンツの一覧情報を作成する。ダイジェスト提示部313は更にその一覧情報を、ダイジェスト抽出部312から受信した識別情報が示すクライアントCLTへ送信する。その後、処理は終了する。
　［ダイジェストの表示方法］
　ユーザがクライアントCLTの１つに対し、ＮＡＳ120に保存されている動画コンテンツの一覧の表示を指示した場合、そのクライアントCLTはＮＡＳ120へ、その一覧のダウンロード要求を送信する。ＮＡＳ120はその要求に応じて動画コンテンツの一覧情報を上記のように作成し、そのクライアントCLTへ返信する。そのクライアントCLTはその一覧情報を利用して、それに含まれるダイジェストを、以下のように画面に表示する。
　図１９の（ａ）は、図３に示されているクライアントの１つが視聴対象の動画コンテンツの選択画面に表示するダイジェストのレイアウトの一例を示す模式図である。図１９の（ａ）を参照するに、クライアントCLTの画面SCNにはダイジェストDG1、DG2がそれぞれサムネイル表示されている。ダイジェストの表示領域はそれぞれサイズが等しく、マトリクス状に配置されている。そのマトリクスでは、表示領域の順序が最高評価値の大きさの順序を表す。例えば、画面の左上に表示されるダイジェストDG1は最高評価値が最も大きく、それよりも右又は下に遠く離れて表示されるダイジェストほど最高評価値が小さい。従って、画面の左上に表示領域が近いダイジェストほど、ユーザの嗜好に合う可能性が高い。更に各表示領域の下には、動画コンテンツのタイトルTTLに加えて最頻出単語MFWが表示されている。最頻出単語MFWは、そのダイジェストがどういう点でユーザの嗜好に合うのかをそのユーザが理解するためのヒントになり得る。このようにクライアントCLTはユーザに、視聴対象の動画コンテンツを選択する際に、ダイジェストDG1、DG2そのものだけでなく、それらの表示領域の位置と最頻出単語MFWとを判断材料として利用させることができる。
　図１９の（ｂ）は、図３に示されているクライアントの１つが視聴対象の動画コンテンツの選択画面に表示するダイジェストのレイアウトの別例を示す模式図である。図１９の（ｂ）を参照するに、クライアントCLTの画面SCNにはダイジェストDG3、DG4がそれぞれ、サムネイル表示されている。但し、図１９の（ａ）とは異なり、ダイジェストによって表示領域のサイズが異なる。これは、表示領域のサイズが最高評価値の大きさを表すことに起因する。例えば、表示領域のサイズが最も大きいダイジェストDG3は最高評価値が最も大きく、表示領域のサイズが小さいダイジェストほど最高評価値が小さい。従って、ユーザの目に付きやすいダイジェストほど、そのユーザの嗜好に合う可能性が高い。こうして、クライアントCLTはユーザに視聴対象の動画コンテンツを手早く選択させることができる。
　《変形例》
　（A）本発明の実施形態によるホーム・ビデオ・システムは、図１に示されている電子機器の他にも、光ディスクの再生専用機、プリンタ、スキャナ、コピー機、固定電話機等、多様な電子機器及び情報家電を含んでもよい。また、ＬＡＮのトポロジーは、図１に示されているスター型の他に、ハブ又はＬＡＮスイッチを利用してバス型又は樹木型等、多様な型式であってもよい。更に、電子機器間での動画コンテンツの転送は、ネットワーク経由以外に、メモリカード等の可搬性記録媒体に記録された状態で行われてもよい。
　（B）図３に示されているＮＡＳ120では、関心情報収集部315がＬＡＮ上の関心情報源ITSを検出し、それらに対して各ユーザに関する関心情報を要求する。その他に、関心情報源ITS又はルータ110が、ユーザによる情報の視聴に関するログを記録し、そのログを更新する度に、又は定期的に、そのログを関心情報収集部315へ送信してもよい。
　（C）関心情報収集部315が収集する上記の関心情報は一例に過ぎない。ユーザが送受信したＥメールとその添付ファイル、ユーザが作成／編集した文書／音声／映像ファイル、それらのファイルを管理するディレクトリに関する情報等、ユーザが視聴可能な情報、及びその情報に関連する情報は、関心情報収集部315が自動的に取得可能であり、かつ音声又は文字列を含んでいれば、関心情報として利用可能である。
　（D）関心情報収集部315は、収集された関心情報の中から、所定の基準を満たすものを選択して基準単語表の作成に利用してもよい。例えば、視聴された時点が現時点から１週間若しくは１ヶ月等、所定の期間以内である情報、又は、視聴され、若しくは検索された回数が所定の閾値以上である情報が、実際の関心情報として採用される。
　（E）図２に示されているダイジェスト生成装置200と外部インタフェース220とは、複数のＬＳＩ等の集積回路から構成されてもよい。更に、それらの集積回路がマルチチップ・モジュールであってもよい。その場合、マルチチップ・モジュールには複数のチップが１つのパッケージに封止されているので、それらの集積回路は単一のＬＳＩに見える。その他に、ダイジェスト生成装置200が、製造後にプログラムが可能なＦＰＧＡ（Fieldrogrammableaterray）、又は、内部の回路セル間の接続及び設定を再構成可能なリコンフィギュラブル・プロセッサによって構成されてもよい。
　（F）本発明の実施形態によるダイジェスト生成装置200は、ＮＡＳ120以外にも、例えば録画装置130、表示装置140、ＰＣ150等、図２に示されているＣＰＵ201、メモリ部202等と同等なハードウェア構成を含む電子機器であれば搭載可能である。また、そのような電子機器であれば、図３に示されているダイジェスト生成装置200のいずれの機能部311、#12289;315も単独で実装可能である。従って、ダイジェスト生成装置200の機能部がＬＡＮ上の複数の電子機器に分散されてもよい。特にスマートフォン160のように、ＣＰＵパワーが比較的低く、又は記憶容量が比較的小さい電子機器であっても、ダイジェスト生成装置200の一部の機能を分担可能である。更にダイジェスト生成装置200が、インターネット等、ＷＡＮ上のクラウド・サーバに搭載されてもよい。
　（G）図２に示されているダイジェスト生成装置200は動画コンテンツの復号にハードウェア・デコーダ203を利用する。その他に、ＣＰＵ201がアプリケーション・プログラムに従ってソフトウェア・デコーダを構築して、動画コンテンツの復号に利用してもよい。
　（H）区間分類部311は動画コンテンツの各区間を、それの表す映像の表示時間が一定であるように定める。区間分類部311はその他に、音声又は字幕が連続する期間の映像を表す動画コンテンツの部分を１つの区間と定めてもよい。区間分類部311はまた、音声又は字幕に、「次は」及び「以上で」等、話題の変化を示す語句が出現する時点で動画コンテンツの区間を分けてもよい。
　（I）区間分類部311は単語別の出現回数から特徴ベクトルを構成する。区間分類部311はその他に、ＴＦ－ＩＤＦ（Termrequency－Inverseocumentrequency）等に従って単語別の出現回数から単語別の出現頻度を算定し、それを成分とする特徴ベクトルを構成してもよい。区間分類部311はまた、出現回数又は出現頻度が所定の閾値を超え、又は下回る単語を特徴ベクトルの成分から除外してもよい。それにより、特徴空間の各次元に対応する単語を、動画コンテンツの特徴付けに適したものに制限することができる。
　（J）区間分類部311は特徴ベクトルの類似度の算定に、式（１）の表すコサイン距離を利用する。区間分類部311はその他に、単語別の出現回数を成分とする特徴ベクトルを正規化によってノルム＝１の特徴ベクトルに変換し、正規化後の特徴ベクトル間の内積を類似度として算定してもよい。
　（K）区間分類部311は、動画コンテンツが表す音声又は字幕に出現する単語と特徴空間の次元とを１対１に対応させる。区間分類部311はその他に、それらの単語（例えば「首相」、「与党」、「法案」、「晴れ」、「雨」、「台風」）を所定数のカテゴリー（例えば「政治」、「天気」）に分類してカテゴリー別に単語の出現回数を加算し、得られたカテゴリー別の出現回数又は出現頻度を特徴ベクトルの成分としてもよい。その場合、特徴空間の次元がカテゴリーの総数に抑えられるので、区間分類部311の負荷が軽減される。
　（L）図３に示されているダイジェスト抽出部312、ユーザ識別部314、及びクライアントCLTの間でのデータ交換におけるプロトコルは上記のものには限られず、他の様々な形態が利用可能である。例えば、クライアントCLT又はユーザの認証が省略されてもよく、また、動画コンテンツの一覧情報を暗号化して伝送するプロセスが追加されてもよい。
　（M）ダイジェスト抽出部312は、１つのシーンが表す音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性を、両集合の共通部分に属する単語の数で評価する。その場合、ダイジェスト抽出部312は基準の単語に対し、関心情報におけるその単語の出現回数に応じた重み付けをしてもよい。それにより、重みの高い基準の単語に一致する単語が音声又は字幕に多く出現するシーンほど、類似性が高く評価される。
　（N）ダイジェスト抽出部312は形態素解析により、テキスト・データの表す文字列から名詞を「単語」として抽出する。その他に、動詞、形容詞、形容動詞、又は副詞が「単語」として抽出されてもよい。
　（O）図１に示されているシステム100内の表示機器140等は、ダイジェスト生成装置200が生成するダイジェストを動画コンテンツの選択画面に利用する。その他に、表示装置140等がユーザに、動画コンテンツ本体に代えて、そのダイジェストを視聴させてもよい。例えば報道番組であれば、本来の放送時間よりも短い時間で、ユーザの嗜好に合うニュースのみをユーザに視聴させることができる。
　《補足》
　本発明は、上記の実施形態に基づき、下記のように特徴付けられてもよい。
　区間分類部は、１つの動画コンテンツ内で隣接する２つの区間の間で特徴ベクトルの類似度を算定して許容下限と比較し、その類似度が許容下限以上であれば、それら２つの区間を同じグループに分類する。その場合、各シーンでは、隣接する区間の対のそれぞれで特徴ベクトルがほぼ同じ向きに揃う。すなわちシーンの違いが、それらの間での音声又は字幕の特徴の違いを的確に反映する。
　区間分類部は、１つの動画コンテンツ内のｊ番目（文字ｊは１以上の整数を表す。）と（ｊ＋１）番目との区間の間での特徴ベクトルの類似度が許容下限未満である場合、（ｊ＋２）番目の区間から順番に、（ｊ＋ｋ）番目（文字ｋは２以上定数ＧＰ以下の整数を表す。）とｊ番目との区間の間での特徴ベクトルの類似度を更に算定して許容下限と比較する。整数ｋが閾値ＧＰを超える前に、更に算定された類似度が許容下限以上に達すれば、区間分類部はｊ番目から（ｊ＋ｋ）番目までの区間を同じグループに分類する。一方、整数ｋが２から定数ＧＰまでのいずれの値であっても、更に算定された類似度が許容下限に満たなければ、区間分類部はｊ番目と（ｊ＋１）番目との区間を異なるグループに分類する。その結果、各シーンでは特徴ベクトルがほぼ同じ向きに揃い、その向きとは特徴ベクトルの向きが大きく異なる部分が含まれていたとしても、その部分は、定数ＧＰよりも少ない数の区間全体の長さしか連続していない。一方、異なるシーンの間では特徴ベクトルの向きが大きく異なる。このように、シーンの違いが、それらの間での音声又は字幕の特徴の違いを更に的確に反映する。
　ダイジェスト抽出部は、複数のグループのそれぞれが表す音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性を、両集合の共通部分に属する単語の数で評価する。その数が多いほど、音声又は字幕の特徴が、基準の単語の集合で表現される特徴に合う可能性が高い。従って、ダイジェスト生成装置は動画コンテンツのダイジェストを自動的に、迅速に、かつ基準に対して的確に抽出することができる。
　本発明によるダイジェスト生成装置は関心情報収集部を更に備えていてもよい。その関心情報収集部は、ユーザが外部装置を操作して視聴したコンテンツ、又はそのコンテンツに関する情報をそのユーザに関する関心情報としてその外部装置から取得し、その関心情報が表す音声又は文字列に含まれる単語の集合を基準の単語の集合として設定する。例えば、外部装置が、ユーザの操作に従って情報をネットワークで検索する装置である場合、その装置によって検索された情報、又は検索に用いられたキーワードが関心情報として利用可能である。外部装置が、ユーザにブラウザを操作させることによってＷｅｂページをネットワークからダウンロードする装置である場合、その装置によってダウンロードされたＷｅｂページが関心情報として利用可能である。外部装置が、ユーザの操作に従って放送番組を予約録画する装置である場合、その装置に録画予約がされた放送番組の番組情報が関心情報として利用可能である。外部装置が、ユーザの操作に従って動画コンテンツを画面に表示する装置である場合、その動画コンテンツのタイトル、番組情報、音声データ、又は字幕データが関心情報として利用可能である。それらの関心情報は、ユーザが視聴したコンテンツ又はそれに関する情報であるので、それが表す音声又は文字列に含まれる単語の集合はユーザの嗜好を適切に表現しているものとみなすことができる。従って、本発明によるダイジェスト生成装置はダイジェストを、ユーザの嗜好に合うものにすることができる。
　本発明によるダイジェスト生成方法は、電子機器を用いて動画コンテンツからダイジェストを生成する方法であり、
　１つの動画コンテンツに含まれる複数の区間のそれぞれが表す音声又は字幕における単語別の出現回数から当該区間の特徴ベクトルを構成するステップ、
　異なる区間の間での特徴ベクトルの類似度に基づいて前記複数の区間を複数のグループに分類するステップ、
　前記複数のグループのそれぞれが表す音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性を評価するステップ、及び、
　評価された値が所定の閾値以上であるグループをダイジェストとして前記１つの動画コンテンツから抽出するステップ、
を備えている。この方法は、動画コンテンツの区間をグループ分けする際、映像の特徴に代えて、音声又は字幕における単語別の出現回数を利用する。それにより、この方法は電子機器に各グループの特徴を自動的に、的確に、かつ迅速に分けさせることができる。更にこの方法は、ダイジェストとして抽出されるべきグループを、音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性に基づいて選択する。その結果、この方法は電子機器に動画コンテンツのダイジェストを自動的に、迅速に、かつ基準に対して的確に生成させることができる。
　本発明によるダイジェスト生成プログラムは、電子機器に動画コンテンツからダイジェストを生成させるためのプログラムであり、
　１つの動画コンテンツに含まれる複数の区間のそれぞれが表す音声又は字幕における単語別の出現回数から当該区間の特徴ベクトルを構成するステップ、
　異なる区間の間での特徴ベクトルの類似度に基づいて前記複数の区間を複数のグループに分類するステップ、
　前記複数のグループのそれぞれが表す音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性を評価するステップ、及び、
　評価された値が所定の閾値以上であるグループをダイジェストとして前記１つの動画コンテンツから抽出するステップ、
を前記電子機器に実行させる。このプログラムは電子機器に動画コンテンツの区間をグループ分けさせる際、映像の特徴に代えて、音声又は字幕における単語別の出現回数を利用させる。それにより、このプログラムは電子機器に各グループの特徴を自動的に、的確に、かつ迅速に分けさせることができる。更にこのプログラムは電子機器に、ダイジェストとして抽出されるべきグループを、音声又は字幕に出現する単語の集合と基準の単語の集合との間の類似性に基づいて選択させる。その結果、このプログラムは電子機器に動画コンテンツのダイジェストを自動的に、迅速に、かつ基準に対して的確に生成させることができる。
　本発明は、動画コンテンツのダイジェストを電子機器に自動的に生成させる技術に関し、上記のとおり、電子機器に、動画コンテンツの表す音声又は字幕に出現する単語を認識させて、その出現回数をその動画コンテンツの区間のグループ分けに利用させる。このように、本発明は明らかに産業上利用可能である。
　120ＮＡＳ
　200ダイジェスト生成装置
　301動画データベース
　302関心情報データベース
　303動画管理部
　311区間分類部
　312ダイジェスト抽出部
　313ダイジェスト提示部
　314ユーザ識別部
　315関心情報収集部
　VSR動画源
　CLTクライアント
　ITS関心情報源
Patent WO2014103123A1 - ダイジェストを生成するための装置、方法、及びプログラム - Google Patents
