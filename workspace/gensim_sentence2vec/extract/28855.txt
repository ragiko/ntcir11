
1.順列・組合せ
1.1 順列・組合せ
1.2 二項定理
2.確率
2.1 事象
2.2 確率の定義
3.確率変数
3.1 確率変数
3.2 平均と分散
3.3 確率分布
3.3.1 離散型分布
3.3.2 連続型分布
3.3.3 多変量確率分布
4.統計
4.1 統計的推定
4.1.1 標本と母集団
4.1.2 中心極限定理
4.1.3 区間推定法
4.2 統計的検定
4.2.1 仮説検定
4.2.2 平均値の検定
4.2.3 母平均の差の検定
4.2.4 母分散及び等分散性の検定
1.順列・組合せ
1.1 順列・組合せ
［定義］ 有限個の対象から幾つかを取り出しそれを順に並べたものを順列という.一方,取り出した順序を問題にしないで,それらの組合せだけに注目するとき,その組を組合せという.
例1: 例えば,3 個の数字 {1, 2, 3} から,2 個の数字を取り出した順列は,
(1, 2), (2, 1), (1, 3), (3, 1), (2, 3), (3, 2)
の 6 種類あります.しかし,組み合わせは,順序を問題にしませんので,
(1, 2), (1, 3), (2, 3)
の 3 種類になります.
相異なる n 個のものから r 個をとる順列の総数は以下のようにして考えます.まず,最初は,n 個の中から 1 つ選択します.次に,残りの ( n - 1 ) 個から 1 つ選択します.この手続きを r 個選択するまで繰り返すことになりますので,その総数は,
n × ( n - 1 ) × ・・・ × ( n - r + 1 )
となります.
［定理］ 相異なる n 個のものから r 個をとる順列の総数は,
である.
組合せに関しては,順列を元にして考えます.相異なる n 個のものから r 個をとる順列の総数は上のようになりますが,組合せとしては同じものが含まれています.同じ組合せのものは,r 個の順列の数だけ含まれていますので,組合せの数は,nPr を rPr = r! で割ってやればよいことになります.
［定理］ n 個のものから r 個を取り出す組合せの数は,
である.
例 1 の場合に対して,上記の定理を使用して順列及び組み合わせの数を計算すれば,6 及び 3 になることは明らかだと思います.順列や組み合わせは,様々な分野で使用されます.場合によっては,順列や組み合わせのすべての場合について調べたいようなことも起こります.しかし,順列や組み合わせの数の計算には階乗が使用されています.そのため,n の値が大きくなると,その数は膨大なものになり,すべての場合について調べることは不可能になることも少なくありません.参考のため,その数の比較を以下に挙げておきます.
n
n2
n3
n4
n5
n!
1
1
1
1
1
1
5
25
125
625
3126
120
10
100
1000
10000
100000
3628800
20
400
8000
160000
3200000
2.43 × 1018
50
2500
125000
6250000
312500000
3.04 × 1064
以下,特別な場合に対する,順列や組み合わせの数を計算するための定理をあげておきます.
n 個の中の p 個が同じものであれば,nPn の中には,p 個の並べ方( p! )だけ同じ順列が含まれています.このことを考慮すれば,以下の定理は明らかだと思います.
［定理］ n 個の内で,p 個は同じもの,q 個は他の同じもの,・・・,s 個がまた他の同じものであるとき,これらの n 個を並べる順列の数は,
である.
例えば,A,B,C,D からなる 4 個を円形に並べた場合,A が上に来ても,右に来ても,下に来ても,又,左に来ても,他の 3 つの並び方が同じであれば,同じ順列とみなされます.しかし,それらを上,右,下,左の順で直線上に並べた場合は,異なる順列となります.従って,以下の定理が成立します.
［定理］ 相異なる n 個のものを円形に並べる順列(円順列)の数は,
n-1Pn-1 = (n - 1)!
である.
以下の定理は,順列の定義から明らかだと思います.
［定理］ n 個のものから重複を許して r 個とる順列(重複順列)の数は,
nΠr = nr
である.
例えば,A,B,C の 3 ( n ) 個の中から,重複を許して 5 ( r ) 個とる組合せについて考えてみます.この場合,例えば,以下に示すような選び方が考えられます.
一般的にいえば,右に示すような 7 ( = n + r - 1 ) 個の  の内,どれか 2 ( = n - 1 ) つを縦棒にする(残りは )ことによって一つの選び方が決まります.結局,7C2 が縦棒の位置の選び方,つまり,組合せの数になります.
［定理］ n 個の中から,重複を許して r 個とる組合せの数は,
nHr = n+r-1Cn-1 = n+r-1Cr
である( r 
なお,組み合わせに関しては,以下に示す定理が成立します.
［定理］ 組合せの数 nCr に関しては,次の式が成り立つ
nCr = nCn-r
nCr = n-1Cr + n-1Cr-1   (パスカルの公式)
1.2 二項定理
( a + b )n において,b の一次の項は,n 個の ( a + b ) の中の一つだけは b を選択し,他は a を選択した場合の積となります.( a + b ) の選び方としては n ( = nC1 ) 通りありますので,その係数は n となります.同様にして,他の項の係数も計算できますので,以下の定理が成立します.
［定理］ 二項定理
nCr のことを二項係数と呼び,
のようにも記述します.例えば,この定理を利用することによって,
(x + 2)10
における x7の係数を,
10C327 = 120 x 128 = 15360
のようにして,計算することができます.また,下の定理は,二項定理の拡張です.
［定理］ 多項定理
ただし,p1, p2, ・・・, ps は 0 または正の整数であり,Σ は p1 + p2 + ・・・ + ps = n となるすべての整数値 p1, p2, ・・・, ps についての和を表す.
ここで,
を多項係数と呼び,以下のようにも記述されます.
2.確率
2.1 事象
［定義］ 一定の条件の下で繰り返し行うことができ,その結果が偶然に支配されるような実験や観測を一般に試行という.試行によって起こる可能性のあるすべての事柄の集合 Ω が確定しているとき,その集合を考えている試行の標本空間といい,その要素を標本点,または,単に標本空間の点という.
［定義］ 標本空間 Ω の部分集合を事象といい,試行の結果が 1 つの事象Aに属するとき,事象Aが起こったという.標本点の 1 つ 1 つを特に根元事象という.それに対して,2 個以上の点からなる事象を複合事象という.また,標本空間全体を全事象,決して起こらない事柄は空集合 φ で表され,それを空事象という.
例1: 1 つのさいころを,1 回だけ投げることについて考えてみます.明らかに,この結果は偶然性に左右され,試行と考えることができます.このとき,標本空間 Ω は,「k の目が出る」ことを k で表すと,
Ω = {1, 2, 3, 4, 5, 6}
となります.根元事象は,1, 2, 3, 4, 5, 及び, 6 であり,また,複合事象としては,いろいろ考えられますが,「偶数の目が出る事象A」という場合であれば,以下のようになります.
偶の目が出る事象A = {2, 4, 6}
［定義］ 以下の定義において,例1を具体的な例として説明を行う.
和事象 A∪B: 事象AまたはBが起こるという事象.例えば,事象Aを「4 以下の目が出る」,また,事象Bを「偶数の目が出る」事象としたとき,事象「A∪B」は,{1, 2, 3, 4, 6} となる.
積事象 A∩B: 事象AとBが同時に起こるという事象.例えば,事象Aを「4 以下の目が出る」,また,事象Bを「偶数の目が出る」事象としたとき,事象「A∩B」は,{2, 4} となる.
余事象 A: 標本空間Ωの中で,事象Aが起こらないという事象.例えば,事象Aを「4 以下の目が出る」事象としたとき,余事象は,{5, 6} となる.
排反事象 事象AとBが同時に起こることがない時,記号的には A∩B = φ である時,事象AとBは互いに排反である,または,排反事象であるという.例えば,事象Aを「奇数の目が出る」,また,事象Bを「偶数の目が出る」事象としたとき,これらの事象は排反である.
2.2 確率の定義
［定義］ 標本空間Ωの各事象Aに対して次の 3 つの条件を満たす実数 P(A) が対応させられるとき,その値 P(A) を事象Aの起こる確率という.各事象に対して確率が与えられる標本空間を確率空間といい,各事象を確率事象という.
任意の事象Aに対して,0 ≦ P(A) ≦ 1
P(Ω) = 1, P(φ) = 0
事象AとBが互いに排反,即ち A∩B = φ ならば,以下の関係が成立する.
P(A∪B) = P(A) + P(B)
確率現象を表現するのに,各根元事象に対して,各事象が発生する確率を明記した以下に示すような表がよく使用されます.この表のことを,確率分布表と呼びます.
根元事象
E1
E2
・・・・・
EN
全事象Ω
確率
p1
p2
・・・・・
pN
1.0
例2: 例1において,各目が出る事象に 1/6 という数値を対応させると,上の定義から,明らかにこれは確率となります.
上の例において,各目が出る確率を 1/6 と設定したことに違和感を感じなかったと思います.経験的に,多数回サイコロを投げれば,各目の出が出た回数を試行回数で割った値が,本来そのサイコロが持っている各目の出る確率に近づいていくこと,そして,その値が 1/6 であることを経験的に知っているからです.このことを保証したのが以下に述べる法則です.
［大数の法則］ ある試行を N 回繰り返し行い,事象Aが起こった回数が n 回であるとき,n / N を相対度数という.試行回数 N を十分大きくするとき相対度数 n / N が,ほぼ一定値 p に近づくならば,p を事象Aの起こる統計的確率(確率)という.このように定義された p が,試行回数 N を大きくしていくと,事象Aの本来持っている確率(先験的確率)に限りなく近づくことが知られており,これを大数の法則という.
以下,確率に関する定義や定理をいくつかあげておきます.
［定理］
事象A1,A2,・・・,Ar が排反ならば
P(A1∪A2∪・・・∪Ar)
= P(A1) + P(A2) + ・・・ + P(Ar)
任意の 2 つの事象A,Bに対して
P(A∪B) = P(A) + P(B) - P(A∩B)
余事象に対して
A⊂Bならば,P(A) ≦ P(B)
［定義］ P(A) > 0 であるとき,事象Bに対して,
と定義し,事象Aが起こったときの事象Bの条件付確率という.
［定理］ ベイズの定理 事象A1,A2,・・・,Ar が互いに排反であり,かつ,その内どれかの事象が必ず起こるとき,即ち,
Ai∩Aj = φ  ( i ≠ j )
A1∪A2∪・・・∪Ar = Ω
ならば,任意の事象Bに対して次の式が成り立つ.
ベイズの定理は,事象A1,A2,・・・,Ar が互いに排反であり,かつ,すべての原因を挙げている場合に,ある事象Bが起こったときそれがどの原因によって発生したかを示す確率 P(Ai｜B) を求めるために使用されます.
例えば,2 つの箱があり,各箱には赤い玉と白い玉が入っていたとします.箱 1 には,赤い玉が 20 個,白い玉が 80 個入っており,また,箱 2 には,赤い玉が 60 個,白い玉が 40 個入っていたとします.今,どちらかの箱から玉を 1 個取り出すものとします.また,各箱から取り出す確率を P(Ai) ( i = 1, 2 )とします.
どちらの箱から取り出しても良いとしたとき,各箱から取り出す確率 P(Ai) (事前確率)は,いずれも 0.5 になります.今,どちらかの箱から球を取り出した結果,玉の色は白だったとします.このとき,いずれの箱から玉を取り出したかを示す確率(事後確率)は,
P(Ai｜B)   B:白い玉であるという事象
のように表現でき,取りだした球が白であったという結果によって,事前確率とは異なってきます.具体的に,箱 1 から取り出した確率は,ベイズの定理によって,以下のように計算できます.
ベイズの定理は分かりにくいかと思いますので,あと一つ例を挙げておきます.
例3: 患者がある種の症状(例えば,咳が出るなど)を訴えるとき,その 5 %がA疾患であることが知られているとします.また,ある精密検査Bは,真のA疾患患者に対して 70 %陽性反応を示し,疾患でない患者に対しても 10 %陽性反応を示すものとします.先の症状を訴えた患者の精密検査結果が陽性反応を示したとき,その患者がA疾患である確率はどのようになるでしょうか.
事象を
A1: A疾患である
A2: A疾患でない
とすると,ベイズの定理は満たされています.また,事象Bを,
B: 精密検査Bが陽性である
とすると,以下の確率が得られます.
P(A1) = 0.05   A疾患である確率(事前確率)
P(B｜A1) = 0.7   A疾患である場合に,精密検査結果が陽性になる確率
P(B) = 0.05 × 0.7 + 0.95 × 0.1 = 0.13   精密検査結果が陽性になる確率
以上の点から,精密検査結果が養成であった場合におけるA疾患である確率(事後確率)は,ベイスの定理から以下のようになります.
例えば,サイコロを投げる場合に,意図的なことを行わなければ,1 回目に 1 が出たからといって,2 回目に 1 が出る確率が変化するわけではありません.このように,各試行が互いに影響を及ぼさないような試行は重要です.下に示すのは,そのような試行に対する定義です.
［定義］ r 個の事象A1,A2,・・・,Ar に対し,それらの任意個の異なる事象の組合せAi,Aj,・・・,Ak に対して
P(Ai∩Aj∩・・・∩Ak) = P(Ai) P(Aj) ・・・ P(Ak)
が成り立つとき,事象A1,A2,・・・,Ar は互いに独立(統計的に独立)であるという.また,1 回毎の試行がそれ以外の試行に何らの影響を及ぼさないとき,すなわち各回の試行が互いに独立であるとき,このような試行を独立試行,または,ベルヌーイ(Bernoulli)試行という.
3.確率変数
3.1 確率変数
［定義］ 標本空間Ωで,ある属性について標本がとる可能性がある異なる数値が
x1,x2,・・・,xk
であるとする.各標本に対してそれのとる値を対応させる変数 X を考える.Ω上で X がそれぞれの値をとる確率が定まっているとき,X を確率変数(random variable,stochastic variable)(離散型確率変数)といい,x1,x2,・・・,xk を X の標識という.
確率変数 X が値 xi をとるという事象を
{ X = xi }
で表し,その確率を
P(X = xi) = pi  (i = 1, 2,	・・・, k)
で示す.このように,X がとる値それぞれに対して確率が定まるため,確率は関数の形で,
f(x) = pi  ( x = xi のとき)
= 0   (その他の x )
のように記述できる.この関数を確率変数 X の確率密度関数(probability density function)といい(離散的な場合は,単に,確率関数ということもある),確率変数 X は,確率分布 f(x) に従うという.
［定義］ 確率変数 X がある値 x に対して,X ≦ x である確率 P(X ≦ x ) を,確率変数 X の確率分布関数(distribution function),または,累積分布関数(cumulative distribution function)という.これを F(x) とすれば,次のようにかける.
F(x) = P(X ≦ x)
［定理］ 確率分布関数の性質
P(a x の非減少関数
右連続性 limxa+0F(x) = F(a)
F(∞) = 1
F(−∞) = 0
0 ≦ F(x) ≦ 1
サイコロを投げるような場合は,確率変数は離散的な値だけを取ることができます.そのような場合を離散型分布といいます.離散型分布に対する確率分布関数は,確率関数( X が xi という値を取る確率に相当),
fX(xi) = P(X = xi)  (i = 1, 2,	・・・)
を使用して,
のように記述できます.例えば,サイコロを投げるような場合における確率関数と確率分布関数は以下のようになります.
確率変数が連続値を取るような分布も存在します.例えば,手で棒を垂直に立てた後,手を離したとします.そのとき,棒が倒れる方向 X は,0 から 360°の間の任意の値を取ることができます.このような分布を連続型分布といいます.棒の例の場合,分布関数の値は角度 x に比例しますので,右図のようになります.
それでは,連続型分布の場合,離散型分布の確率関数に相当するような関数は存在しないのでしょうか.その答えが下の定義です.
［定義］ 次の式で表される f(x) が存在するとき,f(x) を確率変数 X の確率密度関数という.
また,確率分布関数 F(x) は f(x) から
として与えられる.
先に述べた棒の例では,その確率密度関数は以下のようになります(右図参照.このような分布を,一様分布といいます).
ここで注意してもらいたいのは,離散型分布の確率関数とは異なり,確率密度関数 f(x) は,X が 値 x を取るときの確率を表しているわけではないことです.この点は,棒の例からも明らかだと思います.例えば,任意の a ( 0 ≦ a ≦ 360 )の対して,f(a) は 1/360 になりますが,これは決して「倒れたときの角度が a である確率は 1/360 である」といったことを意味していません.なぜなら,倒れたときの角度がある特定の値に完全に一致する確率は限りなく 0 に近いからです.
確率密度関数において,確率としての意味を持つのは上右図の斜線で示した部分の面積です.図の斜線部の面積 S は,下に示すように,倒れたときの角度が a から b の間に入る確率を意味しています.確率分布関数と確率密度関数の関係式において,f(x)dx を確率( dx を 斜線部の幅 (b - a) とみなす),積分記号を Σ 記号とみなせば,離散型分布との対応が取りやすいかと思います.
3.2 平均と分散
［定義］ 平均(集合平均,期待値)
［定義］ 分散と標準偏差
σ2 を分散,σ を標準偏差と呼ぶ.
分散は,上の図に示すように,ばらつきの程度を表しますが,具体的にどの程度ばらついているかを示す指標として,次の定理がよく知られています.
［定理2.1］(チェビシェフの不等式)
確率変数 X の平均が μ,標準偏差が σ であるとき,次の不等式が成立する.
P(|X - μ| ≧ kσ) ≦ 1 / k2
この定理は,確率変数が平均から標準偏差の k 倍以上離れている,つまり,
X > μ + kσ,または,X 
である確率が 1 / k2 以下であることを示しています.例えば,3σ 以上平均から離れている確率は 1 / 9 より小さくなります.この不等式は,余り精度の良いものではありませんが,その利点は,任意の分布に対して成立することです.
［定理］ 平均と分散の性質
a, b を定数として,E[aX+b] = aE[X] + b
E[X+Y] = E[X] + E[Y]
X, Y が互いに独立ならば, E[XY] = E[X]E[Y]
V[X] = E[X2] - E[X]2
V[aX+b] = a2V[X]
X と Y が独立ならば, V[X+Y] = V[X] + V[Y]
次に,平均や分散のより一般的な定義について考えてみます.以下の定義等は,離散的な分布に対しても成立しますが,簡単のため,連続的な分布だけを取り扱っていきます.
［定義］ φ(X) を確率変数 X の関数としたとき,
を φ(X) の期待値という.
［定義］ φ(X) = Xk,または,φ(X) = (X - μ)k ( k = 0, 1, 2, ・・・)としたとき,
を,各々,X の原点周りの k 次モーメント(moment),及び,平均 μ 周りの k 次モーメント(moment)という.
明らかに,原点周りの 1 次のモーメントは平均,また,平均 μ 周りの 2 次のモーメントは分散に相当します.
［定義］ φ(X) = etX としたとき,
をモーメント母関数(moment generation function)という.
確率変数 X のモーメント母関数を求めることができれば,以下に示すように,確率変数 X のすべてのモーメントを簡単に求めることが可能です.マクローリン展開,
を使用して,eθXを展開すると,
のようになります.従って,モーメント母関数は,
のように記述できます.例えば,この式をθで微分し,θに 0 を代入すると,右辺は E[X] となり,平均を求めることができます.一般に,k 次のモーメントは,
E[Xk] = M(k)(0)
のようにして求めることが可能です.なお,モーメント母関数が一致する 2 つの確率分布は同一の分布となります.
3.3 確率分布
確率変数がどのような分布をするかは,先に述べた度数分布表を使って表す場合もありますが,理論的に与えられる確率分布も多くあります.ここでは,代表的な確率分布を紹介します.
3.3.1 離散型分布
二項分布
繰り返し行われる独立試行で,もし各々の試みに対して単に 2 つの結果だけが可能で,それらが起こる確率が各試行を通じて一定である場合,その試行をベルヌーイ試行といいます.成功の確率が p で失敗の確率が q = 1 - p であるベルヌーイ試行を n 回行った結果,x 回成功する確率(確率関数,右図参照)は以下のようになり,この分布を母数 p の二項分布と呼びます.
二項分布という名称は,この式が,(py + q)n を展開したときの yx の係数に等しいことに由来します.なお,二項分布の確率分布関数,平均,及び,分散は以下のようになります.
平均: E[X] = np,  分散: V[X] = npq
二項分布は,n の値が大きくなる( np ≧ 5 と nq ≧ 5 が成立する程度)と後に述べる正規分布,
に近づきます.
ポアソン分布
二項分布は,p の値が小さく,n の値が非常に大きくなると,λ = np のポアソン分布に近づきます.単位時間内に到着する電話の呼び数 x の分布等がポアソン分布に従うことが良く知られています.母数 λ のポアソン分布の確率(確率関数,右図参照),平均,及び,分散は以下のようになります.
平均: E[X] = λ,  分散: V[X] = λ
ポアソン分布は,λ の値が大きくなる( λ > 10 程度)と,正規分布,
に近づきます.
3.3.2 連続型分布
一様分布
先に述べた棒の例が一様分布の例です.一様分布の確率密度関数,平均,及び,分散は以下のようになります.
密度関数  f(x) = 1 / (b - a)   a ≦ x ≦ b
= 0       x  b
平均: E[X] = (a + b) / 2,  分散: V[X] = (a - b)2 / 12
指数分布
指数分布は,ポアソン分布と強い関係があります.例えば,電話の呼び間隔が平均 1 / λ の指数分布をするとき,単位時間内に到着する電話の呼び数の分布は平均 λ のポアソン分布をします.母数 λ の指数分布の確率分布関数(右図参照),確率密度関数,平均,及び,分散は以下のようになります.
分布関数  F(x) = 1 - e-λx   x ≧ 0
= 0        x 
密度関数  f(x) = λe-λx   x ≧ 0
= 0     x 
平均: E[X] = 1 / λ,  分散: V[X] = 1 / λ2
正規分布(ガウス分布) N(μ, σ2)
C/C++ による密度関数,分布関数,片側α値(片側 p %値)を計算するためのプログラム例  
アプレット版では,密度関数,分布関数,片側α値(片側 p %値)の計算を画面上で実行することが可能です.ただし,結果はすべてテキストエリアに出力されます.
正規分布は,非常によく使われる分布です.母数 μ,σ の正規分布 N(μ, σ2) の確率密度関数(右図参照),平均,及び,分散は以下のようになります.
平均: E[X] = μ,  分散: V[X] = σ2
平均が 0,標準偏差が 1 である正規分布 N(0, 12) を標準正規分布と呼びます.確率変数 X の分布が N(μ, σ2) の正規分布に従うとき,次の変数変換(標準化変換)によって得られる確率変数 Z は標準正規分布 N(0, 12) に従います.
Z = (X - μ) / σ
また,値 α( 0 ≦ α ≦ 1 )に対して,以下の図に示すような値 λ を正規分布の α 値,または,p %値( p = α×100 )といいます.α は,図からも明らかなように,確率変数の値が λ 以上になる確率(両側の場合は,確率変数の値が λ 以上,又は,ーλ以下になる確率)に相当します.α 値は,後に述べる推定において非常に重要となりますので十分理解しておいてください.なお,以下に述べる各分布に対しても,同様に,α 値を定義することができます.
自由度 n の χ2 分布
C/C++ による密度関数,分布関数,片側α値(片側 p %値)を計算するためのプログラム例  
アプレット版では,密度関数,分布関数,片側α値(片側 p %値)の計算を画面上で実行することが可能です.ただし,結果はすべてテキストエリアに出力されます.
x1,x2,・・・,xn が互いに独立な確率変数で,それぞれが標準正規分布 N(0, 12) に従うとき,
χ2 = x12 + x22 + ・・・ + xn2
なる確率変数 χ2 が従う分布を自由度 n の χ2 分布といいます.自由度 n の χ2 分布の確率密度関数(右図参照),平均,及び,分散は以下のようになります.
平均: E[X] = n,  分散: V[X] = 2n
ここで,Γ は,ガンマ関数であり,次のように定義されます.
Γ(1) = 1, Γ(p+1) = pΓ(p)
Γ(n+1) = n!   n: 整数
C/C++ によるガンマ関数の計算をするためのプログラム例  
アプレット版では,任意のデータに対するガンマ関数の値を計算することができます.
自由度 n の t 分布
C/C++ による密度関数,分布関数,片側α値(片側 p %値)を計算するためのプログラム例  
アプレット版では,密度関数,分布関数,片側α値(片側 p %値)の計算を画面上で実行することが可能です.ただし,結果はすべてテキストエリアに出力されます.
x1,x2,・・・,xn が互いに独立な確率変数で,それぞれが標準正規分布 N(0, 12) に従うとき,
なる確率変数 x が従う分布を自由度 n の t 分布といいます.自由度 n の t 分布の確率密度関数(上図参照),平均,及び,分散は以下のようになります.
平均: E[X] = 0,   分散: V[X] = n / (n - 2)   平均,分散は,n ≧ 3
なお,自由度が大きくなると,t 分布は正規分布に近づき,自由度が無限大になると,標準正規分布 N(0, 12) と一致します.
自由度 n1,n2 の F 分布
C/C++ による密度関数,分布関数,片側α値(片側 p %値)を計算するためのプログラム例  
アプレット版では,密度関数,分布関数,片側α値(片側 p %値)の計算を画面上で実行することが可能です.ただし,結果はすべてテキストエリアに出力されます.
χ12 が自由度 n1 の χ2 分布,χ22 が自由度 n2 の χ2 分布に従い,かつ,χ12 及び χ22が互いに独立であるとき,
x = (χ12 / n1) / (χ22 / n2)
なる確率変数 x が従う分布を自由度 (n1, n2) の F 分布といいます.自由度 (n1, n2) の F 分布の確率密度関数(上図参照),平均,及び,分散は以下のようになります.ただし,平均に対しては n2 > 2,分散に対しては n2 > 4 とします.
3.3.3 多変量確率分布
同時確率分布
例えば,2 個のサイコロを振る場合,それぞれのサイコロの目を X 及び Y として,X = 1,Y = 5 となるような確率を考えるように,同時に 2 つの試行を行ったときの確率分布を調べたい場合があります.このような確率分布を 2 次元確率分布といいます.これに対して,今まで取り扱ってきた 1 変数の場合を 1 次元確率分布といいます,2 次元確率分布に対しても,1 次元確率分布の場合と同様に確率密度関数を定義できます.
［定義］ X のとる値を x1, x2, ・・・, xm,Y のとる値を y1, y2, ・・・, yn とする.また,X が xi( i = 1, 2, ・・・, m ),かつ,Y が yj( j = 1, 2, ・・・, n )の値をとるときの確率が pij,つまり,
P(X = xi, Y = yj) = pij
であるとき,
h(x, y) = pij  (xi,かつ,yj のとき)
= 0  (その他)
を確率変数 X,Y の同時確率密度関数(simultaneous probability density function)という.
また,連続型分布に関しては,
となるような関数 h(x, y) が存在するとき,h(x, y) 確率変数 X,Y の同時確率密度関数(simultaneous probability density function)という.
2 次元確率分布において,Y の値にかかわらず X の分布を知りたいようなときがあります.このような場合は,それぞれの X における Y の値をすべて足し合わせれば(積分すれば)よいことになります.このことを示すのが次の定義です.
［定義］ 確率変数 X,Y の同時確率密度関数が h(x, y) であるとき,
をそれぞれ h(x, y) より定まる X,Y の周辺確率密度関数(marginal probability density function)という.連続型分布の場合も,同様に,
をそれぞれ h(x, y) より定まる X,Y の周辺確率密度関数(marginal probability density function)という.
1 変数の場合と同様,確率変数 X と Y の関数 φ(X, Y) に対して,その期待値を定義できます.
［定義］ φ(X,Y) を確率変数 X,Y の関数としたとき, 
を φ(X, Y) の期待値という. 
X や Y に対する平均や分散も,1 変数の場合と同様に定義できます.さらに,2 次元分布に対しては,2 変数間の関係の程度を表す量として次のものが定義されています.
［定義］ 確率変数 X,Y に対して,
σxy = C{X, Y] = E[(X - E[X])(Y - E[Y])] = E[(X - μx)(Y - μy)]
を X と Y の共分散(covariance)という.
実際の問題では,共分散の代わりに,-1 〜 1 の値をとるように正規化した相関係数(correlation coefficient)
が使用される場合が多いと思います.相関係数は,相関がある場合(変数 X が大きくなると変数 Y も大きくなるような場合)には 1 に近く,負の相関がある場合(変数 X が大きくなると変数 Y は小さくなるような場合)には -1 に近くなり,相関がない場合は 0 になります.値を解釈する目安は,概略,以下のようになります.
0.0 ≦ |ρxy| ≦ 0.2 : ほとんど相関がない
0.2 ≦ |ρxy| ≦ 0.4 : やや相関がある
0.4 ≦ |ρxy| ≦ 0.7 : かなり相関がある
0.7 ≦ |ρxy| ≦ 1.0 : 強い相関がある
最後に,2 次元分布に対する平均,分散,及び,共分散の性質をあげておきます.
［定理1.1］ 確率変数 X,Y に対して以下の式が成立する.
E[aX + bY] = aE{X} + bE[Y]
V[aX + bY] = a2V[X] + 2abC[X, Y] + b2V[Y]
C[X, Y] = E[XY] - E[X]E[Y]
確率変数の独立
先に述べた統計的独立の概念は,確率分布を使用しても表現することができます.
［定義］ 確率変数 X,Y の同時確率密度関数を h(x, y),X の周辺確率密度関数を f(x),及び,Y の周辺確率密度関数を g(y) としたとき,すべての x,y に対して,
h(x, y) = f(x)g(y)
が成立するとき,確率変数 X と Y は独立であるという.
［定理2.1］ 確率変数 X,Y が独立なとき,
E[XY] = E[X]E[Y]
が成立する.
p.139 定理1.5.5
上の定理より,明らかに,確率変数 X,Y が独立なときは,共分散や相関係数は 0 になります.
4.統計
4.1 統計的推定
4.1.1 標本と母集団
［定義］ 調査や観測の対象となる属性を持つすべての個体の集合を母集団という.母集団から取り出された一部のデータの集合を標本といい,データの数を標本の大きさという.また,母集団の平均,分散などを母平均,母分散といい,一般に母集団の特性値を母数という.
調査や観測等によって,我々が知りたいのは母集団の特性値−母数−です.観測された標本 x1, x2, ・・・, xn から,母数を推定する方法を統計的推定と呼びます.母平均や母分散を推定する方法として,以下に示すような標本統計量(標本平均,標本分散などは,母平均,母分散等に対する点推定値)がよく使用されます.
上記の統計量の内,分散や標準偏差の概念は多少分かりにくいかもしれません.分散は,データのばらつきを表す指標です.分散が大きいほど,データがばらついていることになります.先に述べた正規分布のグラフを見てもらうと,σ が小さいほど,尖ったグラフになっています.つまり,σ が小さいほど,データのばらつきが少なく,平均の周りに集中していることになります.極端な例として,分散が 0 であることは,すべてのデータが同じ値になっていることを意味しています.
標本統計量も一つの確率変数です.ある観測で得られた標本平均や標本分散は,確率変数 X や S2 の一つの実現値であると考えられます.従って,その統計量を計算できます.例えば,標本平均と標本分散の平均は以下のようになります.
E[X] = μ    μ:母平均
E[S2] = (n - 1) σ2 / n   σ2: 母分散
上式から明らかなように,標本平均の平均は母平均と一致しますが,標本分散に関しては,一致しません.標本平均のように,標本統計量の平均が母数と一致するような統計量を不偏推定量と呼びます.母分散の不偏推定量は,以下のようになり,先に述べた標本分散の代わりによく使用されます.
また,多変数の場合は,以下に示すような標本統計量がしばしば使用されます.
ただし,
X1, X2, ・・・, Xm : 確率変数
Xi1, Xi2, ・・・, Xin : 確率変数 Xi に対する標本確率変数
とします.
4.1.2 中心極限定理
［定理3.1］ 確率変数 X1, X2, ・・・, Xn が互いに独立で,平均が μ,分散が σ2 の同じ分布に従うとき,確率変数,
X = (X1 + X2 + ・・・ + Xn) / n
の平均及び分散は以下のようになる.
E[X] = μ, V[X] = σ2 / n
［定理］ 中心極限定理 確率変数 X1, X2, ・・・, Xn が互いに独立で,平均が μ,分散が σ2 の同じ分布に従うとき,それらの平均 X の確率分布は,n を十分大きくすれば,正規分布 N(μ, σ2/n) で近似される.
中心極限定理が適用できる標本の大きさの目安は,概略,以下の通りです.
分布が平均に対して左右対称の場合: n ≧ 30
分布が平均に対して左右非対称の場合: n ≧ 50
4.1.3 区間推定法
先に述べた点推定量には,その値がどの程度信頼できるかの情報が全く含まれていません.そこで,点推定量を元に,母数の値が,どの程度の信頼度で,どの範囲に含まれるかを推定するのが,区間推定です.以下においては,母平均及び母分散の区間推定法に関して簡単に述べます.
［定義］ 未知の母数に対して,未知母数 θ が a ≦ θ ≦ b となる確率が (1 - α),つまり,
P(a ≦ θ ≦ b) = 1 - α
となるように決定した [a, b] を信頼水準(confidence level)(信頼係数,信頼率)(1 - α) における信頼区間,または,100(1 - α)%信頼区間という.
母平均の区間推定(母分散 σ2 が既知の場合)
母集団が,正規分布 N(μ, σ2) に従っているものとします.ただし,標本の大きさ n が大きいときは,必ずしも正規分布である必要はありません.このとき,中心極限定理により,標本平均 X は,N(μ, σ2/n) の正規分布をします.従って,
は,標準正規分布 N(0, 12) に従います.A(α) を標準正規分布の α 点とすると,
P(|Z| ≦ A(α/2)) = 1 - α
という関係が成り立ちます.つまり,
となります.このことより,推定の信頼度を (1 - α) とすると,母平均の信頼区間は,以下のようになります.この式は,標本平均 X が得られたとき,母平均 μ が以下の区間に入る確率が (1 - α) であることを意味します.
母平均の区間推定(母分散 σ2 が未知の場合)
［定理］ n 個の確率変数 X1, X2, ・・・, Xn が平均 μ の同じ正規分布に従い,互いに独立ならば,その標本分散を S2 としたとき,
で定義される確率変数 Tn-1 が,母分散に関係なく,自由度 n-1 の t 分布に従う.
上の定理を利用することによって,標本の大きさが n である場合,標本平均が X,標本分散が S2 であるとき,母平均 μ の信頼度 (1 - α) の信頼区間は,自由度 n-1 の t 分布の α 点を tn-1(α) とすると,以下のようになります.
母分散の区間推定
［定理］ n 個の確率変数 X1, X2, ・・・, Xn が同じ正規分布 N(μ, σ2) に従い,互いに独立ならば,
で定義される確率変数は,自由度 n-1 の χ2 分布に従う.
上の定理より,正規母集団から大きさ n の標本を無作為抽出したとき,母分散 σ2 に対する信頼水準 (1 - α) の信頼区間は,自由度 n-1 の χ2 分布の α 点をχ2n-1(α) とすると,以下のようになります.
4.2 統計的検定
4.2.1 仮説検定
実験等によって得られた標本統計量に基づき,何らかの推論を行いたい場合があります.例えば,標本平均からその「母平均が μ である」ことを検証したい,2 つの母集団から得られた標本平均に基づき,それらの「母平均が等しい」ことを検証したい,といった場合です.このような場合,まず,一つの仮説 H0(帰無仮説)をたてます.例えば,上の例では,「母平均が μ である」,「母平均が等しい」などがその仮説に相当します.また,上の仮説に対立する仮説,「母平均は μ でない」,「母平均が異なる」などの仮説 H1 を対立仮説といいます.
既に述べたように,標本統計量も一つの確率変数です.同じ母集団から採った標本平均であっても,常に同じ値になるわけではありません.したがって,2 つの母集団から得られた標本平均が同じ値になったとしても,必ずしも 2 つの母集団の母平均が等しいことを意味しているわけではありません.同様に,2 つの標本平均が異なっていても,それらの母平均が異なっているとは限りません.
そこで,以下に述べるような方法によって仮説の正誤を判定します.標本統計量は設定した仮定の下で何らかの分布をします.得られた標本統計量がその分布の滅多に起こらないような値であったとします.例えば,標本統計量が平均 50,標準偏差 10 の正規分布をすると仮定したとき,実際に得られた標本統計量が 85 であったような場合です.実際,このようなことが起こる確率は,0.001 以下です.このような場合に対する解釈として 2 つあります.一つは,滅多に起こらないことが起こったという解釈です.他の一つは,設定した仮定が間違っていたという解釈であり,一般には,この解釈を採用します.その際,先に述べた α 値((α×100) パーセント値) λ を使用します.得られた統計量の値が λ より大きい(または,小さい)とき,つまり,仮定した分布の基で,得られた統計量の値が実現する確率が α 以下であるとき,最初の仮定が誤っているものとして棄却します.この方法を仮説検定といいます.
α 値((α×100) パーセント値)として,普通,5 %,または,1 %が用いられ,これを有意水準といいます.仮説Hが有意水準 α で棄却されたとき,検定結果は水準 α で有意差があるといいます.また,仮説を棄却する範囲のことを棄却域といい,確率分布の片側または両側に棄却域をとる場合を,それぞれ片側検定,または,両側検定といいます.
ある仮説が棄却されたとしても,仮説が誤っていることを意味しているわけではありません.あくまで,得られたデータのもとでは,誤っている可能性が高いことを示唆しているにすぎません.仮説 H0 が正しいにもかかわらず棄却される誤り(第 1 種の誤り)も当然発生します.同様に,棄却されなかったとしても,仮説が正しいことを意味しているわけではないことに,十分注意してください.仮説 H0 が誤っているにもかかわらず採用されてしまう誤り(第 2 種の誤り)が起こる可能性があるからです.
次の節において,非常に簡単な仮説検定の例を示します.検定目的や条件によって,様々な検定方法が存在します.詳細については専門の書籍等を参照してください.
4.2.2 母平均の検定
［定理］平均の検定(母分散が既知の場合) 母集団Ωの母平均 μ に対して,その値が μ0 であるという仮説,つまり,次のような帰無仮説をたてる.
帰無仮説 H0: μ = μ0
このとき,母集団が,正規分布 N(μ, σ2) に従っているものとする(標本の大きさ n が大きいときは,必ずしも正規分布である必要はない).中心極限定理により,標本平均 X は,N(μ, σ2/n) の正規分布をする.従って,
は,標準正規分布 N(0, 12) をする.そこで,A(α) を正規分布の α 値としたとき,標本から計算された z が不等式,
を満たすならば,有意水準 α で,仮説 H0 を棄却する.
上の定理では,暗黙に,対立仮説として,
H1: μ ≠ μ0
を仮定し,両側検定を行っています.しかし,対立仮説が,
μ > μ0,または,μ < μ0
のような場合は,片側検定を行い,棄却域をそれぞれ,
z > A(α),または,z 
のように設定する必要があります.この考え方は,以下に述べる議論においても同様です.
［定理］平均の t 検定(母分散が未知の場合) 正規分布 N(μ, σ2) に従っている母集団Ωの母平均 μ に対して,その値が μ0 であるという仮説,つまり,次のような帰無仮説をたてる.
帰無仮説 H0: μ = μ0
このとき,Ωからの大きさ n の標本平均を X,標本分散を S2 としたとき,
で定義される確率変数 Tn-1 が,自由度 n-1 の t 分布に従う.そこで,tn-1(α) を自由度 n-1 の t 分布の α 値としたとき,標本から計算された t が不等式,
を満たすならば,有意水準 α で,仮説 H0 を棄却する.
なお,母分散が未知の場合であっても,標本数が大きい場合は,母分散の近似値として標本分散 S2 を用いて,最初の定理を使用することが可能です.
4.2.3 母平均の差の検定
ここでは,2 つの平均値の差を検定する方法について説明します.3 つ以上の平均値を比較したいような場合は,分散分析を利用して下さい.
［定理］平均の差に関する検定(母分散が既知の場合) N(μx, σx2) に従う母集団から大きさ m の標本を抽出したときの標本平均を X とし,N(μy, σy2) に従う母集団から大きさ n の標本を抽出したときの標本平均を Yとしたとき,2 つの母平均 μx と μyに対して,その値が等しいという仮説,つまり,次のような帰無仮説をたてる.
帰無仮説 H0: μx = μy
このとき,
は,標準正規分布 N(0, 12) をする.そこで,A(α) を正規分布の α 値としたとき,標本から計算された z が不等式,
を満たすならば,有意水準 α で,仮説 H0 を棄却する.
［定理］平均の差に関する t 検定(母分散が未知で,かつ,同じ場合) N(μx, σ2) に従う母集団から大きさ m の標本を抽出したときの標本平均を X,標本分散を Sx2とし,N(μy, σ2) に従う母集団から大きさ n の標本を抽出したときの標本平均を Y,標本分散を Sy2としたとき,2 つの母平均 μx と μyに対して,その値が等しいという仮説,つまり,次のような帰無仮説をたてる.
帰無仮説 H0: μx = μy
このとき,
で定義される確率変数 Tm+n-2 が,自由度 m+n-2 の t 分布に従う.そこで,tm+n-2(α) を自由度 m+n-2 の t 分布の α 値としたとき,標本から計算された t が不等式,
を満たすならば,有意水準 α で,仮説 H0 を棄却する.
4.2.4 母分散及び等分散性の検定
［定理］分散の検定 n 個の確率変数 X1, X2, ・・・, Xn が同じ正規分布 N(μ, σ2) に従い,互いに独立ならば,
で定義される確率変数は,自由度 n-1 の χ2 分布に従う.そこで,分散に対する検定を行うには,まず,帰無仮説,
帰無仮説 H0: σ = σ0
を設定する.自由度 n-1 の χ2 分布の α 点をχ2n-1(α)としたとき,標本から計算された y が不等式,
を満たすならば,有意水準 α で,仮説 H0 を棄却する.
［定理］分散の比に対する検定 N(μx, σ2) に従う母集団から大きさ m の標本を,また,N(μy, σ2) に従う母集団から大きさ n の標本を抽出したとき,
で定義される確率変数 F(m-1, n-1) が,自由度 (m-1, n-1) の F 分布に従う.そこで,2 つの正規母集団から抽出されたデータに対して,それらの母分散が等しいという仮説,つまり,次のような帰無仮説をたてる.
帰無仮説 H0: σx2 = σy2
このとき,自由度 (m-1, n-1) の F 分布の α 点を F(m-1, n-1)(α)としたとき,標本から計算された x が不等式,
を満たすならば,有意水準 α で,仮説 H0 を棄却する.
なお,αが大きいときのα点を計算したい場合は,次の関係を利用できます.
F(m, n)(1-α) = 1 / F(n, m)(α)
静岡理工科大学
菅沼ホーム
目次
索引
確率と統計
