iPhone 4と4S、似ているようで大きく違う。カメラやCPUも違うが、機能の有無でいえば「Siri」に対応するかどうかが決定的な違いだ。本稿では、現在のところiPhone 4Sオンリーの機能となっている「Siri」を分析する。
メインの言語が日本語でもOK
iOSは、『設定』の「言語環境」で指定した言語により、メッセージやダイアログに使う文字列を決定する。しかし、Siriを含めた「音声コントロール」は(メインの)言語設定から独立しているため、日本語環境のままでもSiriでは英語、あるいはドイツ語やフランス語を使用できる。だから、現状Siriは日本語をサポートしないが、英語やドイツ語であれば日本語環境下でも支障なく利用できる。
インターネットへの接続が必要
Siriは内蔵マイクで音声を収集し、一定の処理をくわえたうえでなんらかのデータをインターネット上のサーバへ送信、その結果を受けてなんらかの処理を行ったり、音声合成機能で言葉を発したりする。ただし、3G回線でも利用できるため、送受信されるデータ量はそれほど膨大ではない(キャリアの帯域を大きく消費しない)と推測される。
だからSiriの利用には、インターネットへの接続が必須だ。無線LANと3G回線の両方が使用できないときSiriを起動すると、「Siriを使用できません」とメッセージが現れ、処理は停止される。
ちなみに、iOS 5以前からある「音声コントロール」は、機内モード時などインターネットに接続できない状態でも機能する。音声コントロールはローカルのリソースを、Siriはクラウド上のリソースを使用するという点で、両者はまったく異なる実装ということがわかる。
日本語版Siriを先取り?
公式発言はないが、Siriの技術はAppleがゼロから開発したものではなく、同社が2010年に買収したSiri社の技術をベースにしていると考えられる。そしてSiri社の音声認識技術は、iOS 5のリリース直前までApp Storeで公開されていた同名のアプリで判断するかぎり、Nuance Technology社(以下、Nuance社)が開発/運営しているクラウドベースの音声認識エンジンを使用している。現在iPhone 4Sに搭載されている「Siri」も、音声認識そのものはNuance社の技術を利用している可能性が高いのだ(クラウドベースのサービスであるだけに判定は難しいだろう)。
このNuance社の技術は、長い年月をかけて収集された膨大な量の音声サンプルに裏付けられており、だいぶ以前から日本語をサポートしている。iOS向けにも、自社の技術をアピールする目的で日本語音声認識アプリ『Drago Dictation』を公開しているので、実際に試してその認識精度の高さを体感してほしい。
そしてSiriが引き続きNuance社の技術を利用しているのならば、来年にも公開予定とされている日本語版Siriは、このDragon Dictationと同等の日本語認識精度を持つものと考えられる。iOS 5向けに最適化が実施されるにしても、その精度から大きく外れるものでもないだろう。
「空耳英語」は通じるか?
これまで挙げた事実から判断すると、Siriはクラウドベースの技術であることから、音声認識時に参照される波形パターンもまたクラウド上にあると考えられる。敢えてクラウド上に置くということは、パターンが膨大な数であると同時に、その多くはネイティブスピーカーのものであると考えるのが妥当だろう。
ということは、「What time is it now?」は「ホワット・タイム・イズ・イット・ナウ」と日本語読みするより、ネイティブスピーカーを気取って発音したほうが認識率は高いことになる。実際、Siriにはそのような傾向があるのだが、話者の英語能力や滑舌の問題があり、客観的な基準での判定は難しい。
そこで、有名な「掘った芋いじるな」(What time is it now?)など、言われてみれば確かに(英語にも日本語にも)聞こえる英文をSiriに話しかけるテストを実施してみた。結果は下表に示すとおりで、短いセンテンスであれば、結構な確率で意図したとおりに認識されるという手応えを得られた。しかし、ネイティブスピーカー風の発音から外れると、途端に意図しない言葉で認識されてしまった。
音声認識エンジンの詳細がわからないため、断定的なことは言えないが、"クラウドの向こう側"にネイティブスピーカーの音声サンプルが相当量あることは確かだろう。そしてそれが、来年には提供されるはずの日本語版Siriの実力を裏付けているとも言える。
iPhone 4Sの音声アシスタント機能「Siri」を試す - 空耳英語は通じるか? | iPhone | iPad iPhone Wire
