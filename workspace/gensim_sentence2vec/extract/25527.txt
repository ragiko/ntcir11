
1.はじめに
音声自動翻訳は、1. 音声を聞き取って、2. 別の言語に翻訳し、3. 音声にして出力する、という3つの要素技術から出来ています。これら3つは音声翻訳にとっては「部品」ですが、従来からそれぞれ独立した技術として研究開発されており、すでに音声を聞き取って文字にする音声認識ソフトやWEBページを翻訳するソフトなどが市販されています。  
では、これらのソフトを買ってきてつなぐと音声翻訳ができるのでしょうか?
答えはNOです。例えば、通常の自動翻訳ソフトは正しい文が入力として与えられることを前提として設計されているため、音声認識結果が誤っていても無理やり正しいものと解釈して翻訳しようとします。その結果しばしばとんでもない誤訳が起こります。これを避けるには、例えば、認識結果の信頼性が低い場合には翻訳せずに処理を中断して再度入力を求める、といった処理が有効です。
また、通常の音声認識では認識結果を一つに絞り込んで出力しますが、この絞込みの誤りを避けるため、複数の可能性を残したまま翻訳まで試み、最終結果をみて1つに絞り込むと性能が上がるかも知れません。
本稿では、特に、音声認識と自動翻訳の統合に焦点をあて、認識結果の信頼性を評価する技術、および、音声認識と翻訳を組み合わせて最も正しそうな結果を出力する技術を紹介します。さらに、これらを含むシステム全体を設計・評価するための前提となるデータ収集について紹介します。
2.音声認識結果の信頼性を評価する技術
音声認識結果の正誤を自動的に検知しユーザに誤った結果を提示しない技術をリジェクションと言います。音声認識では、入力された音声と音響モデル(音声の特徴を表すモデル)・言語モデル(言葉のつながりを表すモデル)・辞書との照合が行われ、照合の結果、他と比べて最も尤度(ゆうど)が高い単語列を認識結果として出力します。尤度とは統計的観点から見た尤もらしさの度合いで、尤度が高い単語は正しく、尤度が低い単語は誤っている傾向があります。この尤度の値(絶対値)をリジェクションに用いることができるでしょうか?実は、尤度に基づいて正誤を判定するのは一般的には難しいと考えられています。たとえば、音響モデルの尤度は、母音・子音などの音の違い、話者、話し方、周囲の雑音によって大きく影響を受け、結果が正しいのに尤度が低い、あるいは、誤っているのに尤度が高いということが起こるからです。
そこで私たちは、音声認識の過程で生成される単語グラフから単語の信頼度を出す方法を考案しました。単語グラフとは、入力音声と音響モデル・言語モデル・辞書との照合結果をネットワーク状に表現したものです。図1が簡略化された単語グラフの例で、左端のSと右端のEを結ぶ1つの経路が1つの認識結果候補に対応します。
ある単語の信頼度はこの単語を通る経路の尤度が単語グラフ内の全経路(上記の例では6つ)の尤度の総和に対してどの程度の割合であるか(事後確率)という値で定義します[1]。正しい単語であれば対立候補が現れにくいので事後確率は高く、誤った単語であれば事後確率が小さくなるので、単語のリジェクションのための有効な指標になります。この事後確率はGeneralized 
Word Posterior Probability(GWPP:一般化単語事後確率)と呼ばれています。 
3.複数の認識候補からの最適翻訳
上で述べたように音声認識処理の内部では、複数の認識結果候補に対して音響的・言語的観点から尤度を計算し、この尤度の尤も高いものを1つ選択しています。しかし、この尤度には様々な要因で誤差が含まれており、2位や3位のものが実は正解ということがしばしば起こります。旅行会話表現集の読み上げ音声を認識した結果によると、上位10位までの認識候補に正解の含まれる率は上位1位だけに比べて11%も向上します。
そこで、我々は音声認識候補の2位以下を捨ててしまうのではなく、複数個(たとえば上位10個)の認識結果に対して全て自動翻訳を試みることを考えました。翻訳までやってみてから音声認識時に得られる尤度と翻訳時に得られる尤度を組み合わせた「統合スコア」を使って最終的に一つの結果を選ぶというわけです(図2)。
ここで重要な「統合スコア」は、音声認識結果に対する音響的・言語的尤度、自動翻訳結果に対する訳語の対応の良さをあらわす尤度、翻訳結果の言語的な正しさを表す尤度など、様々な尤度に重みを付けて加えたものです(正確にはlog-linear 
modelというものを使います)。この重みは、入力音声データとこれに対する正解翻訳結果の組を大量に(数百以上)用意して、正解候補の統合スコアが極力高くなるように自動調整します[2]。
この方法で認識結果の上位20位を使うことで、1位のみ使った場合に比べて最終的な翻訳結果の誤りを4%以上削減させることができました。なお、スコアの近い認識結果同士は一部しか違わないのが普通です。そこで、複数の認識結果を別々に翻訳するのではなく、共通部分をまとめた図1の単語グラフのような形式のままで翻訳することによって高速化を図っています。
4.音声翻訳実験とデータ収集
音声翻訳全体の研究を実証的に進めるために、我々は日本語と外国語(英語や中国語)のネイティブを被験者として、様々な条件下で音声翻訳システムを使った対話実験を行い、データを収集してきました。このデータは先に述べたリジェクションの研究などに使えるだけでなく、システムに対する利用者の発話の性質を解明する上でも有用です。
たとえば、翻訳システムを通した対話の言語的な特徴(言語表現の頻度などの統計量)は、「人間の通訳を介した対話」、および、「旅行会話集のような表現」の両方の特徴を含む(合成したもの)であること、音声翻訳システム利用法の説明によって入力音声の言語的、音響的特徴が体系的に変化すること、などが明らかになってきました[3]。
前者の結果は音声認識や自動翻訳のパラメータを決定する際に参照する言語データを選ぶ手がかりになります。後者の結果は、音声翻訳システムの利用者に対して、使い易くかつ音声翻訳性能が向上するようなガイダンスを設計するのに直接利用できます。
さらに、2004年の年末には、関西国際空港等で我々の音声翻訳システムを外国人旅行者に実際に使ってもらってデータ収集を行いました。アンケートによれば英語話者の50%、中国語話者の53%が自分の言いたいことがほぼ伝わった、という評価をしています。
5.まとめ
本稿では音声自動翻訳のシステム全体の統合にかかわる研究の一端をご紹介しました。これらの研究は多岐にわたりますが、いずれも要素技術の研究だけでは出てこないものです。その内容も、要素技術を単にうまく組み合わせることだけに留まらず、個々の要素技術の設計や最適化までも含みます。これらは要素技術からシステムの利用実験まで一体的に研究しているATRだからこそできるユニークな研究分野といえます。
参考文献 
●ATRの音声翻訳技術
