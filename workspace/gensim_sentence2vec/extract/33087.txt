希望講座 : 自然言語処理学講座
取り組みたい研究テーマ : 専門用語抽出
私が NAIST で取り組みたいと思っているテーマは「専門用語抽出」です。
私は現在、ライフサイエンス統合データベースセンター (DBCLS) という生命科学系の研究所で
リサーチアシスタントとして働いており、疾患と関係がありそうな蛋白質や遺伝子を論文などの文
献から探すという仕事をやっています。DBCLS では蛋白質核酸酵素 (PNE) というバイオサイエン
ス分野の論文を取りまとめた学術雑誌のテキストが 20 年分近く利用できます。これはバイオサイエ
ンスの分野では重要なレビュー紙となっていますが、このテキストを元に、自然言語処理の技術を
使って、上記の関係を見る、という試みはまだされていません。実際に、この PNE のテキストに対
して、自然言語処理の技術を使い関連性を見ようとした際に、既存の辞書だけではきちんと形態素
解析することができなかったことがあるという経験から、このテーマに取り組みたいと思うように
なりました。例えば、「急性骨髄性白血病」という単語を含む文章を形態素解析すると「急性」、「骨
髄」、「性」、「白血病」に分かれて形態素解析されてしまう、といったような問題です。また、疾患に
関連するような遺伝子の情報を表示するシステムでは、関連する用語を検索するためにインデック
スを作成する必要がありますが、そのインデックスを作成するためには、専門用語を的確に一語と
して認識できなければなりません。しかし、上記のように病名が細かく分割されすぎては適切に疾
患との関連性を見つけることができません。このような理由で、名詞のつらなりからなるような複
合名詞を一つの単語として認識できる技術が必要となってきます。
隠れマルコフモデルを用いた ChaSen(茶筌) や条件付き確率場と呼ばれる手法を用いた MeCab
(和布蕪) など、現在の日本語の形態素解析はかなり高精度でできるようになっています [1]。しか
し、これは新聞雑誌のような一般的な文章において、という制約があります。つまり、学術論文な
どに代表されるような専門用語が大量に含まれる文章においては、一般的な文章のように正確に形
態素解析をできる保証はありません。また、実際にそのような専門用語が大量に含まれる文章にお
いて形態素解析をするとかなりのミスが出てきます。なぜこのような精度の差が出てくるのでしょ
うか。それは形態素解析を支える辞書の差にあります。生物、医学、情報分野に代表されるような
分野の専門用語の多くは既存の形態素解析に使われる辞書には含まれていません。
また、自然言語処理の分野が扱うトピックとして機械翻訳、意見マイニングなど、様々なものが
ありますが、それらのほとんどが形態素解析がきちんとできる、辞書が整備されているということ
が前提にされています。このように自然言語処理の分野において、形態素解析、それを行なうため
の辞書整備というのは基盤のようなものであり、非常に重要です。
しかしながら、そのような分野での専門用語辞書を整備さえすれば問題は解決する、というほど
問題は単純ではありません。なぜならば、専門領域において、専門用語は次々と登場してくるから
です。このような領域において、人手で辞書を整備しようとなると非常に大きなコストがかかりま
す。また、インターネット上の Blog から流行語を抽出して最近のトレンドを分析するような研究な
どにおいても、それらの流行語は辞書に載っていないことが多いため、専門分野における問題と同
じ問題をかかえています。
そこで、私が取り組みたいのは、専門用語を自動的に抽出できるような理論の体系付けです。現
在、専門用語を抽出するために使われているものとしては、単名詞が複合名詞を形成するために連
接する名詞の頻度を用いているものがあります [2]。しかし、この手法は単純に様々な頻度の情報を
使っているだけで、まだまだ改善の余地があるものだと考えています。語頭、語尾や係り受けなど
の情報を素性としてうまく取り込み、私がこれまで研究、学習してきた統計学や機械学習の理論を
用いながら、うまく専門用語を抽出できるような枠組みを構築していきたい思っています。統計学
や機械学習を用いることで、数値的な判断ができるようになり抽出が自動化できるため、辞書整備
のためのコストの削減に貢献できるでしょう。また、上記の例では日本語を例に取り説明しました
1
が、専門用語に関連する問題は言語を問わず存在します。日本語という一言語だけでなく、世界に
ある多くの言語において通用するような頑健な理論を構築したいと考えています。
また、このような研究をやりたいと考えた上で、NAIST に入りたいと思った理由は大きく分ける
と二つあります。
一つ目は NAIST が大学院大学であり、学部を持たないことから新しい研究を始めやすく、研究分
野を変更する人のことを深く考慮したシステムになっているということです。私が現在所属してい
る大学院にも自然言語処理の研究室はいくつかありますが、先日参加した NAIST の個別進学相談
会において、自然言語処理学講座の先輩の話を聞く中で、NAIST のほうが他分野から移行してきた
人へのサポートが充実していると思いました。また、システムが整備されているだけでなく、実際
に他分野から来られたという方も多く、専門分野を統計学から自然言語処理に変更しようとしてい
る私としては、頑張り方次第でやっていけるのではないかという自信を持つことができました。
また、なぜ現在の専門である統計学から自然言語処理の分野へ移るのかということに関してです
が、私の問題意識として高度な統計学、機械学習の理論だけでは現実に起こっている問題を解決す
るには十分ではなく、そのような問題を解決のためには実データへの深い理解や興味が必要である、
というものがあります。学部時代にデータマイニングを使ったコンサルティングを行っている会社
にインターンに行きました。そこで様々なデータ解析を行いましたが、解析している業界や商品に
関する知識や興味がないと、高度な解析を行ったとしても、その業界の人にとって常識となってい
ることしか知りえない、ということを痛感しました。それ以来、統計や機械学習を武器とし、自分
が面白いと思える分野は何だろうと探してきました。そして、機械学習を勉強していく中で、自然
言語処理の研究に出会いました。これまでは単純な数値型のデータ、例えば売り上げのデータなど
を扱ってきたのですが、自然言語処理では、言語情報を扱います。私達が情報、知識を入手する際
には多くの場合、言語を利用しています。これを統計や機械学習でうまく扱えるとなると、これま
で先人の人たちが書き残してきた大量の文章から必要な場所を抽出してきたり、関連するところを
簡単に知ることができるようになる可能性があります。これらがもっと高精度に高速にできるよう
になれば、どんなに素晴らしいことだろう、また、このようなことを自分も研究したいと思ったの
が、統計学から自然言語処理の分野へ移る理由です。
NAIST を志望する二つ目の理由は、NAIST が世界で活躍している大学院であるということです。
卒業生の方では、研究者やエンジニアとして世界の第一線で活躍している方が多数いらっしゃいま
す。また、在学中の方でも国際会議に論文を通している方、海外のインターンに積極的に参加して
いる方、研究成果をオープンソースとして公開されている方がいらっしゃいます。私は専門用語抽
出の理論構築だけではなく、それを実現するためのツールの実装も行ないたいと考えていますが、
NAIST の自然言語処理学講座では、自然言語処理の基盤となるような辞書、コーパス、形態素解析
システムなどが作成、オープンソースとして公開されており、実際に幅広く使われています。私が作
りたいと考えている専門用語抽出のためのシステムもこれらの仲間入りをし、社会の役に立つよう
なものにしたいと考えています。このように素晴しい先輩達と共に研究できる環境があり、私もそ
の先輩方のようなキャリアパスを歩みたいと考えている、というのが NAIST を志望した理由です。
このように非常に整った制度があり、優秀な先生、先輩が多数いらっしゃる NAIST で様々なこと
を勉強し、自然言語処理の分野に貢献できるような研究成果を挙げたいと思います。
参考文献
[1] Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto. Applying conditional random elds to
Japanese morphological analysis. In Proceedings of EMNLP, pp. 230-237, 2004.
[2] 中川裕志、森辰則、湯本紘彰. 出現頻度と連接頻度に基づく専門用語抽出. 自然言語処理, Vol.10,
No.1, pp. 27-45, 2003 年 1 月
2
Short Essay - SSSSLIDE
