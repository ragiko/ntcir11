
Cohen, B. H. (2007). Chapter 4: Standardized Scores and the Normal Distribution. In B. H. Cohen (Ed.), Explaining Psychological Statistics (3rd ed.). (pp. 87-122). NJ: Wiley.
zスコアは「(得点−平均)/標準偏差」である。平均と標準偏差が既知のどのような分布についても算出することができる。正の値ならば平均よりも得点が上であり,負ならば下である。特定の基準に依拠しない値であるため,zスコアは標準得点 (standard score) とも呼ばれる。p88
zスコアの利点は,異なる分布のロースコアを比較できるということにある(p88)。ただし,分布の形が極端に異なっている場合には有意味な比較はできない(p90)。
zスコアからローデータを算出することもできる。zスコアに標準偏差を掛け,平均を加算する。
*Rではscale()でやってくれるが,これに用いられる標準偏差も不偏標準偏差になっているため,本とは値が異なる。
df = c(30,40,60,70)
scale(df)
[,1]
[1,] -1.0954451
[2,] -0.5477226
[3,]  0.5477226
[4,]  1.0954451
*補正するには自分で関数を書くしかない模様。
sdd      x = x[complete.cases(x)]
y = sqrt( var(x)*(length(x)-1)/length(x) )
return(y)
}
zscore = function(x) (x-mean(x)) / sdd(x)
zscore(df)
[1] -1.2649111 -0.6324555  0.6324555  1.2649111
zスコアの平均は0,標準偏差は1となる(p90)。ただし,使いやすさから,SAT (大学入学用:Scholastic Assessment Test) やGRE(大学院入学用:Graduate Record Examination)では平均500,標準偏差100にしてあるし(p91),Tスコア・偏差値では平均50,標準偏差10,ウェクスラーのIQでは平均100,標準偏差15にしてある(p92)。変換には,zスコアに変換後の標準偏差を掛け,その値に変換後の平均を加算すれば良い。
ローデータをzスコアに変換しても分布の形は変化しない。p90
平均0,標準偏差1の正規分布を標準正規分布という。つまり,正規分布のロースコアをzスコア化すると,標準正規分布になる。
正規分布の平均から平均+1zの間には,34.13%が入る。つまり,平均±1zの間に,約68%が入る。
ある集団の心拍数にコーヒー摂取が与える影響を調べたいとき,ある集団の平均をまず測定する。しかし,その平均をどこと比べれば良いのか。その平均が正常か異常かは,同じサンプルサイズの集団をなんども募集して,そのたびに平均心拍数を計算して,それで分布を描いてみて,元の集団の平均心拍数がどこに位置するかを調べる他ない。つまり,ある集団の平均が高いか低いかを知るには,平均の分布が必要になるのである。p97
個々のサンプルの値(個人の心拍数)が正規分布を取る変数は,集団の平均(集団の平均心拍数)も正規分布を取るという性質がある。p98
個々のサンプルの分散よりも,個々の集団の分散は小さい。そしてそれは集団のサイズが大きくなるほど小さくなる。この平均の標本分布の標準偏差のことを,標準誤差 (Standard error of the mean) と呼ぶ。その大きさは,ローデータの標本分布の標準偏差を,サンプルサイズの平方根で割った値になる。p99
母集団が正規分布である場合,平均の標本分布も正規分布になる。しかし,母集団が正規分布でない場合でさえ,平均の標本分布というのは母集団分布よりも正規分布に近い形になる。さらにどんどん標本数を増やしていけば,正規分布に非常に近い形になる。これを中心極限定理と呼ぶ。p100
*大数の法則(たいすう,らしい。law of large numbers)との区別に注意。大数の法則は平均値の話。中心極限定理は平均の標本分布の形の話。
大数の法則は,ある変数の母集団から抽出したサンプルのサイズが十分に大きいとき,そのサンプルの平均(標本平均)は母集団平均と一致する,というもの。
中心極限定理は,ある変数の母集団から「サンプルを抽出するその標本平均を計算する」を繰り替えして得られる分布(平均の標本分布)の形が,例え母集団分布が正規分布でなくとも,母集団分布よりも正規分布に近くなる,というもの。さらに,その「近さ」は1回の抽出でサンプルをいくつ抽出するか(サンプルサイズ)に依存していて,例えば,N = 5, 50, 500というそれぞれのサンプルサイズで無限回母集団からサンプルを抽出し,その平均の標本分布をみてみると,N = 5, 50, 500の順に段々正規分布に近づく,というものである。
ここから,Nが十分に大きい時,ある変数の平均値は正規分布から抽出されたものだと仮定しても問題ない,ということになる。そしてパラメトリック検定はこの前提に立脚している。
平均の標本分布を仮定することで,グループの平均のzスコアというものも出せる。そのときの式は「(グループ平均−平均の標本分布の平均)/標準誤差」となる。
中心極限定理から,サンプルサイズが十分に大きい時,ある変数の平均の母集団は正規分布だと考えてよいことになり,その前提に立脚した検定手法が利用可能になる……が,逆に言えば,ある変数のローデータの母集団分布が正規分布でない(例えば,反応時間),かつ,サンプルサイズが小さい場合は,その変数の平均の母集団が正規分布ではないと考えられるので,この前提に立脚した大部分の検定方法(パラメトリック検定)は使わないことが重要になってくる。 (p110)
幸運なことに,サンプルサイズが30〜40であれば,まずまず正規分布に近づくことが分かっている (p110)
*p115の図4.13に,まぁまぁローデータの標本分布が歪んでいても(図のN=1),N = 10で見た目には正規分布に近づいている様子が見える。N = 10で結構補正されるものだなぁ。ただし,極端に歪むことが予想される場合には,N = 100は取りましょうとの注意書きもありました。
また,多くの統計的続きは,単純無作為抽出 (simple random sampling) を前提としているが,心理学者の行うサンプリングはほとんどがこれを満たしていない。
直線や円を数式で定義できるのと同様に,正規分布も数式によって定義されている。p113。なぜ山形になるかというと,ネイピア数eの指数がマイナスなので,この部分が最も小さくなるときが最も値を大きくするが,それが平均値にXが一致するときだからである。p114
*数式は書くのが大変なのでここには書かないが,Rのスクリプトを書いておく。
pi    #円周率
sdd    x = x[complete.cases(x)]
y = sqrt( var(x)*(length(x)-1)/length(x) )
return(y)
}
e = exp(1)    #ネイピア数
X = 1:10000	#入力データ
bunbo = sqrt(2 * pi * sdd(X)^2)
shisuu = -(df-mean(X))^2 / (2*(sdd(X)^2))
Y = (1/bunbo) * e^shisuu    #出力データ。正規分布の数式。
plot(Y)	#上記の式を描画 
分布の高さは,その関数(f(x)もしくはy)の密度と呼ばれる。したがって,このような数式をよく確率密度関数と呼ぶ。p114
こうした分布において,ある一点の確率は無限に小さくなるため,求められない。ある範囲の確率であれば,確率密度関数をその範囲で積分することでその確率を得ることができる。
この章の最後に確率論の基礎(条件付き確率まで)の解説あり。非常に分かりやすい。
文献読み 2013_05_INOHARA Keisuke's web site
