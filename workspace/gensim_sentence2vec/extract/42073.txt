本論文では, 未知語の確率モデルと単語の出現頻度の期待値に基づいて日本語テキストから未知語を収集する方法を提案する. 本手法の特徴は, 単語を構成する文字の種類ごとに異なる未知語モデルを使用することによりひらがな語や複数の字種から構成される単語を収集できること, および, 単語の出現頻度の期待値を文字列の単語らしさの尺度とすることにより出現頻度が低い単語を収集できることである. 人手により単語分割された EDRコーパスから無作為に選択した10万文(246万語)を用いて語彙数11,521の統計的言語モデルを学習し, EDRコーパスの残りの部分から無作為に選択した10万文(247万語, 未知語率7.72%)をプレーンテキストと見なして語彙獲得実験を行ったところ, 本手法による語彙獲得の精度は再現率61.5%適合率67.2%であった.
We present a novel lexical acquisition method from Japanese texts based on a probabilistic model for unknown words and expected word frequency. The benefit of the proposed method is that it can collect hiragana words and words which consist of more than one character types by using a different unknown word model for the character type configuration of a word, and that it can collect low frequency words by using the expected word frequency as the likelihood measure of a word hypothesis. We trained a statistical language model with 11,521 vocabulary from 100 thousand manually word segmented sentences (2.46 million words) which were randomly selected from the EDR corpus, and extracted new words from another 100 thousand unsegmented sentences (2.47 million words) which were randomly selected from the rest of the EDR corpus, and whose out-of-vocabulary rate was 2.1%. The lexical acquisition accuracy of the proposed method was 61.5% recall and 67.2% precision.

