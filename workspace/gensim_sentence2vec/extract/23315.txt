第1回インテリジェントホームロボティクス研究会http://intelligenthomerobotics.org/?conference=%E7%AC%AC%EF%BC%91%E5%9B%9Eihr%E7%A0%94%E7%A9%B6%E4%BC%9A2014年12月7日(日)•10:00-10:15 委員長挨拶岡田浩之(玉川大学)ロボット学会の専門委員会として今年設立されたインテリジェントホームロボティクス(iHR)研究会の説明。ロボカップ@ホームとかジャパンバーチャルロボティクスチャレンジ(レスキューロボットのシミュレーション競技)の話とか。•10:15-10:30岡田浩之(玉川大学),ジェフリー トゥ チュアン タン(東京大学) ,ロボカップ@ホーム標準プラットフォームリーグの提案最初にロボカップの紹介。いままでよりも様々な機関の参入を促すための、@ホームのStandard Platform League(SPL)の提案。安価で入手可能な統一ハードウェアを使い、競技後にソフトウェアを公開することで、参加機関の急速な底上げを図る。•10:30-10:45佐野睦夫,大井翔,池ヶ谷剛,宮脇健三郎,西口敏司,井上雄紀(大阪工業大学),認知障害者のための生活密着型リハビリテーション支援ロボットの取組ロボティクスの福祉応用。調理を対象としたリハビリをロボットで支援。料理は日常行動の中で動作の種類が多く、モチベーションも上がるのでリハビリに適している。課題としてはリハビリ中の患者の危険行動予測、多様な行動を適切に評価できる評価方法の開発など。インタラクションロボットを使って振り返り支援を行う。障碍者支援ロボットは、障碍者とロボットだけでなく、医療関係者・リハビリ担当者との関係が重要。•10:45-11:00長井隆行(電気通信大学),ヒューマンロボットインタラクションとホームロボティクスロボットによる「理解」とは何か。経験を分類し、その分類に基づいて観測できない事実や未来を予測すること。理解をするロボットの実現のために、ロボットによる言語獲得をめざす。必要な内容は分節化、反射行動、まねをする、アフォーダンスなど。記号創発ロボティクスの話。人間とロボットが1週間インタラクションし続けることで60単語ぐらいを獲得。ロボットの学習進度と教示の複雑さに相関がある。子供とロボットとの遊びについての調査。子供の状態を推定しながら遊ぶようにシステムを作ると、子供がロボットの顔をよく見るようになる。•11:00-11:15杉浦孔明,堀智織,是津耕司(NICT),ホームロボットにおけるクラウド型音声対話システムの利活用サービスロボットとのインタラクションにおいて、音声対話のコストが高い。そのため、音声対話のツールキットrospeexを作成・公開した。インタフェースはHTML5なので、プラットフォームに依存しないで動く。合成音声は声優っぽい(HMMベース、大きな声優データベースを利用)。クラウドベースなので、認識・QA・合成をすべてクラウドで行っていて、入力から出力までクラウドと3往復しているが、レスポンスはほぼリアルタイム。クラウドロボティクスに関する技術動向。ロボット専用だとマーケットは小さいが、スマホでも使えるならユーザは広がる。1年運用したところ、使われていた単語は挨拶と一問一答の質問で半分程度で、その他に移動・把持、家電操作、認識・学習関連単語など。•11:15-11:30中村友昭,小堀嵩博,西原成,長井隆行,金子正秀(電気通信大学),CRFとSVMを用いた家庭用ロボットのための命令理解音声認識結果を受けた言語理解。GPSRタスク対象。提案法では、行動の識別をSVM、文からのスロット項目の抽出にCRFを使う。音声認識のNベストから行動識別をM種類推定し、それぞれについてスロット項目を推定して、その中で最もそれらしい組み合わせを選ぶ。音声認識では、タスク依存のN-gramと通常の大語彙認識用N-gramの両方で認識をして、それらしい方(文頭にロボット名を読んでいるもの、など)を選ぶ。学習用に1500文程度の発話を人手で作り、アノテーションをしてモデル学習に利用。13:00-13:30 キーノート講演1: インテリジェントホームロボットへの期待
佐藤知正先生(東京大学)ホームロボットを実現するためのサービスの在り方。日本政府「日本再興戦略」の中のロボット革命(産業用ロボットとサービスロボット)。経産省その他の省庁が概算要求をしている。これを単なるブームに終わらせないために、社会実装を念頭に置くことが重要。成功例1:Brooksによるルンバの成功要因。圧倒的技術力、ビジネスモデル。成功例2:トレーニングマシン。単体では売れないが、デイサービスにトレーニングメニューを提供すると同時に、デイサービス開所ノウハウまで含めたパッケージで売り出したところ成功。スマイルカーブ。単品の製品は利益率が少ない。サービス込みで開発・販売することが重要。ビッグデータ活用例。GEの航空機エンジンとフライト診断パッケージ販売、コマツの建設機械稼働情報データベースの例。科学技術イノベーションを実現するプロセス。技術だけでは変革は起きない。未来のライフスタイルのデザインとビジネスモデルが必要。福祉サービスの全体像。ICF:国際生活機能分類。その他、技術とサービスを合わせて社会実装していくことの重要性について説明があった。13:30-14:00 キーノート講演2: 米国ロボット企業のロボットビジネスに対する考え方～ マーケティング重視型のアプローチについて ～
池田明広先生(セールス・オンデマンド株式会社)iRobot社、Romotive社のマーケティング・販売をやっている会社の社長さん。Roombaの研究は1997年ごろに開始。そこから2年程度で開発。iRobot社のミッション。DDD作業(Dull, Dirty and Dangerous)のロボット代替。さまざまな実用化されなかった技術。Romotive社。教育用ロボットRomo。スマホと移動台車を組み合わせ、そこに独自技術のソフトウェアを載せる。Roombaの販売。全世界で1200万台売れていて、その1/10は日本で売れている。iRobotの売り上げは最初の10年はほとんどなく、わずかな売り上げも受託研究だった。受託研究で開発した会議室掃除用ロボットを発展させてRoombaが誕生。会社には産業・軍事用と民生用の2部門があり、前者で開発した技術を後者に移転している。Roombaの掃除計画には地雷探査ロボットの技術が使われている。日本におけるルンバの展開。2002年にルンバを発売してから一時売れなくなった時期があり、マーケティングに力を入れるようになった。日本の掃除機市場は飽和していて買い替え市場しかない。ルンバは既存の掃除機カテゴリの外に新しいカテゴリを作るよう努力した。認知度を上げるため、ヨドバシAKIBAで有力でスペースを借りてコーナーを作った。また、「ロボット」という名前ではイメージがつながらないため、「自動掃除機」というネーミングに変えた。製品理解のために、掃除効率・騒音・排気などについての説明を重ねた。最後に「日本人気質」が問題になった(楽をすることは悪だ、という考え方)。これはパラダイムシフトが起きる最終段階だった。ルンバの成功要因。マーケットニーズの把握、コンセプトの明確化、機能特化。事業としてのロボットビジネス。ロボットがビジネスになるには10年ぐらいかかる。10年先から今を俯瞰することが必要。人材の底上げも必要になる。14:00-14:15中川友紀子,中川範晃((株)アールティ),サービスロボットを身近に置くための考え方株式会社アールティの沿革。イベント「ロボLDK」(2007)とその書籍「ロボットのいる暮らし」。ドラえもんとアトムのサービスロボットとしての比較。自立型、操縦型、装着型ロボット。ASIMO運用で得た結論。女性が一人で運べないロボットは大変すぎる。触れないロボットはサービスロボットじゃない。RIC90の開発(12kg以下)。ネコ店長その他のアプリケーション。https://twitter.com/nekotenchoしなやかさを実現するモジュールの自己開発ロボットアームNEKONOTE•14:150-14:30影広達彦,平松義崇,秋山靖浩,本間 健,上田泰士,中村亮介 ((株)日立製作所),人間共生ロボット「EMIEW2」日立のロボット開発。60年代から産業用ロボット開発。2000年代から生活支援・原発用等開発。EMIEW2は80cm14kg。2速ロボットだが足には車輪がついていて倒立振子制御。頭に14chマイクアレイがあり、音源分離で音声だけを拾う。首にLRFがあって、部屋のマップを作って自己位置推定。各種計算はバックエンドサーバで実行。質問の意図理解。さまざまな言い回しの理解にDNNを利用。カメラによる物体認識(Web上の画像との類似検索による)。室内の監視カメラ映像との連携。室内移動時に、マップに基づいて「危険ポテンシャル」を推定し、最も安全な経路を通る。http://www.hitachi.co.jp/rd/portal/research/robotics/emiew2_01.html•14:30-15:45山川宏((株)ドワンゴ人工知能研究所),汎用人工知能とホームロボティクス知能とは何か:未体験のデータについて予測する能力  推論技術+知識表現知識表現から見た人工知能の歴史:ゲームエキスパートシステムディープラーニング汎用人工知能(Artificial General Intelligence):異なる領域において多様で複雑な問題を解く  Wozniak Test (2007)AGIを目指す意義:現在は汎用性が足りない。単純な能力で人を超えるよりも、汎用性を目指す人間レベルのAIの実現汎用性の壁:ノーフリーランチ定理(性能を上げるには性能を作りこんだ方がいい)Benjioによる一般事前知識:Smoothness, Multple explanatory factors, ..汎用的な知能を実現するには?:多様なルールをあらかじめ設計 or 領域知識表現の獲得脳に学ぶAGI:全脳アーキテクチャ(WBA)•14:45-15:05飯尾尊優,塩見昌裕,亀井剛次,Chandraprakash Sharma,萩田紀博 (ATR),高齢者のための見守り支援技術の取り組みさまざまな見守り支援。画像自体はプライバシーが問題なので距離画像を利用。転倒の検出、身長から人のカテゴリ推定などができる。離床センサなどとの比較により有効性を検証。日常的にかかわるロボットの「安心」:安全でも安心ではない(安全であっても怖いものは怖い)信頼感、予測可能性、権威人による移動支援:声かけが大事車椅子ロボットによる声かけ塩見昌裕,萩田紀博 (ATR),環境センサを用いた保育支援技術の取り組みロボットによる保育支援:センサを利用した見守り、勤怠管理、知育アプリなどロボティクスならではの支援:人位置情報に基づいた情報処理子供の注意をひきつけるロボット Sphero:子供の気を引くことで保育士の負担を減らす玩具型ロボットについての要望:社会的「正しさ」についてのふるまいロボットを利用する人たちに「コミュニケーションできる対象」と認知されることが重要ロボットを利用する人たちをケアする立場の人(介護士、保育士)に指示されることが重要15:05 閉会15:30-17:00 ロボカップ@ホームリーグジャパンオープン2015に関する議論
11月20日(木) 午後  EA(1)(1)    14:45-15:15    反射率可変の音響壁面システムに関する研究 ～ スピーカの異なる各種ユニットの基本性能比較 ～    古川勇太・尾本 章(九大)VRAWSはスピーカとマイクを使って仮想的に任意の反射率を持った壁を作る技術.スピーカの種類によっていくつかのバリエーションがある.それぞれを壁だと思った場合に,壁としてどういう性質なのか(吸音率など)を測った.(当然だが)入射音を超えるエネルギーを反射する壁を作ったりできる.また,2台のVRAWSを対向させて動作させた時の性質を調べた.(2)    15:15-15:45    送信波と受信波の干渉に着目した音響距離推定手法の動体検知パラメタの検討    河納隼一・黒枝翔太(日本文理大)・松本光雄,福島 学(日本文理大)・柳川博文(千葉工大)
15:45-16:00    休憩 ( 15分 )音の反射による距離計測.計測点からインパルスを放射して,放射音と観測音のクロススペクトルから距離を求めるという極めて標準的な方法.この発表では計測対象が動いている場合の検討をしている.基本的には短時間に何度も計測するだけのようだ.ペットボトルに水を詰めて,紐をつけて振動させたものを計測している.11月20日(木) 午後  EA(2)/EMM(1)(3)    16:00-16:30    機械の異常に対する音・振動間の相関情報活用による診断法    折本寿子・生田 顕(県立広島大)機械の音信号と振動信号の大きさの相関の変化を見ることによって,機械に異常があるどうかを診断する.音と振動の相関からベイズ的に異常の発生確率を推定するが,異常時の信号が学習に使えないことが多い.そこで,正常時の学習データを使って音から振動(またはその逆)の分布を予測する式を作っておいて,予測誤差が大きくなった場合に異常があったと判定する.また,2種類以上の異常が起きた場合の定式化を行った.式についてはよく理解できなかった.(4)    16:30-17:00    自己組織化マップに基づくビットエラー耐性のある量子化法    伊藤彰則(東北大)私の発表.ビットエラーが起きたのを無視して逆量子化した時に誤差が少なくなるようにセントロイドを決めるベクトル量子化.思ったより時間がなかった.
減ってる学会電気・情報関連学会(信学会,情処,照明,映像情報メディア,電気) http://www.lcieice.org/report.html映像情報メディア学会 http://www.ite.or.jp/data/journal/passed_issues/?mode=disp&key=127日本物理学会 http://www.jps.or.jp/outline/kaicho.html日本生物物理学会(会員数増強キャンペーン) http://www.biophys.jp/topnews/topnews01.html日本分光学会 https://www.jstage.jst.go.jp/article/bunkou1951/52/1/52_1_1/_pdf日本生化学会 http://www.jbsoc.or.jp/download/news_071001.pdf日本外科学会 http://www.tpkfrog.com/miki-hp/memb-decrease/memb-decrease.html日本動物学会 http://www.zoology.or.jp/html/03_activity/03_syourai/kakenhi/kaiin99.html無機マテリアル学会 http://www.simj.jp/company/index.htmlエレクトロニクス実装学会 http://www.e-jisso.jp/publish/journal/pdf/147/14070000.pdf海洋音響学会 http://www.masj.jp/masj/home/index.php/2011-06-09-08-11-30日本生理学会 http://physiology.jp/data/download/20060412105545.pdf顕微鏡学会 http://www.microscopy.or.jp/magazine/45_2/pdf/45-2-73.pdfマテリアルライフ学会 http://materials-life.org/?p=4日本実験力学会 http://www.jsem.jp/about/president.html日本産業技術教育学会 http://www.jste.jp/oldsite/Site/xue_hui_shao_jie.html骨材資源工学会 http://kotsuzai.info/index.php/message土木学会 https://www.jsce.or.jp/president/files/letter_0611.pdf日本消化器外科学会 http://www.jsgs.or.jp/68/modules/contents/index.php?content_id=1日本関節病学会 http://jsjd.info/outline.html日本家屋害虫学会 http://www.kaokugaichu.jp/about/chairman.html日本菌学会 http://ja.wikipedia.org/wiki/%E6%97%A5%E6%9C%AC%E8%8F%8C%E5%AD%A6%E4%BC%9A日本神経病理学会 http://www.procomu.jp/jsnp2014/greeting.html地盤工学会 https://www.jiban.or.jp/index.php?option=com_content&view=article&id=677%3A2008-09-14-23-07-28&catid=38%3A2008-09-14-21-08-38&Itemid=12日本EU学会 http://eusa-japan.org/contents_JPN/records_j/aisatsu_kubo.htm日本磁気学会 http://www.magnetics.jp/archive/intro/aisatsu.html日本薬学会 http://www.pharm.or.jp/whats/kaito.htmlシステム制御情報学会 http://www.iscie.or.jp/j/?%E7%AC%AC%EF%BC%95%EF%BC%93%E6%9C%9F%E4%BC%9A%E9%95%B7%E5%B0%B1%E4%BB%BB%E3%81%AE%E3%81%94%E6%8C%A8%E6%8B%B6日本呼吸器外科学会 http://www.jacsurg.gr.jp/about/message.html日本地震学会 http://www.zisin.jp/modules/pico/index.php?content_id=2322日本赤外線学会 http://www.jsir.org/wp/?page_id=423品質工学会 http://www.qes.gr.jp/qes/qes_soukai2014.pdf日本小児神経外科学会 http://jpn-spn.umin.jp/gakkai.html日本混流相学会 http://www.jsmf.gr.jp/gakai_13/14.shtml日本品質管理学会 http://www.jsqc.org/ja/kankoubutsu/news/articles/2014_09/index.html日本色彩学会 http://www.color-science.jp/teikanan/index.html日本結晶成長学会 http://www.apheresis-jp.org/modules/about/index.php?content_id=2日本語文法学会 http://www.nihongo-bunpo.org/images/nihongobunpo_gakkai_uneikaizenan.pdf増えてる学会日本顎咬合学会 http://www.ago.ac/menu/info_kaiinnsuu.html日本てんかん学会 https://www.jspn.or.jp/journal/journal/pdf/2011/06/journal113_06_p0647-0647.pdf日本眼科学会 http://www.nichigan.or.jp/member/rijikai/11211.jsp日本看護科学学会 http://www.umin.ac.jp/umin20/memorial/pdf/chap05_murashima.pdf日本高血圧学会 http://www.jpnsh.jp/greeting.html日本教育工学会 http://www.jset.gr.jp/profile/日本泌尿器学会日本尿路結石症学会日本補綴歯科学会 http://hotetsu.com/s1_02.html日本口腔インプラント学会 http://www.shika-implant.org/publication/dl/gougai.pdf日本臨床バイオメカニクス学会 http://www.clin-biomechanics.org/outline01.htm日本ヘルニア学会 http://jhs.mas-sys.com/society/index.html日本成人先天性心疾患学会 http://www.jsachd.org/about/greeting.html日本臨床分子形態学会 http://www.rinshoudenken.gr.jp/aisatsu.html日本有病者歯科医療学会 http://www.jjmcp.jp/日本大腸肛門病学会 http://www.coloproctology.gr.jp/news/2014/08/04/post.php日本消化吸収学会 http://www.jsdaa.org/info/index.html日本観光研究学会 http://www.jtb.or.jp/researcher/column-tourism-society-umekawa日本精神分析学会 http://www.seishinbunseki.jp/society/greeting.html日本アフェレシス学会 http://www.apheresis-jp.org/modules/about/index.php?content_id=2増えているかもしれない学会日本整形外科学会 http://www.joa.or.jp/jp/joa/about.html日本糖尿病学会 http://www.jds.or.jp/modules/about/index.php?content_id=1日本血管内治療学会 http://jsei.umin.jp/日本呼吸器内視鏡学会 http://www.jsre.org/about/日本睡眠学会 http://jssr.jp/data/aisatsu.html日本神経学会 http://www.neurology-jp.org/gaiyo/enkaku.html日本小児麻酔学会 http://www.ped-anesth.com/greeting.html日本臨床歯科CADCAM学会 http://www.jscad.org/about_us/greeting.html日本膵臓学会 http://www.suizou.org/gaiyo/rekishi.htm日本末梢神経学会 http://jpns.jp/greeting/index.html横ばい日本フランス語教育学会 http://sjdf.org/SJDF_admin/12_vicepr_discours.html言語文化学会 http://language-culture.info/その他科学コミュニケーションの動向 http://www.nistep.go.jp/achiev/ftx/jpn/stfc/stt008j/feature2.html21世紀における日本の学術誌出版 http://www.nii.ac.jp/sparc/publications/newsletter/pdfper/6/sj-NewsLetter-6-3.pdf医学会を減らせ! http://net.keizaikai.co.jp/archives/9992
土佐山田駅からのバスがやや遅れたおかげで,発表開始から10分ほど遅れて会場に到着.10:30 - 12:10 通信研究会2(10) MIMOを用いたOFDMパワーアンプの電力付加効率改善 亀田博文(東京理科大),原 直也(東京理科大),白戸裕史(東京理科大),村口正弘(東京理科大)無線通信.OFDM通信では平均電力に対するピーク電力が大きく(PAPRが大きい)増幅効率が悪い.そこで信号を定振幅成分とそこからの差分の2つに分解し,2つのチャネルをMIMOで送受信する.2つのチャネルを別々に増幅することで,それぞれの信号に最適なアンプの動作領域を設定することができる.(11) 予等化によるOFDMパワーアンプの電力付加効率改善の検討 松永亮(東京理科大),笠原悠昭(東京理科大),白戸裕史(東京理科大),村口正弘(東京理科大)前の発表もそうだが,基本的な内容(OFDM,PAPR,PAE,SNRなど)に対する丁寧な説明があり,ナイーブな印象を受けると同時に非専門家にはわかりやすい.通信業界は略語が多いからね.OFDMではPAPRが大きくて増幅効率が悪いので,OFDM変調信号をシグモイド関数に通してピークを抑圧したうえで送信.受信側では伸長処理でピークを強調したうえで復号する.PAPRが改善し,効率が上昇.雑音には弱い.(12) 雑音耐性に優れた可視光通信の検討 吉留祐樹(東京理科大),佐々木良輔(東京理科大),村口正弘(東京理科大)可視光通信.利用シーン例で車車間通信とか車と信号機の通信を挙げていたが,それは筋が悪いんじゃないのかなあ.OFDM通信で複数あるサブキャリアのうちどれか1つだけ使うことで耐雑音性を上げる.どのサブキャリアを使うかを情報として使い,サブキャリアのチャネル番号をシンボルとして使う.FSKとの違いについて説明していたが,要するに復号方式が違うだけのような気がする.(13) LEDの周波数特性を考慮したOFDM可視光通信の検討 金 載ホ(東京理科大),番場雅敏(東京理科大),村口正弘(東京理科大)上と同じくOFDMを使った可視光通信.こちらはサブキャリアの低周波側では16QAMを,高周波側ではQPSKを使うことで全体の効率を上げる.13:10 - 14:25 画像工学研/メディア工学研(14) 異なるスパース性で設計した基底を選択的に用いる画像符号化の一検討    今泉貴裕・王 冀・八島由幸(千葉工大)従来法では,画像の小ブロックごとにDense SIFTを計算し,それをクラスタリングして基底を作って,その重ね合わせで入力画像のブロックを表現する.また,スパース基底を使うことで重み係数をスパースにし,符号化効率を上げている.これに対して,圧縮率の目標値によって最適なスパースネスが異なる.そこで,学習時のスパースネスの違う基底を複数用意し,ブロックごとによさげな基底に対する重み係数を符号化に使う.それぞれの基底単独よりも性能が高く,PSNRはDCTよりも良い.(15) HEVCにおける係数レベル成分間予測方式の検討    河村 圭・内藤 整(KDDI研)最近規格化された映像符号化規格HEVCのうち,色形式RGB4:4:4(PCやスマホなどのスクリーンコンテンツ向け)での符号化性能の改善が目標.従来の方法(CCD法)では輝度の残差を使って色差の残差の予測精度を上げる.提案法では,それを逆DCT前に行うことで後段の並列処理部分を増やすのが目標.基本的にはDCTの前でもあとでも同じだが,DCTドメインでの4x4 TU (Transform unit)に対しては線形性が成り立たないので,その部分の扱いを工夫するなどHEVC特有の話題が多く,全部は理解できなかった.従来手法と比べて画質にはほとんど差がない.(16) 三次元弱幾何検証に基づく特定物体認識    吉田大我・島村 潤・谷口行信(NTT)BoWベースの物体認識では,幾何的情報が失われることが利点でもあるが欠点でもある.「弱幾何検証」法では,特徴点の間のスケール・回転などの一貫性を検証する.しかしこの方法では,3次元空間上の物体を違うアングルから撮影した写真間の対応が取れない.また,3次元物体の撮影角度の一貫性を調べる方法が提案されているが,すべての対応点を調べるため時間がかかる.そこで,3次元的な対応をとりつつ弱幾何検証と似た方法を使うことで,3次元制約を検証しながら高速にマッチングを行う.具体的には,弱幾何検証での回転とスケール変換だけではなく,一般のアフィン変換を許すことで3次元的な位置変換を模擬する.クエリ画像とリファレンス画像に含まれる同一visual wordの特徴点について,それがどういう視点移動に対応しているのかについて投票を行うと,正解リファレンスとクエリの特徴点ペアのほとんどが同じ視点移動に投票するので投票箱のヒストグラムが鋭くなる.また,繰り返し出現するパターンの重みを下げるためにtfidfによる重みづけなども行う.Visual wordの種類を増やした方が全体の実行時間が速くなるというのが意外だった.
信学会3つ+電気学会+映像情報メディア学会共催・連催という複雑な研究会.場所は高知工科大学.11:30-12:45 LOIS研究会(1) パターン認識による生活音識別アルゴリズム    西 宏之・金 金・木村義政・柿木稔男(崇城大)西先生急病のためキャンセル.(2) 作業時間変化に対する調理手順最適化アルゴリズムのロバスト性評価    松島由紀子・舩曵信生(岡山大)忙しい人のために多種類の料理を最適な手順で作る為のアルゴリズム.これまで提案したアルゴリズムの作業時間が熟達度等の違いで変化した時にどのくらいうまくいくか評価.最適化アルゴリズムはシミュレーテッドアニーリングに基づく.手順を作るための「調理シミュレーションモデル」はやけにヒューリスティックな感じ.調理作業の時間がランダムに増減するとき,再スケジュールをしてもほとんど関係ない.(3) 歩道通行者の主観を利用した歩道状態推定手法の検討 岩本秀明・武藤伸洋・伊藤達明・内田典佳・浦田昌和・竹中 光・中川純一・岡本 学(NTT)歩道の状態をセンシングして,それをクラウドに集約して活用するプロジェクト.歩道利用者(ベビーカー)が問題個所(急こう配,凸凹など)を手動でラベル付けし,そのラベルをセンサーデータと合わせてブートストラップ的にラベル推定モデルを作るつもりらしい.機器はベビーカーの下の方にスマートフォンを括り付けたもの.識別はSVM.路面形状の推定精度は84～95%程度.13:45 - 15:25 通信研究会1(1) 全光ネットワークにおける四光波混合と電力消費を考慮した光パス設定 松本智(東京理科大),平田孝志(関西大学),村口正弘(東京理科大)WDMで光ルーティングを行うファイバネットワーク.四光波混合(非線形性によって入力光以外の周波数の光が発生する)が生じにくいように1つのファイバに乗せる光の波長を工夫し,またできるだけ1つのファイバに対して多くの波長を使ってファイバ数を減らすことによって光増幅器の利用個数を減らして消費電力を削減する.この2つは相反するので,これらのトレードオフを決めるパラメータを導入したうえで,整数計画法によってそのファイバのどの波長をどこのノード間で使うかを最適化する.最適化手法についての質疑が全体としてかみ合っていなかった.(2) 産業用途向け無線通信技術におけるリアルタイム性確保に関する検討 丸地俊也(東芝),吉川正臣(東芝),大西直哉(東芝),秋田耕司(東芝),笠見英男(東芝),古川剛志(東芝)産業機器(工場とか)で無線によるリアルタイム伝送を行う.評価では無線といいつつ有線通信で遅延評価をしている.伝送を高速化するため,送受信処理をFPGAでハードウェア化.伝送は1対1なので,MAC処理を省いてパケットサイズも大きくして性能を稼ぐ.1対1の通信でプロトコルも独自なら,その上をIPにする必要がない気がした.(3) 山間部における920MHz帯電波伝搬フィールド試験結果 降幡智(中部電力),原田義久(中部電力),野崎正典(沖電気工業),久保祐樹(沖電気工業),西村弘志(沖電気工業)最近使えるようになった920MHz帯の無線が山の中でどれだけ使えるかを1年間フィールドテストした.森の中に発信・受信機を設置してひたすらデータを取っている.途中で木の伐採があると損失が変わるとか,いろいろ興味深い.また,山間部での損失推定のための推定式を提案.(4) 地域内情報流通ネットワークの構築に向けた無線LANアクセスポイント間放送型通信に関する検討 眞中絢美(東海大),宇津圭祐(東海大),野澤靖弘(東京都港区),福崎稔(東海大),石井啓之(東海大)高輪地区で行っている日常生活支援アプリ開発・地域ネットワーク利用プロジェクト.日常の連絡や非常時の安否確認などのためのAndroidアプリを作成.基本的に役所にサーバがあり,その内容を家庭の端末に配信したり,安否・健康状態などを集めたりする.自宅にインターネットをひいていない家庭のため,地域の無線LAN経由で通信を行う(通常は旅行者用,非常時は非常連絡用などにも使う).アクセスポイントは街灯に設置.APと端末はインフラモード,AP間はアドホックモードで通信する.また,APに対して放送的な情報配信を行うため,再送を伴うブロードキャスト型通信BBISSを使う.15:40 - 17:20 EMM研究会(5) 3Dプリンター造形物内部に埋め込んだ情報のサーモグラフィによる非破壊読出し    ピヤラット シラパスパコォンウォン・鈴木雅洋・上平員丈(神奈川工科大)・高嶋洋一(NTT)・海野 浩(神奈川工科大)3Dプリンタで出力した造形物の著作権保護.造形物の内部に空洞を作っておき,その空洞の配置に情報を埋める.読みだすときには造形物に熱を加え,熱伝導をサーモグラフィーで計測して熱伝導の不均一性を調べることで空洞の有無を検出する.従来はX線で読みだす方法などが検討されていたようだが,熱を使う方法は安価なのが特長.これは本来の意味での透かしといっていい感じ.(6) 定量的スクランブル強度制御およびファイルサイズ増加抑制可能な可逆的プライバシー保護手法    島浦紳吾・姜 錫・坂本雄児(北大)監視カメラ画像のプライバシー保護のためのスクランブル手法.JPEGの8x8ブロックの直流分はいじらず,低周波部分をスクランブルして,高周波部分にはスクランブルに関係する情報を埋める.また,目的のPSNRによってスクランブル強度を調整する.さらに,人間がいる領域を推定し,その部分だけスクランブルすることで全体のデータ量増加を抑える.スクランブル手法はDCT係数の符号を反転させるだけ.情報埋め込みはヒストグラムを使った可逆埋め込み.(7) 整数MDCT領域でのスペクトル拡散と振幅拡張に基づく可逆かつ強耐性音響電子透かし    西村 明(東京情報大)高知出身の西村先生.攻撃に強い可逆電子透かし.また,MP3符号化などの攻撃を受けた場合でも,電子透かしのない状態に近い音質まで戻せる(準可逆).従来手法は,決められた区間全体のパワーを量子化して,その最下位ビットに情報を埋める方法.提案手法は,整数MDCT領域でサブバンドの値を増幅して,位相をずらすことで情報を埋める.また,同期ビットをスクランブルしてLSBに埋めることでフレームを同期する.攻撃を受けてLSBが壊れた場合には,1サンプルずつずらしながらMDCTを行って相互相関を取ってフレームを推定する.MP3エンコード攻撃を受けた場合でも,埋め込みを行っていない信号をMP3エンコードした場合と同程度の音質まで戻すことができる.(8) IHC電子透かしコンテストの高画質カテゴリにおける加法電子透かし法の性能評価    戸塚拓伸(阪大)・吉田真紀(NICT)・藤原 融(阪大)IHC電子透かしコンテスト(画像部門)には高耐性カテゴリと高画質カテゴリがあるが,高画質カテゴリでIHC基準を満たしてスペクトル拡散に基づく方法を提案.以前提案した(高耐性カテゴリのための)方法のパラメータを調整して高画質にする.後の話は基本的にどうパラメータを探索したかについて.総当たりだと時間がかかりすぎるので,二分探索で探索時間を削減した.17:35 - 18:25 招待講演(9) 車載カメラ映像からの歩行者検知    陳 国躍・張 興国・猿田和樹・寺田裕樹(秋田県立大)最初に以前やっておられたアクティブ騒音制御の話.コストが問題であまり実用化されていない.秋田県立大学に移ってから画像信号処理を始める.テーマは車載カメラ画像からの歩行者検知で,検討課題はvisual wordの選択手法,特徴点の分布と分析など.歩行者の候補領域検出.高速な手法としてBING(Binarized Image Norm Gradient)法を使う.特徴量はHOG, LBP, EOHなどなど.位置ずれに頑健にするため,Bag-of-Featuresを特徴として使う.Visual wordの選択.人間のBoFと非人間のBoFとの差を取り,それを大きい順に並べると,人間の検知に重要なvisual wordだけを取り出すことができる.Visual wordの数を半分以下にしても検出性能はほとんど落ちない.BoFとHOGを比較すると,BoFのほうが位置ずれに強い.選択された特徴点の分布.有効な特徴点は主に体の領域に分布している.このあと「グレース浜すし」(寿司屋ではない)で懇親会後,数名で高知市内の居酒屋で2次会.「桃太郎」と「瀧嵐」を飲んだ.
スペシャルセッション音声A/音声B/電気音響［音によるシーン理解とその進展 I］・あらゆる音の検出・識別を目指して—音響イベント検出研究の現在と未来—(NTT CS研・大石康智)さまざまな録音に対して、これまでは音声や音楽などの特別な信号を検出・識別することが多かったが、それ以外の雑音も含めてすべての音を認識する「音によるシーン理解」。ICASSPでの発表件数も徐々に増えている。これまでの研究課題を「音の特定度」と「時間的参照範囲」を軸として整理する。特定度は、データベースの音との同一性基準(完全同一波形かどうか)で、時間的参照範囲はフレーム単位か長時間統計を使うか。これらの分類は音楽検索からの借用。大分類として「同一音の検出・識別」「音響イベントの検出・識別」「音声・音楽の区間検出・識別」「音環境の検出・識別」の4つを認定。同一音の検出は完全に同じ波形の検出。研究は少ないが、今後の需要は高い。音響イベント検出では、MFCC-HMMやNMFなどが利用されている。音声/非音声/音楽区間の検出・識別では音声区間検出技術などが使われ、汎用信号区間検出技術(GSAD)もITU-Tで標準化されている。音環境の検出・識別は、映像クリップへのインデクシングや推薦などに使われる。BoWをベースにSVMなどの識別が一般的。関連する競争型ワークショップ。CLEAR(2006-2007)は12種類の音響イベントの検出と9種類の音環境の識別を行っている。D-CASE(2012-2013)はオフィス環境での16種類の音響イベント検出と10種類の音環境の識別を行っている。Albayzinはスペインの大学機関でのワークショップ。87時間分のTVニュース番組の音響信号の時間区分化タスクがあった。TRECVID MED(2010-2014)はTRECVIDの中のMultimedia Event Detectionのタスク。TRECVID MER(2012-2014)はMultimedia Event Recountingで、イベントが検出された証拠を列挙して説明するというタスク。全体的な傾向。シンプルな特徴量や識別器で大規模データを評価している。音響イベント検出は難しく、特にイベントが重なると困難。最先端の機械学習を駆使した研究の紹介。DNN、ベイズ学習。特にベイズ学習の研究例の紹介。・Acoustic word learning from temporal-frequency patches for sound event detection (NICT・Xugang Lu)音のイベント検出(例としてTED Talkの音響イベントによるセグメンテーションが出てきた)。古典的にはMFCCやPLPなどの特徴量によって特徴抽出し、HMMなどでモデル化するか、統計量をSVMなどで分類する。ここで音声の場合には信号の「構造」がよく定義されているが、音響イベント(拍手、笑いなど)ではその中にどんな構造があるのかよくわかっていない。ここで、繰り返し観測される時間周波数パターン上のパターン(Acoustic Word)を教師なし学習によって抽出し、それに基づいて識別を行う。学習の際にはwhiteningを行う。Acoustic wordを抽出した後、入力信号のセグメントから各Acoustic wordへのユークリッド距離のベクトルを作る(posteriogramみたいなものか)。係数の小さいところは0に置換してベクトルをスパース化する。従来のGMM-HMMでは、十分な性能が出ない。Whiteningは効果がある。スパース化を行うとちょっと性能が上がる。Acoustic wordの数は多い方が性能が上がる。・画像認識技術に基づく映像中のイベント検出(NII・佐藤真一)画像・映像認識タスク。何が写っているか、何をしているか、場所はどこか、何のシーン化などを計算機により解析する。従来のタスクでは、さらにこれをブレークダウンして「画像・映像意味分類」「物体検出」「画像・映像検索」「テキスト変換」などが行われる。画像・映像分類では、100～10000程度のあらかじめ決められたカテゴリに画像・映像を分類。物体検出では、あらかじめ定められた物体を画像・映像中から検出して場所を特定する。画像映像検索はクエリから対応する画像・映像を見つける。テキスト変換は、画像や映像を説明する自然言語を生成する。画像の特性。前の物体は後ろの物体を隠すので、本質的に非線形の扱いが必要。画素・部品の絶対位置はあまり意味をなさない。照明条件、物体の姿勢、背景などを無視しなければならない。画像認識処理の主な流れ。局所特徴量(SIFT,DenseTrajectoriesなど)を抽出し、Bag of Wordsを作ってSVMなどで識別。画像認識におけるコンテキスト。車の認識器を学習させると、道路を検出していたりする。また家を識別しようとすると周囲の植え込みを認識する識別器ができることがある。これらの情報はコンテキストとよばれ、物体認識を助けると考えられている。データ収集。音声の場合は収録ができるが、画像の場合には自分でデータを作成することが難しいので、既存の画像・映像から収集して利用する。「タスク指向データ収集」はタスクを決めて(識別クラスなど)からデータを収集する。COIL-100, Caltech 101/256 データセットなど。「無背景」や「姿勢正規化」などの制約を与えて問題を簡略化している。PASCAL VOCやImageNetはより難しいタスク。全体としては問題が簡単になりすぎる傾向がある。「データ指向データ収集」ではタスクと独立にデータが選ばれている(TRECVIDなど)。こちらは逆に問題が難しくなりすぎ、何の問題を解けばよいのかわかりにくくなりがち。正解の付与を行う場合に、タスクがないので0から正解を付与する必要があり、判断に迷うこともある。厳正な評価のために。テストデータを開発者からいかに隔離するか。PASCAL VOCでは評価データの正解は公開されず、サーバに評価結果を送ると正誤判定だけが返ってくる。TRECVIDでは評価データを公開正解は参加チームの結果提出後に公開。スペシャルセッション音声A/音声B/電気音響［音によるシーン理解とその進展 II］・Detection and classification of acoustic events using multiple resolution spectrogram patch models (NTT)音響イベント検出において、音響イベントごとに時間・周波数解像度がどのように影響するかを調べ、複数の時間周波数解像度によるスペクトログラムパッチを使う方法を提案。スペクトログラムのセグメントを使ったDNN-HMM(オートエンコーダによるプリトレーニング)を識別器として利用。複数の時間周波数解像度によるスペクトログラムを計算して、イベントごとに精度の高い解像度の特徴だけを選んでそれぞれ識別し、その結果を統合して最終結果を得る。・イベント遷移を考慮した音響トピックモデルによる欠損を含む観測からの音響シーン推定(NTT)井本さん。不特定多数のユーザによって適当に収録された音響コンテンツを対象に音響イベント検出をしようとすると、タッピングノイズなどの雑音によりデータに欠損が生じるので、それへの対処。音響イベントから音響シーンを推定する手法として音響トピックモデルを利用。欠損の補間方法として、音響イベント系列の生成をHMMでモデル化し、観測されなかったイベントはHMMから生成する。さらにイベント生成をHMMとした音響トビックモデルの導出。従来法では欠損があると性能が大きく下がるのに対し、提案法では欠損があっても性能が下がらない。・クラウドセンシングにより収集された環境音のシンボル表現を用いた音地図構築手法(岡山大)原先生。環境音の感じ方は物理量だけでなく時間帯や場所、人による影響もある。将来的にそのような研究に役立てるため、今回は時間・場所の情報を持つ大規模な音環境データベースを作成した。環境音収録アプリをAndroidで収録。音そのものと8帯域BPFの出力値を収録。騒音レベルは常に収録し続け、音そのものの収録はデバイス保持者が手動で行う。実際に音を収録する実験を行い、騒音レベルを地図に重ねてマップを作った。また、人鳥虫車風の音の識別実験を行った。識別はGMM-UBM。F値で0.5くらい。・車両の自動検出と分類—都市センシングを目指して—(TOA)音と振動から車両の検出と分類を行う。状況は車が1台だけ走行している状況を仮定。識別タスクは乗用車vs.トラック。特徴量にはTDSC(フレーム内の波形の局所最大値と局所最小値、ゼロクロス間隔などから計算)を使う。分類では音よりも振動を使ったほうが性能がよく、両方を組み合わせることでさらに性能が上がる。最後に都市センシングの構想について。・Speaking-face detection for multimodal person recognition in TV shows (岐阜大)田村先生。TV映像中の人の認識。音声・映像中の顔や文字などの情報を統合して人の認識を行っていく。そのために、発話中の顔の認識を行う。映像中から顔を検出してそのシーケンスを作成し、シーケンス内の各画像について高次局所相関特徴量を計算する。音声については通常の39次元特徴量を用いる。識別器はGMM。正解精度76%ぐらい。スペシャルセッション音声A/音声B/電気音響［音によるシーン理解とその進展 III］・運筆音を利用した手書き数字認識(三重大)表題の通り。対象は数字0～9で、手本をなぞり書き。認識方法はHMM(状態数は書いている時間に比例)。特徴量はMFCC+Δ。ΔΔは使っても性能が上がらない。認識率85%ぐらい。0と6、4と5などの誤認識が多い。・ロボットのための音シーン理解技術の実装例(大阪産大)マイクロホンアレイで複数の音源の内容を収録し、方向推定によって音源方向を特定。音源にビームを向けて特定の音源の音を収録し、また音源方向にNULLを作ることで背景音を収録する。収録後、言語音だったた書き起こす。プラットフォームはRobovie。マイクロホンアレイにはMEMSマイクを使っている。・多重衝突音のパワー包絡を用いた危険音検出の検討(立命館大)監視カメラで音を取って危険な音を検出する。従来はMFCC+HMMによる識別だったが、今回は危険音、特に衝突音が短時間に繰り返し発生する音(多重衝突音)に有効な特徴量を検討。これらの音は「椅子が倒れる」とか「物が落ちる」に対応する。研修に有効な特徴量として、時間波形のパワーの包絡を利用した。識別はパワー包絡を特徴量としたGMM。GMMをフレームごとに構成するので、認識対象は固定長である必要がある気がする。パワー包絡だけだと単発音(コップを置く音など)との識別が難しいので、最初にヒューリスティックに単発音かどうかを判定し、その後識別を行う。・反復スペクトル減算のための連検定に基づく雑音環境識別(立命館大)音声強調のために重み付き反復SS(L-SS)を用いてミュージカルノイズを抑えながら雑音を抑圧する。その性能を上げるため、雑音環境ごとに異なるSSパラメータを利用する。Kurtosis比からミュージカルノイズが出ているかどうかを判定し、ミュージカルノイズが出ない程度の反復回数にとどめる。実験の結果、定常雑音と非定常雑音ではパラメータの値が大きく違う。そこで、雑音が定常的なのかどうかを判定するために「連の検定」を利用する。この方法で高精度に定常・非定常判定ができる。・ユビキタスセンシングに基づく日常生活行動データベースの構築(名古屋大)西田先生。COI STREAMのプロジェクト。高齢者の生活行動のセンシングと見守り。生活行動の認識を行うための基礎データとして、実環境を対象にした72時間連続での日常生活行動データベースを構築した。収録したのは映像、音(小型カメラによる)、加速度、角加速度、位置、地磁気(スマホによる)。集めたデータをタグ付けした。各行動での音声対数パワー分布が示されたが、行動によって結構違う。また、13の行動パターンの認識を行った。処理単位は1分、音のMFCCと加速度の平均+標準偏差。識別はGMM。評価データ以外をすべて学習に使うと、約90%の精度。・うっかり者を手助けする環境音認識アプリの開発について(和歌山大)環境音認識システムROCKON。歩きスマホ中に周囲の環境音を認識してユーザに知らせるというアイデア。実際の消防車の音は認識できたそうだ。認識システムの評価として、AdaBoostとHMMの性能比較を行った結果、HMMよりもAdaBoostの方が性能が高かった。データはAndroidアプリを自作してクラウドソーシングで集めているそうだ。
音声B［HMM音声合成］・HMM音声合成のための系列内変動を考慮した高速スペクトル強調法の検討(東北大)能勢先生。生成パラメータがなめらかすぎることに起因するHMM音声合成の自然性低下を防ぐため、従来は大域分散(GV)を制御したパラメータ生成が行われている。しかしこの方法では文によってパラメータ分散が変動せず、また計算コストが大きい。提案法では単純に生成パラメータの分散が自然音声に近くなるようにパラメータを定数倍するだけの簡単なものだが、うまくやれば単純な操作で品質を改善できる。・HMM音声合成における加算モデルに基づく任意話者への感情付与法の検討(東芝)大谷さん。感情付き音声を合成するには学習話者の感情付き音声データが必要なのだが、それがない話者の音声を元にして感情音声を合成する方法。様々な話者のさまざまな発話スタイルの音声パラメータを「基本バイアス+さまざまな要因によるバイアス+変動」で表現し、基本バイアスの部分を適当な話者の平静音声にすげかえると、その話者の別感情の音声が合成できるという仕組み。・H/L型アクセント推定と音響モデリングを統合したHMM音声合成の検討(名工大)合成用テキストのモーラ毎にHかLかをCRFで推定する。またCRFで推定したアクセント高低を元にHMMを学習する。ルールベースのアクセント推定よりも高精度。・因子分析に基づくHMM音声合成における基底クラスタリングの検討(名工大)音響パラメータを因子分析による基底の重ね合わせで表現し、基底の重みを変えることで発話スタイルを制御する。基底はコンテキスト毎に必要だが、それだと数が多いので複数コンテキストで基底を共有する。・日本人英語音声合成における話者性を保持した韻律補正(奈良先端大)クロスリンガル音声合成(日本人の個人の声質で英語音声を合成する)。適応データとして従来は日本語発話を使っていたが、今回は日本人英語を使って英語音声用HMMを適応する。ここですべてのパラメータを適応すると合成音声も日本語っぽい英語になってしまうので、状態継続長と対数パワーの分布はそのまま使って、それ以外のパラメータだけ適応する。デモは確かに英語の上手さが向上しているのだが、同時に「発話の個人性って何だろう」とちょっと考えてしまった。音声A［対話・マルチモーダル］・対話システムにおける応答選択法の検討(奈良先端大)非タスク遂行型の対話(雑談など)を用例ベースで行う。対話の「快適度」を指標として発話の選択を行う。「快適度」を付与するために、入力発話への自動応答に対してユーザーが「コメント」を与え、それを元に快適度を付与したコーパスを作る。コーパス収集ではシナリオを想定。快適度をリッジ回帰により推定する。特徴量は過去の快適度、コメント発話が行われたかどうか、コメント発話の単語ベクトル。また、応答文選択では協調フィルタリングの手法を使う。・対話中の音声言語特徴量に着目した嘘の検出法と日英間比較(奈良先端大)音声を使った嘘の自動検出。利用したコーパス(日本語偽言コーパス)では、対象者が特定の項目に対して嘘を言うように設計されている。収録音声に対し、嘘かホントかの識別を行う。識別木はbagging。音響特徴量・言語特徴量・個人性を使う。チャンスレートを上回る性能が得られた。有効な特徴量を日本語と英語で比較。日英ともに有効なのはF0の中央値、母音継続長、最終フレームのパワーなど。言語的特徴は日英でだいぶ差がある。・多人数会話における音響情報と視線情報の確率的統合による話者区間検出(京大)スマートポスターボードを使ったマルチモーダル会話コーパスを利用して、音と視線情報(実際は顔向き)から発話区間を推定する。特徴量はMUSICによる音源方向推定結果(MUSICスペクトル)、視線配布(何をみているか)、視線状態(向き合っている人がいるか等)。識別として、音響と視線が同時確率になるか独立になるかで3種類のモデルを比較。結果、従来のモデルよりもEERが改善した。今回の特別講演はクリプトン・フューチャーメディアの伊藤社長。知っている内容が多かったが、初音ミクを取り巻く現象と世界展開についてよくまとまった内容だと思った。音楽音響［音楽情報処理I]・音圧関数のZero Level Crossing 密度による低周波スペクトル(福岡教育大)1/fゆらぎとかの話を続けている三谷先生。相変わらず何が目的なのかよくわからない。音の高さとゼロクロスの関係がどうなっているのか調べているようなそうでないような。・音色の視覚化による演奏支援の試み−フラクタルアートを用いた音色の視覚化−(松江高専)楽器の音色の視覚化。対象はクラリネットのロングトーン。調波成分の基音と倍音の比、高調波成分の大きさなどを特徴量として利用。「エスケープタイム・フラクタル」アルゴリズムを使ってフラクタルアートをリアルタイムに生成する。演奏支援として、お手本が描く図形と同じになるように自分の演奏音を変えるよう練習する。特徴量をグラフ化した場合よりも練習による改善が大きいということだけど、音の練習をするのに音を聞かせないで図だけ見せることにどういう意義があるのだろう。・補助情報を用いた混合音楽信号操作における様々な音源制御に関する検討(東北大)うちの研究室の西野君。補助情報を使って混合音中の特定の音の音量だけを変える。今回はさまざまな楽器について提案法の効き具合を調べた。管楽器などだとよく効くが、バイオリンのピチカート奏法など非調波成分が多い場合はうまくいかない。「F0情報を送るぐらいならMIDIデータをそのまま送信して手元でならしたらいいんじゃないの」という山田先生のコメント。・押し込み可能なデバイスを用いたコンプレッサの操作齟齬を解消するインタフェイスの検討(東京工科大)コンプレッサの物理インタフェース。3Dマウスを使い、ボタンを押し込むことでコンプレッサの閾値を下げることができる。実装はMAX。「押し込み感」ってそんなに大事なの?・ジョンソンSU分布を用いた確率モデルによるオクターブ和音の認識(三重大)和音認識。基本的にはGMMによる和音認識を行うが、調波成分のモデル化にガウス分布ではなく歪度・尖度も制御できるジョンソンSU分布を使う。倍音の番号毎に異なるパラメータで分布を表現し、パラメータはEMで学習する。また単音モデルを学習しておくことにより、オクターブ違いの和音を認識する。GMMとの比較ではだいぶ良い性能を出しているようだ。ポスターセッション 音声A・B(聞いたものだけ)・音声への情報ハイディングを用いたアバタの口唇・表情制御の検討(東北大)うちの研究室の齋藤くんが発表。Kinectでユーザの表情と口の開きを取って、その情報を音声信号にハイディング。再生側では情報を取り出してLat式ミクさんが口パクをするというシステム。受けはどうだったんだろうか。・HTML5による音声入力ウェブアプリケーションの開発キット(和歌山大)西村先生。HTML5ブラウザを使って、分散音声認識を簡単に記述するためのキット。きみも今すぐ http://w3voice.jp にアクセスだ!・感情ラベル付き会議録自動作成のための笑声・関心の自動検出(豊橋技科大)秋葉研。会議の録音から「笑声」「話笑い」「関心」を検出するという、へえうふふ検出。うふふは比較的良いがへえは再現率が低い。・自由発声した情報要求に含まれるキーワードの音響・言語的特徴の調査(豊橋技科大)秋葉研。音声検索のためのキーワードの「検索貢献度」というのを定義して、それが音響特徴と相関しているかを見た。いまいち関係なし。・音声入力によるスタンプ描画インタフェースの類似度の検討(東京工科大)相川研。音声によるオノマトペ入力からLINEスタンプを検索するらしい。オノマトペとスタンプのマッピングをどうしてるか興味があるが、聞けなかった。・音声認識結果を学習文に用いた認識誤りに頑健な発話トピック推定手法(日立)カーナビへの音声入力からトピックを推定するときに、認識誤りに対応するために、入力音声の自動書き起こしをトピックモデル学習に混ぜる。・フレーミングに基づいた協調的説得対話方策の強化学習(奈良先端大)説得対話だが、あらゆる現実を自分の方にねじ曲げるだけでなくユーザにも歩み寄り。ポジティブ・ネガティブ表現を混ぜた推薦的(?)発話(フレーミング)を混ぜるところがポイントらしい。対話制御はPOMDPだが、こういう複雑な意志決定のために十分なデータ量がある気がしない。・Deep Learningによる教師つき適応の結果を用いた日本語講演音声の誤り解析(山形大)小坂研。DNN-HMMにさらに話者適応をして、それでも残っている誤りは何なのか調べた。半分ぐらいは同音異義や同じ発音で別単語系列になっているもので、ここまでくると音響モデルでは限界が来たって感じ。・HMM歌声合成における決定木に基づくコンテキスト削減の検討(東北大)うちの研究室の松本君。HMMの状態クラスタリングを改善するために有効コンテキストを選んだ。客観指標はちょっとだけ改善。・顔特徴量を用いた合成音声のスタイル制御の検討(東北大)うちの研究室の畢君。重回帰HSMMによる音声合成の感情制御のスタイル入力に顔画像を使う試み。あまりうまくいってないのはテストに使った畢君の顔のせいもあるかも。・歌声の地声—裏声変換のための基本周波数とスペクトル傾斜の操作(金沢大)声区の変換。F0とスペクトル傾斜をいじると地声と裏声の感じを変化させることができる。難しい操作なのかと思ったら、そうでもないようだ。・歌唱熱唱度の言語依存性に関する研究(東北大)うちの研究室のハオ君。日本語と中国語の歌唱について、日本語と中国語のネイティブ話者が感じる熱唱度に違いがあるかどうか。現在は各評価者間の相関に言語差があるかどうかだけ見ているが、もうちょっと分析手法に検討の余地がありそう。19時から懇親会。ノースアイランドビール http://www.2002cb.co.jp/ から4種類のビールが大量供給。全種類飲むだけで酔っぱらってヘロヘロに。出し物はオキさんによるトンコリ演奏 http://www.tonkori.com/ 。想像以上にロックな音楽だった。
スペシャルセッション「音楽と音のデザイン」1・音楽と音のデザイン(岩宮眞一郎)スペシャルセッションの趣旨説明と企画全体の概略。従来の音楽伝達(楽譜演奏家演奏場聴衆)では「音づくり」の過程はなかった。しかし現在のポピュラー音楽では、音の加工・編集などの音づくり(デザイン)が不可欠。現代音楽の世界では、調性が従来のクラシックから変化し(ミュジック・セリエルなど)、またミュジック・コンクレートや電子音楽など音楽素材が拡大してきている。演奏者は自分で音から作るようになった(新しい音、おもしろい音の追求)。そのため音のデザインが重要な要素となった。さらにコンピュータによる「音場のデザイン」、メディアアートのような芸術とデザインの境界分野、インタラクティブ音楽のようなものも一般的になってきた。いずれもテクノロジーの発達と深い関わりがある。・音楽制作における音づくりとミュージシャンにとっての音(布施雄一郎)音楽テクニカルライターの人。元ローランドの技術者。現代ではポピュラー音楽は全リリースタイトルのおよそ2/3。ポピュラー音楽の音には、楽器の選択、音づくり機材(アンプ、エフェクタ)の選択、録音方法、ミックス、聴取環境などの要因が関係する。すなわち、ミュージシャン・エンジニア・リスナーの3者がそれぞれ音づくりに関係する。(この講演では前2者に焦点を当てる)エンジニアの音づくりには、「できるだけ生に近い(補正的)音づくり」と、「積極的に音を加工する」音づくりの2つがあり、ポピュラー音楽では後者が主流。90年代に入ると、PCM音源が発達し、音色数が膨大になり・デジタルエフェクトなどのツールが多様化する。ここから、「音づくり」から「音選び」へと作業が変質する。これまでの取材では、ミュージシャン・クリエーターはみんな「いい音」を作りたいと言うが、「いい音」の解釈は様々。いい音には「生に近い」「音のクオリティ」「音の好み」などの解釈があり、ミュージシャンの多くは「いい音」を「好みの音」という意味で使っている。バンドの演奏では、そのままでは互いにじゃまをする帯域があるので(アコースティックギターの中音域など)、録音の際には調整が必要になり、生の音とは全く違う音が「原音」として記録されている。若いミュージシャンには、音色や帯域などだけでなくさまざまな挑戦をしている人たちがいる。たとえばサカナクションやSEKAI NO OWARIはバイノーラル録音の音楽をリリースしている。また実ホールでの録音、心臓音や花火などのサンプリングなどを利用している。これらは技術的には新しいものではないが、ミュージシャンが技術を利用することによって一般のリスナーに認知されつつある。ライブ音響は最近大変改善している。音響的には最悪な東京ドームなどでも、かなりいい音で演奏ができるようになってきている。ライブの音響は、一般的なポータブルオーディオに比べて良い音楽体験を提供していて、最近はライブを見てからCDを買うという消費行動の人が増えている。ハイレゾオーディオについて。従来はオーディオマニアのものであったが、昨年SONYがハイレゾ対応ウォークマンを発売したことで状況が変わりつつある。MORAの会員はハイレゾ対応後に急増していて、しかも20代・30代が増えている。今の若い人は生まれたときから圧縮音源しか聞いていないので、ハイレゾの音は新鮮だったのかもしれない。ミュージシャン主導でハイレゾを主導する動きやハイレゾ対応ウォークマンの新製品などもあり、新しい動きがありそう。ハイレゾは「音の良さ」を一般の人にアピールするために良い機会。・ポピュラー音楽における和音進行デザイン(三浦雅展、櫻井美緒、江村伯夫)セッションの中で唯一招待でない発表(乱入)。SerraらのMillion Song Datasetによる研究では数十年前からコード進行は変わらないということであったが、それが本当か詳細に調べた。1960年代からの音楽が対象で、XFフォーマットのMIDIデータ中のタグに含まれるコード名を調査した。孤立コードは全パターン中の約89%が出現。2コード進行や3コード進行は全パターン数より遙かに少ないが、年代ごとに種類数は増加している。コードを個別に見ると、I,V,IVなどのトライアドが最多で、2000年代には1970以前には見られなかったコード進行(一時転調、古典和声から外れたものなど)が出現する。また各年代によって好まれるコード進行がある。4音以上からなる和音はほとんどが7thだが、それを除くと1970代以前はあまり出現しなかったのに対して2000年代には頻出する。音声B［感情音声］・Study on perceived emotional states in multiple languages on Valence-Activation space (JAIST)異なる言語での感情の知覚にどういう差があるかを調べる研究。対象は中国語・日本語・ドイツ語で、評定者は日本人・中国人・ベトナム人。評価は興奮軸と価値軸の2次元それぞれで5段階評価。「ニュートラル」な音声の位置が3言語でわずかに違っている。それ以外の感情については、曲座標で見たときの角度は言語によらないが、ニュートラルからの距離は言語によって有意に異なっていた(中国語の距離が小さい)。・Valence-Activation2次元空間での感情表現に基づいた感情音声合成(JAIST)先週北九州で聞いたのと同じ話(だと思う)。V-A空間上の座標からSTRAIGHT分析された音声の感情パラメータを変換する関数を推定し、再合成した音声が元のV-A空間上の位置と同じところに知覚されるかどうか調べた。その結果、negative-inactiveの音声の自然性が低い。また、合成音はV-A空間上で意図した分布よりだいぶ原点に近づいている。・感情が聴取による話者認識に及ぼす影響−聴取結果の考察並びに韻律的特徴との比較−(上智大)人間による話者の知覚に感情がどう影響するか。評価法はABX法。平静と比べると、喜びの表情の認識性能が悪化し、悲しみ・怒りは上昇する。特徴的な話者がいると、その話者については認識性能が高い。勾坂先生からだいぶ厳しい意見があった。・単語アクセント型ごとのF0波形に着目した単語音声の感情変換(筑波大)宇津呂研。音声の感情の変換。能書きが長い。ある感情の話速とF0軌跡をアクセント型ごとに平均し、変換元音声の話速とF0軌跡を同アクセント型の目標感情のものと入れ替える。目標音声に十分近いかどうかの主観評価実験を行ったところ、結果は3.8/5。このあと「感情音声」研究について匂坂先生から厳しめのコメントがあり,フリータイムにディスカッションがあった.匂坂先生の意見にはおおむね同意.ポスターセッション音声A・B河原先生・篠田先生と立ち話をしていたらポスター見る時間がなかった.・エンマコオロギ(Teleogryllus emma)を誘引する為の疑似誘引歌の作成(国士舘大学)エンマコオロギの鳴き声の分析と,それをもとに人工的に合成した音でコオロギを呼ぶことができるかの実験.研究目的が「昆虫と会話すること」というところが実にロックだ.・音声の持つ感性情報のマルチモーダルな表現を目指した母音の聴覚印象による連想色の感性的分析(早稲田大)匂坂研.男性のさまざまなF0パターンの5母音を聞かせて,連想する色を答えさせた.F0の高さはおおむね色の明るさに関連していて,色相はF1-F2平面上の母音の位置と対応がつくらしい.聴覚・音声・話速とポーズが非母語話者の聞き取りやすさに与える影響(東北大)うちの研究室のハフィヤン君が発表。日本語に不慣れな外国人が日本語分を聞くときにポーズをどのように入れたらよいか。話速が適切であれば、すべての文節間にポーズを入れるよりも、構文的に部分木が切れるところにだけポーズを入れた方がよい。・聴取関連特徴に基づく非母語話者の促音聴取難易度推定(早稲田大)日本語非母語話者による促音の聞き取りの精度は発話速度や音韻のラウドネスに依存する。そこで、発話速度関連特徴(Onninn継続時間長など)、音韻のラウドネス、音韻特徴(摩擦音など)の回帰によって非母語話者の促音の正答率を予測する。・非負値時空間分解を用いた発話リズム変換の検討(NTT CS研)磁気センサで取った調音器官の動きを個々の音韻とその強さに分解する手法(非負値時空間分解)を使ってこれまで発話リズムを抽出してきたが、今回は音声信号のみから同様の方法で発話リズムを推定する。ここでいう発話リズムは分解によって得られたアクティベーションのことを指しているらしい。音声の特徴量はLSP。通常のNMFと違い、アクティベーションに単峰性を仮定する。ここで抽出した発話リズムをネイティブの発話リズムに置き換えて「本人の声で良いリズムでしゃべった音声」を作る。・残響を付加した音声に対する聴性脳幹反応による単語了解度の低下に関する検討(九大)聴性脳幹反応(ABR)は聴取した音の包絡に似た波形になることがわかっている。今回はさまざまな残響を畳み込んだ音声(親密度コントロール済み)を若年者と高齢者に聞かせ、単語了解度を測定したところ高齢者の方が単語了解度が低かった。次に残響を畳み込んだ音声を呈示してABRを測り、その振幅の実効値と単語了解度の関連を調べた。その結果、若年者については創刊がなかったのに対し、高齢者では直接音と残響音に対するABR振幅実効値の変化率が単語了解度と相関を持っていた(残響音に対するABR振幅が小さい方が聞き取りがよい)。変化率の違いには内耳の機能(外有毛細胞関連)が関係しているのではないかと考察。このあとウェルカム企画「ギターエフェクタによるサウンドメイキング術」.北大の青木先生と札幌在住のミュージシャン塚原義弘氏が掛け合いで話をしながらエフェクタの音作りを実演する.出演エフェクタはディストーション,ディレイ,トーキングモジュレータ,ワウ,フランジャー,コーラス,ルーパーなど.青木先生の掛け合いは相変わらず絶妙で,塚原さんの即興演奏は素晴らしい.これだけ自由に音を作りながら演奏できたら楽しいだろうなあ.
Seoul National University Session (1)Il-Young JeongVocal separation from monaural music using Schatten p-/lp- norm RPCA歌唱を含むモノラル音楽信号を歌唱と伴奏に分離する.RPCAはRobust PCAの略で,相関行列を低ランク行列とスパース行列の和に分解してPCAをかける方法のようだ.提案法はこれを一般化した方法のようだが,数学的には十分ついていけない.通常の伴奏のスペクトログラムは水平・垂直な線からなっていて,行列としては単純な形になっているので,行列を思い切り圧縮した後で残差を取ると複雑な形の部分(ボーカル)だけが残るという原理.RPCAでL1/L2 normを使っているところをShatten p-normに変えてpの値を振ってみたら少し性能が上がった.Kang Hyun LeeEnhanced IMM-based Feature Compensation using DNN加法性雑音に対する音声認識の特徴補償.IMM-based feature compensationは雑音を複数のカルマンフィルタで予測しながら,それを除去する線形フィルタをかけ続ける手法のようだ.複数のカルマンフィルタからの出力を混合し,混合したスペクトルが最もクリーン音声に近くなるように混合比を決める.「クリーン音声との近さ」の評価はGMM.提案手法では,GMMの部分をDNNに変えてみた.全体に性能が改善するが,条件によっては非常によく効く.JAIST SessionYasuhiro Hamada, Elbarougy Reda Elsaid and Masato AkagiPresenter: Yasuhiro Hamada ( PhD Candidate)Emotional Speech Synthesis Based on the Position of Emotional State in Valence-Activation Space感情の2次元平面(valence-activation)上の点を指定し,無表情な入力音声に感情を付加する.STRAIGHTで分析して得られた21種類の音響特徴(詳細不明)について,感情空間上の点との線形回帰を行う.そのモデルを使って音響特徴を変換して音声を再合成.主幹評価実験の結果,sadな音声の自然性が低かった.感情の知覚については,おおむね意図通りではあるが,程度は予定よりも小さい.合成に問題があるのか,評価者の点数づけに問題があるのかはっきりしない.Jessada Karnjana and Masashi Unoki Presenter: Jessada Karnjana ( PhD Candidate)An Audio Watermarking Scheme based on Singular-Spectrum Analysis入力音声をSVDによって分解し,特異値をいじって音に戻すことで情報を埋める.波形を直接SVDで分解すると,フーリエ変換に似たような波形の細かさごとの分解が行われる.それで,次数の大きい方の特異値の領域を選んで,最大値と最小値のどっちかに特異値を変えてしまう.MP3攻撃などに対しては頑健.Tohoku Univ. Tohoku Gakuin Univ. SessionShoya Yarimizu and Yukio IwayaPresenter: Shoya Yarimizu ( Masters course student)Perceptional evaluation of virtual sound fields different in threshold frequency of the spatial aliasing包囲型マイクロフォンアレイによる音場再現では高周波領域で空間的エイリアシングの影響が避けられないが,どのくらいの周波数まで空間的エイリアシングがあると聴覚的に問題なのかを主観評価によって調べた.音は全部シミュレーションで作ってHRTFを畳み込んでバイノーラル呈示.ABX試験で違いを調べてd'を計算したところ,エイリアシングが起きない上限周波数1kHzと2kHzはオリジナルと違うが,4kHz以上は区別できない.Yu Bi, Takashi Nose, and Akinori ItoPresenter: Yu Bi ( Masters course student)HMM-based style control of synthetic speech using facial featuresうちの研究室の畢君が発表.HMM音声合成の感情制御を顔画像からやろうという試み.Kinectで取った顔の特徴をPCAで圧縮し,直接重回帰HSMMに突っ込んで学習する.楽しい顔を見せると楽しい感じの音声が合成されるというわけだが,研究的にはまだまだ.Zeyu Hao, Takashi Nose, and Akinori ItoPresenter: Zeyu Hao ( Masters course student)Investigation of language dependence of singing enthusiasm熱唱度が言語依存かどうかの調査.「雪の華」の日本語版と中国語版を十数人の素人に歌わせ,それを評価した時に評価者の母語と歌唱言語によって熱唱度評価に差が出るかどうかを見た.中国人が中国語の歌を評価した時の方が,中国人が日本語の歌を評価した時の方が評価の一貫性が下がる.Chinese Academy of Sciences SessionJi XuCoalescence Type based Confidence Warping for Agglutinative Language Keyword Spotting膠着語の音声認識というのだが,何語がターゲットで何が問題なのかさっぱりわからん(質問したところ韓国語だそうだ).キーワードスポッティングの時に,信頼度を基準として単語検出を行うが,短い形態素は湧き出しが多いので信頼度を変換してから検出するという話のような気がする.Xin LiSubword-based Speech Recognition and Spoken Term Detection for Uyghurウイグル語の音声認識.ウイグル語は膠着語なので単語の認定が難しい.10万弱の語に対し,教師なし形態素分割を行う.それをつかって音声認識システムを構成した.「単語」を単位とした場合よりも,形態素や教師なし分割単位を使ったほうがやや性能がよい.同様にSTDをやった場合には形態素のほうが教師なし分割単位よりも高い性能.Seoul National University Session (2)Soo Hyun BaeAcoustic event classification in the office environmentオフィスでの音響イベント検出.特徴量はMFCC+Δ+ΔΔ+ZCC+spectral flux+etc.で,識別はSVM.多クラス識別のために,すべてのクラス間のSVMを学習する.また,何段階かで識別を行い,段階ごとに特徴量を変えるらしい.検出するのはコック,ドア音,拍手,咳,電話など.GMMよりも1%ほど良い.Ji Won ChoiModeling Human body effects for acoustic channels音場再生で再生時に(元の音場にはいない)人間がいることの効果.無線通信では人間の体をモデル化して(円筒形の導体として)扱っている.そこでこの研究でも音場の人間の影響を調べた.Tohoku Univ. SessionShu Kitajima, William Martens, Shuichi Sakamoto and Yoiti SuzukiPresenter: Shu Kitajima ( Masters course student)Sound localization of vowel sounds with different formant frequencies母音を刺激に使った音源定位実験.2つの母音を前や後ろから(仮想音響ディスプレイを使って)呈示して,方向を答えるタスク.2つの母音をどう方向から提示したとき,片方が/e/の場合に逆方向に知覚しやすい.理由はまだ不明.Shun Torai, Tomoko Ohtani, Shuichi Sakamoto and Yoiti SuzukiPresenter: Shun Trai ( Masters course student)Influence of irrelevant speech movie presentation on serial recall tasks数字発話を聞いてあとから思い出すタスクで,しゃべる内容と違う発話動画を見せるとタスクのパフォーマンスがどう変わるか.ターゲットの音声に関係ない音声をかぶせて,さらに「数字の発話映像」を見せた場合と「関係ない音声の発話映像」を見せた場合の比較.音声がかぶることでタスクの性能は下がるが,映像を見せることによる影響は見られなかった.Tomori Miyashita, Zhenglie Cui, Shuichi Sakamoto and Yoiti SuzukiPresenter: Tomonori Miyashita ( Masters course student)Effects of inter-word pauses on speech intelligibility of four-continuous-words under long-path echo condition防災無線でロングパスエコーによる聞き取りの悪化を防ぐため,単語間にポーズを入れる(エコーがポーズと重なって直接音との重なりが小さくなる)という提案.さまざまな遅延に対してポーズの長さをいろいろ変えたが,聞き取りの良さには統計的有意性はない.Arif Herusetyo Wicaksono, Jorge Trevino, Shuichi Sakamoto and Yoiti SuzukiPresenter: Arif Herusetyo Wicaksono ( Masters course student)Analyzing redundancies of spherical microphone array recording with crosscorrelation球形マイクロフォンアレイSENZIの信号圧縮のための基礎検討.200チャンネル以上ある入力信号の間にどのような相関があるか調べた.数百ヘルツぐらいまでは隣接チャネル間の相関が比較的高いが,それ以上だと相関は低い,
Keynote 3:Tracing back the processing history of multimedia contentProfessor Alessandro PivaUniversity of Florence, Italy私が座長.8時半スタートだったのだが,客が集まらなくて10分遅れでスタート.・テーマは「ビデオの処理履歴の追跡」.最初の例では,高圧縮ビデオをリサンプルして高品質コーデックにする(しかしビデオの品質は高くならない)とか.そのような処理履歴をどうやって知ることができるか.基本的な考え方としては,処理の際に生じるアーティファクトを手掛かり(フットプリント)として処理を推定する.・撮影時のフットプリント.デジタルカメラで撮影するときには,集めた光をRGBのフィルタに通した後で補間(demosaicking)をすることで得られる.その処理にメーカーや機種による差があるので,撮影したカメラがわかる.・符号化のフットプリント・編集のフットプリント.さまざまな画像処理・処理チェーン.さまざまな処理を順番に行う.Homogenious(トランスコードなど)とheterogenious(異なる処理を順番に適用)がある.これらの検出(処理されたことを知る)と推定(どのような処理が行われたか)がある.・Homogenious chains (JPEG/MPEG/MP3)・JPEGの場合.DCT係数を量子化するので,DCT係数のヒストグラムを見ると量子化ステップの整数倍にだけ値がある.2回JPEG圧縮をした時に,量子化が違っていたり,DCTブロックがずれているとそれがわかる.(ヒストグラムの頻度に2つの量子化ステップに依存した周期が現れ,ブロックがずれているとヒストグラムに周期が見られなくなる).そこで,JPEGをデコードした後に別な画像を張り付けてもう一度JPEG圧縮すると,場所によってJPEG圧縮回数が違うので,編集されたことがわかる.あるブロックが編集されたかどうかをベイズ推定で当てるDCTブロックがずれたかどうか(トリミングされたかどうか)を当てる・2つのJPEG圧縮の間にほかの処理が入っていた場合(今回はコントラスト補正).コントラストを補正すると,DCT係数のヒストグラムが持つ周期が変化する(ピクセル値の分布が変わるため).コントラスト補正の検出としては,元のDCTヒストグラムと,JPEGブロックのアラインメントをちょっと変えたときのDCT係数のヒストグラム(もう少しなめらかな分布になる)との類似度を使う.・オーディオ・ビデオの場合.MPEGの場合はJPEGと類似(二重量子化の検出).Iフレームの圧縮はJPEGとほぼ同じなのでJPEGの方法が使えるが,どのフレームがIフレームになるかは再エンコードした時にはわからない.そこで,再エンコードされた各マクロブロックが,前のエンコードでどのようなブロックだったのかを推定する.9:20-10:10Keynote 4Security and privacy challenges at border between cyber and physical worldsProfessor Isao EchizenNational Institute of Informatics, Japan・あらゆるシーンで実世界の情報がキャプチャされてサイバー世界にアップロードされる.それに伴うプライバシーや著作権の問題. 例:映画泥棒.人気映画は封切り後2週間ぐらいでビデオ共有サイトに海賊版が出回る. 例:ディスプレイキャプチャ.PCのディスプレイを撮影することで情報が漏えい.・いったん実世界を通してキャプチャされるとDRMは役に立たない・IR Hiding: 撮像デバイスには写るが人間には知覚されない信号を使う 近赤外線(near-infrared)LEDを使う 人間の視覚はは10Hz付近の時間変化に敏感(Bartley effect)なので,10Hzの信号を使う この技術のニュースリリース,ニュース映像を流す.映画泥棒の映像も流れる. IRカットフィルタへの対策.IRカットフィルタは赤外線を選択的に反射するので,IRカットフィルタがどの席で使われているかがわかる.・ディスプレイ撮影への対策 iCabinet.ハーフミラーでディスプレイ映像とIR信号を混ぜる. より小さいデバイスとして,LCDバックライトを使った薄いデバイスを開発.・顔画像撮影への対策 デジタルカメラによる(意図しない)顔撮影顔認識(Facebookなど)プライバシー侵害 撮影された映像からの顔検出(Viola-Jones)を邪魔する信号をIR-LEDで放出する装置(プライバシーバイザー),目の上と鼻の部分にLEDが仕込まれていて,Viola-Jonesで使うHaar-like特徴を攪乱する. 顔検出実験.何もしないと,20m以上離れた顔も普通のデジタルカメラ画像から検出できる. 現在はLEDを使わずメガネの反射特性だけを使ったプライバシーバイザーを開発中.レンズ部分が網みたいなものでできた白いメガネ10:30~12:00 Session D1: Signal Processing Methods for Music Information Retrieval in the Future InternetSession Organizers: Prof. Kyogu Lee and Prof. Akinori Ito次は私がCo-Organizerのセッション.D1-01 "A Singing Voice Synthesizer Controlled by Arm Motions Using Compressed Phoneme Determination Algorithm" by Masashi Ito, Tomohiro Ashina and Yujiro Saegusa腕の動きで歌声合成をする一連の研究の一つ.このシステムでは発音する母音を手の回転角度で指定するが,回転角の遷移と母音のフォルマント遷移が対応していないために不自然な発音系列になる.そこで.現在の回転角ではなく,回転角と角速度から予測される最終回転角度から発音母音を推定する.D1-02 "Analysis of English Pronunciation of Singing Voices Sung by Japanese Speakers" by KazumichiYoshida, Takashi Nose and Akinori Ito当研究室の吉田君が発表.日本人による英語歌唱の発音評価.自動評価が目標だが,今回は英語ネイティブ話者による評定の分析結果を発表.歌唱音声に特に起きやすい発音誤りの分析(語末子音の脱落など)と,英語ネイティブ話者/日本語ネイティブ話者による評定の一貫性の分析.日本人による英語歌唱音声の評定は日本人同士でも一貫性がなく信頼できない.また,歌唱経験者は歌唱音声の発音が未経験者に比べて良い.D1-03 "Assessing the Intended Enthusiasm of Singing Voice Using Energy Variance" by Akinori Ito私の発表.音声パワーの平均・分散のセグメントごとの平均と分散から,どのぐらい歌唱者が熱唱するつもりかを当てる.性能72%ぐらい.D1-04 "Transcribing Frequency Modulated Musical Expressions from Polyphonic Music using HMMConstrained Shift Invariant PLCA" by Dooyong Sung and Kyogu Lee複数楽器による音楽信号からの音楽表現(ビブラート,グリッサンド)推定.PLCA(Probabilistic Latent Component Analysis)はNMFの確率版みたいなやつ.SI-PLCAは信号を基底・シフト・アクティベーションに分解する.アクティベーションをHMMで制約することで音符を切り出す.表現に対応する.まだ識別まではいってない.D1-05 "On-line Nonnegative Matrix Factorization for Music Signal Separation" by Seokjin LeeNMFのオンラインアルゴリズム.式展開が完全には追えなかった.ある時間までの計算結果が,次のフレームでの計算結果に反映できる漸化式を導出しているようだ.応用としてモノラル信号から多チャネル信号を作る課題を扱っている.D1-06 "Melody Extraction for Vocal Polyphonic Music Based on Bayesian Framework" by Liming Song,Ming Li, Yonghong YanNo Show.13:30~15:20 Session E1: Technologies for Speech Communication in the future InternetSession Organizers: Prof. Yonghong Yan, Prof. Nam Soo Kim and and Prof. Masato AkagiE1-01 "Emotional Speech Recognition and Synthesis in Multiple Languages Toward Affective Speech-to-Speech Translation System" by Masato AKAGI, Xiao HAN, Reda ELBAROUGY, Yasuhiro HAMADA and Junfeng LI音声翻訳に感情認識合成をいれる試み.そのための多言語感情音声認識・合成について.感情を3層モデルで表現(音響信号プリミティブ感情).感情はactivation-valenceの2次元.E1-02 "Quantized F0 Context and Its Applications to Speech Synthesis, Speech Coding and Voice Conversion" by Takashi Nose and Takao KobayashiF0の値を量子化して教師なしでシンボル化し,その系列をコンテキストとして使う.応用は音声合成と音声符号化(認識合成によるボコーダ).E1-03 "Voice Activity Detection based on Statistical Model Employing Deep Neural Network" by Inyoung Hwang and Joon-Hyuk ChangDBNによる音声切り出し.全体的に従来法(ふつうの方法とSVM)よりもよいが,雑音が大きい場合,衝撃音が支配的な場合,未知の雑音の場合などで特に性能が上がる.E1-04 "Speaker adaptation using nonlinear regression techniques for HMM-based speech synthesis" by Doo Hwa Hong, Shin Jae Kang, Joun Yeop Lee and Nam Soo KimHMM音声合成の話者適応に線形回帰ではなくカーネル回帰の一種MPLKR(Maximum Penalized Likelihood Kernel Regression) を使う.ガウシアンカーネルを使った時にMLLRよりもほのかに改善.E1-05 "Boosted Hybrid DNN/HMM System Based on Correlation-Generated Targets" by Mengzhe Chen, Qingqing Zhang, Jielin Pan and Yonghong Yan代読.DNN-HMMの話だが,1999年に3層NNでいまいちだった方法のリベンジらしい.方法がよく理解できなかったが,HMMの状態間の相関(何の?)を見て,似ているものを共有するという話のような?E1-06 "Enhanced Out of Vocabulary Word Detection Using Local Acoustic Information" by Xuyang Wang, Ta Li, Pengyuan Zhang, Jielin Pan and Yonghong YanSTDの話.Confusion networkでインデックスされた音声文書の検索.OOVがあった場合にサブワードで探索するのだが,その時に言語スコアを無視して音響スコアだけを使うという話?よくわからない.15:40~17:10 Session F1: 3D Spatial Audio Technologies in the Future InternetSession Organizers: Prof. Yoiti Suzuki, Prof. Li Junfeng and Prof. Seong-Cheol KimF1-01 "Virtual Auditory Display by Remote Rendering Via Computer Network" by Yukio Iwaya, Makoto Otani, Takao Tsuchiya and Junfeng Li岩谷先生.ネットワーク越しにデータが転送できる仮想音響ディスプレイ(ヘッドホン利用).リモートで音源にHRTFを畳み込み,アンドロイド端末で再生.通信はHTTP.条件によってはリモートで畳み込んだ方がローカルより速い(マシンが速いので).全体としてはローカルでレンダリングした場合と同程度.F1-02 "Effect of Interaural difference for localization of spatially segregated sound" by Daisuke MorikawaITD・ILDの違いと「音源が分離できるかどうか」を調べた基礎的な研究.ホワイトノイズの音源2個を異なるILD・ITDで呈示して,音源の数を答えさせるタスク.音像が離れれば離れるほどよい,というものでもないらしい.左右に同程度離れているより,中心ともう片側に離れている方が分離がよい.F1-03 "Representation of individual HRTFs using weighting coefficients of SENZI" by Shuichi Sakamoto, Yoshiki Satou, Jorge Trevino and Yoiti SuzukiSENZIは球の上にマイクロフォンが250個ぐらい張り付いている集音装置.ここで録音した多チャネル信号を重みづけして加えることで,HRTFを畳み込むのと同じ効果を得る.この時のマイクロフォンへの重み係数を見るとHRTFそのものより単純なので,重み係数の方をHRTFの個人性の表現として使おうという提案.また係数を球面調和関数ドメインで表現.F1-04 "Feasibility Study for Objective Measurement on Sound Localization Using Auditory Evoked Potential" by Chan Jun Chun, Seok Hee Jeong, Jong Won Shin, Hong Kook Kim and Jin Ah Kang音源定位の客観評価(機械が音源定位するのではなく,人間がどう音源定位しているかを機械的に測る)の提案.被験者にさまざまな方向からの音を聞かせて脳波を測り,それを周波数分析した.その結果α波に近い領域(8～10Hz)にピークが見られた.その他,どの方向から音を聞かせるとどの位置のどの周波数に影響があるか,など.F1-05 "Auralization of musical instruments in virtual halls considering source directivity" by Park Kyoungsoo, Jeong-Hun Seo, Kim JeungHun and Cheon Sung Jun発表時に大掛かりなデモをやって大変そうだった.仮想コンサートホールの話.ホールの室伝達関数だけでなく,各楽器の音響放射特性も関係する.各楽器を平面上の包囲型マイクで録音し,包囲型スピーカーで再生.ソウル大のホールの伝達関数を畳み込んだもののデモがあった.後で聞いたら,この時持ち込んだスピーカーからアンプまで全部自作なのだそうだ.F1-06 "On the Performance and Robustness of Crosstalk Cancelation with Multiple Loudspeakers" by Xing Yang, Risheng Xia, Zhonghua Fu, Junfeng Li, Yonghong Yan, Shuichi Sakamoto and Yoiti Suzukiトランスオーラル再生のためのクロストークキャンセル.スピーカー2個でキャンセルする方法と3個でキャンセルする方法の定量評価.(当然だが)3個でキャンセルしたほうが性能がよく安定性もよい.
aitoの日記 | スラッシュドット・ジャパン
