本文では,音声認識結果に基づく新たな特徴量を定義し,その特徴量を用いてシーン分割の高精度化を行う手法を提案する.提案手法では,処理対象映像中の固定長の小区間において,音声認識結果から得られる単語の出現分布に基づき新たな特徴量を定義する.さらに,この特徴量を用いることで算出される区間同士の類似度を話題の類似度として定義する.この話題の類似度の時間変化から話題が切り替わるおよその時刻が検出されるため,その時刻に注目することで,既存のシーン分割手法との併用によりシーンカットの過剰検出を抑制することが可能となる.その結果,従来よりも映像の内容に基づいた高精度なシーン分割が実現される.
This paper proposes an improvement method for scene segmentation which uses new features defined from speech recognition result. In the proposed method, the new features are defined based on the appearance distribution of terms in fixed-length short segments of video materials. Furthermore, similarities between two segments are calculated from the obtained features as similarities of topics. Then, the changes of topics are detected from the time transition of the similarities, and the problem of over segmentations caused in the traditional methods can be alleviated by combining both their methods and our method. Finally, the proposed method realizes accurate scene segmentations based on the topics of video materials.

