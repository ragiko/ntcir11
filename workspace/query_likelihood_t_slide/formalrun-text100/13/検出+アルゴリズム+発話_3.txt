人間どうしの会話のマルチモーダルなセンシングヤアノテーションを指向して、雑音下において頑健に発話区間を検出する方法を提案する。本手法は、LPC残差の高次統計量と自己相関関数を組み合わせた特徴量に基づいており、オンライン版のEMアルゴリズムによって学習・分類を行う。展示会場においてウェアラブルデバイスによって集められた会話データに対して評価を行った結果、(1)提案する特徴量によって、背景発話などに対して頑健に検出できること、(2)オンラインEMアルゴリズムによって、リアルタイムに学習・適応が可能なこと、がわかった。提案する特徴量は、計算量も小さく、処理遅延も少ない。
This paper addresses the problem of segmenting audio data recorded with embedded devices for the purpose of intelligent sensing in the context of multi-modal interactions. We propose a real-time method for robust speech detection in natural, noisy environments. It is based on a fusion of high order statistics of the LPC residual and autocorrelation, and adopts an on-line version of Expectation Maximization algorithm for the classification. Experimental evaluations show that the proposed method provides better detection performance under different types of natural noises, working robustly against other voices in the context of multi-speaker interactive situations. As the proposed method is based on features which have a low computational cost, and has a small latency, it is suitable for real-time tracking applications.

