・音声認識誤り検出のための相対的意味信頼度(NEC)コンフュージョンネットワークを使った単語信頼度推定手法だが、通常のような事後確率ではなく、ネットワークの各単語位置ごとに周囲の単語コンテキストから単語を識別する識別器を学習し、それを使って信頼度を推定する。認識される文の単語数分だけ識別機の学習をするという富豪的方法。・話者や発話固有の特徴の違いに注目した認識性能の個人差の要因分析(静岡大)さまざまな特徴(話速、母音間距離、構造歪など)から個人ごとの音声認識性能を予測する試みだが、いまいちうまくいかないので、ある認識精度より高いか低いかを識別してみた。その結果から、各特徴量で見る優劣と最終的な認識性能の高低の関係を調べた。目的がよくわからなかったが、声を聞いただけでわかるわけではない特徴(話者適応したあとのHMMを使う特徴とか)があって、もっと直接音声だけから観測される特徴を使ったほうがいいのかなと思った。・会話分析タスクにおける複数人自由会話の遠隔発話音声認識の評価(NTT)堀さん。ミーティング音声認識で、遠隔マイク(距離1m)で収録した音声に各種信号処理を行なって、どの程度認識性能が改善するか調べた。NTTグループの持つ信号処理(残響除去、ビームフォーミング、ブラインド音源分離、雑音抑圧)と話者適応を全部入れると、ピンマイクよりは認識性能が上がり、ヘッドセットマイクに近い性能が得られる。NTTならではのデラックスな手法。・Chinese Language Model Construction by Collecting Style-dependent Texts from Web Data (NICT)胡さん。以前増村くんがやっていた話し言葉言語モデル作成と似た方法で中国語の言語モデルを学習してみた。ただしスタイル選択部分はナイーブベイズではなく、種になる話し言葉言語モデルを使ったパープレキシティにしきい値処理。ランダムに文書を選ぶ場合に比べてWERが半分ぐらいになる。・発話付与のためのEMアルゴリズムを用いた多対多アライメントの評価(奈良先端大)鹿野研。未知語に読みを与えるための準備として、文字素と発音の対応をとっておく必要があるが、その精度を上げるための方法。未知の文字並びに未知の読みがついている場合におかしな読みの割り振りになってしまうのを防ぐ。EMアルゴリズムベース。・非負値行列因子分解に基づく話題性を反映した言語モデルの構築(NHK)今井さん。言語モデルの話なのだが、NICTの堀さんと字幕の標準化の話で盛り上がっていた。企画上存在する機能(字幕が少しずつスクロールするとか)であっても非対応の受信機があるため、NHKでは実質的にその機能を使うことができないとか。・Juliusにおける複数言語モデルの検討(奈良先端大)鹿野研。トピックごとに言語モデルを学習し、それを汎用言語モデルと融合させたものを複数使って並列に音声認識を行う。やりかたは少々違うけど15年ほど前に盛んに研究された内容のような気がする。・クエリ拡張と音節認識の統合による音声ドキュメント検索(名大)武田研。通常のベクトル空間モデルによる検索と、音節連鎖のベクトル空間モデルによる検索を組み合わせる。さらに、ベクトル空間を TF-IDF ではなくバイナリ特徴にしたベクトル空間の結果も組み合わせると少し上がる。TF-IDFが最適ではない、ということを言っているような気がするが、それは結構昔から言われているんじゃないだろうか。・音声中の検索語検出における低出現頻度モデル集約(岩手県立大)石亀研。認識用のtriphoneで、出現頻度が小さいものを中心音素ごとに集約してしまうという話なのだが、それは単に従来の音素クラスタリングの変形ではないだろうか。それよりも、連続単語認識と音素ベースのSTDで性能が最高になる音響モデルが違うという話の方が興味深かった。何か理由があるのかな。・STDベース音声ドキュメント検索の索引付けによる高速化(豊橋技科大)秋葉研。音節bigramを使った高速なSTD。音節bigramによる索引付けでおおまかに発話を予備選択し、選ばれた発話に対してDPによる単語検出を行う。しかし後段のDPをやらなくてもそれほど性能が違わない。単語と音節bigramの索引だけを使う方法ともあまり差がないような気がする。・部分空間上の索引を用いた音声検索語検出における距離計算の厳密化(豊橋技科大)秋葉研。以前からやっているハフ変換を使う単語検出方法で、最終的に得られるスコアが音節ごとのスコアの累積になるようにアルゴリズムを変更。従来の簡易な方法よりも性能が向上した。
音響学会3日目午前 音声Aポスターセッション(聞いたものだけ) | aitoの日記 | スラッシュドット・ジャパン
