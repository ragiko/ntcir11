情報ベース機能の開発
マルチモーダル・情報ベース機能つくば研究室岡 隆一
開発の目的
私の担当している自己組織化情報ベース領域について、1997年度の成果を中心にお話していきたいと思います。まず最初に我々の技術領域の目的を話し、次に各分散研及びつくば研の昨年度の研究成果を話し、最後に結論を述べます。
全体的に何をやっているかというと、マルチモーダル情報の相互の要約検索システムを最終的には作りたいということです。ここでマルチモーダルと言っている内容は、テキスト、静止画、それから動画像です。それから音声もあります。それぞれのデータベースは基本的にはインデックスでラベリングはされていないものを想定します。テキストについてはもともと記号列ですが、テキストの全体を表すラベリングは行っていないということです。もちろん、静止画及び動画像についてはラベリングは行っていないものを用います。実世界の生のデータをいかにデータベースとして自己組織化させるか、そして自ら組織化しているデータの間で相互検索の機能を働かせることができるかということが課題です。図1を参照して下さい。
図1.情報ベース機能の開発課題 
まず研究の分担ですが、三菱電機の分散研とつくば研では、テキストの組織化と検索を行っています。日立の分散研とつくば研とでは、静止画の自己組織化を行っています。それからISS、昨年度まではISSと呼んでいましたけど現在はKRDLといいますが、そこではモーションイメージングの検索を担当しており、あとでご紹介いたしますが、モーションイメージの「要約」の研究を行っています。つくば研でも、モーションイメージングと音声の自己組織化を行い、音声と動画像の相互検索システムの構築を試みています。
音声からテキストへの変換に関しては、音声の話題の自動検出、それから単語認識を行います。それを介してテキストの検索するという研究がつくば研で進んでいます。テキストの中での検索も考えられ、静止画の中、それから音声、動画像の中でも自己検索が考えられ、次にそれらの間での相互検索が考えられます。この場合、例えば音声によって動画像を検索して、それから静止画へ行きさらにテキストにもいきます。このように全体が相互に行き来できるようにすることを目指しています。
三菱分散研で研究していること
では、研究成果の内容を順番にお話していきます。最初は、三菱の分散研の成果をお話しいたします。ここでは、簡単なサーベイという印象的説明にとどめたいと思います。詳しくは別途発表されます。
三菱では、自己組織化のデータベースを作るアルゴリズムを元つくば研出向者の豊浦さんが滞在中に私どもと一緒に開発しましたが、その自己組織化の方式について引き続き研究しています。
基本的に何をしているかというと、ネットワークの形に時系列データを自己組織化するということです。そのときに我々が提案したアルゴリズムがありまして、それはネットワークを作るときにノードとアークをいかに過去の構造、すなわちそれまで作ってきているネットワークの部分ネットを使いながら新たに作るかというための方式です。この方式を使って時系列データの大規模ネットワークを作る。ここでいう大規模とは、ノード数にして数十万から数百万の大きなものです。かなり莫大な大きさのネットワークになるのですが、そういうものを実際に使っていこうと思っています。豊浦さんが三菱に帰られて、そのネットワークのノードを文章から構文解析したものを用いて単語系列を作り、その単語をアークに対応させたようなネットワークを作って、この空間を視覚化しています。そのとき、文章がこの空間の中で任意に表現されることになります。このように表現された中にテキストを置きまして、人間との対話において、例えば指示操作などのヒューマンインタフェスを介し、現在自分がどういう物に関心を持っているかを指示し、それに近いテキストを表示したり空間の近くに持ってきたり、あるいは現在あまり関心のないものは遠くに置くようなことを通じて、良好な検索を行うシステムを開発されています。
日立分散研で研究していること
先ほど、日立分散研で静止画の検索システムを開発していると申しましたが、日立分散研の特徴は、静止画に関するキーワードが付加されているものを用いるということです。静止画の画像だけではなくて、単語が付加したものです。これをうまい具合にクラスタリングをします。このときに正準相関という手法を使っていますが、いくつかの空間軸で表された統合されたものにすることによって、静止画に付随する単語の相互の性質を検索において利用することができるものとなっています。また、視覚化を通じて現在どういうものが検索されているかを表し、それに関連したものを例えば手前に持ってきたりして、さらに検索を続行できるシステムが開発されています。
ISSで研究していること ISSにつきましては、同じく検索ですが、ここでは特に動画像の検索を中心に研究しています。特に動画像の中で例えば走っている汽車をビデオの中から取り出すというときに、その動きの特徴まで含めた画像の検索システムがなされるようにしています。また、動画像サマリーという形で、いろいろな動きのシーケンスを代表するようなフレームを取り出して作るというような研究もなされています。
つくば研で研究していること
次に、つくば研の研究状況を少しだけ紹介させてもらいます。先ほど申しましたようなIPM、インクリメンタル・パス・メソッドと呼んでいますが、これは言ってみれば時系列データを自動的にデータベース化する方式です。データベースは、相互結合ネットワークになります。現在、動画像と音声の自己組織化のデータベースを作るのに用いています。
簡単に申しますと、ノードとノードの間に静止画の動画像の中の1フレーム分が置かれるということです。実際は、この動画像自身はVQコードでされていますので、現実にネットワークの中でアークに対応する記号ノードというのはVQのコードが張りつくということになります。そういう時系列データを先ほどのネットワークに入力しますと、例えばニュース番組についてはこのようなネットワークができます(図2)。このネットワークの中に例えば、現在実験しているのは約6時間分のNHKの番組ですが、かなりの量の動画像データが1つの相互結合型のネットワークの中に納まるということになります。同様に音声データについてもIPMネットワークを作ります。ネットワークの中に、音声のクエリーを用いて音声を検索します。この場合のクエリーと言うのは、検索したいデータです。そのとき、音声のここでの特徴はスポッティングベースという形で、区切りのある検索クエリーを用いるのではなくて、たれ流しというか、例えばニュース番組でしたら1分間ぐらいの長いデータを検索クエリーとして用います。それを例えばこの1分間ぐらいのニュース音声のデータの中に類似しているものが、任意の長さで過去のデータのどこかにあるかを検索します。そうしますと、例えば、消費税という音声が1分間のクエリーの中に出てきたとします。この消費税という音声に自動的に近い表現の音声が音声ネットワークの中から探されます。この場合、過去のデータの中で例えば2個見つかったとします。つまり、消費税という部分が過去のデータの中に見つかったとします。そのとき消費税という音声が流れていたときの動画像を、これはスポット的になっていますが、動画像として取り出します。そうすると、同じ消費税という言葉が話される時、過去にはどんな画面が流れていたかということが検索できます。
図2.動画像と恩性の相互検索システム 
今は音声から動画像を検索しましたが、逆のこともできます。動画像を見せておきますと、その中の近い動画像の系列が過去のデータベースの中に見つかれば、そのときに話されていた音声を取り出すことができます。同じ時系列でも片方は動画像、片方は音声だというときに相互に検索が可能となります。現在これを数時間、4時間分ぐらいのデータについて実験して、かなりの検索性能が上がっています。ここではスポッティングベースという方法で検索が行われますので、入力についてはエンドレスにできます。例えばテレビの画面で1時間分の検索のクエリーを入れたときに、自動的にその区間を検出して過去のデータとのマッチングをしながら検索を行うこともできます。
さて、同じ自己組織化方式について言いますと、先ほどのIPMは時系列としての特徴を扱うものです。即ち、時系列の前後関係を取り扱っているのですが、データが例えば新聞記事とかインターネットのニュースになると、数百万とか数千万件の記事を相手にしなければならない。そういう場合には必ずしも単語の前後関係というよりは単語の2項関係を扱わないといけないのではないかということで、2項関係に基づく自己組織化のやり方を考案しました。この方式をギャラクシーと呼んでいますが、これに最も類似している手法は、数量化4類です。
日本の統数研で開発された数量化の手法の中に数量化4類というのがあります。数量化4類では用いる2項関係が親和度になっていて、その分散が一定の下でクラスタリングをしますと標本サンプルの適切な配置ができます。ギャラクシー法では、同じく親和度を用い、標本の配置座標の差分の評価を非線形にしたこと、それから標本分散について数量化4項では分散一定という条件でしたが、これを球の中の一様に分布するとしたことに特徴があります。こういう条件でクラスタリングをしますと、例えばこれは人工データですが、1000サンプルで各10個で1つのクラスタを作っているとします。親和度については、その大きさはクラスタ内では0と1の間での一様分布に従う値を当てはめていきます。それ以外のクラスタ間にはノイズということで、例えば0と0.1とか、0と0.2とかいうような間での一様分布の値を与えます。こうすると、多様なクラスタのサンプルができます。1000サンプルについては100のクラスタがあることになります。これのクラスタリングを数量化4類でやりまして、任意の10クラスタを取り出してみますと、だいたいこういう形になります。これはノイズが0.1、すなわちクラスタ間のコンフュージョンが0と0.1の一様分布であるという場合です。クラス内は先ほど申しましたように、0と1の一様分布です。こういうノイズのときには100個の中の10を任意で取り出すと数量化4類では区別できず集まってしまいます。これをギャラクシークラスタリングでやりますと、このように分散してきます。つまり分離していることが表現されます。人間の直感ではこういうクラスタが本来存在しているわけですが、数量化4類ではこういう形になって分離しない。しかし、ギャラクシークラスタリングの場合は分離するということで、クラスタリングとしては有効であると考えられます。
現在、この方式をニュースグループのfj.aiの過去の4000記事のそれぞれにChaSenというパージングによって、単語系列に分解します。その単語系列の中の単語がキーワードになります。このキーワードの2項関係を用いてキーワードの配置された空間を構成します。この空間の中での単語を結ぶパスが1つの記事の表現になるわけです。例えば1つの記事があったときに、その記事に近い記事というのはこのトラジェクトに近いところに存在するであろうということを利用して、検索システムを作ることができます。例えば、これはインターネットで現在公開していますが、検索文を入れますと、その4000記事の中から候補が出てきます。検索されたものをさらに入力として入れることができます。いずれにせよ従来のキーワードマッチング、あるいはベクトル空間ベースの検索システムより人間の直感に近い検索になるのではないかと考えられます。
現時点で使えるのは4000記事ですが、fj.aiの85年ぐらいから現在までの記事を約90%以上集めましたが、その統計は約230万記事になります。これは著作権の問題がないと考えられていますので、全部ギャラクシークラスタリングを行わせ、全記事の検索システムを公開する予定にしています。
これらの技術を総合すると、動画像を入れて、その動画像から音声を検索し、さらにその解の結果を用いてテキストを検索することもできます。このような実験をまもなく始めたいと思っています。
昨年度の研究の成果を含みますと、かなり有力な方法が形成されつつあるといえます。現在、少し研究が進んでいないのが、静止画とテキストの間の相互検索です。これをまともにやりますと任意の画像の理解になりますが、そこまではいくのは大変ということで、イグザンプルベースというか、画像とテキストが対になっているデータを用いてマルチモーダルにイグザンプルベースの考えを使ってこの研究を進めていきたいと思っています。この場合データベースとしては、画像に関しては数万から数十万ぐらい、テキストについては2または3000万ぐらいの個数のデータを対象として評価にかけたいと思っています。実際のリアルワールドを表わすには、もっと巨大なデータベースを対象に実験が可能でなければならないと考えます。
最後に、各分散研のテーマを先ほど挙げましたが、最終的な目標に達するためには、かなりお互いに協力していかなくてはならないと思っていますので、これからも協力関係を一層進めながらやっていきたいと考えています。 
RWC NEWS Vol. 13  Jan. 1999
