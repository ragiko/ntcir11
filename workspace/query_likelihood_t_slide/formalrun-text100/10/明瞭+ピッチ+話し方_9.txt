
上に述べたように、最近の音声合成技術はここ十年ほどの間に急速に進化してきました。現在では、情感を移入しようとする感情音声合成の研究・開発が各所で進められています。
十数年前はPCのハード、ソフトともに貧弱なため、音声合成をPCで手軽に試してみることはできませんでした。
ところが1994年 「C MAGAZINE 3月号」 という雑誌で、リコーのテキスト音声合成ソフト 
「VC2 Ver,3.3」 というプログラムが紹介されているのをみて、早速試してみました。このプログラムは出力にビープ音を使っていて。とても人の声とはかけ離れたものでしたが、とにかく音声合成でできたときは驚きでした。なにしろ当時は 
MIDI 音源すら内蔵していない時代でしたから声らしきものが出るのが感激でした。
その後、SoundBlaster社の拡張ボードで型番も忘れてしまいましたが、これに英文を入力すると、かなり自然な、人間の声に近い音声を発生させることがわかりました。ただし、この拡張ボードは英文しか受け付けないので、VC2の出力するカタカナ混じりの記号化された配列をいったん英字に変換してから入力しました。ところが日本語の 
「ア」 を入れるのには 「ah」 、「イ」は 「ie」、「ウ」は 「ou」、「コ」は 
「koh」または「koe」など、日本語らしい発音にするために苦心したものでした。それでも外人のしゃべる日本語といった感じの発音は、それなりに楽しいものでした。
ただ、このような音声は、よくロボットがしゃべる平板な話し方で、これに飽きてきて、どうにかならないかと考えていました。
幸い 
SoundBlaster 
の拡張ボードは一音ごとにピッチ(音の高低)が設定できるので、ピッチを変化させてみたらと思い試してみました。
文節の始まりはピッチを高く、少しずつピッチを下げていくときわめて自然な表現ができることを発見しました。
文節が終わったら、次の文節の先頭でピッチを上げ、また少しずつピッチを下げていきます。ピッチの低減率は文節先頭の規定のピッチ、文節終端の規定のピッチと文節の長さから計算できます。
この仮説が正しいかを、実例で確認してみたいと思います。
「おしゃべりテキスト」 を使い 「抑揚」 
を変えることでどんなに印象が変わるか調べてみましょう。
テストする文章は           
昔むかし、ある所にお爺さんとお婆さんが住んでいました。 
おじいさんは山へ芝刈りに、お婆さんは川へ洗濯に出かけました。 
とします。
音声の選択は、「読み秀君」 とし、抑揚を 
(2) に設定してみると、こんな具合です。聞いてください。
抑揚を (5) 
に設定し、声が高くなるので、ピッチを (4) くらいに下げてみると、こんな具合です。聞いてください。聞いていただけばわかるように、後者のほうがきわめて自然なしゃべり方になります。
この状況をもっとわかりやすくするために、音声を視覚的に、直感的に見ることができるグラフィカルなソフトを用意しましょう。
それは Speech Filing System(SFS) 
のなかに含まれる WASP というソフトです。
このソフトを立ち上げ、音声ファイルをドラッグアンドドロップすると波形、Wideband 
spectrogram、Narrowband spectrogram、Fundamental Frequency 
などを表示しますが、ここでは波形とFundamental Frequency を表示します。
Fundamenntal Frequency 
(基本周波数)とは声のピッチ(高さ)と考えていいでしょう。
子音は破裂音や摩擦音などで、高周波成分で構成され、Fundamental Frequency 
という概念がなく、一方母音には、アクセントやイントネーションに大きく影響する Funadamenntal Frequency 
で含まれ、この周波数の高いときは、声のピッチ(高さ)を高く、この周波数が低いときは、声のピッチ(高さ)が低くなります。
したがって、Speech 
Filing System の WASP は音声の解析に最適だと考えられます。
Speech Filing System のなかの 
SFSWin も同じような機能があります。
「おしゃべりテキスト」の設定で、音声の選択を ProTALKER
の 読み秀君 や 読み子ちゃん を選択すると、「一般設定」で下の図のような設定パネルを使って速度、ピッチ、抑揚、音量を指定できるようになっています。
(すなわち Speech Engine に ProTALKER を選んだ状態のとき)
声の選択で L&H 
を選ぶとの図のようなパラメータコントロールパネルが表示され、ここで同じように速度(レート)、ピッチ、音量を指定できるようになっています。      
また声の選択で True Voice を選ぶと、、「一般設定」で 下右の 「General Control 」 
が表示され、「Avdanced...」 ボタンを押すと右下の図のような 「Advanced Controls 
」 が表示され、ここで同じように速度、ピッチ、音量を指定できるようになっています。 
ここからは、抑揚も制御できるので ProTALKER
を使うことにします。
右の図は「おしゃべりテキスト」の設定で
音声選択を ProTALKER
の読み秀君 にして 
一般設定で抑揚を 2
に設定したときの音声の分析結果です。
音声ファイル を試聴できます。 
声のピッチがフラットなのが、波形ではほとんどわかりませんが、下段のグラフ Fundamenntal Frequency 
の赤い線からはっきりとわかります。これがロボット風のしゃべり方です。 
右の図は「おしゃべりテキスト」の設定で                                  
音声選択を ProTALKER
の読み秀君 とし 
一般設定で抑揚を 5
に設定したときの音声の分析結果です。
音声ファイル を試聴できます。
声のピッチが文節の始まりから、文節の終わりに向かって右肩下がりに減衰していく様子が赤い線で明瞭に示されています。      
そしてかなり話し方が自然になったと思います。 
このように Speech Filing System の WASP 
を使うと声のピッチの変化の様子、すなわち声のアクセントや抑揚 (イントネーション)の様子が非常にわかりやすくなります。
ここからは、「おしゃべりテキスト」を使い、音声に感情を持たせる 感情音声合成 
を試みたいと思います。
同時に WASP で Fundamenntal Frequency 
の変化する様子を表示させながら確認したいと思います。
まず、テキストとして以下の文章を使います。
「それがどうしたっていうの。そんなこと どうだっていいじゃないの。」
ここでは、喜怒哀楽と普通の 5種類の感情 
を表現することにチャレンジしてみたいと思います。
喜怒哀楽 のうち 「喜」 と 
「楽」 はよく似ているので 「楽」を外し、「楽」 を 「落」 
と読み替えて 
「落胆した」 または 「落ち込んだ」
ということにします。
普通 / 喜んだ / 怒った / 落胆した / 哀しい
の5つの感情に対して 「おしゃべりテキスト」 で、次のように設定してみました。
音声の選択は ProTALKER
の 
「読み子ちゃん」 
とします。
音声合成に関する一考察
