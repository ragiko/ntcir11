14:10-16:15    音声検索語検出音響情報の話者依存ベクトル量子化を用いた音声検索語検出(立命館大)山下研.VQコード列を使ったワードスポッティング.VQコードブックは話者ごとに作成.音素認識の結果とVQコードブックから,VQコード列と音素との対応スコアを求め,それに基づく連続DPでキーワード音素列との照合を行う.DPパスは無限の伸び縮みを許すものを使っているので,継続時間の制御を行っているがアドホック.HMMに基づくワードスポッティング,音素認識結果からのスポッティングと比べて高性能.1状態の話者依存離散HMMと理論的に等価ではないんだろうか.そういう意味では,音声ドキュメントごとに,最適な認識のパラメータを付加情報として与えるという考え方は面白いかもしれない.音声中の検索語検出におけるtriphoneモデル集約方式の検討(岩手県立大)伊藤慶明先生のところ.サブワード単位の単語スポッティングで,monophoneだと荒すぎるがtriphoneだと細かすぎる.そこで,triphoneをクラスタリングすることで,誤認識に強く,かつ検出能力の高いサブワード単位を設計するのが目標.triphoneをk-meansとかでクラスタリングする方法と,出現頻度の高いtriphoneからbiphoneを作っておき,低頻度triphoneに含まれるbiphoneがすでにあるbiphone集合に含まれている場合には当該triphoneを削除する方法(集約)などを試している.しかし音素片を使った場合には及ばなかった.集約手法がアドホックであることはわかったが細かいことはわからなかった.高速音声ドキュメント検索における検索クエリ分割手法およびマッチング手法の比較評価(豊橋技科大)新田研.以前からやっているサフィックスアレイによる単語検出の評価.サフィックスアレイの照合時間を短くするため,クエリをいくつかのサブクエリに分割するのだが,その分割長が検索時間・性能にどう影響するかを評価した.どのくらいに分割するか,また分割キーワードのいくつが検出されたらキーワード検出とみなすかを検証した.その結果,サブキーワードは6～8音素,サブキーワードが1つでも検出されたらキーワード検出とみなす場合がもっとも高性能であった.画像の直線検出に基づく音声中の検索語検出のための画像用フィルタ(龍谷大)南條研.音素間距離画像マトリクスを濃淡画像と考えて,直線検出によってワードスポッティングをする方法.削除・挿入誤りがあると直線がずれてしまうので,画像処理的方法でむりやり直線検出を行う.最初に直線を強調するフィルタをかけて線を太くして,線がずれている部分をごまかす.それと同時に雑音が増えるので,雑音除去フィルタによって雑音低減を行う.音素間距離はバタチャリヤ距離.音節n-gramインデックスによる未知語の音声検索法の改善(豊橋技科大)中川研.音素n-gramの転置インデックスによる高速単語検出だが,インデックスを作るときに置換・挿入・脱落誤りを考慮してインデックスを増やしておく.この方法自体は去年聞いた気がするのだが,どこが新しいんだろうと思って聞いてみたのだが,ベースラインの連続DPをn-best化して比較したことと,複合語が扱えるようにした(一部が既知語であっても良い)ことが新しいようだ.16:25-18:30    検索, 抽出, 訂正, 整形音声検索語検出を利用した音声ドキュメント内容検索の検討(豊橋技科大)秋葉研.音声ドキュメント検索にサブワードベースのSTDを使う.STDのやり方は連続DP.STDの検出結果から文書ベクトルを作り,その結果に対してベクトル空間法による検索を行う.クエリの語彙だけを使った小語彙認識でSDRをやることに相当するようだ.検出単語はTF-IDFで重みをつける.短い単語に対してアドホックな対処を行うと性能が改善する.音声ドキュメントのパッセージ検索に対する適合モデルとWeb拡張の適用(豊橋技科大)秋葉研.適合モデルを使った手法と,Webを使ったクエリ拡張.適合モデルはどういうものか完全には理解できなかった.クエリを生成する確率モデルを文書コレクションのユニグラム確率で補間したような感じ.これと,クエリからWeb検索して得たWeb文書から作った確率モデルをつかって補間した適合モデルを作り,これと検索対象文書の確率モデルとのKLダイバージェンスで順位付けをする.Webで拡張したほうが精度が下がってしまったが,Webで検索された文書が検索意図と異なっていたという分析.複数トピックモデルを用いたキーワード抽出(岐阜大)速水研.LDAを使ったトピック境界推定.手法は,音声認識結果を複数文からなるフレームに区切り,LDAで各フレームのトピック混合比を求めて,その混合比の間のコサイン類似度を使ってフレーム間のトピック一貫性を求める.また,異なるトピック数で複数のLDAを求めて,それらによるトピックベクトルを統合することで若干性能が向上する.また,LDAによるユニグラム確率を元に,各フレームで話題となっている単語を抽出する.TF-IDFによるキーワード抽出より高精度.応用はビデオへの字幕作成ということで,デモビデオも会ったのだが,字幕の中で現在の話題のキーワードを赤くしているだけなので,そのためだけにがんばって計算する必要があるのかなあという感想.Confusion Networkを用いたCRFによる音声認識誤り訂正(神戸大)有木研.認識結果からConfusion Networkを作り,その中から正解に近い候補を探す.原理的にはN-bestでも同じ.誤りかどうかの識別モデルにはCRFを使う.素性としてunigram,bigram,trigram素性と各単語の信頼度,およびある単語とその周辺の発話(前後6発話)のLSAによるコサイン類似度の平均(意味スコア)を用いる.意味スコアを入れることで少し良くなる.「Juliusの吐くconfusion networkは信用できない」という南條さんのコメント.整形された会議録とその原音声のアラインメントに基づく整形箇所の自動検出(豊橋技科大)中川研.音声とその会議録があるときに,そこから音声の忠実な書き起こしを手動で作るための補助手段.会議録と音声とを照合し,どこが異なっているかを自動的に調べる.音声に対して音節認識を行い,話速を推定して,その話速をもとにして少し(6秒ぐらい)ずつアラインメントを取っていく.次に,アラインメント結果を元に,会議録の各単語がそのとおり発話されているかどうかをSVMによって判定する.識別の特徴量は,単語認識と音節認識の対数尤度比,音節時間長の平均,分散,および音節長を確率分布化したときの尤度.特定の単語(助詞など)は整形されやすいという特徴も入れる.話者オープンだと大きく性能が低下する.
音声ドキュメント処理ワークショップ午後まとめ | aitoの日記 | スラッシュドット・ジャパン
