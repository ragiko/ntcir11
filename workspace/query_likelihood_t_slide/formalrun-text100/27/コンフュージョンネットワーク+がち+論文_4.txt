「機械学習」というワードになんとなく惹かれつつも、具体的にやりたいことがあるわけでもないので、手を動かすことなくただひたすら「いつかやる」ために解説記事やチュートリアル記事を集める日々を過ごしていたのですが、このままじゃイカン!と Machine Learning Advent Calendar に参加登録してみました。
が、やはり何もしないまま当日を迎えてしまったので、お茶濁しではありますが、せめて「機械学習ってどんな手法やライブラリがあって、どんな応用先があるのか?」というあたりをざっくり把握して最初に何をやるのか方向付けをするためにも、たまりにたまった機械学習系の記事をいったん整理してみようと思います。
機械学習の概要
特定のライブラリや手法の話ではなく、機械学習全般に関する解説。
機械学習チュートリアル@Jubatus Casual Talks
冒頭に、
初めて機械学習を聞いた⼈人向けです
数式を使いません
ガチな⼈人は寝てて下さい
とある通り、機械学習ってそもそも何?どう嬉しいの?というところがスタート地点である自分にとってすごくありがたかったスライド。
ざっくり目次的なものをまとめると(かなり抜粋)、
機械学習って何?
例: スパム判定、商品推薦、コンピュータ将棋・囲碁・チェス
その他適用分野
機械学習が向かないタスク
ルールベースとの比較
機械学習って何してるの?
教師あり・教師なし学習とは?両者の目的の違い
線形分類器(図解がわかりやすかった)
Python / scikit-learn
Python で機械学習しよう!(環境構築 on Mac編)
Mac 上に Python で数値計算、機械学習を行うための環境構築の手順。全編スクショ付きですごくわかりやすいです。(が、あくまで環境構築手順だけで、実際に機械学習を行ってみるところまではカバーされていません)
インストールする数値計算、機械学習ライブラリは以下の4つ。
NumPy
数値計算を効率的に処理するためのライブラリです
配列の操作がとても簡単になるので、行列計算には必須っぽいです
SciPy
様々な科学計算が実装されたライブラリです
内部でNumPyを利用しています
matplotlib
グラフ描画のライブラリです
内部でNumPyを利用しています
scikit-learn
機械学習に関する様々なアルゴリズムが実装されたライブラリです
機械学習の Python との出会い
NumPy や SciPy などの科学技術計算モジュールの具体的な使い方を学べるチュートリアル。PDF版やePub版も用意されていて、もはや書籍。
前書きにもある通り、機械学習のごくごく初歩的な話とか、Pythonのごくごく初歩的な話は省略されているので、はじめの二歩目ぐらいに目を通すとよさそうです。
このチュートリアルでは,いろいろな機械学習の手法を Python で実装する過程をつうじて,NumPy や SciPy など科学技術計算に関連したモジュールの具体的な使い方を説明します. 機械学習の手法についてはごく簡単な説明に留めますので,詳細は他の本を参考にして下さい. また,クラスなどのプログラミングに関する基礎知識や,Python の基本的な文法については知っているものとして説明します.
目次
はじめに
本チュートリアルの方針
単純ベイズ:入門編
最初に実装するのは,特徴量がカテゴリ変数である場合の単純ベイズ (Naive Bayes) です. この単純ベイズの実装を通じて,NumPy / SciPy を用いた行列・ベクトルの初歩的な扱いについて説明します.
NumPy 配列の基礎
単純ベイズ:カテゴリ特徴の場合
入力データとクラスの仕様
学習メソッドの実装(1)
予測メソッドの実装
単純ベイズ:上級編
単純ベイズ:入門編 で実装した NaiveBayes1 クラスを,NumPy のより高度な機能を利用して改良します. その過程で,NumPy の強力な機能であるブロードキャストの機能と,この機能を活用する手順を紹介します.
クラスの再編成
単純ベイズの実装 (2)
配列の次元数や大きさの操作
ブロードキャスト
クラスの分布の学習
特徴の分布の学習
実行速度の比較
pythonの機械学習ライブラリscikit-learnの紹介
Python の機械学習ライブラリ scikit-learn のチュートリアル。scikit-learn でできること(機能)がカタログ的に紹介されています。
それぞれの機能について簡単なサンプルコードと実行結果が示されているので、色々とつまみ食い的に試してみるのによさげ。
サンプルデータの自動生成
> sklearnにはIrisなどのトイデータセットやサンプルデータの自動生成などの機能もあります。
(0のデータ)
線形SVMによる二値分類
データをトレーニング用とテスト用に分けて、トレーニングデータで訓練したモデルでテストデータを予測してみます。
分類結果の評価
分類器で得られた推定結果がテストデータとどれぐらい一致しているかでモデルの評価を行います。
Confusion Matrix
Accuracy (正解率)
Classification Report
Precision Recall curve
ROC Curve
クロスバリデーション(交差検定)
上のほうで二値分類を試すときにデータをトレーニング用とテスト用に分解しました。しかし、データを分けるとそれぞれに使えるデータが少なくなってしまいます。
クロスバリデーションではデータをいくつかに分割して、1個をテスト用、残りをトレーニング用に使ってスコアの計算をします。このとき分けられたデータのすべてがテストに選ばれるようにくりかえし評価を行い、そのスコアの平均を使って評価をします。
グリッドサーチ
適切なパラメータを選ぶのによく使われるのがグリッドサーチという方法で、これはいくつかのパラメータの組み合わせを実際に試して評価関数を計算し、スコアがよかったパラメータを選ぶというものです
不均衡データ
ラベルごとのデータ数が大きくアンバランスなデータだと学習がうまくいかないときがあります。たとえば正例:負例=1:100とかだったりすると、十分なデータがあっても訓練したモデルはすべてを負例に分類してしまったりします。こういうときはクラスに対する重み(LinearSVCならclass_weight)を変えたりresample関数を使ってトレーニングデータ内の比率が1:1に近くなるようにアンダーサンプリングやオーバーサンプリングをしたりすると結果がよくなることがあります。
特徴量の抽出
分類器のモデルの入力(データのベクトルによる表現)をどうやって作るかという話
scikit-learnを用いた機械学習チュートリアル
scikit-learn のチュートリアルスライド。
スライドというメディアの特性上、コードは少なく図が多いので、上の「pythonの機械学習ライブラリscikit-learnの紹介」に出てくる機能の補助資料として読むとよさそうです。
Deep Learning
はじめるDeep learning
ずっと「ディープラーニング」というキーワードは「何かすごそう」ぐらいに気にはなってて意味はわかってなかったのですが、冒頭の説明が超わかりやすかったです。
つまるところ、Deep learningの特徴は「特徴の抽出までやってくれる」という点に尽きると思います。
例えば相撲取りを判定するモデルを構築するとしたら、普通は「腰回りサイズ」「マゲの有無」「和装か否か」といった特徴を定義して、それを元にモデルを構築することになります。ちょうど関数の引数を決めるようなイメージです。
ところが、Deep learningではこの特徴抽出もモデルにやらせてしまいます。というか、そのために多層、つまりDeepになっています。
具体的には頭のあたりの特徴、腰のあたりの特徴、そしてそれらを複合した上半身の特徴・・・というように、特徴の抽出を並列・多層に行って学習させて、それでもって判定させようというのが根本的なアイデアです
技術の詳細説明はさくっと読み飛ばしてしまいましたが、deep learning の代表的なライブラリも挙げられていました。
pylearn2
Caffe
nolearn
deepnet
yusugomori/DeepLearning
通常なら最新の実装も搭載されているpylearn2、画像認識ならCaffeらしいです(経験者談)。
研究やとりあえず試してみる場合に必要になる学習データを提供してくれているサイトのリストもまとめられていて、即ストックさせていただきました。
最後に pylearn2 を用いた実践手順もあり。
Deep learning
機械学習はじめの一歩に役立つ記事のまとめ - Qiita
