自然発話音声には, 正しく意図を伝えるための強調発声や言い直し, 感情表現など, さまざまな発話様式が含まれている.より良いヒューマンインタフェースとして音声認識システムを考えた場合, これらの発話様式の変動に頑健な音声認識システムを構築することは非常に重要である.特に現在の音声認識システムでは, 誤認識の発生は避けられず, その言い直しに対して頑健にする必要がある.言い直し発話では, より明瞭に発声する, 音素継続時間長が増加するという変化が生じるとともに, 音節強調発声の出現頻度が増加するという傾向がある.本稿では, 言い直し発話における音節強調発声に有効な音声認識手法について検討したので報告する.音節強調発声は, 発話様式が孤立音節発声に近くなるとともに, 音節間の音響的特徴が変形する.本手法では, 後続音素環境が無音のtriphone母音モデルと, 先行音素環境依存biphone母音モデルをマルチモデル化して用いることにより, 上記の音節強調発声の問題に対処する.デコードの際, 音素ごとに尤度の高いモデルを選択することで, 認識辞書の拡張や音響モデルの切り替えを行うことなく, 音節強調発声に対する認識率を向上することができた.
Speaking styles in spontaneous speech often vary in order to convey stress, emotion or error recovery. In a speech recognition system for an intelligent human-machine interface, it is crucial to achieve robustness against speaking style variations. The system must be especially robust with regard to error recovery speech because current speech recognition systems always exhibit errors. Speech in error recovery tends to be uttered in a syllable-stressed way and to have longer phoneme durations. This paper investigates a robust method to recognize syllable-stressed speech for error recovery. In syllable-stressed speech, each syllable is uttered in an isolated way and the acoustic characteristics between syllables are changed. To cope with these problems, we propose a new recognition method. For isolated syllables, we use a vowel model which is succeeded by silence with a conventional triphone model. For the change in acoustic characteristics between syllables, we use a left context dependent biphone vowel model with a conventional triphone model. During decoding, the model which shows the highest likelihood for input speech is implicitly selected for each phoneme. This method improves the performance for syllable-stressed speech without any need to expand the recognition dictionary or explicitly select the models.

