技術分類
4-2 データベース索引の生成方法
4-2-4 分類、索引、検索方法
技術の名称
4-2-4-A 状況概念の検索
技術内容
状況概念に基づくデータベース索引生成方法を取り上げる。状況概念とは、動画像に現れる物体間の時間的、空間的な相関関係に基づく意味概念である。チームによる球技などの試合では、ボールと複数のプレーヤとの間に時間的、空間的な相関関係をもったプレーが存在する。映像からその相関関係を抽象的に表現し、所望のシーンの検索を可能にする。
(1)特徴
図1に索引生成システムの構成を示す。左側がデザイナ、右側が動画像データベースである。デザイナが状況概念に関する知識の定義づけをし、それに基づき、システムが動画像データに対して索引付けを行う。ユーザは索引付けされた動画像データに対して検索を行う。
(2)機能説明
例えばサッカーの試合の映像の場合は、システムは動画像データを画像処理して、キーフレーム単位のボールとプレーヤの位置情報に変換し、抽象化しておく。キーフレームとは、ボールがあるプレーヤに接触しているすべてのフレームである。
デザイナは、画像中に所望の状況が確認される典型的なシーンを、モデルシーンに指定する。システムは、モデルシーンに対して画像処理を施し、状況概念を構成するために必要な情報を抽出し、モデルシーンにおけるキーフレームをデザイナに提示する。デザイナは、提示された各キーフレームに対して状況概念に関する知識を記述する。
システムは、モデルシーンから得た情報と、デザイナが定義づけした知識に基づいて状況概念を構成し、キーフレーム単位のデータに変換された動画像データとのマッチングを行う。マッチング結果はデザイナに出力する。同時に、状況概念に関する定義情報を用いて、動画像データに対する索引付けを行う。
図
図1 状況概念に基づく動画像データベース索引生成システム
出典:「動画像データベースにおける状況概念の検索」、「情報処理学会研究報告 No.111-008」、(1997年1月)、細田祐一、吉高淳夫、平川正人、市川忠男著、社団法人情報処理学会発行、59頁 図1 システム構成
応用分野
オフライン編集
出典/参考資料
「動画像データベースにおける状況概念の検索」、「情報処理学会研究報告 No.111-008」、(1997年1月)、細田祐一、吉高淳夫、平川正人、市川忠男著、社団法人情報処理学会発行、57頁～64頁 
技術分類
4-2 データベース索引の生成方法
4-2-4 分類、索引、検索方法
技術の名称
4-2-4-B 時刻印付オーサリンググラフによるシーン検索
技術内容
時刻印付オーサリンググラフは映像記述のひとつの方法で、映像に対する断片的な内容記述と記述間の意味的な関連性に基づいた映像記述を行う。
(1)特徴
時刻印付オーサリンググラフでは、記述者は事前にシーンを定義する必要はない。検索要求に合ったシーンを、検索ごとに特定することができる。
(2)機能説明
時刻印付オーサリンググラフによる映像記述の例として、約30秒間のアニメーション映像の記述を図1に示す。ノードとリンクからなる無向グラフで記述される。ノードはある時点の映像に対する内容記述を表し、リンクはこれらの記述間の関連性を表す。
記述者は、ある時点の映像に対する印象や感想、情景や出来事を表現する言葉を、タイムコードとともに書き出す。それが1つの時刻印付ノードになる。一方、映像全体に当てはまり、特定の時刻の対応付けができない記述は時刻印なしノードとして扱う。その上で、たがいに何らかの意味的関連性があると思われる内容記述を持つノード間をリンクでつなぐ。リンクは、単語間の共起関係に基づいて、自動生成することも可能である。
図2に映像検索の例を示す。ユーザは、欲しいシーンの内容を表現する自然言語文を検索要求として与える。システムは、上記の映像記述の中から、検索文を最もよく表現できる記述部分を見つけ出し、この記述部分に対応する映像部分を選択する。
このためシステムは、まずキーワード・マッチングでマッチ・ノードを見つけ出す。次いで、グラフ探索でマッチ・ノードを連結する最小の部分記述グラフを見つけ出す。図2では、太線で示したグラフが極小部分記述グラフである。この部分記述グラフに含まれるノードに対応するカット映像をすべて含む一連の映像部分が、検索結果のシーン映像になる。
図
図1 時刻印付オーサリンググラフによる映像記述
出典:「時刻印付オーサリンググラフによるビデオ映像のシーン検索」、「情報処理学会論文誌 Vol.39 No.4」、(1998年4月)、是津耕司、上原邦昭、田中克己著、社団法人情報処理学会発行、925頁 図1 時刻印付オーサリンググラフによる映像記述
図2 時刻印付オーサリンググラフによる映像検索
出典:「時刻印付オーサリンググラフによるビデオ映像のシーン検索」、「情報処理学会論文誌 Vol.39 No.4」、(1998年4月)、是津耕司、上原邦昭、田中克己著、社団法人情報処理学会発行、926頁 図2 時刻印付オーサリンググラフによる映像検索
応用分野
オフライン編集
出典/参考資料
「時刻印付オーサリンググラフによるビデオ映像のシーン検索」、「情報処理学会論文誌 Vol.39 No.4」、(1998年4月)、是津耕司、上原邦昭、田中克己著、社団法人情報処理学会発行、923頁～932頁 
技術分類
4-2 データベース索引の生成方法
4-2-4 分類、索引、検索方法
技術の名称
4-2-4-C 多段階自己組織化マップによる検索
技術内容
カット割した映像群を、その内容によって自動生成するシステムを、自己組織化マップSOM(Self-Organizing Map)を用いて構築することを取り上げる。
(1)特徴
カット映像に対するコンテンツ記述情報をシーン映像の記述情報として継承させ、その記述内容をもとに再びSOMに学習させる。これにより、意味情報に基づくシーン映像の分類と検索を可能にする。類似シーン検索システムに相当する。
(2)機能説明
SOMは教師なし強化学習モデルである。データに隠されたトポロジカルな構造を学習アルゴリズムにより発見し、2次元空間で表示する。特徴の良く似たデータ同士は出力マップ上の近い位置に配置される。
映像データは、まず映像そのものの色情報や色合いの情報であるコンテンツ情報、すなわちDCT(Discrete Cosign Transform)情報で分類し、SOMとして用意しておく。これをカット映像に対する意味記述支援メカニズムとして、シーン映像の意味記述や検索を行う。すなわち、SOM中の同じセルに分類されたカット映像に対して同じ内容記述を施す。内容記述はキーワードで行う。
図1にその生成過程を示す。左側では、分類したカット映像からDCT成分を抽出し、DCT情報カット特徴ベクトルを生成し、コンテンツ情報SOMを生成する。次いで、右側のように、ビデオ映像の意味記述を行い、記述情報カット特徴ベクトルを生成する。これをDCT情報カットベクトルと統合し、ハイブリッド型SOMを生成する。
ユーザは、映像の意味内容を基にした分類を用いて映像に対する問い合わせを行う。
図
図1 ハイブリッド型SOMの生成過程
出典:「多段階自己組織化マップによるビデオ映像記述支援と類似シーン検索」、「情報処理学会論文誌 Vol.39 No.4」、(1998年4月)、波多野賢治、亀井俊之、田中克己著、社団法人情報処理学会発行、938頁 図3 ハイブリッド型SOMの生成過程
応用分野
オフライン編集
出典/参考資料
「多段階自己組織化マップによるビデオ映像記述支援と類似シーン検索」、「情報処理学会論文誌 Vol.39 No.4」、(1998年4月)、波多野賢治、亀井俊之、田中克己著、社団法人情報処理学会発行、933頁～942頁 
技術分類
4-2 データベース索引の生成方法
4-2-4 分類、索引、検索方法
技術の名称
4-2-4-D 映像シーンの高速分類手法
技術内容
映像シーンの高速分類法のひとつとして、過去に入力された映像と同一の映像の入力を、リアルタイムで検出し、クラスタ化する方法を取り上げる。
(1)特徴
連続して入力される映像について、その特徴を時系列圧縮して記憶しつづける。同時に、それまでに入力された映像系列の中から、最新の入力映像と一致する無制限の長さの部分映像区間をすべて見つけ出す。
(2)機能説明
次々と入力される映像の中から同一のシーンを見つける。まず、入力映像からフレームごとに特徴量を抽出する。次いで、抽出した特徴量系列についてデータ圧縮を施し、格納する。そのときの特徴量を、既に格納されているすべての特徴量と照合する。
図1に特徴量抽出の流れを示す。逐次入力される各フレーム画像から、RGB表色系の各成分について色平均を求め、それら3つを組みにしてフレームの特徴量とする。同一特徴量区間を切り出し、区間番号、特徴量、フレーム番号を示す特徴量テーブルを作成する。
図2は、新たな入力映像と既に入力され記憶してある映像との照合を示す。新たなフレーム画像から特徴量を抽出し、特徴量テーブルの末尾に追加する。一方、既に特徴テーブルに記憶されている特徴量の中に、最新の特徴量と一致するものがないか探索を行う。区間の変わり目を基準点として、フレーム精度での位置決めを保証する。
図3は、シーン照合の高速化を示す。まずフレーム入力ごとに特徴が一致するフレームを探し出し、候補として記憶する。次にフレームが入力されると、記憶した候補と一致しているかを調べ、一致しない候補は記憶から削除する。このような繰り返しにより、入力ごとに段階的に候補を絞り込む。
図
図1 特徴量抽出の流れ
出典:「時系列フレーム特徴の圧縮符号化に基づく映像シーンの高速分類手法」、「電子情報通信学会論文誌 Vol.J81-D2 No.8」、(1998年8月)、長坂晃朗、宮武孝文著、社団法人電子情報通信学会発行、1833頁 図1 特徴量抽出の概念図
図2 新たな入力映像と既に入力され記憶してある映像との照合
出典:「時系列フレーム特徴の圧縮符号化に基づく映像シーンの高速分類手法」、「電子情報通信学会論文誌 Vol.J81-D2 No.8」、(1998年8月)、長坂晃朗、宮武孝文著、社団法人電子情報通信学会発行、1833頁 図2 特徴量照合の概略
図3 シーン照合の高速化
出典:「時系列フレーム特徴の圧縮符号化に基づく映像シーンの高速分類手法」、「電子情報通信学会論文誌 Vol.J81-D2 No.8」、(1998年8月)、長坂晃朗、宮武孝文著、社団法人電子情報通信学会発行、1834頁 図3 高速特徴量照合方式の概念図
応用分野
オフライン編集
出典/参考資料
「時系列フレーム特徴の圧縮符号化に基づく映像シーンの高速分類手法」、「電子情報通信学会論文誌 Vol.J81-D2 No.8」、(1998年8月)、長坂晃朗、宮武孝文著、社団法人電子情報通信学会発行、1831頁～1837頁 
技術分類
4-2 データベース索引の生成方法
4-2-4 分類、索引、検索方法
技術の名称
4-2-4-E 録画した番組の一覧表示・検索
技術内容
テレビにおいて、興味あるシーンにすぐアクセス可能な番組ナビゲーションシステムを取り上げる。録画したニュース番組に対して、一覧表示および検索を可能にする。
(1)特徴
図1にシステムの概要を示す。番組構造化処理によって、録画したニュース番組をトピックごとに分割し、各トピックに対してインデックスを付与する。この番組構造化データに対して、番組内容を参照できる番組ブラウザを提供する。
(2)機能説明
トピック分割については、手がかりとなるビジュアルコードという情報を、あらかじめニュース番組内に埋め込む。映像中のテレビの画面としては映らない部分に、テロップを使って埋め込む。トピック分割位置はアナウンサの音声の切れ目を利用して決定する。
インデックスとしては、視覚的な代表画面とキーワードを各トピックに付与する。代表画面としては、ニュース番組の特徴を利用し、トピック中でアナウンサが登場して消える位置を検出し、その位置から数秒後の映像を用いる。
キーワードは、トピック中のテロップの情報と、アナウンサなどの音声情報から抽出する。図2にキーワード抽出処理を示す。テロップ情報を用いるためには、映像からテロップ位置を検出し、背景との分離を行い、文字認識を行う。音声情報についても音声認識技術により、内容を文字にする。さらにビジュアルコードによって示されるジャンル情報を加え、出現頻度などを考慮して、確からしい語句をキーワードとして採用する。
番組ブラウザは、番組選択、トピックブラウズ、ヘッドライン、ジャンルソート、類似検索の5つのモードで構成する。
図
図1 番組ナビゲーションシステムの概要
出典:「見たいシーンにすぐアクセスできる番組ナビゲーション技術」、「東芝レビュー Vol.55 No.10」、(2000年10月)、上原龍也、堀川将幸、住田一男著、株式会社東芝発行、17頁 図1 番組ナビゲーションシステムの概要
図2 キーワード抽出処理
出典:「見たいシーンにすぐアクセスできる番組ナビゲーション技術」、「東芝レビュー Vol.55 No.10」、(2000年10月)、上原龍也、堀川将幸、住田一男著、株式会社東芝発行、18頁 図2 キーワード抽出処理
応用分野
オフライン編集
出典/参考資料
「見たいシーンにすぐアクセスできる番組ナビゲーション技術」、「東芝レビュー Vol.55 No.10」、(2000年10月)、上原龍也、堀川将幸、住田一男著、株式会社東芝発行、17頁～19頁
［更新日 2003年3月28日］
4-2-4 分類、索引、検索方法 | 経済産業省 特許庁
