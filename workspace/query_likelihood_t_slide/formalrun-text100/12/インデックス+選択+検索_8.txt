
検索の仕組み
検索プロセスの基本となる仕組みをこのページで説明します。この仕組みに従ってウェブ上の情報を収集して整理することにより、最も役に立つ結果をユーザーに返すことができます。インデックスは
100,000,000 ギガバイトを超え、その構築に費やした処理時間は 100 万時間を超えています。詳しくは、こちらの動画をご覧ください。
クロールして情報を取得する
Google では、「ウェブ
クローラ」と呼ばれるソフトウェアを使用して、公開されているウェブページをクロール(情報を取得)します。最もよく知られているクローラは「Googlebot」です。クローラは、ユーザーがウェブ上でコンテンツを閲覧する場合と同じように、ウェブページを見て、ページ上のリンクをたどります。リンクからリンクに移動し、これらのウェブページに関するデータを
Google のサーバーに蓄積していきます。
クロールのプロセスは、過去のクロールから得られたリストとウェブサイトの所有者から提供されたサイトマップに含まれるウェブアドレスのリストから始まります。クローラは、これらのウェブサイトを訪れ、他のページへのリンクを探します。その中でも、新しいサイトの情報、既存のサイトの変更点、および無効なリンクを重点的に確認します。
どのサイトをクロールし、各サイトからどのくらいの頻度で、どのくらいのページを取得するかは、コンピュータ プログラムが決定します。Google
では、サイトをクロールする頻度を上げる目的での金銭の支払いを受け付けていません。Google
が目指しているのは、最適な検索結果を提供することだからです。長い目で見れば、それがユーザーにとっても、ひいては、私達にとっても最善だと考えるからです。
ウェブサイト所有者の選択肢
ほとんどのウェブサイトでは、クロール、インデックスへの登録、検索結果上への表示に関して制限する必要はなく、何か特別な作業をしなくてもサイトのページは検索結果に表示されます。しかしながら、ウェブマスター
ツールや「robots.txt」というファイルを使うことで、サイトの所有者は、サイトのクロールとインデックスへの登録方法をご自身の希望にあわせて設定することができます。例えば、robots.txt
を使って、Googlebot によってクロールされないようにしたり、サイト上のページを処理する方法をより具体的に指定したりできます。
サイトの所有者はページ単位でコンテンツをどのようにインデックスに登録するかなど、きめ細やかな登録方法を選択することができます。たとえば、ページをスニペット(検索結果でタイトルの下に表示されるページの概要)やキャッシュ
バージョン(ライブのページにアクセスできない場合用に Google のサーバーに保存されている代替バージョン)なしで表示することを選択できます。また、カスタム検索に自分のページの検索を統合することも選択できます。
インデックスに登録して情報を整理する
ウェブは、一括管理されることなく絶え間なく書籍が増え続けている図書館のようなものです。基本的に、Google
では、クロール時にページの情報を収集した後、インデックスを作成することで、検索対象の正確な場所を把握します。本の巻末に収載されている索引と同様に、Google
のインデックスには、単語と単語が使われていたページに関する情報が含まれています。検索を行うと、まずはアルゴリズムに従ってインデックスから検索キーワードに対し適切なページを見つけます。
検索プロセスは、そこからさらに非常に複雑になります。「犬」を検索する場合、必要なのは「犬」という単語が何百回も出現するページではありません。おそらく求められているのは、写真や動画、または犬の種類の一覧表などでしょう。Google
のインデックス登録システムでは、公開された時期、写真や動画の有無など、ページのさまざまな特性に着目します。Google では、ナレッジ
グラフによって、目的の人、場所、物をもっとよく把握できるように、単なるキーワード マッチング以上のことに日々取り組んでいます。
クロールとインデックス – 検索サービス – Google
