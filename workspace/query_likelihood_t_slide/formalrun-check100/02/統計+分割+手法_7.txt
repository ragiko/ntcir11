日本語処理における複合語の分割は,機械翻訳,自助インデクシング,文書校正,音声合成等で必要とされる基本的技術であるが,従来より困難な問題であることが指摘されてきた.これは複合語の分割が必ずしも一意でないためであり,最長一致法等の手法による自動分割では十分な分割精度を得ることができなかった.本報告では,漢字複合語をマルコフモデルという確率的情報発生源からの出力であると考え,統計的推定による手法を用いた短単位分割法を提案し,その処理手順と実験結果について述べる.現行の実験システムでは漢字のみからなる一般語しか扱っていないが,本手法の特徴には以下のものがある.1)適用分野で用いられる十分多くの漢字複合語をもとに,正しい短単位が機械的な計算により学習できる.2)複合語の分割に曖昧さがあるときに,股も確からしい分割パターンが求められる.3)基本語の出現頻度順のリストや分布といった計量的データの収集が可能となる.本システムは,JICSTより発行されている科学技術論文の抄録データに対して約95%の平均分割精度を達成している.また,あらかじめ用意された辞書の正書項目を利用したり,頻出語の正しい分割パターンを与えるといった各種の改良のもとで約97%の分割精度を得た.今後の課題には,未知語の扱いや,一般的な漢字複合語以外の分割への拡張があげられる.

