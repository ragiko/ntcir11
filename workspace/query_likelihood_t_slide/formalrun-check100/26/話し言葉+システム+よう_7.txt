本稿では,HMM音声合成に基づく話し言葉音声合成システムの構築と,そこで用いられるモデルの有効性に関する分析結果について報告する.我々の合成システムでは,ケプストラム情報はHMMでモデル化され,音素継続時間長(音素長)と基本周波数(F_O)情報は数量化I類でモデル化される.これら3つのモデルを,日本語話し言葉コーパスの学会講演音声を用いて学習し,話し言葉音声合成システムを構築した.このシステムの合成音声の「話し言葉らしさ」を評価するため,全てのそデルを読み上げ音声から学習して構築したシステムの合成音声との対比較実験を行ったところ,話し言葉音声を用いて構築したシステムの方が高い評価を得ることが確認された.これにより,実際の話し言葉音声を用いてHMM音声合成に基づく音声合成システムを構築することが,話し言葉らしい音声の合成に有効であることが示された.また,用いた3つのモデルについて,それぞれがどの程度,合成音声の話し言葉らしさ影響を与えているかに関する種々の分析を,被験者による聴取実験によって行った.
This paper describes construction of an HMM-based spontaneous speech synthesizer and investigates effectiveness of the statistical models in the system. In our system, cepstral features are modeled by HMMs and phoneme duration and fundamental frequency (F_O) features are modeled by Quantification Theory (Type 1). These three models are trained with spontaneous lecture speech extracted from the Corpus of Spontaneous Japanese (CSJ). For comparison, we prepared a speech synthesizer where all models were trained with read speech. Spontaneity of the synthesized spontaneous speech was evaluated by subjective pair comparison tests. Experimental results show that the preference score for the synthesized spontaneous speech is significantly higher than that for the synthesized read speech. This implies that HMM-based speech synthesis using actual spontaneous utterances for model training is effective for producing spontaneous speech. Additional subjective evaluations were also conducted to analyze the effect of individual models used in our synthesizer on the impression of spontaneity.

