人間が話した言葉を自動的にテキストデータに変換する「音声認識技術」が広まりつつある。すでにコールセンターでの自動応答装置(IVR)やカーナビでの利用は一般的であるし、ゲーム機への搭載や、音声認識を用いたネット上の情報検索サービスなども登場してきている。日本国内における音声認識技術は現在どのような状況にあり、今後どのような課題や展望があるのだろうか。
一口に「音声認識技術」と言っても、認識の対象となる言葉の種類や長さ、内容などによってその仕組みや技術的な難易度、実現可能な認識精度がかなり異なってくる。そこで、主に技術的な難易度の観点から、「単語認識」、「書き言葉・読み上げ認識(以下、『書き言葉認識』という。)」、「会話・話し言葉認識(以下、『会話認識』という。)」の三つのレベルに分類してみる。
「単語認識」は文字通り一度に一単語しか発話しないことを前提としたものであり、発話される可能性のある単語を正しく辞書データとして登録しておきさえすれば、ほぼ100%に近い精度での認識が可能である。
これに対し「書き言葉認識」や「会話認識」は、複数の単語が連続した「文章」を認識する技術である。そこで用いられる辞書データには、単語そのものだけではなく、単語どうしのつながり方やその使用頻度などの統計データが必要になってくる。この「単語の使われ方」をデータ化したものを「言語モデル」と呼んでいる。
「書き言葉認識」で認識の対象となるのは、ニュース原稿や新聞記事、報告書の内容や講演でのスピーチ音声など、日本語として比較的しっかりした構造を持ち、文法的にも誤りの少ない文章である。事前に、必要となる単語やその使い方に関するサンプルを十分に用意し、言語モデルを作成することで、発話さえ明瞭であれば平均90%を超える精度で認識することが可能であり、音声によるテキストデータ入力などで実用化されている。
技術的に最も難易度の高いのが、「会話認識」である。人と人との自然な会話において話されている日本語は、これをそのまま文字にすると以下のように日本語として相当崩れていることが多い。
「え、ああ、まあそうですよね。私も、…あ、はい、私としても同じように、ええ、思います」
このような音声を読み取り、意味の切れ目や単語の切れ目がどこにあるかを判断し、正しいテキストデータに変換していかなければならない。そのため、会話認識のための言語モデルを作る際には、「コールセンターでの会話」や「議会での質疑応答」などのように利用シーンを特定し、表現や言い回しのバリエーションをある程度限定することで、実用的な認識精度を得る手法が取られる。
このような言語モデルの工夫の他、音と文字との基本的な対応付けを行うために必要な「音響モデル」も重要な役割を果たす。目的とする利用シーンにあった音響モデルを準備することはもちろん、話者の個人差を吸収するための技術や、ノイズ・騒音への対策、電話や携帯電話音声への対応など様々な技術が開発されている。
【図1】音声認識のしくみ
連載・コラム｜情報通信ビジネス最前線｜音声認識技術の動向｜1.音声認識技術について@ICTベンチャーの創業・起業支援なら情報通信ベンチャー支援センター
