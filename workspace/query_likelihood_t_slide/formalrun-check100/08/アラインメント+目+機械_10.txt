 言語処理学会1日目 #nlp2011
朝5時に起きて豊橋へ。新幹線の中で緊張のため?眠れず、午後からかなりしんどかっったので、飲み会には参加せずホテルへ(チェックインもしてなかったし)。
C1-1     シソーラスを利用した文書クラスタリングにおける次元圧縮アルゴリズムの性能評価
酒井将太, 新美礼彦 (未来大)
背景・目的
ベクトルう区間モデル
シソーラスやオントロジーの利用
シソーラスを用いた文書クラスタリング
手法・理論
シソーラスを利用した特徴ベクトル
日本語WordNet
特徴ベクトル構築
形態素解析を行い、前単語列を日本語WordNetで検索
3種類のsynsetを特徴ベクトルとする
次元圧縮アルゴリズムの適用
LSI、主成分分析(PCA)、属性選択
実験
提案手法:日本語WordNetを利用
既存手法:単語の出現頻度を利用
実験A:楽天でデータ公開されている商品データ
前処理:数字の正規化など
実験結果:シソーラスを用いるとF値が向上
有意水準5%
WordNetでは属性選択が最も良い(LSIとPCAでは下がった)
実験B:Amazonの商品に関するレビュー
クラスタとそれに含まれる文書数の推移
考察
シソーラスによりクラスタリングの精度が向上
属性選択を適用した場合に性能が向上
実験B:正解ラベルのデータがないので性能評価が難しい
まとめ
C1-2     全部分文字列のクラスタリングとその応用
岡野原大輔 (PFI)
概要
単語クラスタリングを拡張子、全部分文字列のクラスタリングを行なう
特徴量を効率的に列挙
乱択特異値分解による潜在表現計算:数十億要素まで処理可能な特異値分解(SVD)
4000万文字に対して1台で285秒
単語クラスタリング
仮定:同じ文脈を持つ単語は同じ意味を持ちやすい
周辺文脈の取り方で異なるクラスタリング結果
直前、直後の単語文法的に同じ役割の単語、品詞
同じ段落、文書の共起:意味的に同じ単語、品詞
アプリケーション
言語モデルのスムージング
クラスN-gram
教師あり学習の特徴量:近年盛ん!
係り受け解析、固有表現抽出などの匡で特徴量として利用
その他:辞書構築、マイニング
フレーズクラスタリング
単語では意味を捉えきれない
人名: ?マイケル マイケル・ジャクソン
製品名、作品名など多くの固有表現が複数単語
フレーズをクラスタリング:フレーズの種類は非常に多い
既存研究:対象のフレーズをクエリログから選択、MapReduceで処理
計算量は変わらないが有用性を示した
提案内容
フレーズクラスタリングを効率的に実現
部分文字列の文脈情報を計算LSAで変換K-means++を用いたクラスタリング
乱択アルゴリズム:redsvd
文脈情報:直前の文字、直後の文字、文、文書
提案1:文脈情報の効率的な列挙
出現場所の異なる部分文字列の列挙は線形時間で可能
提案2:乱択SVD
従来のSVDは大規模行列には適用不可能
疎行列だと並列化しても遅い
ランダム行列をかけて圧縮し、それに対して特異値分解を行なう
行方向・列方向の圧縮
実験
日本語Wikipedia5万文書
線形にスケールすることを確認
例:年号、地名、書名、動詞、の+名詞+に、人名
文書共起を利用した場合:近代ヨーロッパ、仏教、…
まとめ
今後
意味のある部分文字列の抽出
半教師あり学習
ライブラリ公開(コンポーネントは公開済み)
乱択SVDの精度
理論的にはACLで既存研究が出ている
NLPの応用では問題ないレベル
並列化
Mahoutで乱択SVDを実装中
redsvdはメモリ量で限界がある
C1-3     類似論文からの関連用語抽出による論文検索支援システムの提案
南浦佑介, 新美礼彦 (未来大)
背景・目的
CiNiiにおける論文が3ヶ月半で40万近く増加
論文検索システム:専門知識が不足しているとキーワード設定が困難!
目的
関連用語の提示
類似論文とその関連用語を提示
関連度に応じた結果出力
関連研究
論文の関連用語自動収集
提案手法:前処理
専門用語抽出:termexを利用
階層的クラスタリング
関連度指定の実現
提案手法:推薦
被験者実験
C1-4     Newton-CG法による条件付き確率場のバッチ学習
坪井祐太, 海野裕也 (日本IBM), 鹿島久嗣, 岡崎直観 (東大)
概要
CRFの高速なバッチ学習法の提案
オンライン学習とバッチ学習
オンライン学習:性能の立ち上がりが早い、問題依存の設定が必要
バッチ学習:設定が不要で高精度、性能の立ち上がりが遅い
データ数1万くらいなら提案手法のほうが設定が不要で高精度!
貢献
CRF学習へNewton-CG法を適用した
CRF学習でのNewton-CG法の高速化
問題
CRF:条件付き確率の線形モデル
負の対数尤度を最小化
Newton法
2次曲線で目的関数を近似
2次微分(ヘシアン行列)を利用
テーラー展開で近似
Newtonステップでθを更新
Newton-CG法
CG(共役勾配法)を使う
適応的な精度調整
ヘシアン行列は不要
必要なもの:ヘシアン・ベクトル積
CRFにおけるヘシアン・ベクトル積の効率的な計算
行列を作らない計算順
マルコフ性を用いた動的計画法
計算順:左から計算するのでなく、右側を先に計算
DP:点ごとに分解してメモ化
ヘシアン・ベクトル積の計算時間
指数関数の呼び出しコストが大きい
確率計算を大幅に削減可能
実験
フレーズチャンキングと固有表現抽出で比較
バッチ学習:LBFGS
オンライン学習:SGD
まとめ
既存のバッチ学習(LBFGS)より数倍高速
オンライン学習と同等
自動微分による計算
E1-5     分野に依存しない単語極性を考慮した評判分析のための転移学習モデル
吉田康久 (NAIST), 平尾努, 岩田具治, 永田昌明 (NTT), 松本裕治 (NAIST)
分野依存の単語極性
unpredictable, long (battery or latency)
本研究の貢献
評判分析における転移学習
Amazonレビューに適用
分野ごとの単語極性辞書を構築できる
評判分析と転移学習
例:映画データ
Bug-of-WordsSVM
転移学習
訓練データとテストデータの分野が違う!
問題点
転移元と転移先で1:1対応であると仮定
評判分析では多くの分野が必要
アプローチ
転移元と転移先が多対多
分野ラベル、分野依存性、極性の3変数を入れる
グラフィカルモデル
パラメータ推定:Gibbs Sampling
実験設定
Amazonレビュー
ベースライン:単語の極性のみ
転移先を固定、転移元を変化
転移先はラベルなし
学習はTransductive(ラベルあり転移元とラベルなし転移先を利用)
転移元の分野数を増加
転移元を固定、転移先を変化
F値でベースラインより向上
分野ごとの単語極性辞書を構築
stainless(kitchen)など
今後の課題
ラベルなしデータへの重みを考慮したモデル
ドメイン間の類似性を考慮に入れる
まとめ
複数の分野の違いを考慮に入れた転移学習モデルを提案
単語に対して分野モデル、分野依存性、極性の3つの変数を考慮した生成モデル
提案手法をAmazonレビューに適用
分野ごとの単語極性辞書を構築
C1-6     推論ルール学習による単語間の意味的関係推論法
土田正明, 鳥澤健太郎, De Saeger, Stijn, 呉鍾勲, 風間淳一 (NICT), 大和田勇人 (東理大)
背景・目的
意味的関係の知識ベース
大規模なコーパスにも書かれていない意味的関係の単語対
実現したいこと
ダークチョコレート動脈硬化脳梗塞
関連研究:EMNLP 2010
Markov Logic Netowrkで推論
提案手法
Step1:推論ルールの候補の列挙
Step2:推論ルールのスコアリング
評価実験
Yahoo検索APIを利用
C1-7     医薬品の副作用調査を目的とした統合的言語処理システム
大熊智子, 三浦康秀, 外池昌嗣, 増市博 (富士ゼロックス), 篠原(山田)恵美子, 荒牧英治, 大江和彦 (東大)
背景
電子カルテの普及
目的
医薬品の副作用出現調査の支援
システムの構成
医療表現抽出
退院時サマリコーパス
医療表現、時間表現、モダリティ、副作用情報などをアノテート
CRFによる固有表現抽出
関係抽出手法
SVMによる2値分類
医療表現の正規化
薬品名:一般名を付与コードに変換
副作用用語集:5階層
実験
まとめ
招待講演「ゲノムを読む」
講演者 榊佳之 氏(豊橋技術科学大学学長)
生命科学のアポロ計画とも呼ばれたヒトゲノム計画は,6カ国で千人以上の 研究者・技術者が参加した巨大国際共同事業である.そこには工学との融合 による新しいDNA解析技術の開発,私的利益を排除して人類共通の知的基 盤の形成を目指した理想主義的精神,帰納的科学であった生命科学への演繹 的手法の導入など様々な「挑戦」があった.今回の講演では私の個人的ヒス トリーも交えながら,ヒトゲノム解読の歩み,科学者たちの人間模様,そし てヒトゲノム解読後の生命科学の新しい展開など生命科学の大発展の流れを 辿り,新しい研究領域がどのように生まれ,発展して行くのか,そこで技術・ 工学の果たす役割は何かを考えてみたい.
ヒトゲノムとは?
ヒト、細胞、染色体、DNA
ヒトゲノム配列
ヒトゲノムの源流
遺伝:メンデルの法則 1866/1900
DNA:二重らせん構造 1953
1950-60年代の遺伝学研究
セントラルドグマの提唱
遺伝暗号表の完成
ヒトゲノム配列決定の流れ
バミューダ会議
理研のセンターのシークエンス決定室
「配列決定データ処理サンプル調製」のサイクルを回す
それぞれの作業に向き不向きがある
塩基数
ヒトゲノム解読完了:2003年
ゲノムの解析が始まる
ゲノムの基本要素を見つける:遺伝子、発現制御、その他
計算遺伝学
遺伝子RNAタンパク質
Alignment with cDNA/AA
Ab initio gene finding
Genome comparison
DIGIT:Bayesian procedure & hidden Markov Model
動物細胞プロモーターのTATAボックス
比較ゲノム解析
ゲノムの個人差の集団解析
肥満関連遺伝子
遺伝学:変異遺伝子の変化表現型の変化
体内時計
遺伝情報制御システムを理解する:階層性、正と負の制御、頑健性
以前は何年もかかっていた遺伝子解読も今では2分
代謝経路予測例
ポスターセッション
ポスターセッションでは機械翻訳関係の発表が多かったように思います。言語モデルも使われているし、アライメントは個人的にも勉強したので興味深かったです。
P1-5 フレーズテーブルを用いた教師なし用語対訳抽出手法の比較 (pp.178-181)
井手上雅迪, 山本和英 (長岡技科大), 内山将夫, 隅田英一郎 (NICT)
Mosesの学習結果であるフレーズテーブルから、人間が見て役に立つような対訳フレーズを抽出するというタスク。従来研究では教師あり学習を用いていたが、この研究では3つのスコアの順位の平均を取るだけで高精度に抽出できるという。というとその3つのスコアを素性として加えて機械学習というのが思いつくが、それをやってしまうと教師なし学習と呼べなくなってしまうのでやりたくなかったのか? 教師なし学習というよりは素性の研究のような気がする。
P1-6 音声翻訳システム実利用データを用いた統計的機械翻訳のモデル適応 (pp.182-185)
安田圭志, 大熊英男, 内山将夫, 隅田英一郎, 磯谷亮輔, 河井恒, 中村哲 (NICT)
音声翻訳のシステムの利用ログを使って対訳コーパスを自動生成する話し。ユーザーからフィードバックがあるわけでもなく、単に入力の音声認識結果と、翻訳結果をもう1度逆翻訳した結果の一致率を見てコーパスとして採用するどうかを決めているようだ。音声認識の結果と再翻訳の結果が一致した10%の事例では正しい対訳コーパスが生成できたと考えられる。この研究以外にも対訳コーパスを自動生成する話はあったのだが、自動生成した対訳コーパスが増えれば増えるほど精度が向上するかというと、採用できるコーパスの多様性に限界があるのですぐに上限に達してしまいそうな気がした。
P1-7  Improving Sampling-based Alignment Method for Statistical Machine Translation Tasks (pp.186-189)
羅娟, 孫セイ, Yves LEPAGE (早大)
機械翻訳のアライメントのタスクで、一対多のアライメントを実現する改良を行ったという話。改良したツールをAnymalign1-Nというらしい。英語は読むのも聞くのも問題なかったが、ディスカッションとなるとまだうまく話せなかった。
P1-15     文外照応を含む文の検出による抽出型要約の品質向上 (pp.216-219)
西川仁, 長谷川隆明, 松尾義博, 菊井玄一郎 (NTT)
要約タスクで文を抽出するときに、指示代名詞などで文の外を参照しているときは1文前も要約に追加するという話。文外照応の検出にはロジスティック回帰を用いており、素性としては形態素解析以上の情報を用いていない。文書要約って短くなることに意味があると思うのだが、逆に長く取ることで品質が向上するというのも不思議な感じがした。
P2-10     大規模コーパスを用いた固有表現抽出手法の検討 (pp.328-331)
南和江, 藤井康寿, 土屋雅稔, 中川聖一 (豊橋技科大)
大規模コーパスといっても教師あり学習の話なので数千文書の話。固有表現抽出をCRFで学習するのに、FOBOSというオンライン学習を用いると高速化したという。
P2-25     ジャンル別LSIの結果統合による新聞記事のジャンル推定 (pp.384-387)
箕浦健太郎, 田村哲嗣, 速水悟 (岐阜大)
文書のカテゴリ分類の話なのだが、カテゴリごとに文書をベクトル化してLSAで次元圧縮した上で、その行列を混合正規分布にフィッティングさせた尤度でカテゴリ分類を行なうという変わった手法。最尤推定するなら最初から確率モデルのpLSAでやったほうがよいのではと思ってしまったが、単純なナイーブベイズとは違う結果になりそうだし解釈を聞きたかったのだが時間がなくて質問できなかった。
P2-32     言語内・言語間単語共起情報を併用した対訳文書の文アラインメント (pp.412-415)
熊野正, 田中英輝 (NHK)
機械翻訳で対訳コーパスを与えられたときに単語アライメントをする前に文アライメントが必要なケースについて扱った研究。通常の機械翻訳だと文アライメントは与えられるかヒューリスティックに行われることが多いと思うのだが、単語の共起だけを使って(順番を使わずに)文アライメントしてもそれなりの結果になるという。単語アライメントと違ってEMアルゴリズムのように繰り返し最適化するわけでもないようで、仮定がうまく効いているという。
ツイートする
Permalink | 22:08
言語処理学会1日目 #nlp2011 - Yoh Okunoの日記
