2013.2.20 WED
グーグルが脳をヒントに音声認識を向上させた方法とは
ニューラルネットワーク・アルゴリズムの研究分野は、1980年代に一世を風靡したものの、その後は長い間停滞が続いていた。最近では再び人気が高まっている。
人間の音声をアプリ「AndroSpectro」で視覚化したもの。
グーグルはAndroid OS最新版の開発にあたって、OSがユーザーの音声コマンドを解釈する方法に複数の大きな変更を加えた。同社が新たに追加したのは、人間の脳のように振舞うコンピューターの学習システム「ニューラルネットワーク」に基づく音声認識システムだ。
この開発に参加したグーグルの研究者、ヴィンセント・ヴァンホウケによれば、新たな変更がもたらした効果は劇的なものだったという。「(音声コマンドを解釈する)モデルを変更しただけで、これほど精度を改善できたのは驚きだった」(ヴァンホウケ氏)
ヴァンホウケ氏によれば、最新版Android(通称Jelly Bean)における音声認識のエラー率は前バージョンから約25%も低くなり、ユーザーはより快適に音声コマンド機能を利用できるようになったという。また、ユーザーが携帯電話に話しかける時、これまでロボットに話しかけるような不自然さがあったのとは違って、より自然に話すようになっているという。「音声認識精度の向上は、人々の振る舞い方を大きく変えつつある」(ヴァンホウケ氏)
これはニューラルネットワーク・アルゴリズムが、人類のテクノロジーの働きをいかに変えつつあり、どのように人々に利用されているかを示す一例にすぎない。この研究分野は1980年代に一世を風靡したものの、その後は長い間停滞が続いていた。しかし、現実的なアプリケーション開発を模索するグーグルに、マイクロソフトやIBMも加わって、最近では再び人気が高まっている。
ユーザーがAndroidの音声認識ソフトに話しかけるとき、ユーザーの音声スペクトルは細かく切り刻まれ、世界中に広がるグーグルのサーヴァーネットワークの8つのコンピューターに送られる。その後、ヴァンホウケ氏らが開発したニューラルネットワークモデルを利用して、この音声コマンドは処理される。このような大規模な分散型の高速処理は、グーグルがもっとも得意とするところだが、同社はその方法を見つけ出すために、現代のデータセンターに革新をもたらしたジェフ・ディーンらのチームに力を借りた。
ニューラルネットワークは大量のパターン(Jelly Beanの場合はユーザーの音声スペクトル)を分析し、未知のパターンについても予測することができる。これは、体内の神経細胞が他の細胞とネットワークを築き、特別な方法で信号を処理していることにヒントを得て開発したもの。Jelly Beanが利用するようなニューラルネットワークにおいて、グーグルは実世界にある大量のデータを分析することで、言語の働きに関する複数のモデルを作り上げたとみられる。英語の音声検索リクエストに関するモデルもその1つだ。
「脳内の構造を見てもわかるように、優れた知覚システムを作るためには、機能が多層的なものでなければならないと考えられてきた」と話すのは、トロント大学の計算機科学の教授であるジェフリー・ヒントン。「問題はいかにして効率的に学習させるかということだった」(ヒントン氏)
まず、音声の各部分を検出する
グーグルが脳をヒントに音声認識を向上させた方法とは   « WIRED.jp
