テキスト検索と同様に、大量に録画・蓄積されたビデオデータに対しても、利用者の求めるシーンをキーワード検索する機能が求められている。本研究では、講義・講演映像の音声認識結果とプレゼンテーション資料中のテキストという、性質・分量の異なる2種類のテキストを対応付けることで、プレゼンテーション資料を元の講義・講演映像の言語インデックスとする手法を提案する。対応付けはプレゼンテーション資料のスライド単位でとる。これにより、スライド単位で、プレゼンテーション資料のテキストを介した講義・講演映像のキーワード検索が可能となる。正解対応付けとのずれ時間を評価した結果、全スライドの約87%が誤差1分以内に収まった。
Keyword search for the certain scene in video data seems to be in great demand as well as text search. We would like to propose a new approach which enables to make a text index without detailed scripts but with presentation slides. We focus on lecture videos, and we will explain how to make a text index by aligning two different materials ; speech recognition results and presentation slides. We align them by slide so that keyword search for lecture videos can be done by slide. We evaluated the difference time between the correct alignment and our alignment results. About 87% slides are aligned in 1 minute error or less.

