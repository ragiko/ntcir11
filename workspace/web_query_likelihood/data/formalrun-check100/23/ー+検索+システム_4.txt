検索エンジン(けんさくエンジン、英語: search engine)は、狭義にはインターネットに存在する情報(ウェブページ、ウェブサイト、画像ファイル、ネットニュースなど)を検索する機能およびそのプログラム。インターネットの普及初期には、検索としての機能のみを提供していたウェブサイトそのものを検索エンジンと呼んだが、現在では様々なサービスが加わったポータルサイト化が進んだため、検索をサービスの一つとして提供するウェブサイトを単に検索サイトと呼ぶことはなくなっている。広義には、インターネットに限定せず情報を検索するシステム全般を含む。
狭義の検索エンジンは、ロボット型検索エンジン、ディレクトリ型検索エンジン、メタ検索エンジンなどに分類される。広義の検索エンジンとしては、ある特定のウェブサイト内に登録されているテキスト情報の全文検索機能を備えたソフトウェア(全文検索システム)等がある。
検索エンジンは、検索窓と呼ばれるボックスにキーワードを入力して検索をかけるもので、全文検索が可能なものと不可能なものとがある。検索サイトを一般に「検索エンジン」と呼ぶことはあるが、厳密には検索サイト自体は検索エンジンでない。
検索エンジン(狭義)[編集]
ロボット型検索エンジン[編集]
与えられた検索式に従って、ウェブページ等を検索するサーバ、システムのこと。検索式は、最も単純な場合はキーワードとなる文字列のみであるが、複数のキーワードにAND(「かつ」、論理積)やOR(「または」、論理和)等の論理条件を組み合わせて指定することができるものが多い。
ロボット型検索エンジンの大きな特徴の一つとして、クローラ(ロボット・スパイダー)を用いることが挙げられる。このことにより、WWW上にある多数の情報を効率よく収集(日本の著作権法では複製)することができる。大規模な検索エンジンでは、80億ページ以上のページから検索が可能になっている。
収集したページの情報は、前もって解析し、索引情報(インデックス)を作成する(日本の著作権法では編集)。日本語などの言語では、自然言語処理機能が生成される索引の質に影響する。このため、多言語対応した検索エンジンの方が精度の高い検索が可能となる。
検索結果の表示順は、検索エンジンの質が最も問われる部分である。ユーザーが期待したページを検索結果の上位に表示することができなければ、ユーザーが離れてしまうからである。そのため、多くの検索エンジンが、表示順を決定するアルゴリズムを非公開にし、その性能を競っている。検索エンジン最適化業者の存在も、アルゴリズムを公開しない要因になっている。Googleは、そのアルゴリズムの一部であるPageRankを公開しているが、やはり、多くの部分が非公開になっている。Googleの場合、創設初期におけるアルゴリズムについては、創設者自身がウェブ上で公表している論文でその一端を知ることができる。 参照 英語原文[1]日本語の解説[2]
ウェブページの更新時刻の情報を用いて、新しい情報に限定して検索できるものや、検索結果をカテゴリ化して表示するものなど、特長のある機能を搭載したり、検索結果をユーザーへ最適化していく動きもある。
従来のウェブページを検索するだけの検索エンジンにとどまらず、最近ではインターネットショッピング専用の検索エンジンなど、特定の分野に特化した検索エンジンの開発も散見される。商品検索では、価格比較サービス日本最大手の価格.comや、ベンチャー企業が開発するQOOPIEなどある。また、職業検索エンジンとしてはCraigslistなどがある。 google、Yahoo!、インフォシーク、テクノラティ、MARSFLAG、Altavista、ムーター、AlltheWeb、Teoma、WiseNut、Inktomi、SAGOOL、Yahoo! JAPAN (2005.10～) など。
ディレクトリ型検索エンジン[編集]
人手で構築したウェブディレクトリ内を検索するサーバ、システムのこと。
人手で構築しているため、質の高いウェブサイトを検索可能。概要を人手で記入しているため、検索結果の一覧から目的のサイトを探しやすい、サイトのカテゴリ分けがされていることから、特定分野や地区などに限定したサイトを探しやすいという特長がある。
しかし、検索対象となるサイトは人手で入力するため、検索対象となるサイト数が多くできないという欠点がある。
インターネットが一般に使われるようになった初期(1990年代)のころには、ディレクトリ型が主体であったが、WWWの爆発的な拡大によって、あらゆるウェブサイトを即時にディレクトリに反映させることが事実上不可能になり、現在では主流ではなくなっている。 このため、ディレクトリ型検索エンジンでは、検索にヒットするサイトが無かった場合、ロボット型検索エンジンを用いて結果を表示するような、併用型のものが多い。
日立国際ビジネスのHole-in-One(〜04.11)、Yahoo! JAPAN(～05.10)、LookSmart Japan(～06.05)、goo、infoseek、Open Directory Projectなど。
メタ検索エンジン[編集]
ひとつの検索ワードを複数の検索エンジンで検索することをメタ検索という(横断検索エンジンと呼ぶこともある)。 詳細は「メタ検索エンジン」を参照のこと。
検索エンジン(広義)[編集]
全文検索システム[編集]
詳細は「全文検索」を参照
与えられた文書群から、検索式(キーワードなど)による全文検索機能を提供するソフトウェア、システムの総称で、ウェブサーバに組み込んで利用されることが多い。スタンドアローン環境で用いられる個人用途のものもあり、そういったものは特に「デスクトップ検索」と呼ばれている。
歴史[編集]
黎明期[編集]
日本のインターネット普及初期から存在した検索エンジンには以下のようなものがある。黎明期には、豊橋技術科学大学の学生が作成したYahhoや、東京大学の学生が作成したODiN、早稲田大学の学生が作成した千里眼など、個人の学生が作成したものが商用に対して先行していた(いずれも1995年に作成、日本電信電話株式会社のNTT DIRCECTORY 、サイバースペースジャパン(現・ウェブインパクト)のCSJインデックスは1994年に作成)。これらは単に実験用に公開されていただけでなく、多くの人に用いられていたものであり、黎明期のユーザにとっては知名度、実用度ともに高いものであった。またMondouなどのように研究室(京都大学)で作成したものもあった。
Yahoo! JAPAN の独走[編集]
1995年12月にソフトバンクがアメリカ合衆国Yahoo!株を一部買い取り、翌年4月から日本版にローカライズしたYahoo! JAPANをサービス開始した。同年7月の展示会Interopでは机2つぶん並べる程度の小規模ブースで出展する程度の力の入れ具合で、ソフトバンクの一部署として開始する程度だったものが、もともとの米国Yahoo!の知名度、90年代後半のインターネット利用者人口の増加、ディレクトリ型だけだった検索をロボット型も追加、サイト登録した一部のウェブサイトの紹介をするYahoo! Internet Guide(ソフトバンククリエイティブ出版)との連携、日本Yahoo!株高騰のニュースでインターネットを利用しない人にも名前が知れ渡るなど、様々なプラス要因と経営戦略が見事に当たり、検索サイト首位の座を固めた。そして、検索サイトの集客力を武器にニュース、オークションなど、検索サービス以外のサービスを含めたポータルサイトとしての独走を始めた。
群雄割拠[編集]
1997年頃から、WWWの爆発的な拡大に伴って、ディレクトリ型のみであったYahoo!のウェブディレクトリの陳腐化が急速に進んだ。この頃、infoseekやgooに代表されるロボット型検索エンジンが人気を集め始め、Yahoo! JAPANはロボット型検索エンジンにgooを採用するなど、群雄割拠の時代になった。
Googleの台頭[編集]
Googleが1998年に稼動させたGoogle検索は、従来の検索エンジンがポータルサイト化へと進む流れに逆行し、独創的な検索技術に特化し、バナー広告等を排除したシンプルな画面と2000年にYahoo!のロボット型検索エンジンに採用されたことにより、急速に人気を集めた。いつしか[要検証 – ノート]ウェブページ検索の世界シェアのトップに躍り出たとされている。また日本においても、GoogleやYahoo!などの検索エンジンを利用すること=「ググる」というネットスラングが生まれた。この状況に危機感を募らせたYahoo!は、2004年にロボット型検索エンジンを独自技術Yahoo!Search Technology (YST)(Yahoo!が買収したInktomiとAltaVista、Overture等の技術を統合した)に切り替えた。同年、GoogleやYahoo!のエンジンに匹敵すると言われるTeomaを利用した検索エンジン、Ask Jeeves(現・Ask.com)が「Ask.jp」として、2005年、オーストラリアで誕生したMooterが日本に進出し、検索サービスを開始した。
検索エンジンの多様化[編集]
検索という行為が一般化するにつれて、各種目的別に多様化した検索エンジンが現れるようになった。ブログの情報に特化した検索TechnoratiやblogWatcher、商品情報の検索に特化した商品検索サイト、サイトの見た目で検索するMARSFLAG、音楽検索、動画検索、ファイル検索、アップローダ検索ほか、次々と新しい検索エンジンが生まれている。
また、検索エンジンでは判断できない抽象的な条件などでの検索を人手に求めた、OKWaveや人力検索はてななどの「人力検索」「ナレッジコミュニティ」と呼ばれるサービスも登場した。
近年ではパソコンだけでなく携帯電話や携帯型ゲーム機からもウェブサイトが検索される傾向が高くなり、GoogleやYahoo!をはじめとする携帯向けのモバイル検索サイトが登場し活気がでている。
対応端末の多様化[編集]
ソフトバンク・Yahoo! JAPANがボーダフォンを買収し、KDDIがGoogleと提携するなど、携帯電話の分野で検索エンジンの戦いが激化してきている。モバイル検索の分野は長らく公式サイトと呼ばれる世界がユーザーの囲い込みを行っていたため、脚光を浴びることが少なかった。
リーガルリスク[編集]
深層ウェブ[編集]
Googleなどのウェブ検索エンジンでは、データベースの検索結果など多くの動的ページが検索対象になっていない。このような動的ページは「深層ウェブ」「見えないウェブ」「隠されたウェブ」などと呼ばれている。静的ページの500倍の量が存在し、多くは無料だといわれる。深層ウェブは、一般の検索エンジンなどからデータベースなどを見つけ出すか、直接アクセスした上で、それぞれの検索機能から再度検索しなければならない。
このようにWebページが深層と表層に分かれてしまう背景には検索エンジン側が晒される法的リスクがある。深層にあるものは必ずしも検索エンジンから検索されることを前提としていないものも多い。すべての深層データが検索エンジンから検索可能な状態になっていた場合、動的ページの情報提供者の存在意義を脅かす可能性もある。本来であれば非公開とされているようなデータが誤って検索されてしまうという可能性も高くなる。さらに、データベースと連動する動的ページをクローラーが集中的にクロールすると、データベース側の負荷が上がるためサーバ速度の低下やシステムダウンを引き起こす危険が高まる。このようなことから検索エンジンは技術的に深層に入り込めない訳ではなく、あえて避けていると推測することができる。実際、中国の検索エンジン百度は集中的なクロール活動を続けた結果、多くのサーバ管理者から一斉にクレームを受け、クロール活動を大きく制限せざるを得なかった。
著作権との関係[編集]
ロボット型検索エンジンは、その原理上インターネット上のコンテンツを複製してキャッシュとして保存するようになっている。著作権をたてに、ウェブサイトの閲覧利用規約等と称して、一切のいかなる複製も禁ずるとするサイト等があり、どういったものかと古くより話題になっていた[3]。
また、2006年11月には、日本の知的財産戦略本部コンテンツ専門調査会第3回企画ワーキンググループ(WG)において、検索エンジンに関して「著作権法上、複製、編集には権利者の許諾が必要であり、Yahoo!、googleなど大手検索システムのサーバーは海外に置かれているのが現状。」[4]と報告され、これをうけて経済産業省が日本国内でも合法的に検索エンジンサービスが行えるように著作権法の改正や検索エンジンの開発に取り組むと発表し[要出典]、2010年1月の改正で複製が合法とされた。
このことを拡大解釈したのか、あたかも著作権法のために、日本ではGoogleのような企業が育たなかったであるとか、日本におけるネット検索を妨げたのは著作権法である、といった論が巷に見られるが(フェアユース規定がない等の点は従来より指摘されてはいるが)、このWG報告以前に、著作権法によりネット検索の事業が妨げられた、というような話はない。
なお、この場合の"キャッシュ"とは、検索エンジンの内部使用のための複製や要約(スニペット)作成のための複製であり、一時的にウェブサイトが閲覧しづらい場合のためにユーザーに閲覧させる目的のアーカイブ(グーグルでは"キャッシュ"とも呼ばれる)は、依然として法的にはグレーゾーンである。また、アーカイブは、必ずしも検索エンジンの運営に不可欠とまでは言えず、ウェブサイトを丸ごとアーカイブとして提供する場合には著作権法の2010年改正部分が言う複製の範囲を超えるおそれがある。
社会的な問題[編集]
ストーカー行為の助長[編集]
検索エンジンを利用したストーカー行為の事例も発生するようになってきた。個人の氏名で検索すると非常に詳細な個人情報が取得できるケースもあるが、個人情報の削除要請に対し検索エンジン各社は、元のページの作成者に一切の責任があるとして、応じない方針を取っている。Yahoo!では削除要請を依頼するための連絡先すら掲示せず利用者からの依頼を無視することでこの問題に対処する方針をとっている。検索エンジンの利用のうち30%程度が個人情報に関連する検索で占められており、プライバシー問題は検索エンジン各社にとって触れられたくない問題であるのは事実である。
mixiに代表されるソーシャル・ネットワーキング・サービス (SNS) では本名での登録を促しているが、これは名前さえわかればSNSサイトの検索機能で容易に個人を特定可能であり、自らに関連するカテゴリへの参加(喩えば卒業校)や公開された参加者間の会話などで、容易に個人の情報を推測・取得できる。クローズドなサイトで公開されていたものであっても、一般公開サイトに転載されてしまうケースがある。検索機能がストーカー行為を助長しているという指摘もある。
学校裏サイトの問題[編集]
2007年以降問題となっている学校裏サイト。その多くが、特定個人名を挙げての誹謗中傷を主にしたものであり、学校名では検索できない場合でも、個人名で検索するとその存在が判明するものも多い。不特定多数のものが匿名で作るサイトであるため、サイト管理者に対応を求めることが困難であるケースが多い。こういったケースでは検索エンジンからの削除を求める以外に被害の拡大を防ぐことは難しいが、検索エンジン各社は明白な誹謗中傷の場合であっても個々の削除依頼者に不必要なほどの詳細な説明を求めることが常態化しており、不明確な基準により削除をせず、誹謗中傷が引き続き検索エンジンで検索されつづけることも少なくない。
言論弾圧への加担[編集]
中国の検索エンジンでは反政府的な内容や政府が弾圧しているといわれる宗教団体に関する情報は検索結果に表示されなくなっている。Googleなどは検索結果の中に「表示されている内容は一部法律に基づいて省略されている」という記述があるが、結果的に中国政府の言論弾圧に手を貸しているという批判がある。同様の批判はYahoo!やMSNにも向けられている。
こうした露骨な言論弾圧以外にも、上場企業のウェブサイトがスパムと判断され検索結果に掲載されなくなるということがある。検索サイトに表示されることは企業や商用サイトにとって莫大な利益を還元することであり、同時に検索されない場合の不利益は非常に大きい。
誹謗中傷の増幅効果[編集]
インターネット上で実名を挙げて誹謗中傷された場合、検索エンジンの力によりその効果が大幅に増幅される。この誹謗中傷に関する検索結果に対し、Googleでは "通信品位法第 230 (c) 条に基づき、弊社では、Google.com での検索結果から中傷的なコンテンツを削除することを行っておりません。" とし、削除しない方針を明示している。他の多くの検索サイト運営会社は、誹謗中傷に関する検索結果について、インデックスからの削除についてはあいまいにしつつも、不削除の方針を取っている。
不明確な基準[編集]
膨大なインターネット上の情報を網羅的に調査するには大手の検索エンジンを利用するほか方法が無い。このためURLがあまり知られていない無名なウェブサイトやドキュメントなどに関しては検索エンジンに検索結果として表示されなければ、その情報にたどりつく可能性が著しく少なくなってしまう。表示されなくなる基準は露骨な検索エンジン最適化テクニックを使用しているサイトや各国の法律等に反しているサイト(下記中国の例)、公序良俗に悖るサイト(アダルトサイト、誹謗中傷が主体のサイト等)と考えられているが、その明確な基準はGoogleを除いては各社共に不明瞭であり、検索結果から削除される際の該当ウェブサイトへの警告は基本的にない。各社とも、検索エンジンスパムには厳しい姿勢を取る反面、公序良俗に反するサイトの非表示には消極的である。
検索エンジン各社にとって、公序良俗に反するサイトをも含め検索できるような状態にしておくことが結果として自社の検索エンジンのシェアを高めることになるため、積極的に不適切なサイトを排除するという動機は働きにくい。
そのほか[編集]
多言語化の課題 [編集]
いわゆる「使用言語からみたインターネット人口の割合」はInternet Archiveを用いてEuro MarketingとGlobal Reachから過去の月次資料を整理すると次のような推移を辿っている。
検索エンジン - Wikipedia
