　オペレータと顧客の対話が録音されている音声対話データから，顧客が問い合わせを行っている質問発話部を抽出するために，コンピュータに，
　オペレータの音声が録音された第１チャネルと顧客の音声が録音された第２チャネルとで構成されている音声対話データを入力する処理と，
　前記音声対話データの各チャネルについて，所定単位区間ごとの音声のパワー値を算出し，当該パワー値を時系列で並べた音声パワー情報を生成する処理と，
　前記第１チャネル音声パワー情報および第２チャネルの音声パワー情報を時系列で先頭から比較し，所定の判定単位区間各々において，前記パワー値の当該判定単位区間の総計または割合が，より大きい値となるチャネルを当該判定単位区間での主導発話者と判定し，前記時系列でより先頭に近い判定単位区間の主導発話者を先行主導発話者と特定し，前記先行主導発話者の判定単位区間から連続かつ前記先行主導発話者と同一の主導発話者の判定単位区間を先行主導発話時間とする処理と，
　前記先行主導発話者のチャネルが前記第２チャネルである場合に，当該第２チャネルの前記先行主導発話時間に該当する時間を質問発話部として特定する処理と，
　前記音声対話データの第２チャネルの前記質問発話部と特定された箇所の音声データを質問発話部データとして抽出する処理とを，
　実行させる音声データの質問発話部抽出処理プログラム。
　コンピュータが実行する，オペレータと顧客の対話が録音されている音声対話データから，顧客が問い合わせを行っている質問発話部を抽出する処理方法であって，
　オペレータの音声が録音された第１チャネルと顧客の音声が録音された第２チャネルとで構成されている音声対話データを入力する処理ステップと，
　前記音声対話データの各チャネルについて，所定単位区間ごとの音声のパワー値を算出し，当該パワー値を時系列で並べた音声パワー情報を生成する処理ステップと，
　前記第１チャネル音声パワー情報および第２チャネルの音声パワー情報を時系列で先頭から比較し，所定の判定単位区間各々において，前記パワー値の当該判定単位区間の総計または割合が，より大きい値となるチャネルを当該判定単位区間での主導発話者と判定し，前記時系列でより先頭に近い判定単位区間の主導発話者を先行主導発話者と特定し，前記先行主導発話者の判定単位区間から連続かつ前記先行主導発話者と同一の主導発話者の判定単位区間を先行主導発話時間とする処理ステップと，
　前記先行主導発話チャネルが前記第２チャネルである場合に，当該第２チャネルの先行主導発話時間に該当する時間を質問発話部として特定する処理ステップと，
　前記音声対話データの第２チャネルの前記質問発話部と特定された箇所の音声データを質問発話部データとして抽出する処理ステップとを備える
　音声データの質問発話部抽出処理方法。
　オペレータと顧客の対話が録音されている音声対話データから，顧客が問い合わせを行っている質問発話部を抽出する処理装置であって，
　オペレータの音声が録音された第１チャネルと顧客の音声が録音された第２チャネルとで構成されている音声対話データを入力する音声データ入力部と，
　前記音声対話データの各チャネルについて，所定単位区間ごとの音声のパワー値を算出し，当該パワー値を時系列で並べた音声パワー情報を生成する音声パワー情報生成部と，
　前記第１チャネル音声パワー情報および第２チャネルの音声パワー情報を時系列で先頭から比較し，所定の判定単位区間各々において，前記パワー値の当該判定単位区間の総計または割合が，より大きい値となるチャネルを当該判定単位区間での主導発話者と判定し，前記時系列でより先頭に近い判定単位区間の主導発話者を先行主導発話者と特定し，前記先行主導発話者の判定単位区間から連続かつ前記先行主導発話者と同一の主導発話者の判定単位区間を先行主導発話時間とする先行主導発話者・時間特定部と，
　前記先行主導発話チャネルが前記第２チャネルである場合に，当該第２チャネルの先行主導発話時間に該当する時間を質問発話部として特定する質問発話部判定部と，
　前記音声対話データの第２チャネルの前記質問発話部と特定された箇所の音声データを質問発話部データとして抽出する質問発話部抽出部とを備える
　音声データの質問発話部抽出処理装置。
　オペレータと顧客の対話が録音されている音声対話データから，顧客の問い合わせの傾向を推定するために，コンピュータに，
　オペレータの音声が録音された第１チャネルと顧客の音声が録音された第２チャネルとで構成されている音声対話データを入力する処理と，
　前記音声対話データの各チャネルについて，所定単位区間ごとの音声のパワー値を算出し，当該パワー値を時系列で並べた音声パワー情報を生成する処理と，
　前記第１チャネル音声パワー情報および第２チャネルの音声パワー情報を時系列で先頭から比較し，所定の判定単位区間各々において，前記パワー値の当該判定単位区間の総計または割合が，より大きい値となるチャネルを当該判定単位区間での主導発話者と判定し，前記時系列でより先頭に近い判定単位区間の主導発話者を先行主導発話者と特定し，前記先行主導発話者の判定単位区間から連続かつ前記先行主導発話者と同一の主導発話者の判定単位区間を先行主導発話時間とする処理と，
　前記先行主導発話チャネルが前記第２チャネルである場合に，当該第２チャネルの先行主導発話時間に該当する時間を質問発話部として特定する処理と，
　前記音声対話データの第２チャネルの前記質問発話部と特定された箇所の音声データを質問発話部データとして抽出する処理と，
　前記質問発話部データに対して所定の音声認識処理を行い，当該質問発話部データの音声に相当するテキストデータを取得する処理と，
　予め備えられた単語辞書を用いて，前記テキストデータから単語を抽出する処理と，
　前記抽出されたキーワードに対して所定の分類処理を行い，クラスタ数が多い順に並べた分類情報を問い合わせ傾向情報として出力する処理とを，
　実行させる音声データの質問発話部を用いた顧客問い合わせ傾向推定処理プログラム。
音声データの質問発話部抽出処理プログラム，方法および装置，ならびに音声データの質問発話部を用いた顧客問い合わせ傾向推定処理プログラム，方法および装置  
　本発明は，コンピュータに，オペレータと顧客の対話内容が録音された音声対話データから，顧客の問い合わせを含む箇所（以下，#36074;問発話部#12392;いう）を抽出する処理を実行させるための音声データの質問発話部抽出処理に関する。
　さらに，本発明は，コンピュータに，前記音声対話データから抽出された質問発話部を用いて，顧客の問い合わせ傾向を推定する処理を実行させるための音声データの質問発話部を用いた顧客問い合わせ傾向推定処理に関する。
　コールセンタでは，顧客とオペレータとの対話内容を後から聴取できるように，全対話内容を録音した音声対話データを保存している。
　コールセンタに蓄積された大量の音声対話データは，単に対話内容を確認するための資料として利用されるだけではなく，顧客とオペレータとの対話から様々な情報を得て，資料として活用されることが期待されている。
　音声対話データを利用する場合には，その利用目的に応じて必要な部分のみを聞くことができれば十分であり，対話の開始から終了まで全てを聞くことは，多くの時間を要するので効率的ではない。例えば，音声対話データの活用方法の一つとして，対話内容から顧客の問い合わせの傾向を推定する場合には，顧客の問い合わせを含む部分の音声データを抽出する必要がある。
　音声対話データのうち，オペレータと顧客の応答の核心的部分を特定し再生可能とするために，音声認識処理などによって抽出したキーワードやオペレータの端末画面の操作情報などを音声対話録音データにインデックスとして付与しておき，音声対話録音データ再生時に再生開始位置を特定するために利用できるようにする従来方法がある（例えば，特許文献１参照）。  特開平１１－２５１１２号公報  
　音声対話データを活用して，対話内容から顧客の問い合わせの傾向を推定する場合には，以下のような従来方法が行われている。
　〔従来手法１〕
　ステップＳ９０１：コールセンタで録音された音声対話データを作業者が聴取し，対話内容から顧客の問い合わせの箇所を判定する。
　ステップＳ９０２：顧客の問い合わせと判定された箇所の内容を示すキーワードを選択し，書き出す（キーワードをテキストデータ化する）。
　ステップＳ９０３：キーワードデータを分類処理し，分類カテゴリー数の多い順にキーワードを並べて問い合わせ傾向とする。
　〔従来手法２〕
　ステップＳ９１１：予め，オペレータに顧客の問い合わせ内容を記録するように指示する。
　ステップＳ９１２：オペレータが，応対結果として，顧客の問い合わせ内容を記録する（問い合わせ内容をテキストデータ化する）。
　ステップＳ９１３：問い合わせ内容の記録データを分析処理し，問い合わせの傾向を推定する。
　従来手法１および２では，ステップＳ９０２，Ｓ９１２の処理のように，音声対話データから，顧客の問い合わせの傾向を推定するためのデータを，書き起こす作業によって得ていた。従来手法１では，音声対話録音データの聴取とキーワードの選択の作業が作業者によって行われている。また，従来手法２では，問い合わせ内容の記録作業がオペレータによって行われている。
　一方，音声対話データの内容をテキストデータ化する音声認識処理が知られている。しかし，音声対話データに対して一律に音声認識処理を施し，問い合わせ傾向を推定する対象データ（テキストデータ）を得た場合には，以下のような問題が生じる。
　・　音声対話データの全区間に対して音声識別処理を行う場合，音声対話データに顧客が問い合わせをしている箇所（質問発話部）が必ず含まれているわけではなく，無駄となるデータが多くなる。
　・　さらに，質問発話部以外の部分が混在するデータに対して分析処理が行われるため，対話全体の内容の傾向が推定され，顧客の問い合わせの傾向を反映した推定結果を得ることができない。
　本発明の目的は，音声対話データから，顧客の問い合わせを含む箇所（質問発話部）を人手によらずに切り出すことができる処理手法を提供することである。
　さらに，本発明の別の目的は，音声対話データから切り出した質問発話部の音声データを用いて，顧客の問い合わせの傾向を推定できる処理手法を提供することである。
　まず，本発明の原理を説明する。一般的に，対話中の話者間において，主導的に発話している発話者は，発話の応対者に比べて，一定の大きさの音声で継続的に発話する傾向がある。例えば，質問者と応答者との対話では，質問者が先行して主導的に質問を発話し，応答者がその質問に対する応答を発話するという状況が想定される。この状況において，質問は，質問者の先行する主導的な発話としてなされ，かかる質問の発話中は，一定の大きさの音声での継続的な発話として認識できると考えられる。
　本発明にかかる処理は，質問者と応答者との対話中に生じる音声上の特徴を利用して，顧客とオペレータの対話から，顧客が質問していると考えられる発話の期間を抽出するものである。
　本発明にかかる処理によれば，顧客とオペレータとの音声対話データから，音声の大きさを利用して，主導的かつ先行して発話している者（先行主導発話者）を特定し，顧客の音声が，オペレータの発話に先行し，かつ主導的に発話されている場合に，該当する顧客の継続的な発話期間（先行主導発話期間）を，顧客が質問している期間とみなし，当該箇所を顧客の問い合わせを含む箇所（質問発話部）として抽出する。
　具体的には，ここで開示するプログラムは，オペレータと顧客の対話が録音されている音声対話データから，顧客が問い合わせを行っている質問発話部を抽出するために，コンピュータに，オペレータの音声が録音された第１チャネルと顧客の音声が録音された第２チャネルとで構成されている音声対話データを入力する処理と，前記音声対話データの各チャネルについて，所定単位区間ごとの音声のパワー値を算出し，当該パワー値を時系列で並べた音声パワー情報を生成する処理と，前記第１チャネル音声パワー情報および第２チャネルの音声パワー情報を時系列で先頭から比較し，所定の判定単位区間各々において，前記パワー値の当該判定単位区間の総計または割合が，より大きい値となるチャネルを当該判定単位区間での主導発話者と判定し，前記時系列でより先頭に近い判定単位区間の主導発話者を先行主導発話者と特定し，前記先行主導発話者の判定単位区間から連続かつ前記先行主導発話者と同一の主導発話者の判定単位区間を先行主導発話時間とする処理と，前記先行主導発話チャネルが前記第２チャネルである場合に，当該第２チャネルの先行主導発話時間に該当する時間を質問発話部として特定する処理と，前記音声対話データの第２チャネルの前記質問発話部と特定された箇所の音声データを質問発話部データとして抽出する処理とを，実行させるものである。
　当該プログラムを実行するコンピュータは，オペレータの音声が録音された第１チャネルと顧客の音声が録音された第２チャネルとで構成されている音声対話データを入力し，音声対話データの各チャネルについて，所定単位区間ごとの音声のパワー値を算出し，当該パワー値を時系列で並べた音声パワー情報を生成する。
　そして，第１チャネル音声パワー情報および第２チャネルの音声パワー情報を先頭から所定の判定単位区間ごとに比較し，前記音声対話データにおいて先行して発話した先行発話者のチャネルを特定する。さらに，前記判定単位区間内で一定のパワー値による発話の割合が高いチャネルを主導発話者と判定し，先頭に最も近い判定単位区間の主導発話者を先行主導発話チャネルと特定し，当該先行主導発話者と同じ主導発話者が連続する判定単位期間を先行主導発話時間とする。
　さらに，先行主導発話チャネルが前記第２チャネルである場合に，第２チャネルの先行主導発話時間に該当する時間を質問発話部として特定し，音声対話データの第２チャネルの質問発話部と特定された箇所の音声データを質問発話部データとして抽出する。
　これにより，オペレータの音声と顧客の音声とが別のチャネルにそれぞれ録音されている音声対話データから，顧客の問い合わせを含む音声データ（質問発話部データ）を自動的に抽出されるため，顧客の問い合わせを推定する場合に使用するデータを，手作業によらずに容易に得ることができる。
　さらに，ここで開示する別のプログラムは，オペレータと顧客の対話が録音されている音声対話データから，顧客の問い合わせの傾向を推定するために，コンピュータに，前記プログラムと同様の処理を実行させるとともに，さらに，前記質問発話部データに対して所定の音声認識処理を行い，質問発話部データの音声に相当するテキストデータを取得する処理と，予め備えられた単語辞書を用いて，テキストデータから単語を抽出する処理と，抽出されたキーワードに対して所定の分類処理を行い，クラスタ数が多い順に並べた分類情報を問い合わせ傾向情報として出力する処理とを，実行させるものである。
　これにより，音声対話データから抽出された質問発話部データに対して音声認識処理を行い，取得したテキストデータをもとに顧客の問い合わせ傾向を推定する処理を自動化して行うことができる。
　本発明によれば，音声対話データから，顧客の問い合わせの傾向を推定するためのデータを書き起こす作業が不要となり，顧客の問い合わせを含む箇所の音声データ（質問発話部データ）を容易かつ効率的に抽出することができる。
　また，音声対話データから，顧客の問い合わせを含む箇所（質問発話部データ）のみ切り出すことができるため，音声認識処理の処理コストを著しく軽減することができる。
　さらに，質問発話部データに対する音声認識処理によって，顧客の問い合わせを含むテキストデータが得られるため，かかるテキストデータを既知の分析・分類することによって顧客の問い合わせ傾向の推定処理を実現することが可能になる。
問い合わせ傾向推定装置の構成例を示す図である。 質問発話部抽出装置の構成例を示す図である。 質問発話部抽出装置の概要処理フロー図である。 音声対話データのオペレータおよび顧客の発話の例を示す図である。 音声対話データのデータ構成を示す図である。 音声パワー情報の生成処理の処理フロー図である。 音声対話データ（録音１）の音声パワー情報を示す図である。 音声対話データ（録音２）の音声パワー情報を示す図である。 音声対話データ（録音３）の音声パワー情報を示す図である。 音声対話データ（録音４）の音声パワー情報を示す図である。 総応対時間の説明図である。 音声対話データ（録音１～４）の総応対時間を示す図である。 先行発話チャネルの説明図である。 音声対話データ（録音１～４）の先行発話チャネルを示す図である。 先行主導発話者（先行主導発話チャネル）の説明図である。 先行主導発話者および先行主導発話時間を求める処理フロー図（その１）である。 先行主導発話者および先行主導発話時間を求める処理フロー図（その２）である。 音声対話データ（録音１）の先行主導発話時間の計算結果を示す図である。 音声対話データ（録音２）の先行主導発話時間の計算結果を示す図である。 音声対話データ（録音３）の先行主導発話時間の計算結果を示す図である。 音声対話データ（録音４）の先行主導発話時間の計算結果を示す図である。 ルールベースによって質問発話部を判定する処理フロー図である。 質問発話部へ入力されるデータの例を示す図である。 質問発話部判定のルール例を示す図である。 機械学習処理によって質問発話部を判定する場合の学習段階の処理フロー図である。 機械学習処理の教師データの例を示す図である。 教師データによって判別式のための値を計算した例を示す図である。 機械学習処理によって質問発話部を判定する場合の判別段階の処理フロー図である。 問い合わせ傾向推定システムの概要処理フロー図である。 問い合わせ傾向の分析例を示す図である。 
符号の説明 
　１　問い合わせ傾向推定システム
　１０　質問発話部抽出装置
　１１　音声データ入力部
　１２　音声パワー情報生成部
　１３　先行主導発話者・時間特定部
　１４　質問発話部判定部
　１５　質問発話部抽出部
　２０　音声認識装置
　２３　単語辞書
　２５　傾向分析装置
　３　音声対話データ
　５　問い合わせ傾向情報
　７　質問発話部データ
　９　キーワード
　図１は，問い合わせ傾向推定装置の構成例を示す図である。
　問い合わせ傾向推定システム１は，顧客とオペレータとの対話を別チャネルで録音した音声対話データ３から，顧客の問い合わせ傾向を推定した問い合わせ傾向情報５を出力するシステムである。
　問い合わせ傾向推定システム１は，質問発話部抽出装置１０，音声認識装置２０，単語辞書２３および傾向分析装置２５を備える。
　質問発話部抽出装置１０は，音声対話データ３から，顧客が問い合わせをしている発話が含まれる箇所の音声データ（質問発話部データ）を抽出する。
　音声認識装置２０は，単語辞書２３を用いて質問発話部データ７を音声認識処理し，生成したテキストデータからキーワードを抽出する。
　傾向分析装置２５は，キーワード９に対し，クラスタリング処理，傾向分析処理を行って顧客の問い合わせ傾向を推定し，問い合わせ傾向情報５として出力する。
　図２は，問い合わせ傾向推定システム１の質問発話部抽出装置１０の構成例を示す図である。
　質問発話部抽出装置１０は，音声データ入力部１１，音声パワー情報生成部１２，先行主導発話者・時間特定部１３，質問発話部判定部１４および質問発話部抽出部１５を備える。
　音声データ入力部１１は，オペレータの発話音声が録音された第１のチャネル（Ｌチャネル）と顧客の発話音声が録音された第２のチャネル（Ｒチャネル）とで構成されている音声対話データ３を入力する。
　音声パワー情報生成部１２は，音声対話データ３の各チャネルについて，所定単位区間ごとの音声の大きさを示すパワー値を算出し，算出したパワー値を時系列で並べた音声パワー情報４を生成する。
　音声パワー情報４は，各チャネルの音声データの所定単位区間での大きさ（パワー）の平均値を，所定の閾値ｔｈを用いてビット列へ変換し，時系列で並べたビット列の情報である。したがって，発話の音声パワーが一定の閾値ｔｈ以上の大きさであれば，ビットに#65297;#12434;格納し，そうでなければ#65296;#12398;ままとなる。
　先行主導発話者・時間特定部１３は，音声対話データ３のＬチャネルの音声パワー値とＲチャネルの音声パワー値とを，音声パワー情報４の先頭から所定の単位区間ごとに比較し，最も先頭に近い単位区間で前記パワー値のビットが#65297;#12391;ありチャネルを検出し，先行発話チャネルとする。
　さらに，音声パワー情報のパワー値を，所定の判定単位区間で区切り，ビットが#65297;#12392;なっている割合が大きいチャネルを判定し，当該チャネルをその区間での主導発話者とする。主導発話者の判定は，音声パワー情報の全パワー値の列について行う。また，先頭に最も近い判定単位区間での主導発話者（チャネル）を先導発話者（チャネル）と特定する。そして，先行主導発話と同じ主導発話者が連続している判定単位区間を，先行主導発話時間とする。
　質問発話部判定部１４は，先行主導発話者（チャネル）が，顧客の音声が録音されたＲチャネルである場合に，当該先行主導発話者（Ｒチャネル）の先行主導発話時間に該当する時間を，質問発話部として特定する。質問発話部判定部１４は，例えば，ルールベース，学習データを用いた機械学習処理によって判定処理を行う。
　質問発話部抽出部１５は，音声対話データ３のＲチャネルの音声データから，質問発話部と特定された箇所の音声データを質問発話部データ７として抽出する。
　図３に，質問発話部抽出装置１０の概要処理フロー図である。
　ステップＳ１０：質問発話部抽出装置１０の音声データ入力部は，音声対話データ３の集合を入力する。
　図４に，音声対話データ３となるオペレータおよび顧客の発話の内容例を，図５に，音声対話データ３のデータ構成を示す。
　音声対話データ３は，図４に示すようなオペレータと顧客の対話の音声を，既知の録音装置によって録音した音声データである。音声対話データ３は２チャネルで構成される。第１チャネル（例えば，Ｌチャネル）にオペレータの音声データが，第２チャネル（例えば，Ｒチャネル）に顧客の音声データが，それぞれ独立して録音される。
　音声対話データ３の先頭には，データインデックスとして，データの識別情報（録音１），オペレータ名（山田），録音年月日（０５／１０／１１），録音開始時刻（１５：２５：２０）および録音終了時刻（１５：３１：３２）が格納される。
　ステップＳ１１：音声パワー情報生成部１２は，音声対話データ３を所定の単位区間に分割する。単位区間は，例えば，１～２秒の値とする。
　ステップＳ１２：音声パワー情報生成部１２は，各単位区間の音声のパワー値の平均を求め，時系列のパワー値の連続である音声パワー情報４に変換する。
　図６に，ステップＳ１２の音声パワー情報４の生成処理の処理フローを示す。
　音声パワー情報生成部１２は，音声対話データ３の各チャネルに対して，フーリエ変換処理を適応し，［パワー，ピッチ］の列を得る（ステップＳ１２１）。さらに，パワー列の最少時間単位である単位区間ｍを定める（ステップＳ１２２）。音声パワー情報４として，音声対話データ３の先頭から単位区間ｍごとに，平均パワー値を求め，平均パワー値が閾値ｔｈ以上であれば，#65297;#12434;，閾値ｔｈ未満であれば#65296;#12434;付与した，ビット列を出力する（ステップＳ１２３）。
　図７～図１０は，音声対話データ（録音１～４）３の音声パワー情報４を示す図である。図７～図１０に示す音声パワー情報４において，［発話開始：発話終了］の形式で，発話開始時刻から発話終了時刻までの間で値#65297;#12364;付与されているビット列を表す。例えば，単位区間ｍ＝１秒の場合に，［発話開始＝０：発話終了＝３］は，開始０秒から３までの間が，値#65297;#12364;付与されている区間，すなわち，閾値ｔｈ以上の大きさで発話があった時間を意味する。
　ステップＳ１３：先行主導発話者・時間特定部１３は，変換された音声パワー情報４から，属性情報として，総応対時間，先行発話チャネル，先行主導発話者（チャネル），先行主導発話時間を取得する。
　総応対時間は，音声対話データ３の実際の対話の総時間を示す。図１１に示すように，音声対話データのインデックス情報の対話の開始時刻と終了時刻の差で求める。図１２は，音声対話データ（録音１～４）３各々の総応対時間を表す図である。
　先行発話チャネルは，顧客とオペレータの対話において先行して発話があったチャネルを示す。音声パワー情報４のパワー値のビット列において，ビットに#65297;#12364;付与されている最先の単位区間を持つチャネルを，先行発話チャネルとする。先行発話チャネルの値は，#65324;#65292;#65330;#65292;#65324;Ｒ#12392;する。
　コールセンタで録音される音声対話データ３では，一般的に，電話の発呼の受け手側が対話を開始，すなわち最初に発話する。したがって，通常の問い合わせ時の顧客側発呼の場合には最初の発話はオペレータである。反対に，オペレータが顧客にコールバックする場合，オペレータが発呼し，最初の発話は顧客である。一般的にコールバックの対話に顧客の質問が含まれることはほとんどないことから，オペレータと顧客のどちらの音声が録音されたチャネルが先行発話チャネルに該当するかを特定することによって，オペレータのコールバック時の対話を特定することができる。
　図１３に示す音声パワー情報４のビット列では，Ｌチャネルでビット列に#65297;#12364;付与された単位区間＝０，Ｒチャネルでビット列に#65297;#12364;付与された単位区間＝３であるので，先行発話チャネル＝Ｌと求まる。図１４は，音声対話データ（録音１～４）３各々の先行発話チャネルを表す図である。
　先行主導発話者（先行主導発話チャネル）は，所定の判定単位区間における主導発話者のうち，先頭に最も近い判定単位区間の主導発話者（チャネル）である。
　先行主導発話者・時間特定部１３は，所定の判定単位区間内で音声パワー情報４のパワー値のビットが#65297;#12392;なっている単位区間の合計数が大きい（又は割合が高い）チャネルを主導発話者と判定する。そして先頭に最も近い判定単位区間（時系列の最先の判定単位区間）における主導発話者を先行主導発話として特定する。
　さらに，先行発話チャネルに設定されたチャネルの音声パワー情報４において，最初にパワー値に#65297;#12364;付与された単位区間から，先行主導発話チャネルが主導発話者として判定されている単位判定区間の連続を，先行主導発話時間とする。
　図１５は，先行主導発話者および先行主導発話時間を説明するための図である。
　先行主導発話者・時間特定部１３は，所定の判定処理の対象とする単位区間の範囲を示すウィンドウを，所定の移動単位でずらして判定処理を行う。
　先行主導発話者・時間特定部１３は，パワー値の単位区間ｍ＝１秒のときに，単位判定時間に相当する処理のウィンドウサイズｎ＝１５秒（単位区間），ウィンドウをずらす移動単位ｋ＝３秒（単位区間）として，ウィンドウサイズｎ内で，チャネルごとにパワー値として#65297;#12364;付与されている単位区間数を計算し，単位区間数の多いチャネルを主導発話者として判定する。さらに，移動単位（サイズ）ｋ＝３秒ずらしたウィンドウサイズｎ内で，同様に，#65297;#12398;単位区間数が多いチャネルを主導発話者として判定する。
　図１５では，１回目～５回目の判定処理では，主導発話者として#65330;チャネル#12364;，６回目の判定処理で#65324;チャネル#12364;，７回目の判定処理では#65324;Ｒ#12364;それぞれ判定されている。したがって，最先の判定単位区間で主導発話者に判定された#65330;チャネル#12364;先行主導発話者（先行主導発話チャネル）と判定される。
　次に，先行発話者チャネルに特定されたＬチャネルにおいて，パワー値のビットに#65297;#12364;付与されている最先の単位判定区間から，先行主導発話チャネルが主導発話者として判定されている単位判定区間の連続区間を先行主導発話時間とする。
　ここでは，主導発話者がＲチャネルからＬチャネルに変わった場合に，その時のウィンドウサイズｎの半分を加えた単位区間までの連続区間を，先行主導発話期間として計算する。
　図１６および図１７は，先行主導発話者および先行主導発話時間を求める処理フロー図である。
　先行主導発話者・時間特定部１３は，先行発話チャネルに特定されたＬチャネルを選択する（ステップＳ１３１）。ウィンドウサイズｎを設定し（ステップＳ１３２），音声パワー情報のビット列の先頭にポインタをセットする（ステップＳ１３３）。
　ウィンドウ内でＬチャネル側でのビットが#65297;#12392;なっている単位区間数を計算して値Ａとする（ステップＳ１３４）。さらに，ウィンドウ内でＲチャネル側でのビットが#65297;#12392;なっている単位区間数を計算して値Ｂとする（ステップＳ１３５）。
　値Ａが値Ｂより大きいかを判定し（ステップＳ１３６），値Ａが値Ｂより大きい場合は主導発話者＝Ｌチャネルとする（ステップＳ１３７）。値Ａが値Ｂより大きくない場合は，さらに，値Ａが値Ｂと等しいかを判定し（ステップＳ１３８），値Ａが値Ｂと等しければ，主導発話者＝ＬＲチャネルとする（ステップＳ１３９）。値Ａが値Ｂと等しくなければ，主導発話者＝Ｒチャネルとする（ステップＳ１３１０）。
　そして，［ポインタ位置，主導発話者値］の組を出力する（ステップＳ１３１１）。
　次に，ウィンドウを移動単位ｋ分ずらし（ステップＳ１３１２），ウィンドウが音声パワー情報４のビット列の最後まで到達していれば（図１７：ステップＳ１３１３），ステップＳ１３１４の処理へ進み，ウィンドウが音声パワー情報４のビット列の最後まで到達していなければ，ステップＳ１３４の処理へ戻る。ステップＳ１３１４の処理では，ポインタ位置が#65296;#12398;主導発話者値を先行主導発話者の値とする。
　そして，先行主導発話者と主導発話者の値が連続して同じ値をとる単位区間の範囲（Ｌ）を求める（ステップＳ１３１５）。ポインタ位置＝０からポインタ位置＝Ｌまでの区間を，発話時刻に変換し，先行主導発話時間とする（ステップＳ１３１６）。
　図１８～図２１は，音声対話データ（録音１～４）３の先行主導発話時間の計算結果を示す図である。図１８の図において，開始秒は，ウィンドウの開始位置を示し，窓サイズは，ウィンドウサイズｎを示す。主導チャネルは主導発話者と判定されたチャネル，Ｌ割合およびＲ割合は，ウィンドウ内で，#65297;#12364;付与された単位区分数を示す。
　音声対話データ（録音１）３の先行主導発話者（チャネル）＝Ｒチャネル，先行主導発話時間＝５５．５秒である。
　また，図１９の音声対話データ（録音２）３の先行主導発話者（チャネル）＝Ｒチャネル，先行主導発話時間＝１９．５秒である。図２０の音声対話データ（録音３）３の先行主導発話者（チャネル）＝Ｌチャネル，先行主導発話時間＝１３．５秒，図２１の音声対話データ（録音４）３の先行主導発話者（チャネル）＝Ｌチャネル，先行主導発話時間＝１３．５秒である。
　ステップＳ１４：質問発話部判定部１４は，先行主導発話者（チャネル）および先行主導発話時間から，質問発話部を判定する。質問発話部判定部１４は，先行主導発話チャネルがＲチャネル，すなわち顧客の音声が録音されたチャネルである場合に，先行主導発話時間に該当する時間を質問発話部として特定する。
　図２２は，ルールベースによって質問発話部を判定する処理フロー図である。
　質問発話部判定部１４は，図２３に示すような，判定対象の音声対象データに対する，［先行発話者（チャネル），先行主導発話者（チャネル），先行主導発話時間，総応対時間］の組を入力する（ステップＳ１４１）。
　そして，図２４に示すルールベースにもとづいて，ステップＳ１４２～ステップＳ１４７の判定処理を行う。
　図２４のルールベースでは，以下の判定条件が定義されている。
　ルール１：先行発話者＝先行主導発話者であれば，#65362;ｅｊｅｃｔ#65307;
　ルール２：先行発話者＝ＬＲであれば，#65362;ｅｊｅｃｔ#65307;
　ルール３：先行発話者＝Ｌまたは先行主導発話者＝ＬＲであれば，#65362;ｅｊｅｃｔ#65307;
　ルール４：総応対時間が，平均応対時間お１／３以下であれば，#65362;ｅｊｅｃｔ#65307;
　ルール５：先行主導発話時間が５秒以下であれば，#65362;ｅｊｅｃｔ#65307;
　初期値：　ルール１～ルール５のいずれでもなければ，#65345;ｃｃｅｐｔ#12392;する。
ここで，#65362;ｅｊｅｃｔ#65309;質問発話部は存在しない，#65345;ｃｃｅｐｔ#65309;先行主導発話部分を質問発話部分とする。
　質問発話部判定部１４は，ステップＳ１４１の入力が，ルール１に該当するかを判定し（ステップＳ１４２），ルール１に該当すれば，さらに，ルール２に該当するかを判定し（ステップＳ１４３），ルール２に該当すれば，さらに，ルール３に該当するかを判定し（ステップＳ１４４），ルール３に該当すれば，さらに，ルール４に該当するかを判定し（ステップＳ１４５），ルール４に該当すれば，さらに，ルール５に該当するかを判定し（ステップＳ１４６），ルール５に該当すれば，質問発話部はない（ｒｅｊｅｃｔ）と判定する（ステップＳ１４７）。一方，ルール１～ルール５のいずれにも該当しなければ，質問発話部を含むと判定する（ステップＳ１４８）。
　この判定処理により，図２３の各音声対話データのうち，録音１および録音２の音声対話データについて質問発話部を含む（ａｃｃｅｐｔ）と判定され，一方，録音３および録音４の音声対話データについて質問発話部を含まない（ｒｅｊｅｃｔ）と判定される。
　図２５は，質問発話部判定部１４が，機械学習処理によって質問発話部を判定する場合の学習段階の処理フロー図である。
　質問発話部判定部１４は，教師データとして，音声対話データに対する［先行発話者（チャネル），先行主導発話者（チャネル），先行主導発話時間，総応対時間］の組と，この音声対話データが発話質問部を含むか（ａｃｃｅｐｔ）／含まないか（ｒｅｊｅｃｔ）の判定とをセットしたデータを準備する（ステップＳ１５１）。
　図２６は，機械学習処理の教師データの例を示す図である。図２６（Ａ）は，判定値に#65345;ｃｃｅｐｔ#12364;セットされた教師データ群，図２６（Ｂ）は，判定値に#65362;ｅｊｅｃｔ#12364;セットされた教師データ群である。
　質問発話部判定部１４は，マハラノビスの距離判定式について，#65345;ｃｃｅｐｔ#12398;教師データの集合（ａｃｃｅｐｔ集合）に対して，判別分析向けのパラメータを設定する（ステップＳ１５２）。同様に，#65362;ｅｊｅｃｔ#12398;教師データの集合（ｒｅｊｅｃｔ集合）に対して，判別分析向けのパラメータを設定する（ステップＳ１５３）。
　ここで，マハラノビスの距離判定式は，例えば以下の式（１）ように表される。
　　　（ｘ－μ）ＴΣ－１（ｘ－μ）　　　式（１）
　そして，図２７に示すように，教師データによってマハラノビスの距離判定式のパラメータを計算し，判別対象がいずれの集合に類似するかの判別処理に用いる。
　図２８は，機械学習処理によって質問発話部を判定する場合の判定段階の処理フロー図である。
　質問発話部判定部１４は，判定対象の音声対話データに対する［先行発話者（チャネル），先行主導発話者（チャネル），先行主導発話時間，総応対時間］の組を入力し（ステップＳ１６１），ａｃｃｅｐｔ集合との距離Ｄａを計算し（ステップＳ１６２），さらに，ｒｅｊｅｃｔ集合との距離Ｄｒを計算する（ステップＳ１６３）。
　そして，距離Ｄａが距離Ｄｒより遠ければ（ステップＳ１６４のＹＥＳ），#65362;ｅｊｅｃｔ#12392;判定する（ステップＳ１６５）。一方，距離Ｄａが距離Ｄｒより遠くなければ（ステップＳ１６４のＮＯ），#65345;ｃｃｅｐｔ#12392;判定する（ステップＳ１６６）。
　なお，マハラノビスの距離による判定処理は，参考文献に詳説されている（P.C.ahalanobis,Onheeneralizedistancentatistics",roceedingsfheationalnstitutefciencefndia,21936)9-55,936）
　ステップＳ１５：質問発話部抽出部１５は，#65345;ｃｃｅｐｔ#12392;判定された場合に，その音声対話データの該当チャネル（Ｒチャネル）の先行主導発話時間に該当する時間を質問発話部データ（音声データ）７として抽出する。
　この質問発話部データ７によって，問い合わせ傾向推定システム１により問い合わせ傾向が推定される。
　図２９は，問い合わせ傾向推定システム１の概要処理フロー図である。
　問い合わせ傾向推定システム１の質問発話部抽出装置１０によって，音声対話データ３から，顧客の問い合わせを含む質問発話部データ７を抽出すると（ステップＳ１００），音声認識装置２０は，音声認識処理として，音声対話データ３から切り出された質問発話部データ７を入力し，質問発話部データ７に音声認識処理を適用して，認識された文字列からキーワードを出力する（ステップＳ２００）。
　音声認識装置２０は，既知のいずれの音声認識処理で実施してよい。例えば，ＨＭＭ方式による話者認識処理手法を用いる（松井知子，「ＨＭＭによる話者認識」，電子情報通信学会技術研究報告　音声　SP95-111，pp17-24，電子情報通信学会発行，１９９６年１月）。
　傾向分析装置２５は，音声対話データ３から切り出された複数の質問発話部データ７から抽出されたキーワード９に対し，既知のクラスタリング処理・傾向分析処理を施し，問い合わせ傾向を推定し，その推定結果を問い合わせ傾向情報５として出力する（ステップＳ３００）。例えば，傾向分析装置２５は，キーワード９に対して，階層型のクラスタリング処理を実行し，図３０に示すように，クラスタを要素数が多い順にソートし，上位のクラスタを問い合わせの傾向として推定する。
　なお，既知のクラスタリング処理・傾向分析処理としては，本件出願人の出願した「テキスト情報作成装置、事例寄せ装置、ＦＡＱ作成用質問事例抽出装置、検索装置（特開２００４－２８０３６１号公報）」に開示する処理を利用できる。
　以上，本発明をその実施の形態により説明したが，本発明はその主旨の範囲において種々の変形が可能であることは当然である。
　例えば，図１に示す問い合わせ傾向推定システム１は，質問発話部抽出装置１０，音声認識装置２０，傾向分析装置２５の３つの装置を構成するものとして説明した。
　しかし，問い合わせ傾向推定システム１の，質問発話部抽出装置１０，音声認識装置２０，傾向分析装置２５は，１つのコンピュータにインストールされ実行されるプログラムモジュールとして実施することが可能である。
　また，問い合わせ傾向推定システム１，さらには，質問発話部抽出装置１０，音声認識装置２０，傾向分析装置２５を実現するプログラムは，コンピュータが読み取り可能な，可搬媒体メモリ，半導体メモリ，ハードディスクなどの適当な記録媒体に格納することができ，これらの記録媒体に記録して提供され，または，通信インタフェースを介して種々の通信網を利用した送受信により提供されうるものである。
Patent WO2009107211A1 - 音声データの質問発話部抽出処理プログラム，方法および装置，ならびに音声データの質問発 ... - Google Patents
