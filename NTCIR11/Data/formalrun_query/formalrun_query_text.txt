コンフュージョンネットワークを作った使った音声検索で未知語の検索結果が知りたいです
動画のシーン分割の話で統計統計的手法について詳しく知りたいです
ちょっとツールについてちょっと知りたいんだけどもあるツールでCBAPCBAPて書くかなCBAPっていうツールがあるらしいんだけどもそのツールっていうのがどういうことを行うのかどういうようなことするツールなのかっていうのをちょっと教えてほしいんだけども
とかとかそういうのフィラーっていうじゃんかそのフィラーのその数とか割合とかそういうものが講義とか講演の分かりやすさにどれほど影響が得るのかとかどれほど関連がでてくるのかっていうのをちょっと教えてほしいんだけどもどうですかね
最近その音声認識が結構いろんなとこで使われるようになってきてだいぶ精度もいいような気がしているんですけどやっぱりまだ上手く認識されないっていうことが結構あって例えばなんか漢字が間違っていたりとかそれはよくあるんですけど後は全然違う単語に認識されてしまったりとかしてなんでこんなふうになってしまうのかっていうのがちょっとよくわからないんですけどそのように何か誤認識が起きてしまうような原因は何であるかというのが知りたいです
言語モデルのパープレキシティの話なんですけど言語モデルの性能を評価するときにパープレキシティでやるとかパープレキシティていうのは確か直感的に言えば次の単語の予測能力てことで小さいほうがいいとかそういう値だったと思うんですけど勉強したというかそういう知識はあるんですけど実際の研究分野とか応用場面で言語モデルていうのが出てきたときにパープレキシティの値はどれぐらいになるのかなというのを知りたいです
最近よくありますよねなんだっけタブレットとかスマホとかで忘備録を忘備録ていうとかしこまってますけど日記つけたりとか生活のなんか管理をするとかなんかそういうのにスマホとかを上手く使おうみたいな話でライフログとか言ってますけどその今までのライフログていうかそういう手軽に持ち出すようなコンピュータがなかった頃のライフログというか忘備録といえば日記とか手帳とかなんかそんなんだったと思うんですけど新しくなってなんかそのそういうのスマホとかでやるメリットてどういうのはあるのかなというのが知りたいですね日記だと何が駄目だったんですかねそれでなんかスマートフォンだと何ができるようになったのかっていうのを知りたいです
論文の中でアライメントについて説明しているところがあると思うんですけど論文の中だと統計的機械翻訳説明のところでそのアライメントのアライメントについて説明がされているんですけどそこの説明のところのスライド探して欲しいですその論文の中の例だと確か私は本を借りますっていう例文を使って多分説明していたと思うんですけどそこのところのスライドでの説明が聞きたいです
同じ同じ論文なんですけどその研究でIBMモデルっていうのを使ってるところがあるんですけれどその中のヌルヌルジェネレーションモデルの説明のところが少しわかりにくかったのでそこの説明スライドが説明が欲しいです確かそのモデルが目的言語の単語に対応する原言語の単語が無いときにダミーの単語を対応付けるっていうモデルだったと思うんですけどそれのモデルのスコアの計算式のところがちょっと分かりにくかったのでそこのところの説明を詳しくして欲しいと思います
講義の質と講師の話し方の関係性を研究したもので特に声のピッチと明瞭性の関係を説明しているものが知りたいです
話し言葉コーパスにフィラーを導入することでその言語モデルを作ったときに音声認識システムの性能はどのように変わるのか認識結果がどうなるのかっていうのが知りたいです
音声ドキュメントを使って何か検索したいときに音声のドキュメントで得られた情報からWebのデータを得てそのデータも検索する際に使用する手法があるんですけどそれでWebデータからWebテキストを選択してWebインデックスに作るときどのようにしてそのWebテキストからインデックスを選択するというか作成するかの方法を示したスライドが知りたいです
ドキュメント中の強調発話の検出にドキュメント中の強調発話の検出はどのようなアルゴリズムを使って実装しましたか
ピッチ情報を使った強調発話の検出のprecisionとrecallはどのくらいの値になりましたか
音声ドキュメント検索とかだとその未知語音声認識用の辞書に登録されていない単語ていうのがやっぱり問題になってくると思うんですけどそれに対する対策とかが書かれている論文があったら教えて下さい
音声認識とかした場合の場合だとそのテキストが話し言葉そのままになるんですけどそれが書き言葉のものとは書き言葉のものはWebからとってきたりとか論文のものだったりとかそういったものは書き言葉になるんですけどそれとはだいぶ形式が違うというかそのままではあまり一致しないということなのでそれを上手く分ける必要があると思うんですけどその書き言葉と話し言葉を上手く分類というかそれを区別する方法についての説明が知りたいですどういった特徴量使っているとかどういった手法を使っているとかそういうことをですね
自動要約とかそういった研究も進められているようなんですけれども話し話した内容だけをずらずらと書き起こししてもどこが重要なものなのかとかそういったことがよくわからなくて重要な部分だけを抽出したりということで重要文というものをどうやって判別するのかそれで重要文ごとにスコア付けをとかしたりしてそれで要約をするんじゃ研究があると思うんですけどもそういった重要文を見つけるときに特徴量というか色々とあると思うんですけども何を特徴量どんなスコア付けをすると思うんですそのときに特徴量は何を使っているかとか手法どういうふうにやってるのかっていうことがちょっと具体的に書いてあるところが知りたいです
野球中継の構成要素について説明しているところを見せて下さい
わからん言葉があったんですけどインデックス情報ってのを教えて下さい
実況中継の論文があったと思うんだけど実況者の興奮状態っていうのが必要なのかっていうのがよくわかんなかったんで詳しく説明しているもんがあったら教えて下さい
ちょっと知りたいんやけど何やったっけ認識誤りについてのそれを解決するための複数複数認識システムっていうのはどういったシステムかっていうのをちょっと知りたいちょっと教えて教えてくれる
英語の人が英語の翻訳家が日本語に直すときにその日本語の音声日本語の発話っていうのが普段とちがった発話になるっていうのやけど例えばどういうことをいっているのかっていうのがちょっと知りたい知りたい
音声のドキュメントの中からなんか検索するワードですかね検索するシステムについての質問なんですけどもその論文にはメインとしているのが検索の高速化って言うことでその検索するワード音素列ですかねそれを分割して検索を行うということだったんですけどもそのときにその検索する音素列を固定長で分割して余りが出た場合はその余りは捨てるっていうことだったんですけどもその余りっていうのを無視するっていうことはシステムについてシステムに対して何らかの影響ていうのはないんでしょうか例えば分割する方法として固定長じゃなくてその検索する音素列ていうのを等分割して検索するという考え方もあると思うんですけどもそういう考え方っていうのは試したりはしたのでしょうか
音声のドキュメントの中からその文字列とかを検索するシステムの高速化ていう論文の中でその講義音声のデータベースに対して実験してその考察の中でその未知語に対する考察っていうのがとても多くされてたと思うんですけどもその未知語に対して今後何らかの対策といったものを施すということは考えているんでしょうか考えたとして実際にそのような未知語に対する対策っていうのをシステムに加えたとすると今回は高速な検索手法て言うことで高速化ていうのも少し妨害してしまう若干遅くなっちゃうのかなと思うんですけども今後はそういうシステムの変更っていうのは考えているでしょうか
動画の字幕の場所についてどこの場所に置いたら理解しやすいのかについて教えて下さい
言葉を検索するときに人と話すように話し言葉で検索するシステムを教えて下さい
論文の最初のほうの他の研究の紹介みたいなところでそのなんか複数の認識結果を用いた音声検索語検出の紹介のところでラティスだったりコンフュージョンネットワークを使っているという紹介があったんですけど僕ちょっと今研究でコンフュージョンネットワークを用いた手法をやっていこうと思ってるとこなんですけどちょっとラティスっていうのがちょっとよくわからなくてそちらについてお聞きしたいなともう少し詳しく知りたいなというふうに思い
単純論文の中で二つのその単語のアライメントの方法として単純分配法と何かもう一つ分配法の説明があったと思うんですけどそちらの単純分配法のちょっと数式についてちょっとよく理解できなかったのでわかりやすく教えていただきたいなと思いました
ＳＴＤを使ったＳＴＤを使って未知語や認識誤りに対して対処するっていう音声ドキュメントのの講演があったと思うんですけどその確かＳＴＤの手法で連続ＤＰマッチングっていうのがあってそれに対してそれが時間がかかってしまうっていう問題があって確か索引だけを使ったＳＴＤの手法っていうのが説明されたと思うんですけどそれについての手法が知りたいです
擬似適合性フィードバックを使った音声ドキュメント検索の講演なんですけど確かドキュメント長を使っていたと思うんですけどそのその従来のＰＲＦでＰＲＦがどのような問題があったかっていうのを知りたいです
収録データの話なんですけれども音声認識っていうことでどんなような音声データをその認識のために使っているのかっていうので例えば一つのファイルサイズあたりどれくらいの時間どれくらい喋っているのか発話数とかそういうのと後はデータセット全体の収録時間数ていうのを知りたいです
信頼度スコアっていうのを使っていると思うんですけども確信度スコアですかその信頼度確信度のスコアっていうのはどういうことを基に求めているのかっていうところで素性とか例えば言語モデルとか言語確率とかあると思うんですけれどもそういう確信度スコアの求め方の詳細っていうのが知りたいです
スポークンタームディテクションＳＴＤの話なんですけど音声十個の音声認識器を使ってでコンフュージョンネットワークを構成してＤＰマッチングを行うという研究だったんですがそうかＤＰマッチングのそのコンフュージョンネットワークを構成するとノードとノードの間に複数のアークが出来るらしくてその複数のアークとＤＰマッチングを行う際にスコア提案手法となるスコアのスコア付けがあるらしいんですけどもそこがよく分からなかったので説明をお願いしたいと思います
スポークンタームディテクションＳＴＤの研究なんですけどもサフィックスアレイを用いた研究でサフィックスアレイを用いて検索対象を木構造に変換してそこから探索を行うという研究だったんですけどもクエリが長くなると探索時間が指数的に長くなるのでクエリが長い場合はクエリを分割して検索を行うという手法だったんですがクエリを分割するとクエリを分割する前に検出できていた認識誤りというのが分割後には検出できなくなってしまうそうなのでちょっとその部分が分かりづらかったのでその部分に関しての説明をお願いしたいと思います
はいはいビデオとか講演とかの録音とか録画ですねそれをシーンごとに分割するという研究があると思うんですけれどもそのシーン分割するときに音声認識をしてやってでその認識結果を使って分割するとそういう研究があるかなと思うんですけれども音声認識すると認識誤りとか起こりますよねで認識誤りがあるとシーン分割の性能もやっぱり下がると思うんですけれども意外と下がらないということ言われていると思うんです要は間違えるところは同じように間違えるのでその認識誤りしてるけども同じように間違えたものは手がかりになるというところが上手く使えてシーン分析シーン分割の性能自体はそんなに下がらないという話があると思うんですけれどもただ置換誤りだけじゃなくて音声認識には挿入とか脱落とかの誤りもあると思うんですねで特にですね脱落誤り脱落してしまったところはやっぱり影響があるような気がするんですけれどもその脱落誤りによってどのぐらいそのシーン分割の性能に影響が出てくるのかでこれを調べた論文というか発表箇所ですかねそこを知りたいですけれどもだからシーン分割中で特に脱落によってどのぐらいの影響があるのかというところを実験によって調べたとそういう発表があればそれを探したいと思ってますはいお願いします
その音声データの解析をしているんですがそのその解析のやり方の一つにそのスペクトル解析というのがあってそのそのスペクトル解析っていうのがその周波数帯域ごとにそのパワーを求めるっていうやつらしんですけど自分で色々調べていたんですけどそのスペクトル解析の方法の一つにそのフィルタバンク法っていうのがあるらしくてでちょっと見てみたんですけどあまり分からなかったのでそれを説明してるような部分っていうのをちょっと探して欲しいと思うのでお願いします
統計的機械翻訳ていうそのそうですね対訳文というか日本語と英語のその対訳文とかいうのをたくさん用意しておけば計算機で自動的に翻訳できるっていう枠組みがあるんですがそれのその理論というか原理とかそういうのを説明しているシーンというかスライドをお願いします
