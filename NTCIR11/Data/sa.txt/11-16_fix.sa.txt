
では整形された会議録と
その原音声のアラインメントに基づく整形箇所の自動検出というタイトルで発表させていただきます。豊橋技術科学大学のです。
最初にですねいらっしゃるみなさんにあまり説明するまでもないことですけども。
話言葉の忠実な書き起こしていうのは様々な音声言語処理において不可欠
で音声認識しようと思ったらたいてい言語モデルが必要でして言語モデルを作ろうと思ったら忠実な書き起こしてのが必要です
でところがですね、これまたみなさんご存知のとおりですね、話し言葉、
今私がこういうふうに喋っている話し言葉っていうのは結構いろんなフィラーとか言い淀みとか言い直しとか、いろんな
ややっこしいもう現象がたくさん生じてますから
こういう話し言葉に対して忠実な書き起こしをやるっていうのは結構高コストでして、特に時間と費用と両方の観点から高コストで
今私がこうやって喋って五分間くらい喋っておっても、これを書き起こそうと思ったら
十倍ぐらい？いきなりかかったりしちゃったりするわけですね。
そんなようなことは大変なので、なんとかしたい
で、だけどですね、会議とかそういったようなこと考えてみますと記録録らなきゃいけませんから、
話し言葉のそういう特徴っていうのが
成形された、ある程度成形された忠実じゃない書き起こし。会議録とか速記録、そういったものってのはいろんなドメインで
整備されてるだろうと
そういうことは期待されます。
で一番典型的なのは国会会議録ってやつですけれども、
ここに例で示してある通り、こういうような、
「ですね」とか「えーと」とかいったみたいなフィラーとか言い直し、こういったものがたくさん出現してるのが本来の国会の発言なんですけども、
これのここの部分ていうのが
成形されまして、こういうようなところがこの資料見ますとといったように
話し言葉の部分が成形されて、そういったような会議録って形で存在してると、
こういうのがたくさんあるだろうというふうに期待しております。
でそれでそういう背景のもとで本研究の目的ですけれども、
成形された書き起こしっていうのを忠実な書き起こしに
本当だったら自動的に変換できると非常に嬉しい
わけなんですけども、ちょっといろいろやってみたところ難しいので
とりあえずまず半自動的に変換する枠組みっていうのを頑張ってみましょうと。
で半自動的に変換しようと思ったらどうしたらいいかなっていいますと、
もう成形箇所を検出してやって、でその成形箇所を書き起こすと。
で
この成形箇所を書き起こす方は人手でなんとか頑張ることにして、
この成形箇所を検出する方ですね、
こっちの方をなるべく
ローコストにやりたいと、いうのが本研究でして、
でこの本発表で成形箇所の自動検出法手法っていうのを提案します。
でもういっぺん整理しておきますと、
目的は成形された書き起こしを
忠実な書き起こしに半自動的に変換することです。
でこうすることによって書き言葉と話し言葉のパラレルコーパスを自動的に自動的じゃない、効率的に構築致します。
で、目標としてはパラレルコーパスの構築作業の三倍以上効率化できたら良いなあということを考えながら研究をしております。
でこの
本研究の提案手法ってのはだいたい二段階からなってまして、
まず書き起こしと原音声をアラインメントします。
でその次にアラインメントして得られた素性に基づいて検出器を使いましてその成形箇所というのを特定する
いうような二段階になってましてまず最初のアライメントするのをどうやりますかっていうのを説明させていただきます。
アライメントする方法なんですけれども、ここは極めてオーソドックスに大語彙、連続音声認識で実現します。
で単純にですね、書き言葉の、
書き起こしの単語列ですね。これがＷＨからＷＮまでだった時に、
そのＷＩとＷＩプラス一の間に
直接、すぐ単語が後続する場合と
それの直後ですね、ショートポーズが挿入する場合と、
そういったことを許したバイグラムの言語モデルをずるずる作ります。
こういうその言語モデルと

言語モデルとその原音声とアライメントして
アラインメントするっていうことなんですけども、
ここでちょっと問題になるのが
書き起こし、特にですね

普通の成形された書き起こしっていうのは
原音声と対応情報てのは付いてないと。
例えば、こっからここまで喋りましたっていうような情報が付いてないと。
でなのでしかたがありませんからそこをなんとかアラインメントしてやる必要があります。
でどういうふうにしてやろうかっていうことなんですけども、
まず
書き起こしとですね、音声の先頭はいくらなんでも一致してるでしょうと。
でじゃあまず先頭から十秒間切り出してやります、発話区間の。
でこの発話区間、十秒間切り出しまして、
この部分を連続音節認識します。
で音節認識してやると、と、こ、ろ、がっていうふうに、こん中には例えばいくつあるんだ？
二十音節ぐらいありますね、っていうふうに音節の数がまずわかります。
で音節の数がわかるとそれを今度は単語の平均音節長で割ってやると
ここのこの十秒間に何単語ぐらいありますかっていうことがまず推定されるわけです。
で
その次に今度書き起こしの方を見まして、その推定された単語数分だけこの対してのところまでを
取り出します。
で
続いてこの十秒間とこの
その単語数分のこの先頭の部分とアラインメントします。
でところがここでちょっと一つ注意が必要なのは先頭の方は確かに確実に一致してるでしょうけれども、
後ろの方は
ここでだいたいこのぐらいの単語数だよねって、推定したわけですから当然後ろの方は、こことほんとは一致してないってことは可能性が高いですし、
でまたというようなことがありますから
後ろの方はあまり信用できないっていうことで、
ここはちょっと経験的に決めたんですけども先頭の六秒間だけを信用してやって、
でここ、この六秒間とこの最初のいくつかの単語このアラインメントを採用します。
でそうしますと、先頭から六秒間分、約六秒分の

アラインメントができましたから、ここを今度は今度はここの部分、ここを先頭と考えてもう一度同じことを繰り返すと。
つまり例えば一分やりたかったら、その六秒アラインメントするっていうのを十回繰り返すと一分間アラインメントができると、
いうようなことをやってアラインメントしました。
でこれがそのアラインメントの例になります。
でこの例もう少し詳しく見てみますと、
ここがた　い　し　て　で　す　ね　っていうふうに、本当は発音されてるんですけども、
書き起こしの方ではたいしてと
いうふうになってまして、
このですねと、いう部分がカットされてると。
でそうしますとまず何が起きてるかって言いますと、ここのしですね。
たいしのしが、
ほんとのしよりも長くアラインメントされてます。
でさらに、
ての部分が、
ほんとのてじゃなくて、
ねの部分にアライメントされると、
といったようなふうに、

音節区間が極端に長くなったり、また短くなったり、
それとか
全く違う音節にアラインメントされる、そういったようなことが起きていると、
で、いうふうなことがありますので、結局音節区間、極端に長かったり、また短かったりしたりその音響スコアが低い部分ていうのは成形箇所である可能性が高かろうと
いったようなことがアライメントの結果を見ているとわかります。
で
これを使いまして、
そういうアラインメントから得られた素性に基づいて検出器を
作って成形箇所を検出します。
でここは非常に簡単にやりまして、
その成形箇所の検出っていうのを
この単語を単位としましてここは成形されてない、ここは成形されてるっていったような
二値分類問題として定式化します。
でその二値分類問題解くのがサポートベクターマシンを使ってやりましょうと
いったようなふうにやりました。
で、
素性はどうやりましたかっていいますと、その当該単語と直前二単語と及び直後の二単語ですね、
こういう単語に対する以下の素性、この辺の素性をつかってやります。
で以下素性について詳しく説明します。
まず一番大事なのはきっと音響スコアだろうっていうことで、
そのアラインメントして得られたその音響スコア、対数尤度を素性に使います。
で、さらにですね、
単語の時間長によって正規化してるっていうことと、
それから連続音節認識によって得られた音響スコアとの差分を使います。
つまり音節の方の認識の尤度と、それでこっち側尤度じゃなくて確率と、
こっちの方のは単語の方の確率ですから、これで差分取ってやりまして対数事後確率を素性として使っていることに相当します。
でもう一つ次に成形箇所検出なんですけども先ほどアラインメントの例で説明しましたとおり、
成形箇所っていうのは極端に長かったり
また極端に短かったりするだろうと。
で、
今こうやって私こう、こう喋ってますけども、
だいたい人間は自然に喋っている時の癖、
自分が喋り易いスピードってのがおそらく固定されてるでしょうから、
でそうしますと、
まずグローバルにですね、
そのその人がその発話の中ざーっと喋ってる中でグローバルに

グローバルな平均値から、
この単語の部分の音節の長さがどれぐらいずれてますかっていうグローバルなズレ。
でそれからもう一つは、

その単語の
周囲、六音節はっきり言うとだからもう単純には直前一単語と直後の一単語、そのぐらいのスパンですけども、
そういう直前直後の単語とのズレ、
そういうような極端に変動してませんか、この単語の音節長は極端に変動してませんかっていう
素性を二つ入れました。
でこれは単語レベルですけども、もう一つ単語の中に
極端に長い音節、
その　た　い　し　て　の場合、
いうふうに、
たいしてを
た　い　し　て　というふうに
だいたい同じ長さで言うのは当たり前ですけども、これ、た　い　し　て　みたいな感じで、極端に長い音節が入るてことは普通はありえないわけですから、そういうのをやるために
各音節の音節長の分散ですね、
この分散を素性として使います。
で、それからさらに、そういう単純な統計量だけじゃなくってですね、
音節の時間長っていうのが
ガンマ分布で、
だいたい近似してやってるっていう研究、先行研究がありますのでそれに習いまして
忠実な書き起こしと
原音声のアラインメントに音節時間長から学習したガンマ分布でモデル化したスコアっていうのも素性に使います。
でそれから簡単な情報としまして、
ますとか、がとか、ですねとかみたいに
単純にこいつ

成形されやすいでしょうと、
成形されやすい単語ってのは決まってるんじゃないかっていうことで
単純な言語情報ですね。
そういう言語情報も使います。
単語の情報ですね。
でそれから、長い単語ってのはきっと検出成形されちゃい易いんじゃなっていうことで単語の音節も素性に加えました。
あとこれちょっと音節長と時間長は似た、似てるんですけど時間長の長い、

ややこっしい単語は基本的に成形され易いんじゃないかっていうことで、入れてあります。
で、評価実験ですけれども、

二通り
話者のセミクローズドな実験と話者のオープンな実験とやりました。
で話者のセミクローズドの方は成形箇所が七．一％、
で話者オープンの方は成形箇所が三．九％でした。
で検出器、サポートベクターマシンとしてはＴＩＮＹＳＶＭを使いまして、
カーネルは多項式カーネルを使っております。
アラインメントとか連続音節認識のデコーダっていうのはＳＰＯＪＵＳ＋＋を使ってます。
で音響モデルにはＣＳＪから学習した音節モデルを使っております。
でアライメントの精度について説明します。

一音節ぐらいの誤差、
三十ミリセック以内の誤差っていうのを共用してみますと九十七％ぐらいのアラインメント精度になっています。
で主なアラインメント誤りってのはどういうとこに出現してるかっていいますと、
直前後に雑音とかが息とか咳とかが出現してる部分、でこういった部分はは長ーくアラインメントされてしまったりですね、
あと発声が弱い部分ですね、
ここがこことなんですけども、
この非常に弱く発音されちゃってるので、後ろの方にアラインメントされちゃったりといういうようなことが起きています。
でそうは言っても九十七％で
それ以外のこういう誤りの部分てのは本質的に難しい部分なのでだいたい良かろうというふうに考えております。
でまず話者、セミクローズドの実験結果について報告します。
全体の
リコールプレシジョンのカバー、この赤線のカーブになります。
で、この赤線のカーブ見ますと結構良いなあと思ってたんですけど

トレーニングデータに出現した話者、
クローズドな話者二名と
トレーニングデータに出現してのオープンの話者二名の
を分離して、もういっぺん出してみますと、
クローズドな方は青で良いんですけど、
オープンな方は全然駄目だってことがわかって、ゲッと思ったわけですね。
で、で、これを確認するために、
もういっぺん、話者オープンな実験をもう一度やってみますと、やっぱり話者セミクローズドな場合に比べて大きく劣っていると、
いうふうな結果が出てまして、


つまりこの手法でやると、話者オープンの場合はあまり良くない。で、話者クローズドの場合は結構良く出ていると
いうことがわかってきたわけです。
で次にですね、フィーチャーですね、
素性がどういうふうに効いているのかなあということを調べました。
で、この赤線がこれが全部の素性を使った場合です。
で
もともと我々としてはですね、この音響スコアと
それこのセット一ですね、この音響スコアでかなりわかるんじゃないかなあということを思って、始めてみたんですけども、
音響スコアのカーブっていうのもこの緑色のカーブで、
あんまりよろしくない。
で、次に音節の時間長の平均とか分散、そういったものでわかるんじゃないかなあと思って、セット一足す二をやってみたんですけど、これまたあまりよろしくない。
で、そうしますと、セット三
つまり単語の情報ですね、
そういったのを加えてみるといきなり良くなるわけでして、
でさらにまたセット三単体でやってみるとまたかなりいい結果が出てるということになりまして、
ということは結局この成形されやすい単語って決まってるんじゃないのと、
言語的な情報だけで成形箇所でだいたいわかってしまうんじゃないのか
っていうことがこのグラフから
考えられるんですが、
でそれでじゃあほんとにそうなのかっていうことをちょっと調べてみました。

全ての素性で検出した場合と、言語情報のみで検出した場合、
で両方で、両方共に検出できるとこは十四．八パー。で確かにセッ
ト三七だけで検出できるところは三．一パーあるんですけど、
セット一足す二足す三、つまり全体で検出できるところは十．五パーありまして、
実はセット三だけでは検出できないっていうところが結構あるんですね、実は。
で、ということで、先ほど先ほどのグラフから言語情報だけだいたいわかっちゃうんちゃうのと思ったんですけど、実はそうでもない。
ちゃんと音響特徴を加えてあげないといけない。
で、さらに、これちょっとまだよくわからないんですが、
このもう一度ですねとか、
これはね、といったように、
これ明らかにフィラー
ですから、言語情報だけで成形箇所わかってしまいそうなのに、
にもかかわらずやっぱりここらへんもセット三だけではだめで、
セット一二三の全部が要る
いうふうなことになってまして、決して言語情報だけで全てわかるほど甘くないと、
いうことがわかります。
でこれで、これでこのいかにも性能が低いように見えるんですけど、
この性能がどれぐらいなのかっていうことを考えてみますと、
だいたい件数は四十パーで最大五十パーが達成できてます。
でもし仮に百単語から成る会議録があって、
このうち十単語が成形箇所だとしたら、
従来はその百単語全部調べないと十箇所の成形箇所が見つからなかったんですけど、
もうこれに二百箇所のデータを提案書を適応してやると二十五単語出力されるんですけども、
その二十五単語確認したら十単語見つかると、
いうことで、データは二倍要るんですけど、
データは確かに二倍要るんですけど、

成形箇所を十箇所見つけたいと、
そういうタスクだっていうことに限定すれば、四倍の効率で、見つかるわけでして、
それでですからこの方法で一応初期の目標っていうのは達成できてるんじゃないかなあというふうに考えているわけです。
で
実験結果としてもう一つ逆方向ですね。提案手法を逆方向に適用しまして

成形されて無い箇所つまりもともとの忠実な書き起こし文の検出っていうのをやっていました。
でもともと七％成形されているわけですから残り九十三パーが忠実なわけです。
で
それで六十％ぐらいまで、削ってみると九十八パーに
忠実な書き起こしのが増えてます。
でこれは話者セミクローズドの場合ですね。話者オープンな場合も
もともと九十六％、の忠実だったものが
やっぱり六十％ぐらいまで減らすと九十八パーぐらい
の
忠実な書き起こしになってまして、提案手法を使うとかなり
忠実な書き起こし文だけを残すことができるっていうふうに思われるわけです。
で、まとめですけども、本研究で成形された書き起こしから成形箇所っていうのは自動検出する手法を提案しました。
で国会会議録を用いて実験しましたところ、
すいません。話者セミクローズドの場合が実用的な精度が達成できるねっていうことがわかりました。
で提案手法逆に適用しますと、忠実な書き起こし文てのを高精度に検出できましたっていうことを報告をしたいと思います。
発表は以上です。
