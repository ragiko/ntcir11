龍谷大学のです表記のタイトルで発表します

研究の背景なんですが近年この
会の主旨なんですが音声ドキュメント検索というのが盛んにやられています
で講演とか講義などを検索対象として
それを検索するということがやられています
で音声ドキュメントワーキンググループというのに私も所属してましてそこで
色々タスクも作っているというような状況です
で昨日の
先生のお話にありましたけれども
ＮＴＣＩＲとかそんなところでは多言語の音声ドキュメント
検索というのが行われていますが
でＮＴＴとかでは
世界
メディアブラウザとかいうのを使ってまして
多言語の音声ドキュメント検索ということをなんかやろうとしてはるというような状況にあります
昨日の話でもありました通り多言語を対象とする場合は
クエリを翻訳するとか
検索対象の音声ドキュメントを翻訳するというようなどっちもあるというような話なんですが
やっぱり検索語を
検索した後にそれを見たときに分かり易いというような観点から考えますと
検索対象を
翻訳しておくことが望ましいということがあると思います
で検索対象の音声ドキュメントを翻訳しようとするわけなんですが大体においてそういう音声ドキュメントは
自然性の高い文です
でそういう自然性の高い文に対して
現在の機械翻訳というのは
結構難しいというような
感じです
で自然一方自然性の低い文章に対しては
比較的容易な
翻訳ができるというような状況がありますこれはどういうことかといいますと
自然性の高い文というのは
音声ドキュメントの書き起こしみたいなものでして
で自然性の低い文というのはここでは
直訳調の文章ということを想定しています
で実際の例なんですが
毎朝犬の散歩に行きますというような
文章を翻訳しますと
Ｉｔｇｏｅｓｆｏｒｔｈｅｗａｌｋ
ｏｆａｄｏｇｅｖｅｒｙｍｏｒｎｉｎｇとかいう
ちょっと変な英語になります
一方自然性の低い日本語私には朝私の犬の散歩がいつもあります
こんなふうな
文章にしてやると
英語にしてやるとＩａｌｗａｙｓｈａｖｅｔｈｅｗａｌｋｏｆｍｙｄｏｇｉｎｔｈｅｍｏｒｎｉｎｇということで
結構上手く翻訳ができるということがあります
というわけでこの
翻訳前に
変換(W これ前編集というんですがそうしてやることが重要だと
いうことでここでは
自然性の高い文を
自然性の低い直訳調の文章に変換してやるということを考えます
でその機械翻訳の前編集の問題なんですがいろいろやられていますが基本的には
前編集をどう行うかということを
モデル化しないといけない
で今までの研究ではそれは
人手でやってるわけなんですが
基本的には対応付いた自然な文と直訳調な文
の集合が準備する必要があって
それを人手で集めるのは結構しんどい
それから
直訳調の文が集まったとしても
最終的な翻訳にとって必ずしも
こっちの文のほうが
自然な文よりも上手く翻訳できるというわけではないですので
そういうものは
学習データから除いてやるということが必要です
でそのうえでこういうペアのコーパスが集まったとしてもそこから
前編集規則をですね獲得するというのは
やはり大きな問題です
というわけで本研究では

この
直訳調の文と自然な文の対応っていうのを
自動で獲得して
そこから前編集規則も自動で
獲得しようということが本研究の目的です

で実際には統計的機械翻訳の枠組みを用いて前編集をすることを考えます
で統計的機械翻訳は音声認識と同じ枠組みでして原言語の
単語列Ｓが与えられたときに
それを最もよく説明する単語列Ｔ’
を求める問題としてこんな式を変形して結局この式を求める
で
ここの
確率を与えるモデルが変換モデル
でして
こっちの確率を与えるものモデルが言語モデルになる
ということです
で前編集を考えた場合には
このＳのほうに自然な文の文字列を
でこちらのＴのほうに直訳調の文の文字列ということにしてやって
ここからここへ書き換えてやればいいというような問題になります
で一応ちょっと曖昧性があっては困りますのでここでは一応このＰＴを与える言語モデルを直訳調の言語モデル
と
呼びます
でこれは直訳調のテキストで学習します
でこちらのＰのＳＴという
変換確率を与えるモデルを前編集変換モデルと呼ぶことにします
で学習データを自動で獲得する
獲得の仕方についてお話します
で今回は
日英翻訳を対象として実験をすること
にしました
というわけで日本語文の前編集を行います
で学習データの獲得なんですが日本語文と
日本語直訳文がいるんですがそれは日英対訳コーパスを利用して
日本語文と
対訳英文をＭＴで翻訳した日本語直訳
とします
ちょっとわかりにくいので図で説明しますと
日英対訳コーパスがあってその中には
たくさんな対訳ペアがある
ということです
でそっから英文の方を
英日機械翻訳にかけてやって
これいろんな翻訳機があると思うので色々
つくります
で一方こちらをそのまま持ってきて
でこちらを自然な日本語文
こちらを直訳調の日本語文と仮定しまして
このペアを自然な文と直訳調の文のペアと
してやるということをします
でこの中で全部が使えるわけではないのでここからいいのをちょっと選択するのですが
それをどうするかと言いますと
もう一回最終的にはあの英語にしていい方を選びたいので日英機械翻訳機にもう一度かけます
そうしましてこちらも全部かけてやると
で
これとこれを比較して前編集しない場合の英文より
こっちの方が優れていた場合は
こっちを
採用する
んでその何が優れているかというのは
もともとこれは
この
対訳コーパスの英文から来てましたので
これをもってきて
でこいつとの距離を
なんらかの尺度で
計ってやって
こいつにより近いやつを残してやるということをしました
で残った英文がありますからこれを生み出した
元の
直訳調の日本語文のみを残してやると
いうことをします
でそうすると
この日本語文を前編集でこちらへ換えてやって翻訳するとこれよりはよくなるということが保証される
ということになります
つまりこれをこう書き換えてこう英翻訳してやると
直接翻訳するより良くなるということですので
このペアを
学習データとして
なんか
学習データの集合に追加するということをやりますでこれを
コーパス中の日本語と英語の
いろんな対訳
文ペアに対してやります
でこうやってやってやるといろんなペアが集まるんですが
でもう一度おさらいしますと
ここの前編集変換モデルは
この対訳ペアの集合から学習します
でこちらの言語モデルの方は
こちらの
直訳調の文から学習します
で実験なんですがまず学習データの自動獲得をしました
で実験データはロイターの英日対訳コーパス三万一千五百八十文対を使います
でここはいろんな
英日翻訳機が使えるのですが今回は一個にしました
でこのあと
最後に元の英文との
距離を
計るんですがその類似尺度はＮＩＳＴとしました
で結局
対訳ペアをとって英文の方は
英日翻訳して日英翻訳して
でこの
日本語文の方は英文に翻訳して
でこれとのＮＩＳＴスコアを計算して
もしこっちが高ければ
これとこれのペアを学習データに使うということをします
でこのペアというのが三万一千五百八十文対あって
結局これとこれのペアが使えたというのが
二万九千五百九十六
ということで
九十四％が
これをこう書き換えてやると
いい英文になると言うことがわかります
つまり前編集
でほとんどの
日英対訳コーパスのデータが
前編集に使えるということがこのデータに対しては

で実際に学習
データが集まりましたので前編集システムというのをちょっと少ないんですけども統計モデルを学習しました
でデコーダはｍｏｓｅｓ
を使いまして前編集モデルはＧＩＺＡで学習しました
でフレーズトランスレーションモデルを使います
で直訳調言語モデルはＩＲＳＴＬＭツールキッ
トで学習した
五グラムを使いましただいたい機械翻訳では五とか七とか使われることが多いみたいです
で変換単位には今回は単語と文節を使用しました
で今回は日本語日本語の変換ですので
付属語のみの変換というのは
なんかその動詞に対する格が
変化してしまう可能性があってそういう変換は考えにくいですので
文節単位でやるということも考えました
実際にはフレーズトランスレーションモデル使ってますので単語単位で変換してると言っても
一部はフレーズになってるというような感じです
で実際に結果なんですがこちらが文節単位でやった結果でこちらが単語単位でやった結果です
でまず
クローズデータの評価なんですが
前編集なしの場合ですと
前編集あり
クローズデータ千文に対してやった結果
明らかに
文節単位でも単語単位でも
良くなってるということがわかります
で枠組みとしては正しく機能してるということがわかりました
で改善した文の割合はこちら六十から七十％ぐらい
ということで
文節の方がクローズドデータに対してはいいという感じです
で一方オープンセットなんですが平均で見ると結局改善はみられませんでした
で良くみてみると改善した文の割合っていうのがだいたい四割ぐらい
あるというような結果になりました
で平均の精度でみると
オープン文節単位でやったほうがいいですが
改善した文という単位でみると
単語単位でやったほうがいいという結果で今回は文節と単語どっちがいいかということは
ちょっと判断は
ついてません
ただ

クローズドデータの
改善の仕方とかをみると
文節単位というのはかなり
学習データに依存してるのではないかと
いうような
感じです
で全体的に学習
データが不足してまして
特に文節単位は
なんか過学習してるんじゃないかなということが考えられます
で実際に単語と文節の
統計量なんですが
単語の場合は
述べ単語数がだいたい一Ｍ単語で異なり語数が
二十二Ｋぐらいなんですけど
文節の場合は
述べ文節数が
少なくって異なり文節数が多いと明らかに多くって
ほとんど出てこない一回ぐらいしか出てこない文節ばっかり
ですので
あんまりちゃんと推定できてないなというのはわかりますそれでも意外とオープンデータには動いてるというような状態です
でそれから
機械翻訳のデコーダというのはパラメーターチューニングができまして
それも機能ついてましたんで使いました
で実際に何やったかっていうと直訳調の日本語文を参照訳として
前編集後の日本語文のＢＬＥＵスコアを最大化
書いてますけども
結局前編集した後の日本語文が直訳調の日本語文
に近くなるようになんかデコーディングのパラメータを
調整しましたと
いうことです
で開発セット二百文に対して
やったところ
少し良くなりました
でオープンデータに対しても同じような結果で
ほんの少し良くなったんですが結局やっぱり
前編集しなかった場合に比べて
この改善は
まだちょっと
得られませんでした
チューニングには効果があるんですが実際には

日本語文を前編集して直訳調にするようにしかしてませんので
最終目的は日英翻訳ですので
日英翻訳が良くなるようにこれもチューニングしてやればいいかなと
いうようなことは考えられます
で実際にどんなのが効果見られたかという例なんですが
例えば銅は高寄りしたあと続伸し
大半の限月がこの日の高値付近で引けたというような
経済のやつなんですけど前編集してやると
銅はより高く開きました
登り続けていてほとんどの契約が一日の内の高値の近くで結ばれました
大体意味は似てるんですが
これ英文にしてみますと
明らかにこっちの方が
いい英語になっているんですがこれで意味が通じるかどうかはちょっと別問題なんですが
こちらよりはかなりいい
英文になってると
思われます
特に終わりのほうが
結構
分かりやすくなってるような気がします
でもう一つは何かこんなやつで
チリの国営
銅公社コルデルコ社の声明によると
何とかかんというやつがやっぱりこれも
何かこんなふうに変換できまして
何かこの辺に
によるとがではになってまして
調印したがサインしましたぐらいになっているんですけど
これぐらいでも
だいぶ違いまして
こっちがＷｈｅｎｔｈｅＣｈｉｌｅｇｏｖｅｒｎｍｅｎｔｒｕｎ
ｃｏｐｐｅｒｐｕｂｌｉｃｃｏｒｐｏｒａｔｉｏｎとか
ちょっと良くわからない出だしなんですが
こちらのほうは出だしから結構わかりやすくなってて
特に終わりのほうの文章は
間違いがなくって多分
読んでも分かる状態になっています
で一方うまく行かなかった例なんですけど
なんかこんな文章ですが
何故かこうプロジェクトは終了二千年前半のを計画していますというような
ちょっと変な
日本語になってしまいまして
こんなふうに
変な日本語はもちろん変な英語に
なってしまうというような感じです
これはなんか
多分学習データにいっぱい引きずられたんだと思います
で以上ですがまとめますと日英翻訳における統計的前編集をしました
で学習データを自動獲得して
英日対訳コーパスからほぼ同サイズの学習データを自動獲得可能であるということが
わかりました
で翻訳単位は
文節と単語についてはちょっとよく
わからなかったんですが

デべロップメントセットじゃないトレーニング
クローズドの実験みるかぎりはデータが多ければこうなるのかなというような予想です
で四十％程度の文で

英語の品質が向上したんですが
平均的には品質向上はみられませんでした
でドキュメント検索のための翻訳としては
前編集があった場合とない場合の翻訳文から
両方から
索引語など作ってやればいいというようなことも考えられますので半分ぐらい
良くなってるということで用途によっては利用可能な精度ではないかと
いうようなことは
言えますがやってみないとわからないと言うことです
で今後の課題は
あと前編集の学習データを複数のＭＴシステムなど使ってですね
増やしてやる実際もっと
日英対訳コーパス持ってくれば
いいんですがそういうことやる
それから
前編集でデコーダを
最終的な英語がよくなるようにパラメータチューニング
してやればいいかなということを考えています
発表は以上です
