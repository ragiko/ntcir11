石川高専のと申します
統計的な手法による動画シーン分割性能の改善について報告させていただきます


いろいろ情報を共有するシステムはございますけども
私共の
高専も全国の高専が一法人になりましてそういうこともございまして
全国高専の教育素材を
一同にこう集約しまして
全国高専で有効利用できるように
高専間教育素材共有システムっていうのを構築して運用しております
で現在二百三十件ぐらいの教育素材が入っているんですけどもビデオとかがまだこれからという感じ
でこのシステム
にビデオとかを入れてさらに有効利用したり検索したり
ていうふうにしたい
いうのが要望としてまずございます
でビデオ教材とは
いろいろ高専のいろいろな箇所で少しは
あるんですけどもそれがまだ有効利用できてないということで

こういう教材があると要点や
考え方が手軽にわかるっていうことで予習復習自学
自学自習に有効であろう
でしかしながらビデオ教材の種類や数が少ないですとか
あるいはビデオ作成に時間と手間がかかるっていう問題がございます
そこで
本研究では録画したビデオ素材を
話題毎に自動分割致しまして
で
ビデオ教材の作成の手間を軽減したい
また
分割されましたらそれをビデオ検索の
前処理としたい
こういう研究目的で
で講義を録画したようなビデオ素材からビデオ教材作るためには
当たり前なんですが必要なシーンを抽出もしくは不要なシーンの削除が必要です
でしかしながらここで大変なのがこのシーン分割位置をこう決めるっていうのは意外に
後戻り何度もしたりして結構たいへんです
そこでこのシーン分割位置
の自動推定っていうのをやりたい
いうこと
でビデオの中にはご存知のように音声と映像がございます
で映像情報を使えば
ニュース等シーンの切り替わりが明確な場合には非常に有効なんですけれどももしくは編集済みのビデオには非常に有効なんですが
実際のこう授業なんかで
あるいは講義のなんかで
撮ったので
試してみましたところちょっと位置ずれを起こしてそのままでは使えないというのがわかりました
でそこで音声情報であれば
講義内容直接含みますので
シーン分割位置推定には
有望であろうと
いうことで
ビデオ素材から音声情報だけを取り出しまして
音声認識によって誤りはありますがテキスト情報を取り出して
このテキスト情報を基にして
シーン境界情報を得よう
で
あとは人手でといいますか

編集する人の好みといいますか目的がありますので
人手によって要らないところを削ってやればビデオ教材ができると
いう流れでございます
でまず今回の評価に用いました音声認識の条件について簡単にご説明いたします
使いましたビデオ素材は五人の教員による九十分の講義ビデオです
収録には接話型のヘッドセットを用いておりましたので
雑音等の影響はあまり無いと思う
音響モデルは
新聞記事による学習でちょっと講義には合ってないんですけれども二千状態十六混合ＴＲＩ—ＰＨＯＮＥモデル
で言語モデルには
ＣＳＪの言語モデルを使わせて頂きました
でこの音声認識
実験の結果なんですけれども
単語正解率は
五つのビデオ素材
ビデオ
素材の平均で四十三．一％
単語正解精度が二十五．二ということでちょっと
ちょっとかなり低め
これもうちょっと頑張ればもっと良くなると思うんですが
ちょっと
あまり今のところ
頑張っていません
でこのように誤りが多いテキスト情報を基にこうシーン分割位置を推定するわけですが
これまで行なって来た方法は
従来法と呼んで呼ばさしていただきますがこれまでの方法は

この隣接するシーン間が似ていれば一つのシーンとしまして似ていなければ
シーン境界があると
いうような
観点で分割していく方法です
そのために
まず
各シーンごとの話題を代表するようなシーン指標をそれぞれ求めます
指標にはみなさんよくご存知のようにＴＦＩＤＦとかいろいろな指標が提案されている
これまでは独立成分分析を用いた指標を用いております
で得られた指標
間
の
違いを図るために余弦測度を使っておりました
これはコサイン値ですが

シーンが似ていなければコサインが小さくなるということでこの余弦測度の総和が
最小になるような

シーン境界を求めれば良い
そういう組み合わせ問題になりますので
これを動的けいか
く法で解けば
シーン境界が求まる
このような方法を用いております

で
ビデオ教材
作成の支援システムのこれは実行例なんですけれどもこのようにして自動的にシーン分割されたうちのどれか
一つのシーンを選ぶと
動画が再生されますので
不要であれば
削除ボタンを押すということで
ビデオ教材が完成ということになり
ここまでがちょっと従来のあれなんですがここから今回
調査しました結果と言いますか方法です
で統計的手法によるシーン分割と書いてありますけれどもこれは元々
テキストセグメンテーションのところで使われていた方法を
誤りの多い音声
講義音声に適用したらどうなるかっていうことで応用した結果で
まず
与えられるものとして単語系列Ｗがある
でこれが与えられた時に
この各セグメンテーションと言いますか
セグメントの境界
こういう確率が
最大になるように

決めてあげれば良い
いうやり方です
でベイズ則でこのように展開できまして分母の方は

境界には関係ないので無視しまして
この分子のところが最大になれば良いということなんですが
ここでちょっと申し訳ありません予稿集の百三十二ページの

式四なんですが
ここ
ＭＡＸではなくてＭＩＮＩＭＵＭになってしまっておりますので恐縮ですが
申し訳ありませんがＭＡ
Ｘに
訂正させて頂けないでしょうか

百三十二ページの式四です
すいません
で

この確率を最大にこの確率が最大になるようにシーン境界を求めれば良いということになる
でこちらの
最初の項ですが
こちらの項は

いくつかの仮定を用いて展開していきますと
最終的に

各あるシーンにおける
こういう単語が出てくる
生起確率の積
ていう形で

簡単化と言いますか近似
することができる
でこのあるシーンにおいてこういう単語が出てくる確率っていうのは
簡単にはそのシーンの
そのシーンにおいてその単語が出てくる
数を
そのシーンの単語数で割ってやれば良いんですが

ここではディスカウンティングを行なってラプラス法によってディスカウンティングを行なう
をしている
で第二項の方ですけれどもこれは等確率に今のところ
与えておる
これがシーンシーン分割結果です
横軸が
分割率です
この分割率というのは分割数を
その講義の全分数で割ったものです例えば講義の
全文章が百文だと簡単のため百文としまして
分割率が零.二としますと二十分割するっていうような意味です
で縦軸の方はこちらの上の二つが再現率
下の二つが
適合率です
で今回の目的はビデオ編集ということですので
余計な境界があっても無視すれば良い
ですけれども
境界が入っていないと
その周辺を何度も繰り返し主張することによって
セグメンテーションしなくちゃいけないってことで労力が発生します
ということで
こちらの再現率が高い方が今回の場合には良いということになる
そしてこのブルーの方が
従来の


ブルーの方が従来の

隣接するシーン間がなるべく似ていないように決めた境界の例場合です
赤色の方が統計的手法による方法です
これ見て頂ければわかるように
今回の統計的手法の方が
再現率が高くなっているのがおわかり頂けるかと思います
これは音声認識
結果を使った場合
で
書き起こしを使うともっと良くなるかなあと思ったんですけど傾向は
統計的手法の方が
良いんですけれども
先ほどの音声認識の結果と比べると
大差ないと言いますか
むしろ音声認識の方がちょっと良かったりします
でこれはおそらく今回は
音声認識せっかくしたんだけれどもどういう単語であるっていう情報を実は一切使っていなくって
単なる符号化をしてるにすぎないっていうことで
で

比べてるだけなので
どう間違おうと同じようにさえ間違ってくれれば関係ないよと
単なる符号化としてしか動いてないということなので
そういう意味では書き起こしであろうと書き起こしの方がむしろ人がやるので揺らぐということで
そういうことかなあというふうに思う
で先ほどディスカウンティングにラプラス法を使ったと申し上げましたがその他のディスカウンティング法でも念のため確かめました
でここでは予期尤度推定法とリスタッド法についてその他いろいろやったんですがそれほど大差無い結果が
得られました
それからこちら書き起こしテキストですがこちらもほとんど大差無いような結果
ただリスタッド法で一部ちょっと
多少良い良く良いかもしれないとこありましたがおおむね
それほど大きな
差は無いようで
ここまでが
シーンの分割の話なんですけどもこういうシーンの分割を使って
次はシーンの検索をしたいということでシーンの検索結果までは今回
ご報告するできないんですが
少し予備的な
調査をした結果について簡単にご説明させて頂きます
まず利用する情報としましては
音声情報以外のスライド情報等いろんな情報を使う方法がございますけども
私どもの方ではいろいろ黒板での授業ってのも非常に多いってこともありましてスライドを用いない講義にも対応できるっていうことで
音声情報のみを用いる
ていう
のを今対象としておる
それから未知語対策も重要ですけどもこれについてはいろいろと先行
的なご研究がいっぱいございます今回のワークショップでもいろいろと

あったかと思い
音素インデックスを
ファイルを用いる方法とかサブワードを用いる方法とか
講義音声とウェブページをリンクさせて

検索キーワードとウェブページをリンクさせて
ウェブページ同士で比較する方法ですとか
ていうのは様々
ご提案されているようです
それから先ほどもご発表ありましたが検索テストコレクションていうのも
今整備されつつあるようでいろいろ比較しやすくなるかなあというふうにして期待しており
で今回ちょっと予備的に行いましたが一般的な方法です


それぞれの子音から指標ここでは
よく使われているＴＦＩＤＦ
を用いました
でキーワードから
同じく指標を用いて
指標間
の比較を

コサインで
やって
で一番大きくなる
ところを
検索結果とするという
一般的なやり方で
でどの程度の結果が得られるかちょっとベースライン的なものと言いますか目標値をちょっと見極めたいということ
でこれが結果です横軸はキーワードの数
それから縦軸が平均逆数順位
でして
これは
例えば
平均ＭＲＲが零．五ですと
その逆数の二ということで平均的には二以内に結果が出てくるというような感じになる
ですからこの数字が大きい程良いということになる
それからキーワード候補数っていうのは
例えばキーワード候補数が五っていう場合ですと
先ほどの
こちらのキーワード
に与えるものとして
とりあえず今何を与えたら良いかっていうことなんですが
システムにとって一番都合の良いもの
をとりあえず与えてみようということで
それぞれのシーンから出てくる指標
今ＴＦＩＤＦを使っておりますが
それの上位五つ
を
キーワードとしてキーワード候補としてまずここにプールしまして
でその中から
一つ選んだ場合二つ選んだ場合っていうような形ですからこの結果っていうのはいろいろやった
おそらく上限値に近い値になるのかなあというようなかんじです
でもう一つちょっと予備的に調査致しましたのが今度は人に
評価者に
各シーンでどういうキーワードを連想するかっていうのをちょっと
書いてもらいました
で
そしてちょっと調査したんですが
全体のキーワード総数これが百％だとしますと未知語が約十三．八％ぐらい今回の例ではありました
それからちょっと抽象化って書いてあるんですが
これは
直接発話していないけれども
発話内容をこう総括したりとかイベントを表現しているようなものをここではちょっと抽象化と呼んでいますがもっと適切な言葉があれば教えて下さい
例えば演習であるとか
演習とは

実際には言葉にしないんだけれども
イベントとしては演習してると
昔話とか
なんか話の流れとか
いろいろまとめとかっていうような感じでいろんな形で
実際の発話には出て来ないんだけどキーワードにして出てくるっていうのが意外と多くて
で数えましたら全体のなんと十一．四％もございまして
今回この

五つの授業が特殊かもしれないんですけども
また大学の講義とはまた違ってくると思いますけども
とりあえず今回用いたテキストについては

よく
注目されるのは未知語対策なんですけどもこういう抽象化対策っていうのもひとつ
大事
なのかもしれないなあとただ難しいだろうなあと
いうようなことでございます
で以上ちょっとまとめますと
講義ビデオ
を自動的にシーン分割する方法として
統計的なシーン分割手法を講義音声に応用
致しました
でその結果従前用いておりました隣接子音間との比較法よりも
今回の方法の方が

良さそうだということがわかり
それからもう一つ予備的
ですけれども
ビデオシーン検索
に応用するに当たっては
こう未知語対策ばかりではなくて
抽象化表現への
対処っていうのも重要であろうということがわかり
以上です
