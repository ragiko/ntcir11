それでは音節Ｎグラムインデックスによる未知語音声未知語の音声検索法の改善ということで
豊橋技術科学大学のが発表させていただきます
まず背景と目的ですが
背景といたしまして

ウェブ上に多くの音声ドキュメントが存在していると
いう点と
それにより検索の要求が
大きくなっていると
しかし音声ドキュメント
を検索する際には認識誤りや未知語といった音声ドキュメント特有の障害が存在していると
いうのが問題になっています
また連続ＤＰなどによる検索では長時間の音声ファイル
を検索した場合時間検索時間の増大
というふうな問題もあります
そこで本研究の目的として
認識誤りや未知語を含んだ
長時間の音声ファイルに対して
高速な検索手法の提案と評価
というのを目的としています

従来法といたしましては
サブアド系列の
連続ＤＰ
サフィックスアレイＢＡＧＯＦＷＯＲＤＳなどがありますが
本研究のベースラインとしてこのサブアド系列の連続ＤＰを
用いることにします

提案手法の概要です
まず
一般的に
音声ドキュメントを検索したいという際には
まず音声データからテキストに書き起こして

大語彙連続音声認識などで
書き起こして
検索するのが一般的です
しかし
この場合辞書にフーリエ変換
認識の際に使う辞書にフーリエ変換などが含まれていない場合
認識結果に出力されないと
いう未知語の問題があります
そこで
未知語の問題を解決するために音声データを大語彙ではなく音節認識を使って
テキストに書き起こすと
いうことを行なって

辞書
未知語の
未知語でも認識ができると
いうことができます
しかし
認識誤りの問題もありまして例えば
このような置換誤り脱落誤り
挿入誤り
などの
認識誤り
の問題があります
そこで我々が現在までに提案している手法といたしまして
まず
索引の構築を行ないます

索引の構築といたしましては
先ほどの音節認識結果を用いてＮグラムインデックスを構築します
本研究ではＮ＝三として
音節の三つ組み
を
出現位置とペアとして
索引として構築します
このように索引をあらかじめ作成しておくことで
検索を高速に行なえると
いう利点があります
次に認識誤りの対策に関しましては
それぞれ置換挿入脱落に対して行ないました
まず置換誤りに関しましては
認識結果の上位Ｍベスト
認識の複数候補を使って
三つ組みを作成してそれをインデックス
としておきます
次に
挿入誤り
に関しましては
認識結果の音節を一つ飛ばした
三つ組みを
作成することで
対処します
これもその音節を一つ飛ばした三つ組みをインデックスに登録しておきます
で
次に最後に脱落誤り
に関しましては
これは
上記二つは
インデックスに

それぞれ誤り対策を行なったものを登録すると
いう手法ですが脱落誤りに関しましては
検索の際にクエリを脱落させて
複数回検索すると
いうような手法を行なっています
で具体的な例といたしまして
まず置換誤り対策
に関しましては
は
認識結果がこのようになっていて
ワンベストだけではフエキエと
先ほどのフーリエ変換という単語が
置換誤りによって
検出ができないと
ですがこの三ベスト
を使って
それぞれ三ベストに含まれる音節を組み合わせて三つ組みを作ることによって
例えば
この場合だと
フーイというふうなインデックスや
正しいフーリというようなインデックス全てを登録すると
いうことで

置換誤りであっても
三ベスト以内に入っていると
この
使った認識候補
に含まれていれば
検出ができるというような仕組みになっています
次に挿入誤りに関しましては
一つ認識結果の
音節列
で三つ組みを作る際に一つ音節を飛ばして
三つ組みを作るということで
まず
普通のフクウと
いうような

三つ組みを登録して
次に
このウを飛ばして
フクリというような三つ組みを作ります
で
で最後にフーリと
いうような三つ組みを作ることで例えばこの場合だとクが挿入挿入誤りだった場合でも
フーリエ変換というのが検出できると
いうような仕組みになっています
そして
脱落誤り対策ですが
これはクエリに対して
このクエリがフーリエ変換というふうな場合でありますと
このクエリをまず分割して三つ組みを作成します
その際に

フーリやフーエ
リを脱落させてフーエと
いうようなクエリなどを全部作って
それぞれ
複数回検索して

脱落誤りに対処しています
でまた挿入誤りと脱落対策
というのを組み合わせることによって置換誤りの対策にもなると
いうことを示します
まず

このようにフクーリエ変換というふうになっていて
ウがクに置換されていると
いうような場合を考えます
その際に
挿入誤り対策によって一つ飛ばしのトライグラムを作成すると
一つ飛ばしの三つ組みを作成すると
いうことで
このクを飛ばして
フリエと
いうような
三つ組みを作ります
で
それに対して脱落誤り対策で
フーリエ変換というクエリが与えられた時に
ウを脱落させたクエリで検索することによって
たとえここは
認識結果
使っている認識結果の複数候補の中に含まれていなくても
検出ができると
いうような仕組みになっています
そして次に
検出候補の削減ということで
先ほどの
認識誤り対策三つ紹介しましたが
それらを行なうことで誤検出が増加してしまうと
いうような
問題があります
そこで
認識誤り対策をどの程度行なったかと
いうような情報を
距離として
索引に記録しておきます
で
ここでそれぞれ置換距離挿入距離脱落距離とあるんですが
まず
置換距離のほうです置換の距離のすみません

置換距離というのは
バタチャリヤ距離を使ってワンベストとの

複数候補とそのワンベストとの
バタチャリヤ距離で
置換距離というのを定義します
でまた挿入距離脱落距離というのはそれぞれ何音節
挿入を考慮したか何音節脱落を考慮したか
というのを
距離としています
そしてまあこの
距離を
その三つ組みの数で
正規化して
トータルのディスタンスを求めます
で
このトータルがある一定の閾値以下であれば検出すると
検出とする
というのが
検出候補の削減となります
なので置換挿入に関してはインデックスのほうに距離として
定義されています
脱落に関しては
クエリに対して

脱落対策を行なうので検索する際に考慮します
そしてもう一つ問題になる点といたしましては
誤りを考慮したインデックス
誤りまで考慮してインデックスを作成するため

インデックスのサイズが大きくなってしまうと
いうような問題があります
そこで各音節の音響誘導を用いて
インデックスを削減するというような手法をとりました
例を挙げますと
この部分で見ますと

音響各音節のその音響誘導を比較して
ワンベストとの差が
閾値α以下であればインデックスに登録すると
いうことで
例えばこの場合ですとエとウの
尤度の差を見てこれが閾値α以下であれば登録すると
しかし例えばエとイの
ワンベストと三ベストの差が
閾値α以上であったと
いう場合には
このエイっていう音節をこの
イを含む
三つ組みを作成せず
このイを含む三つ組みは
インデックスに登録しないと
いうような方法になっています
で
次に評価実験になります
実験データはＣＳＪのコアデータ約四十八時間を用いました
本研究で
開発されたＳＰＯＪＵＳ＋＋により
結果を使います
また大語彙認識も行なっているので大語彙認識の結果も
使えます
そして音響モデル
に関しましては
左コンテキスト依存音節モデルを使っています
で
音響モデルの学習にはコア講演を除いたＣＳＪの二千五百二十五講演を使っています
言語モデルは
と音節の四グラム
のモデルを使っていて
大語彙認識には単語三グラムの言語モデルで
約二万八千語の辞書語彙になります
で学習には音響モデルと同じくＣＳＪの二千五百二十五講演
用いていま
で
先ほどの条件で実際に認識した結果
になります
音節認識した結果でワンベストですと八十三％
三ベストで八十九％の
五ベストで九十一％というコレクトになっています
五ベストまでいくと九十一％非常に高い値となっていると思います
また

大語彙認識をおこなった際の認識率は
七十一．九％となっています
またこの大語彙認識を
音節列に変換した際の認識率音節の
認識率っていうのは八十三％程度になっています
次にクエリに関してですが
クエリは音声ドキュメント処理ワークグループの
コアデータテストコレクション
の一部を利用しました
既知語クエリはいや三十九種類で未知語クエリは四十四種類
となっています
で
実験内容
になりますが
まず
既知語での検索に関しましては
実験を三つ行ないました
一つは
大語彙認識結果を音節列に変換したものによる
検索
これは提案手法を使ったものです
でまた
音節認識結果による提案手法
を使った検索
そして最後に
大語彙認識と音節認識の組み合わせによって検索を行ないました
このときの大語彙認識
を使った
検索法はテキスト検索で完全一致で
おこなったものを使っています
次に

未知語での検索
に関してですが
未知語に関してはインデックスを削減した
ものによる提案手法の検索
また

これも後で説明しますが未知語クエリの複合語の対処
というのを
やっています
また検索性能と時間の比較を
連続ＤＰと比較しています
でベーストレインとして使う連続ＤＰというのは
複数候補を使った連続ＤＰとなっていて
音節単位での検索
をやっています
で
距離には音節ＥＣＭに基づくバタチャリヤディスタンスを使っています
距離の定義は以下のようになっていまして

複数候補を使うので複数候補を使うとペナルティが発生すると
いうような式になっています
その中で最も小さい
距離であったものを距離として
使います
で
既知語検索のほうなんですが実験結果になります
で
まず
音節に関しまして音節認識結果を使った

検索性能に関しましては
青いほうが
提案手法五ベストまで使った提案手法になっています
で紫のほうがベースラインである連続ＤＰ
これも
五ベストまで使ったもの
になっています
この結果を見ますと
多少連続ＤＰのほうがよいというような結果になっていますが
差はほとんどないと
いうような形になっていま
次に大語彙認識を使っ
て大語彙認識結果を音節列に変換したもので
提案手法と連続ＤＰ
を
やった結果がこの
赤とオレンジになります
赤が提案手法オレンジが
連続ＤＰマッチングになります
これを見ますと
連続ＤＰマッチングのほうが良い結果になっていますが
これは
提案手法でもワンベストしか使っていないと
提案手法というのは
複数候補を使って
良い性能が得られるということなので

現時点では複数候補を使っていないため
連続ＤＰマッチングの差が開いてしまっていると
いうような認識です
そして
大語彙認識結果と音節列の音節認識の組み合わせということで
先ほどの結果から大語彙認識結果を用いたほうが検索性能は良かったのですが
誤りを考慮できないため再現率というのを
上げることが難しいと
なので
そこに音節認識結果を使って

併用することによって再現率を上げようと
いうことを行ないました
どういうことかといいますと
単語
テキスト検索
すみません
まずクエリを二つ
単語単位のクエリと音節列のクエリ
というのを二つ用意して
単語単位のほうでテキスト検索をおこなって
音節列で提案手法の音節認識結果から検索すると
この両方の結果を合わせて最終結果として

検索をすると
いうような手法でその結果がこの赤い線になっています
で先ほど青と
紫とオレンジは先ほどと同じような
提案手法と連続ＤＰマッチングなっていますが
これを見ますと
リコールが高いところで連続ＤＰマッチングよりも良い結果が得られています
で未知語検索に関しまして
ちょっと見にくいんですが
まず実践のほう
赤が提案手法
使った
五ベストまで使った提案手法
青が連続ＤＰベースラインです
で紫が提案手法で三ベストまで使った
手法となっています
で
ここでは点線があるんですが点線というのがこの五ベストの結果
から
インデックスを削減した結果となっています
でそれぞれ閾値を変えて削減した結果
もともと三ギガのインデックスなんですがこれが

一ギガと五百メガ
程度になると
でそれでも検索性能は多少下がるんですが
それでも
ほぼ同じぐらいのインデックスのサイズである三ベストよりは
よい結果と
いうふうになっています
また連続ＤＰと比較しても
プレシジョン
リコールが〇．五のあたりですと
随分よい結果になっているのではないかと
思います
次に未知語クエリ複合語ということで
クエリの中には名犬ラッシーのような未知語クエリがあるんですが
これをクエリは名犬は既知語であって
ラッシーは未知語であると
いうようなものがあります
で
このようなクエリが四十四種類中二十一種類ありました
で逆にこのような
組み合わさったようなクエリではない
一つの単語として未知語である
クエリっていうので例としてはユーゴスラビアみたいなのがあります
でこのクエリ複合語のクエリを検索する際にどうするかと
いう方法で
すみませんちょっと
時間が
おしてるんで

名犬ラッシーを音節認識で
全部検索するのか
名犬とラッシーで分けて既知語のほうはテキスト検索
ラッシーのほうは提案手法で検索する
というふうな方法で

やりました
でその際に
紫のほうが
音節列から検索した
全て音節列
で検索した方法になっていて
青のほうが

名犬とラッシーで分けた結果になっています
で
こうなると分割したほうは性能が悪くなってしまうと
でなぜかというのを調べた結果短いクエリは誤検出が増加すると
いうような
考えに行き着きまして
それぞれ
音節の長さを
五音節以上六音節以上すみません五音節以下六
音節以上
で分けて検索した結果
長いクエリのほうが良い結果と
短いクエリ青なんですけど随分悪くなっていると
いうような結果になっています
検索時間を連続ＤＰと比較したんですが
提案手法はニ．五ｍｓで検索できるのに対して
ＤＰは五百ｍｓと
随分
差が開くと
いうような
結果になりました
以上で
発表を終わりにします
