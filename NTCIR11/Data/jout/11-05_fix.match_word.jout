ダイエットをす正解はあの言語情報による発話一軒以上と推定手法の比較と題しましてえーっと反対の形が発表さしていただきます
えっとーまー研究背景と目的なんですけどまあの一二言うとあのーまー人間とロボットを
人自然な対話をさ対する有効で
まその音声を書いたコミュニケーションが必要でえー
そのーユーザーの
まそれえー土地にいきなりわりと明示されても困るのでえーそのユーザーの発話資料を判断した上
報道させる為に
えーさせたいということで
まこのユーザーの発話の資料発話系列音と
定義しまして
まその二十分の情報を意図した発話を推定するというのはえー本研究の目的です
んでえーと関連研究として
えーっと一つあるんですけどまーあの発話まあの品詞やえ韻律情報による
発話終了予測えー七分
まこれあの発話の最後のえーと品詞の情報や音声のピッチパターンと発端
からえー属したもので
えーっとま韻律の重要だよって言ってるようなえーデーターですけど
ます三四であのおー
水泳と
品詞やえーと発話末の品詞やえ韻律情報と合図との相関のおー調査した結果
まその発話末の韻律情報と相づちの
責任とこの相関はしてて
えー
発話末の品詞情報と相づちの
んえー責任のその相関は
の値というような
えーっと
あります
の
はい
でえーっとー幸い到底
えー
二日常語や
品詞情報などを
設定によって
えー
などを使って決定によって繁栄発話者の交代を推定したものはあるんですけど
まー
この構成されて決定木ではえーと韻律情報の自由度あんまりなくて言語情報は
えーよく使われてというような方法があります
でこのようにあのーま言語情報が重要というようなえー方法があるんですけどえー
その発話末の品詞情報をんー何えー
などそんな形的な情報しか使われてない
なかったり後会話の流れっていうものこれされてないものをもう一つの音と似たので
まーえーっとーま今回は
本稿ではえーっと言語情報注目してさまざまなモデル四つなると水を用いてえー
曲を行ないますと
はいそれでえーとーその発話権の状況を推定しようということなんですけどまー
こうあのー
これらのモデルを試しますと
でこれについてえーっと簡単に説明します
で決定木
ま色々種類あるんですけどま格好を使いますと
っていうのを決定木
あのーま御存じの方多いんですけどまそのーえーっとーノードから
まその御質問個体Ａ最終的に着いたあのーどのクラスで分類するっていうようなもので特徴としては
丸四テキスト変数四ます的変数が存在するような素性をもう簡単に与えたり
後はえーっと構築したモデルの解釈のこういう風に
奇麗で言うのでまーどういった美容院があるのかとか
いう解釈納得し易いという
メリットもあります
えその一方でえーまあんまりその多くの素性えー第一音節量は父や文といったでメリットもあります
で学習用の
あえーとー二重の検証を最大化とするようなあのー特性でするんですよ
内容は
えっとーを奇麗にプラスの分かれるような
んより課題よりクラスの
わりあいに偏りが生まれように分類一つあのーノードを生成して一の
でえーっと文文音声あのー木を成長させていくとか学生を起こすのでえー下では
の場合水泳で
えー
えーっとークロスバリデーション選ん最小値からはそのーです評定閉鎖音スターたい
のところを
方
多摩別の度数のところで枝刈りをするというような
見えるので構成をしてみます
でついえーと三回すえー歳でえーっとＰモデルなんですけど
まこれはあのー経験的確率分布によって素性の
階層モデルによると全体性を一させるっていう制約の下でえーモデルのエントロピーを最大にするモデルえーす
でえっとーまこういう形でえーまー対数うー線形モデルで買っているんですよ
あります
で想定で
まー
父はこれから後はま素性
そしてえーまーそのー
の日間えーあー使われます一般的には
でこの
んーまＸの入力にＹの出力にあるんですけど
その
Ｘの条件が発生でえー
なおかつ場合周りであれば一型それ以内だったら
〇
っていうような形でえーま例えば発話Ｘにあのー
形で
が含まれてるかどうかがまこのＢ水
にえー
とかで
まそのかつその発話が発話条件を一としていいかどうかっていうのもこの場合効率みたいな
形なんですけどこう色んなあー素性
になります
え特徴としては
まこういう二時七
ま素性を制約条件に取り組んごとの可能って言うとおー後二十一つに
おーうーの影響受けについていいような
しょうがあるんですけど
まその有効な素性の
四五の選択が必要というところですえーそしてまたたりします
えー活用まー
こちらの対数尤度関数を最大化するんですけどま試合Ｓとか
始めるとおーなど使って
あります
えとーこれはあの川口起こして安定
あーのー
の
えーそのパラメーターの事前分布として蛙やらプラスうー分布を
仮定して
後えーっと多く
えーっとセット二コースの
訳です
別にサポートベクトルマシーンです
まーこれはえっとのスタートえー
まこれあの丸と三角の二つのクラスの二でえーとこの
教会
この二つのクラスの間を最大化させるマージン最大化に基づいた表一です
でまーこういう風に
その
に住む家のスコアが〇より超えてたらうちいー
〇よりさまざまえースキーというような
形でクラス分類します
で特徴としては
そのパラメーターその場合に
のそのー
各地に持ちにくいと言うとそれは後は
ま今回はそのー複雑な複雑なと言うか線形関係使ってるんであんまり関係ないんですけど
まーそんなこと聞かれるところですとおーん
じゃどうすかねとか使うと複雑な想定も
まそんなあの
ま容易に扱うのはできるという特徴があります
えーとーまーその部分を兼ね関数使おうというような問題が
歩いたりもします
でえーま学生がそのマージン最大化の方法を最大化するようにパラメーター学習するんですけどまこういう形で終わらせられます
てこれはまー後まー実際データーって言っている
まーあの完全に分類できる場合なんですけど
んーまーあの完全二分類できない場合やお母可能な三角形を高めたい場合をまそその実際えーっとえ
えーっとー
その
内側に入り込んだ文の高速
こう加えてやって
この値を
ま最小化するというような
形になります
でえっとー
まその
既存の
会話の流れをむすえーっとあまり考慮されてないという
言ってたんですけど
まーあのー
係数ラベリングもえーもうえー使ってえー推定しますと
で後から来率ラベルのモデルですと
まーあのー代表的な隠れマルコフモデルです
心の状態ついに単純マルコフ立場でしたマルコフモデルなんですけど
えーん
ま家族兄弟Ｘのこれがあの発話の系列に当たるんですけど会話に当たるんですけど
二状態系列え×
まず発話音声えー発話検証といったするとこの系列を求め問題になります
でえーっとー
ま本来はえーと系列全部を見経営歳
えーっと一最もらしい系列を選んでくるんですけどその
築地ついでになるのでその先の会話っていうのは予想できないので続い推定することになるので
まこういう形で
推定することになりますその前のおー推定した結果を利用してす推定することにあります
てこれだとあのー決定的に
えーうー推定していかないといけない
んですけども
保存前向き確率を利用したら
そのー
直前の状態を使うえ実例をえー与えて
えーある程度頑健になるのかなということで
まーこの普通でえーとー情報の推定を
がえー
えー比較してみますと
でえーとーＨＭＭの特徴としてはそのまー
提示られるのも全部で四枚の状態起こる可能っていうのと後
後はまー生成モデル
というまこれ二三
とおーかなと思いどうんーまその日
ＰＸ次元の場合はなってい付いていけないと
えーいけないといけないという生成モデル
脳特有のまー
欠点があります
後まー一独立な素性を
そして四独立な素性を扱わできないというような
まデメリットもありま
テーマ私はえーまー単純に
最尤推定で
取れるんですけど
えー
の
〇二の問題
えーと二つ
えー学習データーに現われて内での大割れない単語が
えー
テストデーターに現われえっとーえー頭ではないちゃうのでえあのー今回は新たスムージングをしますと
で次にえーと三えー歳でえーと二マルコフモデルです
こちらはえっとーそのＮ２さっきえ先程説明したい六モデルに単純まーここ過程を
えー
仮定したモデル
でえーまー
同じように
えーんん
定式化できるんですけど
住ん特徴としてはその
識別モデルっていうのは大きな違いえー
まこっち側ＨＭＭのクラスターあるのでえーこちらえー六年目の
グラフィカルモデルなんですけど
まー
ＨＭＭはそのー状態から
ん家族調整女性の体って言い
えー六年には
えーまず
前の状態等を観測値を元に
今の状態を
まー生成するような形になっても
はいでま学習はその直前の状態が
同じもの
元に
え六モデルを学習してえー
それを使って
推定するというな形になります
えー
で後お姉はあの生まれて一般的に変わる
切れないんじゃないかと思う見たことはないんですけどまＳＶＭ
もう
まー構文のえー
え自然とマルコフモデルを組み合わせた表一もう後四対一日
試してみました
えー
まーそのー
さっきえー六年はそのー
えー
月三月に
えーっとーＭＥモデルを使ってたんですけどこれはそのえー六モデル四ＳＶＭに近いデーターは勿論のであの全く同じような
形なんですけど
番目に
のえーと同じような仮説
でただそのー一家の納豆をえそのー
確率をするする訳じゃないのにえーその辺をえー標準数もいる関数でＳＶＭスコアを
確率にえーっとあのしてます
はい
えと以上あのー
んえ用いた
えーモデルの説明後の説明です
え評価実験なんですけど
あのー
ま自然会話のデーター
生徒に対するモデルの比較を行ないますと
例といったデーターかって言うとその二者の対話は
医者が
自然な
体の
あえーとフリーとおーしてもらって
まそれを書き起こしたデーターです
今から実家がま二
になってます
なってるんです
ｋとただあのー
一日目と形を取ってその子は入ってないです
で会話の提案すると三十八三十九三のペアで
その発話検証統一さ例えば
っていうのを
まーそのー書き起こし文
程度関連付けされているんですけど
それがまー
二千五百三十リズムとの発話は
制約三日前の生産性に乗ってまー大抵いい
大人ぐらいですか
で語彙数の三千八百三十八で発話ごとの平均五五つのまー三からま五人ぐらいのですねずっとその
風景画です
でえっとー
んでえー素性としては二千二
えー
別の取り方をしたんですけど
すどの単語素性
という部分するんですけど
まそんなあの単語の持ってる中で
表明しました
でもう一つに想定とするに付けを
まこれはえーっとー
発音などの品詞の大部分のおー〇一二表わしてえー更にそれプラスえー単語数と
読みの文字数を想定といったものです
まこちらあのーその先行研究でえー使われてた
えーっとーお単語数とか
まその局所的な
特徴量使ってたっていうやつに
ギター
鳥が違うかと思います
でえーっと各モデル化と創設期Ａって本当クローズバリエーション
でえー評価そのもの東京都データーで評価したもので
そのクロス悪いそのオープンデーターと
しました
でえーっとーこちらは実験結果です思うんデーターに対する各モデルのＳＤ法を表わします
でえーとーははおお母はえーその単語数を推定
えーっと一つは
品質を手で
は全体に
構文データー五分データーではえーっと記述統計情報が良い結果となっても
て
んでそれでえーとー一番良かったのは
別案を構成はあー
そのー
デシベルとマルコフモデルを
組み合わせと
もので
でえーっとー
近似素性ではえー水というのは
最良の結果を示しますと
でこちらはこのデーターに対する各モデルの位置なんですけど
えっとー
ま当然えーんんながらの縦軸いうのはこれがえー違うんですけど
元のデーターのみでだいぶ良くなってます
えー
んーそんなに沿っ
品質音声だとそれことはないんですけども
最も強く終わり
変わっている
ことをあのーん
えこちらもえー先程と同様にえーっとおーすえー単語素性だと
えー
そのＳＶＭとマルコフモデル組み合わせたモデルを最良の結果を示していて
えー品詞の素性は
ベースへの最良の結果を示しますと
二えーっとまー祖先による結果をしない
についてなんですけど
五分データーで
えーっとそれでえー単語セット水よりもう品質音声の悪い結果を示しますと
で
えっとーまだこれ何でかって言うとま二三数多く納豆をする学習データーとテストデーター毎年入院したデーターっていうのは
ま現われにくい
凄い表現良くない豊かな例文もそういう類似したデーターは悪くなるので
その分はえー年に祖先のようにえーと少ない人生えー表現しているものは
プラスの
学習データーテストデーターと類似性が高いので
ん結果も良くのえ良くなるのかなと
思いますはい
でえーっとおー
月にクローズデーターですけどえー
ま単語数で
単語を統制した方がその品詞と品詞を統制した
のに比べて
またええー
五分データーの実験の結果は大きく向上しますと
でこれはなぜかって言うと
まそのグループであればうまく推定だと
テストデーターがま全く一緒なのでま類似していると
ので
えまず一
逆にあるんですけど
えーまこの二つ
えーかなり良い結果間って言うと私データーの値になっ兄そのおー
で生データーとテストデーターをあのー竿をね後はできればの結果をする構造的に出会えたと
その得られます
まるでまーそのその音のデーターしか学習データーがない場合は組織別に有効で小規模な
素性を選択同じようになっていてえー
ですけど
ま二大量のデーターの場合はその単語ように
最近は素性を使った高校に有効なのか
思います
で後そのー
えー提示されえーその前向き確率を用いえー
という話をしたんですけど
えー
んまーえーっとーお節五分データー等おーまえーキー確率を用いた方がま全体いいいい結果まー
若干の二十結果になってますと
でこれがえーっとーそのＳＥＭと
システムのマルコフモデル
もう一カップ一
の結果の例なんですけど
まこれが正解ラベルを用いっていうのはその発話の
言語上統一さ
発話の
そしてえーラベル付けされてるもので
まー
これは各モデルを推定結果と音素の発話検証等の
確率を表わしてるものでえーま〇．五超えたら
四十二ラベルが二られるんですよ
えー
後もう一次の三番目なんですけど
で続いには〇．八三四
消えてこう
高い確率Ｓの発話権の続投
多いと済ませ覚えてい推定してるんですけど
そのー
毎年一つ一用いない場合は
まー
ん二．四ぐらいで
まーんー五月一と判別しちゃってえーっと
あるんですけど
その前の駅確率を用いえっとー
えーっとー
まその
すすえーえーともう片方の
状態からの確率えーとー
え実用があーパッケージの何とか
ただしえー正しく推定できます見てますというような
結果です
でえーっとーまークローズデーターだと
のんえーとまえーと結果
用いた方が
絶対に
はえーい
いけない傾向もあったんで
そのー本来
えーっとそのモデルの信頼性が低い場合に
まー
自分あのー
考えるので
でまとめです
でえーっとーのえー本稿ではえー
発話検証統一さ発話の推定についてえモデルや水を比較しますと
元モデルとしてはその五分データーに関してはＳＶＭとマルコフモデル組み合わせたモデルな最良の結果をを得られて
えまえ確率も仕事でえーコンピューターが解消されたと言えます
えークローズデーターは
そのＳＶＭのあーそれらの結果となりますと
えーと前に関してはこの
その中生徒の場合はスイスに行こうでしょうけどまー素性の選択の重要でえー大量の学習データーの場合は
得たモデルの
最後の素性が有効のおー
考えますと
以上です
正常ありがとうございました
