はいえーそれでは
え単語組み合わせ素性を用いたベクトル空間法による音声ドキュメント検索というタイトルで
で同じです拡大学的な御発表いたします
で
もうもう既に何でも発表があるので今さなんですが近年の情報つ下の発展により利用可能なマルチメディアのコンテンツというものが掛かって言とかしているんですけれども
これらのコンテンツには入れ部屋たいと理解のメタデーター色が少なく
従来のテキストベースの検索技術だけで目的のコンテンツを見つけ出すということを習っています
でそんな中で音声が出メントと呼ばれる人の発話のコンテンツについてはえ音声認識の奇麗と思っていることでえーその言語情報を利用した検索が可能になっています
えしかし
え音声認識誤りや未知語といった問題があり誤認識に対して頑健なえー音声ドキュメント検索手法の開発が一つ四つ出ています
ん実要は全体に対する検索例が大きく事例には書いて今
え一つは英語全然最初に発表がありました音声検索語圏
えー既に
でこれはえー
フィルターに与えられた検索語がえーっとドキュメントどこに現われの各閾値を見つけてくれタスクになります
えもう一つはえ音声ないよう検索でし八例で
えユーザーにあか与えられ質問文に関連する文章を見つけてくれっていう内容検索タスクになります
え本研究ではこちらの音声内容検索に焦点を張っています
んでえー従来のえ四等の手法というのは
で一般的な音声認識結果に対してそのままテキストベースの検索手法を適用しております
えしかしえ音声認識の結果ですまー誤りを含んでいる為
これをそのまま文書検索者の手掛かりとしてい利用するというのはえ
確実なものになっています
えそこで本研究では
このような不可欠な手掛かりに対して頑健な働いてえー検索モデルの提案っていうことで
えベクトル空間法の拡張モデルの提案を行ないます
でこれは
えと単語同士の共起情報を用いるという風になっています
んえーほ本発表はこのような流れで発表を行なっていきます
その後え基本的な従来のＳ痩せ方についてです
でえー基本的な支配手法ではこのようなシステムになっています
今全種類として音声理解に対してえー音声認識を行ないこれをテキストに変換します
そして
でそこに現われる単語の頻度情報などを用いて索引付けを行ないます
で次に
すま文が与えられと形態素解析など行って
で
単語集合へ変換します
そして事前に作成した単語索引
後
参照してえ質問文と文書との間の関連度を計算して最適な回答をしてる
量になっています
とこでお金の計算にはえベクトル空間法などが広く用いられています
じゃ結婚はえー一般的な手法であるえー四レシやら
言語ＣＳであるという風に向上しますが
この手話には
に認識を誤った後や未知語が単語作為に現われないという問題があります
一般に
あのーウイルスというのは検索時の有効な手掛かりとなる語なんですけれども
これは未知語となり易い為検索時に利用できずに検索性能の低下を招いてしまいます
また別な政治っていうようなえ
小さな単位では検索が難しい問題もあります
六パーセント
手掛かりとなる単語数が少なくえ
ん二小屋にして雨の影響を作ってしまう為で
あのー
えー支持派ではえ高認識率の下ではえー頑健な検索が可能であるにもさせられているんですけれども
で実際に利用する為には必ずしもこう認識率期待できずやはりえ
ん地名認識や何か一つだけ対策が必要である必ずえーま
後はえー単語を発声しへしあのえ検索例を示します
えっとこのような音声データーに対してまずえー大語彙連続音声にして行って聞き取れた数とかします
そして
で
与えられたクエリーからその帰り表わすキーワードを抽出し
前
このキーワードをえー認識結果が
ポーズをするのですが一方で認識結果に赤で示すような認識誤りがある為に
それぞれの国とでえー意見することができて
えこの文書は正解であるにもかかわらずえ検索できないという問題があります
でこれに対して
えサブバンドのＮグラムを用いた手法というものが提案されています
方では音節内グラムを例に取ってありますと
んで音声に
結果から五音節別に変換します
そしてえ部屋に一位はもうそれぞれ
え
古代例として音節バイグラムですので本日バイグラムえっと変換します
これは実は何とか音節列の間で照合を行なうことで
え認識誤りがあったとしてもこの文章で検索してくることが可能になります
えさて
サッカーのＮグラムを用いればＹには次のような問題があります
え例えばここで困難というようなキーワードが
と考えますとこれは外の世界文書には含まれませんので検索できないことが正しいんですけれども
これも一つ前から三に分解しますと
それぞれの
え音節バイグラムが全く関係ないところで検索することができる為って謝ってこの二つをえー検索して
てしまうっていうことになります
凄く
寒くのＮグラムは単語に比べえーと手掛かりとしてい弱いという問題があります
でそこで
え単語単位としながらたばこも利用したいということで
え単語の検出えー
えー
部屋でえ次のえ四八人取り入れてすこ我々は以前提案しております
まＳＤ水が出は
で
音声データーに対してえー連続音節認識を行なうことでも何な音節列をす徳島
えそして
えー株のキーワードも同様に音節に変換するのですがこの時えそれぞれのえー
えーとっていうことが
たまたまそれの音節に変換します
突然
この音節がえ
認識結果に現われるかどうかテストを行ないますがこの時に一ＴＤを行なうことで
で認識結果に誤りがあってもえーこの誤りを許して検討してくることで
この文章を検出され
検出することができるようになります
で結構何かえー基本的なシステムなんですけれども
後
次にえー提案法である何を組み合わせ素性を用いた検索モデルについて説明していきます
へこんで
またをえー式の誤りに対するえー二つの文について簡単に説明します
の式には
え第一の誤りである人生と第二次の誤りであり利用性というものがあります
日にてのはえ本来出現している語がえ認識結果には出現しないという誤りです
えー
向かって左側がえー正解でしょう
右側にしてからベースになるんですが
で
全体の際にはえー実現している出すというのが認識結果には制限していないえーこれがえー人生の誤り
でもう一つの二四て何て言うのは結果へ反対に本来は四つ原始的なのかえー認識誤りによって認識結果が出現してしまうという誤りです
でこの場合ですと
えー
くらいの文書には
便利できていないダンスという言葉やえ音声というような単語が認識結果に発言してしまってまこれ何二四世の誤りない
ページをＳＤＲの各手法というのはこの人に対処したものになっています
えっとこれは
びっくりっての方がえー
検索対象の文書に出現していなければそのその検索してこれないので
これが対処しようというような
主になっています
え例えばえクエリー拡張であったりっていうのもこの
んえー認知為によって
四年生が終わった一しようというような誤りなえー大学になっています
前に一度二の高いす
方ってのはえあまりありません
んこれはえー全員また関連しなん際にたまたま食中の語が何度も誤って実現するというようなことは
その写真食が考えられる為です
んー
仮にえーん
幾つかの単語が誤って
出てきてしまったとしても関連度を計算する時点でこのような文章とかされえー関連度が低くなる為え検索ん
時があっていては少ないと考えられま
三つだけ我々は気がする二四八文は
え次会を行なう為訳だしあんまりがえー
非常に一緒えー多くて生じてしまいます
違ってえ二話やり方に比べてえ行政が増加すると考えられます
えそこでえこの二音声に対する積極的な対処
テーマ必要となります
でここでで
このような学院についてえー実示す三つの文とか
検索されていたと考えます
パーティーえ一番上の図は正解なんですけれども
した二つの文章はえ音声認識誤りによってたまたまえ誤って検索されてきたようなモデルになります
これについて考えますと
えー
私の一番上の二つについて考えるとブラウスとかまあのゆ
っていう単語や二万マイルと言うと温泉また温泉などというこ
単語はえ電気的にも関連しているようなえー単語であると考えます
で同様に
え下の図ですと分布とマルコフモデルやっぱり連続だったマルコフモデルなどというのもえこれが関連している語であ
雑音の影響や雑音誤りっていう
の同様に関連していると考えられます
てしまって
え講演あんまりによってたまたま説明している何推論えーしたんでいると温泉という単語はその他の単語ですね安くマルコフモデルやらしの分布などというのはあまり関連はないと考えられますし
え雑音と音声音声の誤りというのもこれ同様に関連はないと考えられます
んそこで
このようにです前の方はえー
ただ関連しており同時に出現し易いような語である
便利な人なえっとー
そのそうにないような単語は認識誤りにはない
と考えられますそこに
このような単語の共起情報は類似度を計算に用いるということを考えます
提示さに行けなくすえっとこれはえ二だけではなく
二重についでも言いますので
えーこの辺前の単語の共起について考えます
え例えば後でよらずと音声について
で
見ますと一番側フランス温泉が共起していますが実それでえー下の文章は共起していないので
これも
えこのような関連が薄いのではないと考えられます
えこれを測定に用いり
波の定式化はこのようになります
今
えー
一般的な手法を用いて
で
食い違いのキーワードについてな文章で嬉しいなとこの文書ベクトルを作成します
この二個のベクトルを元に
えそれぞれの検索語
んが
え
その文書に共起しているかどうかという〇一の共起情報のベクトルを作成し
これらを連結して一つの文書ベクトルとして検索を行なってい
もうこれえ提案の検索モデルになります
銀座をえー今説明します本提案
モデルを用いて評価実験を行ないました
このえー
評価実験の目的はこの語語の共起を用いて検索モデルの効果を調べることをです
以下画像として
え四階に基づくえ一般的なベクトル空間モデル
後はえー
提案法であれえ
一外言と語の表記を用いたベクトル空間モデルを実装してえー実験を行ないました
え評価の
最初は
んえ我々が提案していますＳＤえ試合の湧き出し誤りに対してどのような効果があるかということと
えこのモデルはえー一般的なしえ試合に対しても効果があるのかという
で二点で
えテストセットにはえ日本語話し言葉コーパスを対象としたえ四やりな評価用テストコレクションを用いました
でこれは
え自発発話の講演音声二千七百に講演を対象としています
で
で
検索対象の認識結果には
え一方認識モデルがえー検索対象にマッチしているものと
テーマしていないものという二種類を思っていました
今までの五年
え単語正解率が七十八日間
あー松戸では五十五．五パーセントということでま常モデルの方達というものになっています
え検索悔いはえーえ伝える
ないんだドライな三十九くれるとこまで何八十六位の検索に言語クエリーで評価しています
この日もえ全てのクエリーやり方でクエリーと
ピッチ情報のみで構成されるあいむいて
え未知語を含むような五分に的に分けてそれぞれ評価を行ないました
そこで
えまそこ端末についてはそれぞれの語彙辞書が異なっているので出会いって言ってい大語彙クエリーの
え分布はえ分類が異なっています
んー
え評価すぐにはま二というえー正解文書が検出された時点に適合率の平均値こちらの式で表わされるものを持ってます
で実際に自動詞は一点目の
で表にまとめたものがこちらになります
え四四等については単語作品を用いたものと本日バイグラム索引を持っていたもの
実装しえ
電話ＳＤとして
で
音節バイグラム索引と連続ＤＰマッチングの併用地とおー思っていました
でまた
え四つ四か月五二四ある訳得意な部分に八年不得意な部分がえそれぞれ相互的な関係にあるとか並んで
これらは線形に結合したえー
ものもえー実装しました
ほぼ線形い一語はこちらのパラメえー式で求められます
後ででぱっと出たら線形結合のパラメーターとなっており
ある単語
するというのは
えー
え家寿司屋の是正ということをえβを大きくするということは一語への道を絶するような
値になっています
まずえー
講演検索タスクについて
で
単語の状況を用いて案を載せの調査しました
んこちら月に対する実験結果です
んえー確信してねでえ
単純に生き甲斐に思っていたで従来法よりも語の共起を用いたことではそれぞれ検索性能が改善しました
えうちえ試合ではえーっとクエリーで二十五．四パーセントの改善えー一二四八例では一五．五パーセントの改善が見られました
こちらは
て
一認識率の低いあー松戸に対するものです
父も同様に
で
二世の改善は見られたんですけれどもえまそれに比べるとえー改善率は低く
良いものとなっていました
ただし
で
四四文とＳＴＤＳやるのって言わせ方ではえ多くいて二〇一で正解線が見られます
で次に
て公園
本当膨らんでえーい
より小さな単位であるえー
メールを検索性能の調査ということで二十二十一検索のえー評価実験を行ないました
文に近くっていうのは
結果講演を先頭から二四五発話の固定化びっくり
それを一文章としたものです
そして千回二点についてですが
で
このような形で正解は政治家
でま
で分割高くなる前に対してこのような世界パセリが与えられた時には
で
その世界が政治を
の一部でも
そのような考えて公園があー
文章が正解であるということで
この場合ですとかに
二三四二個が世界の餌という風に判定します
えこちら月に対する実験結果です
えー
二十麻酔科においてもえー
提案法は従来法に比べて性能の改善が得られました
特にえー四四八名でえー二十四パーセントの改善
で次にえ知られて二十七パーセントの改善
で認識率の低い文においても人様に改善が見られましたえー
ただし
で公園検索と同様にえーこちらの方が改善率は小さいとなっています
ここでえー声を検索タスクと二十パーセント程度だったと
の回転率を比較しますとでこの検索タスクに比べ二十パーセントで高さの方がえー海
改善率が良いという結果が出ました
でここにえー適応型を判定の単位を考えますと
えーこの検査音な時の判定を一一二えそれぞれの語が共起するかどうかって判定を行なっていました
これはつまり
声で幾ば
で
一公演が平均え
約二百九十発話となっていますので
別かなり大きい範囲で競技を見ていることになります
一方でんえ奇麗な政治家だったとえタスクはえ二十五発話
んー
一個発話で小さい範囲でえ
共起関係ということで
えーそこでえっと全体言語の表現を判定行なうのはみんなが一つにおいては不適当ではないかということで
でどの程度の
えー範囲でこの競技を見るのが適切であるか後公園検索タスクでえ調べました
ん検索の二つでま一対一や例のみを用いて検索対象は松戸で
でこちらがえー実験結果になります
株の後共起関係を行なわない
つまり従来こう
となり
で
んで
ちゃというのは講演全体をえー対象としたないなって今
勉強気のない語
えー
帰ることでえー背中のＬＳＩでもえー
全く持ち得ない従来法に比べると性能が改善しています
後で
で
え次の閾値を小さくえー厳密にするようなものについては
え
であ共起回転単位のおー
た場合に良いえー改善が見られ一方で
え
ＳＤの閾値を大きく誤り湧き出し誤りが多くなるような形については
小さな単位で共起関係を行なう方がえ性能が改善するということが見られました
え次に
えーこのえー次の閾値を変えた場合にこの湧き出し誤りがえＳＤな閾値を書いて湧き出し誤りを変化させた場合の
この提案法の効果について二十パーセント検索タスクに
でえ性能評価を行ないました
でこちらが
て
結果になります横軸がいい二の閾値縦軸がえ寿司屋の性能です
で
それで解決には変化はあるんですけれども
いずれの場合もえー提案
方の影響を気を持っていることで性能の改善が得られました
でまとめですえー今回ベクトル空間を拡張した新しい検索モデルを提案しました
この前はえー単語の共起情報思ってること
三つに分け確実な手掛かり音をするようなモデルになっています
この
え実験
からえー典型的な一やり方
またえ次に面しやり方共に検索性能の改善が見られました
え以上で発表終わります
