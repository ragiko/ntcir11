えーと日本大学の何度です表記のタイトルで発表します
んー
えーっと研究の背景なんですがまー気にえーっとーまーこの
一回の音節なんですがま恩恵音声ドキュメント検索ってのはまー盛んにやられてる
でま公園とか行為などを持っ検索対象として
まそれを検索するということをんがやられて
でま音声だけネットワークグループというのに私も所属してましてえーとそこで
えま色々タスクも作ってるというな状況
で一機能の
間の先生のおー話にありましたけども
不満のＮＴＣＩＲとかそんなところではまー言語の音声ドキュメント
検索というのが行なわれてる
えーＴＤとかでは
ま世界
ミヤブラウザーというのを使ってまして
えーと多言語の静的面倒検索ということをまー何かやろうとしてくるというような状況にあり
いい時のあの話でもありました通りまた言語を対象とする場合は
まあのークエリーを翻訳するとか
検索対象の精度を検討応援するというような丸四五つのあるというな話なんですが
まやっぱり検索語
検索した後にまそれを見た時に分かり易いというような観点から考えますと
ま検索対象
ま翻訳しておくことが望ましいということがあると思い
でえーっとまー検索対象の程度決めるとま翻訳しようとする訳なんですがま大体においてまそういう音声ドキュメントは
後方性の高い部分です
でそういう先生の高い文に対して
現在の機械翻訳ってのは
ま結構難しいというような
感じです
え四で一方自然性は低い文書に対しては
ま比較的容易な
翻訳んができるというような状況がありますこれはどういうことかと言いますと
ま二重性の高い文というのはまー
実音声ドキュメントの書き起こしみたいなものでして
で二重性の低い文ていうのはここでは
ま直訳調の文章ということを想定している
で実際の例なんですが
まーあのー毎朝犬の散歩に来ますというような
文章用翻訳しますと
第四五相談を
お婆時計貧乏人とかいう
ちょっと変ないようになり
で一方町で性の低い日本語私には朝私の犬の散歩が一つもあります
んーこんな風な
えーっと文章にしてやると
まー英語にしてあるとはえ用例坂が多くお前とかビザモーニングということで
ま結構うまく翻訳ができるいうことがあります
そういう訳でえーっとーこの
ほい焼く前に
変換細い編集と言うんですがそしてあることが重要度
いうことでここでは
私え性の高い文を
ま二重性の低い音契約書の文章に変換してあるということを考えます
つでえーとその機械翻訳の前二つの問題なんですがま色々まいやられてますが基本的には
前編集をどう行なうかってことを
まモデル化しないといけないんー
でえーっとまー今までの研究ではまそれは
後でやってる訳なんですが
で基本的に値を水が自然な文とま直訳調の文
×という方が準備する必要があって
まそれ人手で集めるのは結構すぐ
それから
直訳調の文が集まったとしてももう
最終的な翻訳にとって必ずしも
観光地の文の方が
自然な文よりもうまく翻訳できるという訳ではないですので
まそういうものは
学習データーから覗いてやるということが必要
でその上でまこういうペアのコーパスが集まったとしてもうそこから
まー毎日え規則をですね獲得するってのは
えーやはり大きな問題
という訳で本研究では
えっとー
この
直訳調の文と自然な文の対応っていうのを
まー自動で獲得して
そう思うから毎日え規則もま自動で
獲得しようということが本研究の目的です
えー
でえーとまー実際にやっと型で聞いた翻訳の枠組みを用いてえ前えー使用することを考えます
でまー統計的しか親がま音声認識で同じ枠組みでしてえーま原言語
えー単語列例数与えられた時に
まそれを最もよく説明する単語列Ｔ易い
おー求める問題としてまこんな式を変形してって言ってるこの式を求める
んで
えーっとこの
確率を与えるモデルは変換モデル
でして
こちら確率与えるものモデルは言語モデルになっ
いうことです
で毎日一を考えた場合には
このＳの方に自然な文の文字列を
でこちらの二の方にま直訳調の文の文字列ということにしてやって
まこっからこう声が聞かれてやればいいというような問題になります
道をちょっとあえーやはり毎日があって困りますのでここでは一応このｐｔを与えて言語モデルを直訳調の言語モデル
とー
呼びます
でこれ食べアクションテキストで学習します
でこちらのえーっとＰのＳＴという
ま返還確率与えるモデルを前にして変化モデルと呼ぶことにします
でえっと学習データーをまー自動で獲得する
獲得のし方についてお話
で今回は
毎日翻訳を対象として実験をすること
にしました
という訳で日本語文の前研修を行ないます
えー学習データーの獲得なんですが今日本語文と
日本語ちゃう訳文がいるんですがまそれは日英対訳コーパスを利用して
日本語文と
ま対訳例文をＭＤ翻訳した日本語直訳
とーす今
後分かりにくいので図で説明しますと
ま日英対訳コーパスがあってまそん中には
えーとたくさんの対訳ペアがある
いうことです
でそっからえーっとウェブの方
毎日機械翻訳に掛けてやって
まこれ色んな本焼きがあると思うので色々
栗
で一方まこちらそんまー持ってきて
でこちらはまー自然な日本語
こちらは直訳調の日本語文と仮定しまして
まこれこのペアを自然な文と直訳調の文の提案
てやるということをします
んでえーっとまーこのこん中で全部は使える訳ではないので概要ですと選択するんですが
活動しますどうするかと言いますと
えーと毎回ま最終的にはあの英語にしてい言い方を選びたい部分で毎日えー機械翻訳機にもう一度掛けます
そうしましてえーまこちらも全部掛けて
んで
これとこれを比較して前編成しない場合のえー母音より
まこっちの方が潰れていった場合には
二十四
歳
んでまーそのえーっとん何が優れているかというのは
もっともっとこれは
この
対訳コーパスのえー文から付けましたので
これを持ってきて
でこいつとの距離を
ま何らかの尺度でえー
計ってやって
こう一により近いやつを残してやるいうことをし
でま残った五文がありますからこれを生み出した
えっと元の
直訳調の日本語文のみを残してやると
いうことをします
でそうすると
過去の日本語文を前編集でこちらえー書いてやって翻訳するとまこれよりは良くなるということが創作
ということになっ
つまりこれをこう書き替えてこういう翻訳してあると
直接翻訳するより良くなっいうことですので
このペアを
学習データーとして
もう何か
学習データーの使用に追加するということででこれを
まーコーパス中の日本語程度の対
えーっと色んな対訳
文提案に対してやり
今こうやってやるとま色んな部屋が集まるんですが
でえーもう一度二おさらいしますと
九枚平成変化モデルは
この対訳提案しようから学習します
でこちらな言語モデルの方は
こちらの
直訳調の文から学習し
でえーっと実験なんですがまず学習データーの自動獲得をしました
で実験データーの板のえー二つ対訳コーパス三万一千五百八十文釣りを使います
でここはえーっとー色んな
二日後約一は使えるんですが今回は一個にしました
結婚など
最後にえっともっと前文との
距離四
掛かるんですがその類似尺度は二つと通します
で結局
また約八音を決定文の方は
二日翻訳四．一え翻訳して
でこの
日本語音の方はえー文に翻訳して
でこれ共に一スコアを計算して
文字こっちが違っていれば
これとこれのペアを学習データーに使うということをします
でえーっとこのペアってのが三万一千五百八十文についやって
実験これとこれの部屋が使えたというのが
五万九千五百九十六
いうことで
ま九十四パーセントが
ま高齢をこう書き替えてやると
いーえ文になるということが分かります
つまり前平成
でまーま殆どの
ま日英対訳コーパスのデーターが
毎日絵に使えるということがまーこのデーターに対してはえー
行ないます
で実際にえーと学習
データーが集まりましたのでま前編集システムでのあちょっと少ないんですけども統計モデルを学習し
でデコーダーはもうぜー
数を使いましてまえー因子モデルは銀座で学習しました
でえーとフレーズトランスでしたモデルを使います
んで直訳調言語モデルはえーあれＳＤへ電話する
後で学習した
えーと五グラムを使いますとま大体専門家ででは魚とかあなたが救われることが多いみたいです
で変化概要は今回はえーっと単語と文節をえー使用します
で今回日本語日本語の変数変換ですので
ま付属語のみの変換というのはまー
何かこうもう動詞に対する各格はまー
へん化してしまう可能性があってまそういう変化は考えにくいですので
ま文節単位であるということも考えます
まー実際にはフレーズトランス依存モデル使ってますのでえーま単語単位に変化してると言っても
ま一部はフレーズなってるというような感じです
でえーっと実際に結果なんですがこちらが文節単位にやった結果でこちらが単語たえーやったきっかけ
んでまず
えーとクローズデーターの評価なんですが
あまり新鮮な水の場合ですと
まんま決して悪い
タスククローズデーター全部に対しやった結果
えーっとまー明らかに
文節単位でも単語単位でも
まよくなってるということが分かり
でま枠組みとしてはま正しく機能するということが分かりました
二階でした文の割合はこちらのまある六十七パーセントぐらい
いうことで
ま文節の方がクローズドデーターに対してはいいという感じで
で一方まーオープン正当なんですがま平均で見ると結局改善は見られますです
んでまーよく見てみると返した文の割合ってのは大体同じぐらい
あるというような結果になります
でまー平均の精度で見ると
んまーオープンあの分節単位でやった方がいいんですが
破壊です多分という単位で見ると
って言い単語単位にやった方がいいと良い結果でま今回は文節と単語どっちがいいかということは
ちょっとあのー判断は
付いてます
ただ
まーあのー
クローズドデーターの
開店のし方とかを見ると
まー文節単位ってのはかなり
えーっとー学習データーに依存してるのではないかと
いうような
缶詰め
んでま全体的に学習ぶ
データー不足してまして
ま特に文節単位は
なかなか学習してるんじゃないかなということがま考え一
でまー実際にえーっと単語と音節の他あのー
統計量なんですがまな
単語の場合は
ん延べ単語数はま大体一名が単語で異なり語数は
ちょっと二十二型ぐらいなんですけど
文節の場合は
斜め文節数は
苦なくっていうことなり分節が多い明らかに送っている
殆ど出てこない一回ぐらいしか出てこない文節ばかり
ですので
まーマリちゃんついでに弾けないなというのはまーそれでも意外とオープンデーターには多いというな状態
でそれからえっとー
機械翻訳のデコーダーというのはまーパラメーター値人数ができまして
まそれも木の付いてましたんで使いました
で実際に何やったかって言うとま直訳調の日本語文を参照役として
毎日ような日本語文のブルースコアを最大化
ま書いてますけども
結局まい編集した後の日本語文があっ直訳調の日本語文
に近くなるように中デコーディングのパラメーターを
二十合成します
いうことで
で開発えっと二百文に対して
まやったところ
ま少し良くなります
んでえーオープンデーターに対してもま同じような結果で
ほんの少し良くなったんですが結局やっぱり
前編成しなかった場合に比べて
の改善は
六月と言うか
得られますんです
で町に都があるんですが実際にはまー
えーっとまえー
日本語母音お前編集して直訳調にするように知覚してませんので
最終目的や日英翻訳ですので
毎日翻訳が良くなるようにまーこれも睡眠ですてればいいかなと
いうようなことは考ええー
でえーっと実際にどんなあのー学校が見られたかという例なんですがえーっと
例えば道は偏りスタートを苦心し
大半の人率がこの一の高い子付近でしてたというような
ま携帯のやつなんですけどまい編集してやると
まどうはより高く開きました
登り続けていて殆どの契約は一日後また彼の近くで結ばれました
ま大体三家に切るんですが
で後例文にしてみますと
まー明らかにこっちの方が
点もありいー英語になってるんですがまこれで意味が通じるかどうか差別問題なんですが
こっちやよりはかなりいー
良い文になってる
思われる
特にを終わりの方が
結構
分かり易くなってるような気がします
えーっともう一つは何かこんな一つで
四人の国えー
んどうこうしたこのでる娘さんの生命によると
何とか二という数がやっぱりこれも
何かこんな風に変換できまして
何かこの辺に
によると側ではあーになってまして
上位に下がまサインしましたぐらいになってるんですけど
もうこれぐらいにもう
だいぶ違いまして
まこちら講演雑誌理由は場面となん
こうパブリックここれ子音とか
ちょっとよく分からないで出しなんですが
こちらのまで出すから結構分かり易くなっていて
ま特に終わりの方の文数を
間違えではなくてま多分
日本でもある状態になって
んで一方うまくよいかなかった例なんですけど
ま何かこんな文章ですが
となっなぜかこうプロジェクトは終了二千年全反応を計画してますというような
ちょっと変な
日本語になってしまいまして
まこんな風に
現代日本語は勿論現代英語に
なってしまうというような感じです
まこれは何か
多分学習データーに一体引きずられたんだと思い
え以上で数がえーとまとめますと日え翻訳における統計的前編集をします
で学習データーを自動獲得して
毎日対訳コーパスからほぼ同サイズの学習データーを自動獲得可能であるということが
分かります
て翻訳対話
んま文節単語についてはっつってこう
分からなかったんですが
まーあのー
レベルコメントセットでえーっとこれに
クローズドな実験見る限りはあーデーターが多ければ行なうのかなというようなえーそうで
二年四十パーセント程度の分類
えーっと
英語の品質が向上したんですが
ま平均的には一項では見られませんでした
でまードキュメント検索の為の翻訳としては
まーい編集があった場合とない場合の翻訳文から
ま利用法から
えー索引語など作ってやればいいということも考えられますのでま半分ぐらい
よくなってるということでえーま要素によっては利用可能な精度ではないかと
いう風なことは
見えますがままやってみねとかいうこと
て今後の課題は
んーまとっ毎日の学習データーをま複数のＭＤシステムなど使ってですね
増やしてやるま実際もっと
日英コーパス持ってくれは
人ですがまそこで
そいから
えーっとまえー編集でデコーダーを
ま最終的内容が良くなるようにパラメーターついに
でやればいいかなっていうことを考えています
発表は以上です
