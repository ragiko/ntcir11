それでは講義音声認識のためのＬＳＡを利用した語彙推定手法の検討ということで
山梨大学工学部コンピュータメディア工学科
が発表させていただきます。
まず最初にちょっと原稿の
方で訂正がございまして
四．二節のＬＳＡによる語彙推定という節なんですが、八十七ページですね。
こちらに手法の説明が三つ載せてあるんですけれども
手法一ＬＳＡで手法二音素情報というふうに書いてあると思うんですが、そこが
正確には
逆でして、手法一の方が音素情報を用いた場合で
手法二がＬＳＡというふうに
なっております。
この場を借りてお詫び申し上げます。
すいませんでした。
では内容の方に移りたいと思います。
発表内容としては
まず研究の背景と目的について
次に概要説明をさせていただきます。
実際の研究内容としては
ウェブを用いた話題適応化ということを行いまして、その後
語彙推定を行う。
そしてまとめと
今後の課題
というふうに
なっております。
まず背景と目的、研究概要について、説明したいと思います。
背景と目的についてですが、近年ですね音声認識技術というのが発達してきていまして
ニュースだとかそういった朗読音声、については高性能な認識が
できるようになってきていまして自動字幕付与
といったものなどにも利用されていると思うんですけども
最近では
それらの
ものというものを講義、講演、会議発話といったそういう話し言葉についても
応用させていこうということで、そういったものの議事録自動生成
といったものが行われていると思うんですけれども
まだまだ朗読音声と比べると
高精度な認識ができていないという
話し言葉の音声認識はまだ難しいといったことが
あると思います。
その話し言葉の音声認識が難しい理由としては
ここに書いてあるこの言い淀み、言い直し、フィラーなどが多い
そして言語の文法誤りが多い
そしてまた専門的な単語、言い回しが存在する
といったことが、挙げられると思います。
そこで本研究としては
その中でも講義、講演等の音声認識性能の向上を目指していく訳ですけれども
実際にはこの
専門的な単語、言い回しというものに注目しまして講義、講演で使われる語彙を獲得する
また不要な語彙を削除するということで音声認識性能を
改善していこうと思います。
一般的には認識で使う語彙が多ければ多いほど
認識率は良くなるということが言えると思うんですけども
本研究ではそこからさらに
適切な語彙のみに絞り込んで
認識率を改善すると
同じ未知語率、テストセットパープレキシティならば
語彙数が少ない方が認識率が高いというのは
当たり前というか自明であるというふうに思いますので
まずは語彙を獲得し、そこからいらないものを削除する
といったことを行って認識率の改善を行っていきます。
研
究概要についてはまずウェブを用いた話題適応化、ということを行って、まずは
そもそもの語彙を獲得し未知語率を改善していきます。
その後語彙推定ということを行って
語彙の絞り込みを行うんですが、まず始めに
語彙推定の中でどれくらいまで改善されるのかといったことを調べ
その後自動化を行っていくんですが、自動化については
ＬＳＡを用いた手法
音素情報を用いた手法という二つの方法で
不要な語彙の削除を行っていきます。
この話題適応化と音素情報については
昨年度ですね、第二回音声ドキュメント処理ワークショップで
発表されたらの手法を
今回用いております。
次に
ウェブを用いた話題適応化について説明させていただきます。
こちらが話題適応化の概要図となっております。
まずＣＳＪですね。日本語話し言葉コーパス
といったものを用いて基本言語モデル
といったものを作成します。
この基本、言語モデルを用いて一度認識対象の講義音声を音声認識かけます。
その結果を一度仮認識結果、というふうにおいておきます。
この仮認識結果からキーワード抽出ということを行って、そのキーワードを用いてウェブ検索を行います。
そこで集めたウェブ文書集合を用いて再度言語モデルを学習させると
その学習させた適応化言語モデルを用いてもう一度音声認識を行うといった流れになっております。
この中でですね、まずはキーワード抽出とウェブ検索というものについて
お話ししたいと思います。
ウェブ検索用のキーワードなんですけれども、こちらは講義名と認識結果から、抽出、いたします。
まず講義名については講義名の名詞を利用します。
講義名の名詞を用いる理由なんですけれども
講義名というのは話している内容をまず端的に表しているものだ
ということが言えると思いますので
まずはおおよその話題特定のために講義名の名詞というものを用います。
そして認識結果からは今回名詞ｂｉｇｒａｍというものを利用します。
こちらは仮認識結果から抽出した
二個組の名詞
となっております。
例で言うとこの状態
遷移という単語が続いて出てきてた場合にそれらを足し合わせて状態遷移という一つの単語にします。
こうすることで
単語単体で用いるよりもよりもより内容が絞り込めるのではないかと思います。
この名詞ｂｉｇｒａｍの採用方法なんですけれども
それぞれですね、出現回数を数えていきまして
最大頻度のものを分母にとりまして、それぞれの単語が
まず
いくつか
分子にとってどれぐらいの割合かっていうものを計算しまして
その際、今回〇．三以上というものを
検索ワードに用いるというふうになります。これで言うと
この決定性というところまでが
今回検索ワードで用いるものというふうに
なります。
ウェブ検索の方法なんですけれども
こちらにはヤフー検索ウェブＡＰＩというものを利用させていただきました。
検索方法はそれぞれのキーワード集合
先程の方法で抽出したキーワード集合があるんですけれども
そちらからまず一つ一つの単語で
検索をかけます。
その際にヒットした上位二百ページ
というものをウェブ文書集合に追加していきます。
全てのキーワードで
収集したウェブ文書を用いて適応化させるんですけれども
その際にＰＤＦとかパワーポイント形式のデータがあればテキストデータへ変換しまして
ＨＴＭＬタグ等を除去しますと
そして収集した生成した学習データを用いて
適応化を行います。
適応化の方法についてなんですが
こちらはまずそれぞれのですね
学習テキストＣＳＪの学習テキストとウェブテキスト集合からＮグラム頻度
というものを求めまして
そこから重み付きで足し合わせて
重み付き混合Ｎグラムの頻度というものを
利用します。
ここからですね、さらに
それぞれの
テキストから語彙を集めまして、その語彙と先程作った
Ｎグラムの頻度
を
言語モデルを作るということなんですけれども
ＣＳＪについては上位の
二十ｋ二万単語、を用いています。
一応ウェブ集合については
全語彙を用いるということになっております。今回
先行研究のそのらの手法で
ここの足し合わせが一対一がとりあえず一番良かったという結果が出ていたので、本研究でも一対一というものを用いて
Ｎグラムを作成しております。
この方法で適応化した言語モデルを用いて、適応化のまず結果が上がるかどうかという音声認識実験を
行いました。
実験音声には山梨大学コンピュータメディア工学科
コンピュータサイエンスコースで開講された講義音声、五講義分となっております。
科目についてはこちらの
五つとなっ
ております。
音声認識システムにはＪｕｌｉｕｓのリビジョン四．一
を用いました。
音響モデルはＣＳＪから学習したトライフォンモデルの三十八次元
となっております。
評価項目について一般的に用いられる単語正解率、単語正解精度といったものの他に
今回その語彙を獲得するというのが一つの目的でありますので
名詞正解率というのも用いて
みました。
次に実験結果五つ一つ一つを
見ていきます。
まずこちらが一つ目のオートマトンというものの、オートマトンと言語という講義での
認識結果になります。
こちら見ていただくと分かるかと思うんですが、語彙数が
一万単語以上増えることによって認識率全て改善される結果となりました。
その今回の目的である名詞正解率ってものについては六．三パーセントの改善が見られたと
一応
こちらですね。補正パープレキシティと未知語率についても
大幅な改善が見られたかと
思います。
次の実験結果ですが
こちらも先程と同じように
語彙数が増えることで認識率全てにおいて
改善されたということが
いえると思います。
今回適応化五つの項目において一応全てにおいて
同じようにこちらについてはちょっと
他のと比べると値としては
若干ということなんですが一応全てにおいて
改善される結果となっております。
今回この実験によっ
て話題適応化を行って語彙
が
適切に集めれたということが言えると思います。
そこで次は語彙推定ということについて説明していくんですけれども
その話題適応化ということを行ったことでどのような問題が起こるかというと、語彙数が
増加したということで、言語モデルが複雑化する
ということ
もう一つですね曖昧さが語彙数いっぱいある中から、沢山ある中から一つの単語、正解となる
一つの単語を収集しなければ
選ばなければいけないので、曖昧さが増加した、ということが言えると思います。
そこで適切に語彙を語彙
推定ということを行って
適切に語彙を絞り込むことでこの言語モデルの
複雑化ですとか語彙曖昧さというものを
減らすことができる、のではないか。
そうすればさらなる認識率の改善が
期待できるのではないかといったことになります。
今回行った
語彙推定の
概要なんですけども、さきほどのこの
話題適応化といった手法の中に
ですね、ウェブ文書集合を
集めるところまでは同じでそこから語彙推定処理というものを挟み込んで
言語モデルを学習させるといったことを
行います。
この語彙推定には今回ＬＳＡと後もう一つ音素情報といったものを利用させていただきました。
実際にはこの自動化についての説明をする前に、語彙推定によって認識率が改善されるのかということを
まず手動で行うことで評価をしました。
こちらですね、その先程の適応化した認識辞書から必要な単語だけ
講義中に出現した単語ですね。これは
を手動で選択しまして
言語モデルを再構築し直しまして認識を行った結果になります。
こちらちょっと見にくいかと思うんですが
これが一つ一つの講義単位となっているんですけども
一応全て右肩上がりで
認識率が
改善されているのが見えるかと
思います。
またこの結果から一応その講義に必要な語彙というのが大体数千単語程であるということが
分かるかと
思います。
今回のこの自動化をまず手動で行ったことによって語彙推定自体には
語彙を絞り込むことには効果があるということが
言えるのではないかと思いましたのでここから
自動化ということを行っていきます。
自動化の手法としてまず一つ目ですね。先程のＬＳＡ
潜在意味解析といったものを用います。
こちらは単語文書のクラスタリングに用いられてたり、情報検索の分野でも
用いられていると思うんですけれども、特徴としては意味的に似た単語集合を形成できるという
特徴があると思います。
そういった、このＬＳＡを使うことによって
例えばですね、一つの分類結果ではこういった一般的な単語集合ができたり
こちらの方に専門的な単語集合が
形成されたりといったことが
起こり、ここから適切な単語集合を選べれば
上手く語彙が絞り込めるのではないかといった
試みで
す。はい。
詳しく説明しますと、まず流れとしてはまず単語文書のマトリクス行列を作成いたします。
その後特異値分解、ＳＶＤということを行って行列を分解します。
その際にこのように分類されるかと思うんですけれども
この中で今回は単語のクラスタリングを行うので
この単語についてですね
その特異値のランクＫ今回はちょっと百という
値を利用して
近似を行います。
その際の
近似した単語集合と
元々ある単語集合とその単語ベクトルというものを比較してクラスタリングを行い
分類を行います。このクラスタリングには今回Ｋ−ｍｅａｎｓ法を
利用させて頂きました。その後に
各クラスタリングと認識結果をコサイン尺度で類似度計算を行いまして、その際の
上位三集合というものを今回利用しました。
ちょっと見やすくいきますと、例えばこのような、六つの文書があったときにＬＳＡをかけると
こう
文書と単語で行列ができるんですけれども
その際の重み付けにはよくＴＦＩＤＦが利用されるということで
ＴＦには今回対数化出現頻度を用いまして
ＩＤＦには
エントロピーを利用させて頂きました。
この重み付けで行った
この
単語文書行列に対して
ＬＳＡをかけてその際の単語
空間ですね。
に関してそれぞれ
こちら、ベクトルを
取り出しまして
それぞれのベクトルを比べてクラスタリングを行う
といったことに
なっております。
もう一つですね、自動化の手法としまして今回
音素情報を用いた手法というのも行いました。
こちらは適応化された認識辞書と認識結果とのマッチングで単語を選択するんですが
その際に音素列で、完全一致した単語というものを採用します。
そうすることで誤認識の中でも置換誤りといった場合に対処することができるかと思います。
どういうことか
といいますと例えばこのような
音素列があったとしましてそれを音声認識かけた場合に
こういった単語が認識辞書に正解単語が存在するんですけれども
置換誤りが起きてしまったと
いうことがあると思うんですが
こういった置換誤りがある中でもし
単語としてここから
単語で
マッチングを行ってやった場合に、例えばこの講義とかこういったものっていうのは
正解単語が存在するんですけれども
そういったものを
選ぶことができないということが起こると思うんですが
音素列というものを採用することによって
不要なも一緒にもってきてしまうことはあるんですが正解単語を
取りこぼすということはその
方法を使えばなくなるというふうに
考えまして今回こちらを
用いました。
最終的に先程のＬＳＡと
この音素情報という二つの手法を合わせまして
新たな語彙
というものを形成するんですが
まずウェブ文書集合、ＣＳＪの講演集合というのはそれぞれＬＳＡを行ってクラスタリングを行っ
作成します。
クラスタリングを行います
その中から
必要な語彙集合について
必要な単語集合をですね
選択しまして、選択した単語集合というものを形成します。
プログラミングに関連する話題の講義内容であれば
まずはそのプログラミングに関連する単語集合と
それとは別にその
一般的な話し言葉といった部分の単語集合
というものを選択しまして一つの単語集合を形成します。
それとは別にこの適応化した認識結果ですね。適応化言語モデルを用いた認識結果の単語集合と
その辞書とを比べまして
同じ音素列の
単語というものを選択しまして語彙集合を生成します。
それら二つの、語彙集合を足し合わせることで、新たな推定された語彙集合というものを
生成します。
この語彙集合を用いて
認識
を行うんですが、今回その比較として
三つの手法を用いました。まず一つは
音素情報単体だけでどうなるかといったこと
手法二としまして名詞について今回ＬＳＡはちょと補助的な役割
でしか用いていなくて、ＬＳＡは名詞についてのみ行ってその結果の分類結果の上位三集合
それ以外については話題適応化の時の単語全て、というものですね。
手法三はこのＬＳＡと音素情報の両方とあるんですが
音素情報で収集した単語に対して
ＬＳＡを行った名詞のみを足し合わせるといった
ことになっております。
次に実験結果の方を示して行きます。
こちら一つ目ですね。
手法一が音素情報、手法二がＬＳＡのみ、手法三が両方足し合わせたものとなるんですが
ちょっとＬＳＡについては今回
がくっとちょっと認識率が落ち込んでしまったんですが
この手法一ともう一つですね。両方を足し合わせたものというものについては
適応化、ちょっとこの講義では名詞正解率が〇．一パーセント落ちてしまったのですが、それ以外については
一応改善される結果と
なっております。
パープレキシティにおいてですが、語彙数を絞り込むことによって
手法一、手法二、手法三、手法二の場合ちょっと
認識率自体は落ちてしまったのですが、補正パープレキシティにおいては適応化の段階よりは
良くなったと
ですが未知語率については
語彙を絞り込むのがまだちょっと適切ではなかったため
ちょっと落ち込んでしまうといったことが起こりました。
次の結果ですが、こちらですね。こちらの場合は
認識結果全てにおいて
適応化の段階よりは改善される結果となっております。
また語彙数も大体十分の一程まで減らすことができて
十分の一減らして未知語率というものは
こっちでも悪化してしまっているんですが、それでも認識率がそこまで変わらないということで
語彙推定自体には効果があるということが
言えるのではないかと思います。
こちら三つ目ですね。こちらも
先程と同じようにＬＳＡでは落ち込んではいますが、他のものでは
本当若干ではありますが一応改善はなされていると
こちらが四つ目
となっております。
こちら五つ目ですが、こちらも一応
手法三というものが一番良い結果
ということが言えるかと思います。
その語彙推定、今回行ったこの
手法三
なんですけれども
語彙を大体
大幅に絞り込むことで認識率は若干ながら改善されたんですが
未知語率については適応化の段階よりも悪化してしまったと
ですがパープレキシティにおいては絞り込むことで改善が見られているということも言えると思います。
今回語彙推定を行ってこのような結果なったんですが
今後やるとしたら未知語率についてもうちょっと注意しながら語彙をうまく絞り込むことができれば
認識率の改善が期待できるのではない。もっと
先程出した理想値に近づくような、認識率の改善が
期待できるのではないかと思います。
まとめと今後の課題についてなんですが、まずまとめとしまして
話題適応化では語彙を
まず語彙を獲得するということができまして
認識率の、改善、ができました。
語彙推定においてもそのＬＳＡ音素情報
ＬＳＡは補助的に用いた形になるんですが
そのことで適応化の段階からさらに認識率が
若干ではありますが改善されるということが
できました。
語彙数を絞り込むことでパープレキシティにおいても改善が見られたんですが
未知語率についてはちょっと悪化してしまったと
今回の結果で話題適応化、語彙推定、両方含めることで最大で単語正解率においては五．三パーセント
単語正解精度は七．三パーセント、名詞正解率は十四．二パーセント
改善される
結果となりました。
今後なんですが
まず一つとして未知語率を上げずに語彙を絞り込む方法を検討してい
こうと思います。
こちらで今考えているのは文脈毎に語彙推定を行うといったことなんですけれども
今は講義一つ一つで
一つを単位として語彙推定を行っているんですけれども
やっぱりその講義っていうのは
内容としては一つのものを喋っているんですけれども、やっぱり途中途中雑談が入ったりということが
講演とかと違ってあると思うんですけれども、そういったところで
上手くそのやっぱり
語彙が絞り込むことができないのではないかなということで
そういった話題毎を判断できればその話題に応じて
語彙を選び直すといったことを、行う、ということですね。
また今回ＬＳＡを用いてはいるんですが、利用の仕方が本当に
あの簡単なもの、だったために、そういった中でもクラスタリングの方法ですとか
単語集合の採用方法とかいったものを検討していこうと
思っています。
以上で発表を終わります。ありがとうございます。
