おはようございます
それでは時間になりましたので
二日目の音声ドキュメント処理ワークショップを始めたいと思います
で最初のセッションは検索という
セッション名で
先日昨日の検索一からの引き続いての検索の発表が三件ございます
一件目の発表は豊橋技科大のとが
認識候補から正解テキストへの翻訳モデルに基づく
講演音声ドキュメントのアドホック検索というタイトルで発表致します
はい
まず背景ですけども
このこのスライド
昨日もお見せしましたけども
音声ドキュメント処理というのが
大語彙連続音声認識の高精度化実用化に伴い可能になってきました
でそのために音声データをドキュメントのように扱うことが可能になります
で
そういうそれが可能になるための技術として音声データに対する検索とか要約とか
質問応答とか
従来テキストのための
技術
を音声に対応させると
いう
必要があります
でそこでこの研究は
その技術のうちの検索に焦点を当てて
研究を行ないました
でこの発表ですけどもその音声ドキュメントを対象とした認識誤りとか
ＯＵＴ ＯＦ ＶＯＣＡＢＵＬＡＲＹに
頑健なアドホック検索手法を提案致します
そしてその手法を
ＣＳＪ
テストコレクションと
呼んでいます
評価用テストコレクションで評価実験を行いましたのでそのご報告を
させていただきたいと思います
でまずタイトルにですね
アドホック検索という言葉が使われていますけどもこれは
検索者がですね
自分が欲しい文章を
キーワードとか自然言語とかで
表現しますけども
その検索者が欲しい文書
ですね検索要求に
適合する文書を
を見つけるタスクのことをアドホック検索と
呼びます
ですから
必ずしも
検索質問
に現れる単語
が単語などが完全一致する必要は無いわけですね
その
欲しい
欲しい文書がほんとに引けたかどうかと
それを見つけるというタスクになっています
で
音声の検索
音声の分野で検索といいますと
キーワードが
完全一致している箇所を見つけるとキーワード検索をさすことが
多いわけですけどもここで
対象とする検索はそうではなくて
こっちはこちらのアドホック検索の方を
対象としております
で音声ドキュメントを対象としてアドホック検索をするということは簡単に
やろうと思えば大語彙音声認識を
対象
文書
対象
対象の音声データに対して適応してやって
書き起こしのテキストを作ってやればあとは
テキストの
検索の問題
アドホック検索の問題に帰着されますので
そういう手法が使えるだけれども問題点としましては
書き起こしの際に認識誤りとか
そもそもデコーダに
含まれていないＶＯＣＡＢＵＬＡＲＹ
があると
そのために
書き起こしに認識結果が現れないと
いう可能性がありますそのため検索性能が低下してしまうという問題があります
これに対しましてここでは
音声認識で自動書き起こしたテキストから
本来書き起こされるはずであった正解のテキストを
予測してやってその予測
した
テキストで
文書を索引付けしてやるということで
認識誤り等に対応するという方法提案手法を
提案致します
でその予測には統計的翻訳モデルを単語翻訳モデルというものを利用します
これは
Ｐ（Ｗ｜Ｔ）という形で表されますが
Ｔ認識された単語が与えられた時にそれが本来
何であったかと
その確率ですねそのそういったモデルを使って
単語を予測して索引付けをしてやろうという手法です
イメージとしましては
音声ドキュメントがあった時に
大語彙連続音声認識で書き起こしを起こしますけどもここでは認識誤りが含まれると
でこれに対して
翻訳モデルで
本来
正しい語というのを予測してやると
でいろいろな確率で
いろんな語が
予測されるわけですね
でそれは
確率の大小でいろいろありますけれども
これらの単語
を確率を考慮して
索引付けをしてやることで
認識誤りが起こった場合でも
検索ができるということ
ところを目指しているということです
でその単語翻訳モデルの推定方法ですけれども今回は
音声認識の自動書き起こしテキストと
その正解の書き起こしテキスト対からなるパラレルテキストが存在すると
いう過程のものでそこから推定すると
いうことをやりました
で手法としては
パラレルに存在する分をＤＰマッチング取りまして
アライメントを取ってやると
でアライメントが合致しないところに関しては
数え上げの際に部分的なカウントを与えると
いうことで
カウントを集計して最尤推定で求めるという方法を取りました
で
図で説明しますとこういった
自動書き起こしに対して正解の本来の
書き起こしというものが
与えられる
でアライメントを取りますと
正しいところに関しては一対一で対応しますんでここに関しては
それぞれ一つ一回ずつ
現れたというふうに
カウントすると
で問題は認識誤りを起こしているところでここに関してどうやってアライメントを取るかというところが問題になります
でこの問題に対して
今回はですね
二つの方法を使ったんですけど一つは単純配分法と呼んでますけども
わからないところはそれを等分配してやると
感情に関して三通りの
アライメントの可能性がありますんで
これを
三分の一ずつ
現れたというふうに見なして
カウントに加算してやるという方法です
で
部分的なカウントを
コーパス全体で
集計して最尤推定してやると
でもう一つの方法は引き交差を
考慮してやろうという方法で
今の場合ですねこの部分に関して
交差のアライメントを考えてやると
ご覧のとおりの十通りの可能性があります
でこれらの十通りはそれぞれ等しく
現れたという過程を置いてやると
で例えば感情が
患者にアライメントされると
いう可能性はこの十通りのうちの六通りありますので
カウントを十分の六というふうに
与えてやると
いうことですね
であとは一緒で
コーパス全体で集計して
モデルを推定してやると
という
方法を取りました
でこのようにして求めた単語翻訳確率ですけどもこれを
本来の単語の
ＴＦ
単語頻度ですね単語その文書に現れる
頻度を予測するために利用します
でこれはこちらの式で
期待値ですね
本来現れる単語の
頻度の期待値を計算できますので
このＴＦを使って索引付けをするという方法を取りました
でその時にですねあまり
頻度が低いものに関しては切り捨てて索引付けには
使わないということをやりました
で閾値は
零．一から零．０一まで
いろいろ変えてみて
実験を行なっております
で評価実験ですけれども
テストコレクションとして
情報処理学会のＳＬＰ研究室で今
構築中の
ＣＳＪを対象とした音声ドキュメント検索テストコレクション
と
いうものですねこれを使って評価を行いました
そして
自動書き起こしテキストだけを用いたアドホック検索手法と提案手法の比較を行いました
でまずＣＳＪテストコレクションについて簡単に
ご紹介致します
ＣＳＪテストコレクションはＣＳＪの中の
学会講演と模擬講演で全部で二千七百講演
ありますけれどもそれを対象としたテストコレクション検索のテストコレクションです
で
その時にですね講演を検索する
というタスクではなくて
講演の一部ですね講演の中の
だいたい五発話程度の区間
が
検索の
適合文書適合する箇所と
なるような
検索質問
を
に対するテストコレクションになってます
でそういう検索質問が三十九個ある
で
テストコレクションについて詳しい
ことはこちらの参考文献の方を
ご参照いただければと思います
でだいたい雰囲気を
ご説明致しますと
例えばこういう
質問ですね情報検索性能を評価するにはどのような方法があるか知りたいと
いうような
質問がありましてこれに対して
ＣＳＪ
の書き起こしテキストは発話単位で書き起こしが与えられています
で
この質問に対して
適合文書というのが
講演の一部として与えられているとこちらの
バックが薄くなっているところですねここが
この質問に対する適合であるとこういうタグが
付いているということです
でタスクとしてはこういう箇所を
見つけましょうという検索タスクになっています
で
そういう検索テストコレクションとして著名なものにＴＲＥＣのＳＤＲというものがありますけども今回
そのＣＳＪテストコレクションというのは規模の面ではこれに
相当するような
ものができあがっております
で対象はニュース音声と講演音声でかなり違うんですけども
対象
文書の大きさとしては
だいたい同じようなものになっていると
いうことです
で
このテストコレクションを実験に用いたわけですけれども
検索タスクの設定を
少々
アドホック検索に合致するように変更しました
で
本来は
可変長の区間を見つけるというタスクになっているんですけども
それを
固定長の区間に予め
対象文書の方を区切っておいて
でその固定長の区間を
見つけるという検索タスクに定めました
でこれは講演をですね自動的に上から
機械的に何発話かで
区切ってやると
でその区切った区間を見つける
各検索の文書だと
検索対象の文書だと見なしてその文書を見つけましょうと
いうタスクの設定にしました
でその時の固定区間を今回は十五発話三十発話六十発話の三通りで
調べて評価を行ないました
イメージですけれどもこれがＣＳＪの書き起こし
になります
でこれを先頭から自動的に
例えば十五発話で
区切ってやると
でその一つ一つの区間が検索対象の文書ということになります
でこれに対して本来の正解がタグ付けされてるんですけども
この部分が少しでも
重なってる
区間ですね
それを正解の文書だとみなしまして
その区間を
見つけてやろうと
この文書をみつけてやろうという
検索タスクを設定
したと
いうことです
評価尺度としましては
十一点平均精度というものを使っていますこれは
再現率を零．０から一．０まで十一点
取りましてその各再現率ポイントでの
検索精度を調べてそれを平均したものになっています
この値を検索質問全体で平均を取った
ものが評価尺度になっています
で実際には各検索クエリーで検索システムによって上位千件の検索結果を求めて
この
十一点平均精度を計算しました
で
それで学習データと評価データについてお話します
今回
パラレルテキストが必要ということでパラレルテキストは
実際にＣＳＪテストコレクション
で
正解の書き起こしと正解結果が得られてますのでそれを
学習データにしたいんですけどもそれが今回の
検索の
対象と重なってしまってるわけですねそれをうまく使いたいということで
そこ重ならないように
うまく
調整しましたでそれは交差検定
に
習った方法で索引付けをするという方法で
対応しました
どういうことをやったかというと
対象文書
対象の
文書ですねで検索対象の文書のコレクションを
十個に分けてやって
でそのうちの一ブロックを
今回の方法で索引付けするために
残りのブロック
の
文書を学習データとして使うと
で翻訳モデルの学習残りのブロックを
残りの九ブロックで翻訳モデルを
学習して
その翻訳モデルを使って
ある
ブロックの索引付けをしてやると
でこれを十通り繰り返すことで
学習データと評価データが
うまく重ならないように
しました
でまず翻訳モデルを使うことで認識誤りがどれぐらいカバーできるのかというのを簡単に調べてみました
でこれは
一番
左側のポイントですね０のとこのポイントが
本来の単語認識率になっています
でこれに対して翻訳モデルを使うと認識誤りを起こした箇所に関しても
正解単語は予測できるわけですね
で
それ
その単語が翻訳モデルで予測できたかどうかというのを調べた
で
その時に確率が
〇．〇一以上ですねこれはさっきのＴＦで
索引付けするときの閾値に相当するところなんですけども
で
確率が〇．〇一以上で
正解単語が現れたと
いう時に
認識できたというふうに仮定してやると
また翻訳モデルを使うと
だいたい八十六．五ぐらいまでですね
学習データの
量に
習っ
て
認識率も向上していくという
ことがわかります
で
こちらは
今度は検索の程度について
調べたんですけども学習データの量との関係を
調べました
でこれは
横軸が学習データ量ですね
で縦軸が
先ほどの十一．平均
精度になります
で
その文書サイズを六十三十十五と
三通りで
検索の精度を
求めております
で先ほどの
交差検定で十分割すると最大でですね
六百万形態素ぐらい
学習データに使われるんですけども
できれば学習データ少ない方が良いわけでそれでどれぐらいまで
耐えられるかというのを調べたということです
でこれを見ますと
百万ぐらいでだいたい
上限に達していると
いうことですねそれそれ以上上げてもそれほど
もう精度は上がらないということが
わかります
で次に
索引語の閾値ですね
どのぐらいまで
ＴＦを使ってやるかと
いうところを調べました
で
閾値をいろいろ変えてみて
検索性能がどのぐらいになるかと
いうことですね
でこれを調べてみますと
各
検索対象の
大きさですねそれに
よってずいぶん違っていると
で十五発話の場合つまり短い区間ですね短い区間を文書だと見なした時には
なるべく
閾値を下げてやって
多くの
ＴＦを単語を予測してそれを索引に使ってやる方が良いと
いうことになります
ただし
三十発話とか六十発話になると
あまり索引を増やすと逆にノイズになってしまう
で閾値の設定によって
有効なポイントが違うということがわかりました
次にですね学習データに
ワンベストだけを使うかテンベストを使うかと
いう違いを調べてみますこれは
認識認識の候補としては
何ベストかまで
デコーダで出せますので
で例えばテンベストまで使うとするとそのテンベストと
正解単語の
パラレル
コーパスがそれぞれできますので十倍の学習データは得られるわけですね
でワンベストだけを
パラレルテキストとして使ったかテンベストまで使ったかで
性能の比較を
してみたということです
で
これで見てみますと
多少入れ違いは
ありますけれども
おおむねやはりテンベストまで使ってやった方が
検索性能は良いと
いうことが
わかりましたこれは
横軸は先ほどの閾値で
各
発話毎にテンベストとワンベストでそれぞれ比較したもの
になってますそれで
多くのところで
テンベストの方が上をいっているというところがわかるかと思います
はいそれで
提案手法をベースラインの検索手法と比較しましてどれぐらいの性能であるかというところを調べました
で
ベースライン手法としては
書き起こしテキスト本来の書き起こしテキストだけを用いた一般的な文書検索手法を実装して
それとの比較を行な
いました
で索引付けには形態素を用いて検索モデルとしては提案手法も
ベースラインも一緒ですけどもＴＦＩＤＦ
ですね
の重み付けを使ったベクトル空間モデルを使っています
で索引付けに関しては三種類試してみまして
で一つは書き起こしのワンベストだけを使って
索引付けをした場合
で二番目はテンベスト
まで使ってそれを
全て使って
索引付けした場合
でもう一つは
本来
正しいものですね人手で書き起こしたテキストを使って索引付けしたその三通りとの
比較を行いました
で提案手法は
翻訳モデルを使っ
て
そのうちの
今回はテンベストではなくてワンベストですねワンベストの方
の
パラレルテキストだけを使った場合との性能の比較を行いました
実験結果ですけども
縦軸が
先ほどの十一点平均精度になっています
で
それぞれ文書長を十五三十六十で変えた場合の
性能の差を示しています
で各
発話長に対して
左から
ベースラインのワンベストだけを使った場合
でその次がテンベストを使った場合
でオレンジ色のところが
今回
提案しました翻訳モデルを使った場合
で一番
左側が
書き起こしを使った場合になります
でこちらを見ますと
十五発話の場合には
提案手法の性能
が
非常に良いと
従来のワンベストテンベスト
よりも
かなり精度が高い
でさらにですね書き起こし
をそのまま使った場合よりも
高い性能が得られたという結果が
得られていますでこれは
翻訳モデルを使うことによって文書拡張的な効果が
現れたのではないかと考えています
で三十の場合にはやはり四位ですけれども
六十
の場合には
従来手法とそれほど変わらないという結果が得られています
まとめますと提案手法は文書サイズが小さい場合に効果が認められました
で特に
十五発話ですね十五発話の場合には十六．九％の回転が
で大きい場合には
効果が得られませんで
それは
翻訳モデルで誤った語を
推定してしまうとでそのノイズの影響が
相対的に大きくなると六十発話ぐらいあると文書の認識結果ぐらいで十分冗長で
それ以上増やしてもあまり変わらないというような結果が得られました
今後の課題としては
翻訳モデルの精度改善で特に
今単語
の
対応ですけどもそのコンテキストを考慮したモデルのようなものを考え
て
くることが考えられると思います
でもう一つ
検索手法今回単純なＴＦＩＤＦを使いましたけども
翻訳モデルを使う限り
今回の手法だとＴＦに解釈をし直して
ＴＦＩＤＦ
適応したんですけども
その方法には
結局ＴＦに翻訳し直して使うと
いうところで翻訳モデルの利点をあまり生かせてないんじゃないかと考えています
でこれ以上
検索性能は伸びそうもないと
で
翻訳モデルを直接その利点を直接利用する
方法として言語モデルに基づく検索手法
が
考えられてそういう方法を使うと
良くなる可能性があるのではないかと考えております
以上
で発表を終わりますご質問
よろしくお願い
します
