このタイトルで発表するんですが実際発表予定だった君というのが
ちょっと今国際会議で行ってしまったので私がやりま
先週ですかね彼はドクターの三年生で公開審査済んだとこなん
審査委員長は
先生そこにおられる先生だったんですが
彼はドクターの間にですね三つのことを主にやっていたんですが一つはクラス言語モデル
一般のですね
それをやっていてもう一つはトピック依存言語モデル
やってま
で最後にこのテーマですね未知語の言語モデル
を考えようというので
やったわけでその最後にやってきた
内容を紹介
いたしま
で言語モデルというのは
ですね音声認識に使うわけですがそのですねボキャブラリーサイズがだいたい二万とか六万とか
やるわけですがどうしても
辞書に登録されていない
単語があるわけですね
そういうなのをアウトオブボキャブラリーと呼んでいるんですがそれが音声認識率に影響すると
一つは登録されていないから絶対に
その単語が認識されないという問題と
もう一つはその例がここに書いてあるんですね
これ
グーゲルというのがもし未知語であれば似たような単語に
グーグルとかに似て認識されてしまうと
そうゆうなんで登録されていない単語は認識されないという問題と
もうひとつは周辺の単語にも影響を及ぼすという事ですね
言語モデルを使ってますからコンテキスト情報を使って
認識してみますから
そのこの単語だけでなくてその周辺にも誤り
の影響を及ぼすと
経験的に言えば未知語率が
例えば五％あればその一．五倍ぐらいの誤りになってしまうその未知語の影響でですね
だから五％未知語があれば七．五％ぐらいは未知語の影響で
認識率がでない
そうゆうな
そうゆうなので未知語を減らそうというのでボキャブラリサイズを増やすということになる訳ですが
それにしても例えば新しい単語というのはどんどん出てきますて
全て登録することはできないと
ていうことで
いずれにしてもアウトオブボキャブラリーをどう扱うかうということは重要問題なる
ということでそれをどうするかという話
をやっているわけです
で特に情報検索とか内容検索ですね
そういうな
情報抽出とかそういうなことなると固有名詞とか
そういうなのが案外重要であるいは新しい単語ですね
そういうなのが結構重要になってくるから
それが案外未知語になってるというので
やっぱり未知語を真剣に考える必要があろう
いうことになる
でそれでですね
今まではどうされてるかと普通はですね言語モデル作るときに未知語を一つのクラス
ｕｎｋｎｏｗｎワードクラスと
見なして言語モデル作ると
そういうことでこの未知語もですね
単語の履歴として使って
単語を予測するとインボキャブラリーの単語を予測するとかそういうことになる訳ですが
基本的には未知語は一つのクラス
してやっていた訳ですが
しかし一つのクラスで扱うというのは問題があろであろうというのは容易にわかると思うんですね
例えばというのは個人名人名でして
このというんですかねこういうのは鉱物関係の単語であるとしたらこれを一つの
クラスと扱うのはちょっとやっぱり問題があろうと
いうことになる訳です
そういうような意味でここではですね
この未知語もですね
クラスに分けたいと意味的に分類したいということ
でそれでここで使ってるは
ウェブ情報を使ってですねこの新しい単語とよく似た
単語インボキャブラリーの単語を見つけて
そのインボキャブラリーでクラスタリングしてあった単語のクラスに割りつけると
そういうような大きな流れでやろうとして
でどういうような問題があるかということなんすけど未知語を扱うときにですね
で一つは
テストコーパスというのは認識する対象ですからあらかじめこれがわかってないですね
こうずっとオンラインで認識していかないといけないから
そのときに
未知語というのをどないして見つけるかという問題がある訳ですがそういうような研究もあるわけですね
例えばテストデータを結構認識していて例えば七割とか八割認識できたとしたら
それでトピックを推定できて
そのトピックに関係するような単語の
をですね
リストというかそういうなんウェブから探してきてですね
それでどんどんどんどんこうインボキャブラリー無かった単語を登録していくと
いうのが一般的ですね
未知語の見つけ方ですねテストデータに対して未知未知語の見つけ方は
そういうなんが一般的でそれで辞書には登録できるということには
成りうるかなと思うんですけども
我々問題するのは未知語登録したとしても自動的に登録するか
あるいはユーザーがこれは新しい未知語であると思ったら登録するという
いうようなことで何らかので登録できると
未知語をですね
でその前提のもとでその言語モデルをどうするかと
いうことをやろうとしてる訳
でそれで未知語のの扱い方の問題としてはボキャブラリーインボキャブラリーを増やすと十万語にするとか二十万語にするとかそういうようなアプローチありますね
でＯＯＶのレートを下げると
いうことももちろん
現実的だと思うんですがこれは
身振りとかスピードとかそういうな面があるかもしれないけども
本質的に未知語は避けられないと
どんどん新しい単語がでてくるから
そういう問題
も想定しておるわけ
そういうような意味で未知語の言語モデルをどうするかと
というとクラス言語モデルを使うか
サブワードモデルでそういうな未知語をですね
シーケンスで認識するという事もありうるとおもうんですが
ここで発表するのはクラス言語モデルをどうするかと
いうような
考えで
でやって
きた内容を報告するわけ
でクラス言語モデルの紹介なんですが
トレーニングデータからインボキャブラリーに対してはワードベースのＮグラムを作ると
いうことですね
でそのインボキャブラリーを何らかの方法でクラスタリングしておいて
我々は今百クラスか二百クラスにクラスタリングしてるんですけど
そういうなインボキャブラリーに関するクラスに対して
新しい未知語に対してですねウェブデータを使いながら
クラスを推定すると
いうことです
でその
未知語のクラスに対してはクラスベースでＮグラムを使う
こういうなんで併用してやろうということです
でクラス言語モデルは普通はこういうなモデルになると思うんですねヒストリー
単語の履歴で現在の
単語を推定するという確率ですね
それはクラス
のカテゴリで
推定クラスを推定してでクラスから
単語
を予測すると
いうことですね
で未知語の場合は
このですね確率がちょっとわからないというので
この研究では一様分布にしてます
を仮定していますあるクラスが
わかればですねそのクラスに
への単語がもし五百単語あるとしたら
その単語は五百分の一の確率で生じると
いう一様分布を仮定しています
ここらへんは改善の余地あるかもしれないすけど
現在はそういうなベーシックな
でやってる
います
で先程言ったようにインボキャブラリーにある単語は一つのクラスと
見なす
こともできますね
これを一つの
クラス言語モデルと
いう
考え方にすればインボキャブラリーは各単語は一つのクラス
ということ
でアウトオブボキャブラリーに対しては意味的に似たようなクラスに割りつける
いうことですねでさっき言ったようにこの確率は
一様分布で仮定する
そういう
でそれでですねインボキャブラリーをクラスタリングしておく訳ですが
一番よく使われるようなタームドキュメントマトリクスとかバイグラムマトリクス
こっちは現在の単語でこれが
一足す前の単語とかいうこういうようなマトリクスで表現すると
いうことですね
でこれでインボキャブラリーに対してはこういうな要素は
ちょっと見えてないですけどこの行列の要素が
求められているとしてでアウトアウトオブボキャブラリーに対してこれは新しい単語がぽんと入ってきて
辞書には登録しているけども
これをどうするかというとウェブデータからですね
この出現頻度
を
ちょっと見にくいんですが
ちょっと見にくい
ウェブデータからこういうな出現頻度を求めてきてですねでこのマトリクスを作ってこのアウトオブボキャブラリーのベクトルと一番似ているような
インボキャブラリーの単語を見つける
いうことですねでこれが対応するインボキャブラリーの単語が見つかればそのクラス
を採用すると基本的にはそういうような考え
なんで
ここらへんは通常のテクニックなんで
いいとは思いますけどもそれで先程言ったようなアウトオブボキャブラリーとインボキャブラリーの単語の
類似度を計算すると
そこで
ファンクションワード見たいのをですねどこにも出てくるような単語はちょっと考慮しないというので
ＩＤＦという
う
メジャーで重み付けしていますけど
そういうなんでｓｉｍｉｌａｒｉｔｙを計算
でそういうなのインボキャブラリー全てに対して類似度も
も
う求めてその内の一番大きい
対応するインボキャブラリーの
単語を見つけるそのクラス
を採用する
そういうような方法でやっています
でこれが例なんですが
というこれ人名ですかね
人名に対してウェブでデータサーチ
で
で先程のマトリクスを作っ
て
でそれでインボキャブラリーとの類似度を計算する
こういうような
全てインボキャブラリー二万単語とかあるんですが
でそれの最大値に対する
クラスを採用する
そういうことですね
でマトリクスとしてはタームドキュメントマトリクスとバイグラムマトリクスと使ってんですが実験的にはバイグラムマトリクスの方がいいということなったんで
で下のを使うことに
で考え方は以上なんですが
ここでちょっと実験これから実験結果について報告する訳ですが
対象テストデータとトレーニングデータウォールストリートジャーナルのコーパス使いました
で千九百八十七年から八十九年
のデータちょっと古いんですが一般にこうウォールストリートジャーナルの評価データとして
世界的に使われているデータ
それに合わしての
でボキャブラリーサイズは二十キロwords
にしまし
これが基本的なボキャブラリーサイズですね
でそうするとテストセットにあったアウトオブボキャブラリーの種類が六千百
個ですね
六千百種類
テストデータにはですね
でトレーニングデータに対しては
十六万ぐらいあったんですかね
あとボキャブラリ二十キロ以上で収まらないやつが
百六十ｋぐらいあったと
すけども
このテストデータに対してはテストデータのコーパスによって
全然違いますけど
でウェブから百ページ分引っ張ってきた
いうこと
でこういうなので例えば
というのは
どういうような対応する単語に近いかというのを
列挙してあるんですが
これ全部固有名詞
人名ですね
対して人名も引っかかってきてんですけど
綺麗には
なってないんですけど
人名は人名に近いようなやつも引っかかってきてる
インボキャブラリの
人名に近い
単語も引っかかってきてる
でここで問題はですね評価するときに
トレーニングデータの中のアウトオブボキャブラリーと
テストデータのアウトオブボキャブラリー
トレーニングデータ
の二種類があるんすねアウトオブボキャブラリーと称してもですねトレーニングデータでもインボキャブラリとアウトオブボキャブラリー
がありましてテストデータに対しての
アウトオブボキャブラリーというので
で今ここで対象としてんのはＯＯＶ一と書いてあるですね
トレーニングデータにでてくる
ですけども
単語として登録していないアウトオブボキャブラリＯＯＶ一
これをまず最初に対処しようと
いうこと
それの実験結果
でそれでですね
本当はですねこういう様なアウト将来どうするかってといってんですけども将来テストデータに
ＯＯＶ二はどの程度
頻度が頻度
があるかというような
とかいろんな問題が出てくる訳ですが
我々の仮定としてはトレーニングデータが非常に多いとですね
これ例えばインボキャブラリが二十ｋであればアウトオブボキャブラリのレートが
二三％であるとしたら
テストデータにおいてもアウトオブボキャブラリのレートは二三％であろうと
いうような仮定を設け
てやろうとしています
ただ種類はちょっと違ってくるけどですね
アウトオブボキャブラリのレートとかがある程度推定しないと言語モデル作れないですから
テストデータであろうがトレーニングデータであろうが
アウトオブボキャブラリのレートが同じであるという仮定をするとかそういうな考えで
で
評価としては音声認識率とパープレキシティ両方でやるんですが
このパープレキシティというのも怪しいもんで
この補正パープレキシティを使わないとですね平等な比較ができない
例えばインボキャブラリを二十ｋにするか六十ｋにするかというので
パープレキシティが変わってきますが
それでＡＰＰという補正パープレキシティを使うとそういうな問題も補正されます
どういうことかというとですね
補正パープレキシティというのは
アウトオブボキャブラリに対しては一様に分布すると
していると出現しているという仮定ですね
それであのパープレキシティを計算する
そういうこと
そういうようなメジャーで評価してる
それで先程言ったトレーニングデータとテストデータがある訳
それでこれがこっちが赤が補正パープレキシティでこっちが
通常のパープレキシティ
でこれがボキャブラリサイズの登録
の数ですね
で我々今基本的な二十ｋを
と二万語を登録してんですが
最終でトレーニングデータは全部で十六万語
出現していたんでですねボキャブラリ
サイズを
増やすとですね
パープレキシティと補正パープレキシティは同じ値になるのですが
ここら辺でかなり差が出ていますね
二十ｋのときでも差が結構でてる
これがまず
単語の
トライグラムでやればパープレキシティがどうなるかということですね
でこれをですねクラス言語モデル使って提案してるクラス言語モデル
で二十ｋがインボキャブラリサイズで
あとアウトオブボキャブラリサイズをこう登録していくということですね
で二十ｋ登録すれば
全部で四万単語になりますけどね二万単語はインボキャブラリで
登録されてトライグラム求まっているんですが
あとの二万単語を登録してクラス言語モデルを
作ってですね
それでパープレキシティ計算すると
だいたい四十パープレキシティＡＰＰというか補正パープレキシティが四十七．五くらい
でベースラインの
補正パープレキシティが五十一．五であるから
かなり
下がったと
すね
そういうこれはどういうことかといったらこういう二万
ワード登録して後の十四万単語は全部一様分布であると
それを一つのクラスで仮定したやつですね
でこちらは
二万単語登録して未知語
そのクラスに対しては
クラス百クラスとか二百クラスでクラスタリングした
ちょっと時間なくなったんですが後
ですね
認識実験で
てみます
でこれは
ちょっとあのウォールストリートジャーナルの
世界的に使われている評価データは比較的易しくて
うちのデコーダーでも九十五％ぐらいでるわけですね
単語認識率が
でそれでちょっとそれは易しすぎるというか評価できないというのでもうちょっと難しいように
必ず一文は一未知語を含むように
テストセットを作ってやった
タスクで
評価してんですがベースラインでやると
ＡＰＰ補正パープレキシティが百五十ぐらいなんですが
二十ｋぐらい登録すると百四十七．五てちょっと
減るんですけども
ここＡＰＰと比較したらちょっとわかりにくいんですが未知語だけのパープレキシティを計算すると
ベースラインでは
パープレキシティが三百四十二万無茶苦茶な値ですけども
でクラス言語モデル使うと二百万ぐらい
になる
三百四十万から二百万ぐらい
パープレキシティが下がる
で認識実験がこうなんですがボキャブラリサイズを一般にですね増やしていくと誤りに
はどんどん
減ってきます
これボキャブラリーを今六万単語まで
しかやってないんですけども
やると最初アキュラシーが七十二．七であったのが七十九．六というので
一般にだから
インボキャブラリのサイズを増やすというのが
手っ取り早い
認識率の向上方法なんですが
それにしても
アウトオブボキャブラリーの問題が解決できないのでということで我々今研究やってんですが
でそれでやるとこうなりまして
この
ベースラインというのは一クラスの言語モデル
けども未知語に対してそれがこういうような
誤り率に対して
百クラスか二百クラスにやると誤りが減ると
いうことですね
でもう一つちょっと書かなかったんですが
インボキャブラリのサイズをこれが一ｋ増やすいうことは二十一ｋ二十五ｋ
三十ｋにするということですねインボキャブラリ
その通常の方法だともうちょっとよくなります先程の結果より
これが少し一％
○．四％ぐらいよくなるだけですね
さっき言った
三十ｋを戻ると
三十ｋこれ二十ｋプラス十ｋのインボキャブラリとしてやったのが誤り率が
二十三．四ですね
二十三．四に対してクラス言語モデル使っても二十三．八％ですから
単語をどんどんどんどん登録して
Ｎグラムの
単語
モデルを作るのと
を単語登録するだけでクラス言語モデルを自動的に作る
やっても認識率は
それほど変わらない程度に得られた
いうのが
一応
現在までの
結果です
これで終わります
