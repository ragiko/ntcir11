はい
それでは立命館大学が発表します
近年多様な多様の音声データを含んだマルチメディアコンテンツが様々なところに蓄積されるようになりまして音声データ検索のニーズが高まっております
そしてこれに伴いまして音声データを対象として与えられたキーワードを検索する検索語検出の研究が
活性化してきていまして近年ですと
記号列に対する照合と
いうことで連続音声認識
による
単語列を用いた手法や
サブワード認識結果を用いた手法が広く
研究されてきています
古くには音響情報に対する照合ということでワードスポッティングの研究が行われてきていました
最近では未知語対策や認識誤り対策のためですねサブワード認識結果を用いた
手法が
多く研究されているのですがこちらの手法は音響情報に対してサブワード単位の認識結果を出しておきそのサブワード列に対して
検索語もサブワード系列に直しておき照合を行うと
いうものです
しかしですね
これらの手法は音響情報を
認識結果にかけてサブワード列に直すことによって音としての情報が
劣化してしま
っているものに対しての照合ということで
そこが検出に悪影響を与えているのではないかと
いうところに我々は着目をしました
他の研究では複数のサブワード認識結果を用いる
ということでこういった問題にアプローチをかけているのですが我々は
別のアプローチで前回の報告でですが音響情報のベクトル量子化を用いた検出手法と
いうことで提案をしています
こちらの手法は
音響情報に対して話者毎にベクトル量子化を行い生成されたコードブックを元にＶＱコード列を生成しますその予めＶＱコードとサブワードとの関連度を学習しておき検索語もサブワードに直し
照合を行うと
いうことで検出を行うといったものです
そして我々の目的
としましては大量の音声ドキュメントに対して高精度の検索を実現したいということで記号列よりも音響情報に近い表現形式ベクトル量子化によって音響情報を離散化したＶＱコード列
を音声の表現検出として用いると
いうことでこれを実現したいと考えているのですが
前回の報告では学習に書き起こしテキストの利用をでの
評価を行なっていたので良い結果が出ると出る可能性があるというところまでしか話すことができませんでした
で今回は学習に連続音声認識結果を利用したということはもちろんのこと手法の検討を
行いました
前回は最終的な検出区間の決定について複数の閾値処理によって
行なっていたのですが今回は統合スコアによる検出区間の再評価ということで最終的な検出区間の決定を行いました
さらにもう一つ音声の時間構造を考慮という検討を行いましたそしてまた今回の報告についてですがまず前回の報告と重複してしまうんですが
前回の報告した手法について述べさしてもらったあと
今回の提案検討点
についての詳細について話させていただきます
まず前回の手法のフローチャートになりますまず音声ドキュメントに対して
話者毎にベクトル量子化を行いコードブックを作成しＶＱコード列を生成します
と同時に大語彙連続音声認識を行いサブワード列での情報も補助します
この情報からＶＱコードにおけるサブワードスコア我々ＶＰスコアと呼んでいるのですがこちらを算出します
検索語はテキストで与えましてこちらをサブワード列に直しましてこのＶＱコード列とサブワード列を
局所スコアにＶＰスコアを用いて連続ＤＰマッチングを行い
検索語候補区間を
生成します
そして再評価を行い最終的な検索語区間を
決定すると
いう流れになっています
まずＶＰスコアの学習に関してですが
音声認識認識結果より得られたラベル情報を元に学習を行います
このようにですね
ＶＱコードと音素列をフレームごとに参照しまして
ＶＱコード二では音素アが一回二回三回という具合に
各ＶＱコード毎にサブワードの出現頻度を
算出してお
き学習を行います
そしてこちらの式に当てはめていきます
こちら
あるＶＱコードＶにおけるサブワードＰのＶＰスコアになるのですがこちらのＣＶＰ括弧Ｐが
サブワードＰの
出現回数
下がＶＱコードＶの総フレーム数
この割合になりますこちらにログを取った
値に対してこちらが
ＶＱコードＶにおける最も出現回数が多かったサブワードの出現回数と総フレーム数で割合を引くことによって正規化を
行なっていますこういったＶＰスコアを用いて
連続ＤＰマッチングを行いました
そして候補区間の検出は連続ＤＰマッチングで行います
このようなパスを用いて
累積スコアを
計算しましてそこからバックトレースしていき
検出区間の開始フレームを決定し
総フレーム数で割った
平均スコアこちらに対して閾値処理を行なっていきます
式に直すとこのような式になります
この
平均スコアが極大値を示したものを
候補区間と
して
検出を行います
先程の平均スコアに対する閾値処理でも検索語検出は可能なのですが
予備実験を行った結果湧き出し誤りが多発してしまいましたその湧き出し誤りの傾向としまして一つ二つの
サブワードが検出区間の大部分を占めてしまうと
いう湧き出し誤りが多発してしまいまして
これではやはりよろしくないと
いうことで条件を二つ
加えました
その一つとしてＶＰスコアの分散
分散が大きいと湧き出し誤りの可能性が高いと
判断する条件
二つ目として相対的なサブワード時間構造比率
ということで時間構造が不自然であれば湧き出し誤りの可能性が高いと
判断する条件です
まずＶＰスコアの分散に関してですが
このような式で
算出を行いますこちらはフレームごとのＶＰスコアですね
と平均スコアの差を見まして二乗して足し合わせていき
最終的に総フレーム数で正規化した
もので分散を求めましたこうすることによって
極端に低い
ＶＰスコア
があったり極端に
高いＶＰスコアがあったり
する検出
区間は
リジェクトされると
いう流れになっております
そして二つ目として相対的なサブワード時間構造比率に関してですがこのような式で算出するのですがこのＤＬ括弧ＰＪ
がラベル情報より得られたサブワードＰの平均フレーム数
下がラベル情報より得られた
検索語の平均フレーム数
になります
こちらが
検出結果でのサブワードＰのフレーム数下が検出区間の総フレーム数
になりますこの
いわゆるサブワードＰの
平均的な検索語に
おける
割合
こちらが検出区間におけるサブワードＰの割合
この差を見ることによって差を見て二乗して足し合わせていき最終的にサブワード長で
正規化を行った
もので
この相対的なサブワード時間構造比率を表しまして一つの音素に対する
フレーム数が極端に
大きかったり小さかったり
する検出区間は
この条件でリジェクトされると
いう流れになっております
この平均スコアと
スコアの分散と相対的なサブワード時間構造比率この三つの閾値処理を行い全てクリアしたもののみ
検出区間と
最終的な検出区間と
すると
いう流れになっております
ここまでが前回の報告なんですがここからが今回の
提案手法になりますフローチャートとしましては先程と同じなのですが
この再評価の部分
とベクトル量子化の部分
とＶＰスコア
その部分
ここの検討を行いました
まず
統合スコアによる候補区間の再評価ということで再評価の部分の検討なのですが先程の三つの閾値処理によっても
検索語検出
は可能でしたのですが
複数の閾値処理を行わなければならないのでなかなか検出性能が安定しませんでした
ですのでこの三つの要素
を総合的に見た統合スコアを算出して
それにのみ閾値処理を行うと
いうことで再評価を行いました
この統合スコアの算出に関してですが
先程の三つの値を平均と標準偏差から正規化した値に対してそれぞれに重みを加えまして足し合わせた足し合わせることによって統合スコアを算出しましたこの統合スコアが閾値以上であれば正解それ以下であれば誤検出と
判断して検出を行うと
いう流れになっております
そして
検討の二つ目として音声の時間構造への対応ということでセグメント量子化の導入を行いました
前回は
当該フレームの音響情報のみ見てベクトル量子化を行なっていたのですが今回はセグメント量子化と
いうことで当該フレームの前後二フレーム計五フレームですねを見てベクトル量子化を行い音声の時間構造を表現しているＶＱコード
の生成を
こうやって行いました
そして三点目としてこちらも音声の時間構造への対応
なのですがＶＰスコアにおけるサブワード単位こちらの検討を行いました
前回は音素サブワード音素だけでのみ評価を行なっていたのですが今回は
サブワードを半音素とした
場合での
結果も出しました
ここで言う半音素というものは音素を時間的に二分割した
サブワードとなっていましてこのように
アの前半後ろにＫがくるアの後半前にアがきていたＫの前半という具合に
音素を半分に二分割したサブワードとなっています
そして音素でのラベル情報から半音素でのラベル情報を作成し
先程と同じくＶＱコード二では半音素が一回二回三回という具合に算出を行い先程の式に当てはめて
ＶＰスコアの算出を行いました
これらの
検討点を踏まえまして評価実験を行いました
検索対象の音声ドキュメントはＣＳＪ日本語話し言葉コーパスのコアデータ百七十七講演検索語は音声ドキュメント処理ワーキンググループがＳＴＤ評価用として選択している未知語セット五十語
音響情報は十二次元のＭＦＣＣ
ベクトル量子化におけるコードブックサイズは千二十四評価尺度としまして再現率適合率Ｆ値処理時間を求めました
今回複数の検討を行いましたのでどれが効いているかと
いうのがわかるように条件別に評価実験を行いました
そしてこちらが条件別の検索語検出の結果となります
Ｆ値を見ていただくのが一番わかり易いかと思うのですがまずセグメント量子化の有無に関してセグメント量子化を導入することによってＦ値を零．四二七まで上げることが出来ました
そして次に再評価の
部分についてですが
統合スコアを用いることによって
Ｆ値を零．五四四に上げることが出来ました最後にサブワードの検討についてですが音素から半音素にした場合ですね
性能が
落ちて
しまったのですが
認識結果を単語認識のワンベストから単語認識のテンベストにすることによって若干改善され更にですね単語認識のテンベストと音節認識のテンベスト両方を用いることによって
最も若干ですが最も良い結果が
得られました
ここから考えられることとしまして
サブワードの音素と半音素では半音素のほうがモデル数が六十倍
多くなっていますので単語認識のワンベストだけじゃ一モデルあたりの学習のサンプル数が
少なくなってしまうので
性能が落ちてしまったと
そして認識結果を増やすこと毎に
性能が改善されていったと
いうことが考えられますまだですね
この二つでも十分に学習できていないという可能性も考えられるので今後
この学習のサンプルを増やしていくということも検討に入れていきたいと思っています
こちらは参考までに
基本的な手法であるサブワード間との照合
との性能を比較しましたここでいうサブワード間の照合というのは音声ドキュメントに対して音声認識をかけ
音素列に展開したものに対して
検索語も音素列に直して照合を行ったと
いうものとの結果の比較になります結果から検出性能において提案手法に優位性があるということが確認されました処理時間に関しましては今回工夫を行なっていないので
今後
検討していきたいと
考えております
まとめです
検索対象の音声ドキュメントの表現手法として音響情報をベクトル量子化して得られるＶＱコード列を用いる手法の検討を今回行いました
手法としましては話者別にベクトル量子化を行い
ＶＱコードとサブワードの関連度に基づいてテキスト入力された検索語との照合を行うと
いうものです
評価実験から
統合スコア
セグメント量子化ＶＰスコアの学習を半音素で行うことによって検出性能が大幅に向上したと
いうことが確認されました
従来手法との比較により検出性能において優位性を確認しました
課題としましてはサブワードの検討ということで
半音素以外にももっと時間的に精緻な
サブワードありますのでどういったサブワードを用いていくのか
と更にその際に起こってしまう
学習のサンプル数の
サンプル不足
いうところをどうやって解消していくかと
いうところが今後の課題として挙げられます
高速化についても検討していきたいと考えています発表としては以上ですご清聴ありがとうございました
