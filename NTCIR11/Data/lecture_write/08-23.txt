はいそれでは講義音声のコンテンツ化とブラウジングシステムの改良と
題しまして豊橋技術科学大学のが報告させていただきます
まず研究の背景についてご説明いたします
近年ネットワークの大容量化に伴いまして
収録しておいた講義や講演などを
ネットワーク越しに配信して利用者が好きな時間に自分のＰＣで好きな場所で学習できるｅ−ｌｅａｒｎｉｎｇという
システムが
普及してきていますこれは主に大学などの大学高専などの研究機関や企業の研修などにおいて広く利用されて
います
ただ現状のシステムでは
動画の再生講義の動画の再生と
それの時間と連動したスライドの同期再生のみ
というシンプルな
教材が多く
その講義を学習しようと思ったら実際に一時間の講義を学習しようと思ったら同じだけの時間を必要とする
というのが現状のシステムです
でせっかくその一度デジタルデータにしたものですから重要な部分だけを流して聞いたりとか
この
このキーワードについて聞きたいといった要望があるかと
思います
そこで本研究では
そうした効率のよい学習が可能となる
講義の音声の書き起こしや重要部分の提示機能
また講義のキーワードの抽出
などを自動的に行って
そのビデオ教材に付加する
システムというものを
開発しています
でこちらが一般的なｅ−ｌｅａｒｎｉｎｇの教材の例です
こちらに講師の映像動画が映っていますでその隣に
その
ビデオの時間と連動して
その時間に表示されていた講義のスライドの画面
というものが表示されています
でこちらの画面にはこちらの左下のほうには
講義のスライドのタイトルの一覧が表示されています
これ例えばこの辺を聞きたいと思ったらそこをクリックすればビデオをそこに
ジャンプさせることが
できます
こういったシステムをもとにして我々の研究室では音声認識を利用して
付加情報を
加えた教材っていうものを開発しています
こちらのスライド画面
の下まずこのこの部分を見ていただきたいんですけども
これは音声認識から自動的に得られた書き起こしを表示しています
でこれは講義音声全体をいくつかの区間に分割しておりまして
現在発話されている部分が白くハイライト表示されています
で例えばこの書き起こしをずらっと見てこの辺聞きたいと思ってそこをクリックすればビデオをそっこにジャンプさせるという使い方も
できます
またこれは要約になっていまして
このシステムが重要であると推定した文だけを表示
しています
もちろんその表示している部分だけを再生するということができますので
利用者はそのシステムがあまり重要じゃないと判断した部分については飛ばして
短時間で学習するといったことが
可能になります
またこのスライド画面
のスライドの画面を見ていただきたいんですけども
いくつかの単語にリンクが張られています
このリンクは
発話と対応付けられていまして例えばこのニューラルネットワークといった
ところについ
ニューラルネットワークという単語が発話されている部分を聞きたいと思ったらここをクリックすると
ビデオをその場所へジャンプさせることができる
という使い方ができます
またこのキーワードはスライドから抽出したものですけども
こちらの書き起こしから
抽出キーワードの一覧っていうのもこちらに表示しています
で先ほどご説明した要約
ですけれども
全体の文の
重要そうな方から何％表示させるかといった設定は
こちらのほうでいくつか切り替えて使うことが
きます
また再生速度もゆっくり聞く
時や早く早く飛ばしたい時など
のために設定できるようにして
あります
では実際のデモ
がありますので
ごらんください
ちょっと画質が悪くて申し訳ないんですけども
はい先生の
やつなんですけど
でキーワードこれクリックすると
そこに
ジャンプすると
言う使い方が
できます
これは
要約になっているんですけども
ちょっとわかりずらいですね
こちらのほうで要約率を切り替えて
使うことが
できます
はいこのような
感じで
動きます
それで
と
この様に全体をずっと見て
でこの辺聞きたいと思ったらそこをクリックすれば
ビデオもそこにジャンプできると
いうような使い方もできます
でこのシステムの全体像なんですけどもまず講義
行う際に音声音声とビデオを録画しておきます
またそのとき同時にスライドのデータとして
もちろんその画像とかテキストとかスライドに含まれるデータもちろんそうなんですけども
スライドが
どの時間で切り替えられどのタイミングで切り替えられたかといったかといったその切り替え時間も
保存しておきます
これはこのワークショップの収録にも使われているＥＺプレゼンテーターを使って実現しています
す
収録した音声データに対していくつかの
収録した音声データをいくつかの細かい区間に分割します
で便宜上この一つの区間を一文文とします
それぞれの文に対して音声認識を行いまして書き起こしテキストを
取得します
でそうしましたら
その書き起こしテキストから得られる言語的情報と音声データから得られる韻律情報の二つを利用して
重要度のその文が重要かどうかといった推定を行います
で重要であると判断された文だけ
を集めてその講義の要約と
しています
でスライドデータですけどもこちらは
さきほどお見せしたようにキーワードを抽出してそのキーワードと発話を対応づける
インデキシングという処理を行います
で最終的に先ほどのような画面が
できると
いう形になっています
このシステムを被験者実験で評価しました
被験者は十二人当大学の学生
に依頼しました
で
先ほどお見せした書き起こしなどキーワード
抽出などそういう機能を付加した
改良版と何も付加していない一番最初に見せたようなシンプルな教材の二種類を
同じ授業について
自由に使っていただいて便利さ
その機能の付加をした
コンテンツの便利さを五段階で評価して
いただいたところ
結果はこのようになりました
まず要約機能については便利
であるというのが六人
書き起こし表示機能についてはとても便利というのが七人
で再生速度調整機能については便利と答えた人が六人
インデキシングについて
インデキシングについてはこれちょっと
問題なんですけどもどちらとも言えないと
いう答えが一番多かったです
でしかしコンテンツ全体としては非常に前向きな
前向きな肯定的な
評価を得ることが
できました
でこの被験者実験をやって
課題が
見えたんですけども使用後の
被験者のコメントとして
まず書き起こしにやはりいくつか間違いがあってそれを読むと逆に混乱する
あとはキーワードは専門用語を取ってほしい一般用語は意味がないと
いう意見がありました
でインデキシングに使うキーワードなんですけども
この被験者実験を行ったときは
その
まだキーワードの抽出単位が茶筌の名詞
であった
ということであんまり専門用語などを拾って来れなかったという
状態でした
そこで今回の報告ではこの
インデキシングのキーワード抽出などについて
ちょっと
追加実験を行ったことを報告したいと
思います
このシステムはこの
講義音声の自動認識要約インデキシングの
三つの部分から主に成り立っているんですけども
今回の報告ではこの二つについて
追加実験
について報告したいと思います
まず講義音声の認識について
行ったことを報告します
で
講義音声の認識を行う際に
従来まで使っていたＣＳＪのコンテキスト独立の
百三十三音節モデル
を従来まで使っ
使っていたんですけども
今回新たにＣＳＪのコンテキスト依存の九百二十八音節
のモデルを使って講義音声の認識を行って
いました
で言語モデルは二つとも同じです
でただ特徴量が学習環境の違いから
二十五次元と三十八次元という違いが出ていますのであまり厳密な比較ではないんですけども
この二つのモデルの比較を行いました
このコンテキスト依存モデルについては次のスライドで詳しく説明しますが
この実験で認識の対象とした講義は
昨日の先生の発表でも
紹介されましたＣＪＬＣの一部
の講義です
で
当大学で収録された四話者四講義四話者五講義
の
講義を使用しました
それでコンテキスト依存音節モデルに
ついてなんですけれども
これは一つの音節が直前の
一つの同じ音節でも直前の音節が何であったかによって場合分けして
分類して学習するというモデルです
例えば
例えばと言いますか
前の音節が
前の最後の音節が五つの母音あいうえお
とＮの撥音字の間違いがありましたけども
撥音と促音ＳＩＬ無音の八種類について
場合分けをしています
で百十六音節をベースとしてそれの八倍ですから九百二十八音節のモデルと
なっています
でこれは朝日という単語を認識する際のモデルのつなぎ方の例ですけれども
前の単語Ｅという単語の最後がＯであった場合
そのＯ
のコンテキスト依存のＡという
ものが接続します
であとはそのコンテキストを考慮したモデルが
接続されていくと
いうように
認識されていきます
それでこのように
コンテキスト依存モデルを
コンテキスト独立の通常のモデルと比較した結果が
こちらです
で認識結果を正解精度Ａｃｃｕａｃｙと
認識率のCollectの二種類で評価しています
でこのグラフ
の赤い青いほうが
コンテキスト独立
で赤いほうが今回行ったコンテキスト依存の
モデルの結果です
でコンテキスト独立の音節モデルと比較して
全講義の平均でコレクトでは五．四四％Ａｃｃｕａｃｙでは
一％とちょっと少ないですけども向上することが
できました
でつぎにインデキシングについて
の
実験の
報告を行いたいと思います
で
最初にご説明したようにインデキシングとは
このスライドＰｏｗｅｒＰｏｉｎｔ
のスライドをＨＴＭＬに変換しておいて
でその
各単語の
ところにリンクを張りまして
ここをクリックしますとメディアプレーヤーの
再生時間
時間を対応づけたあらかじめ対応付けておいた時間へとジャンプさせると
いう機能です
でこれにこの機能によって利用者は聞きたいところがより探しやすくなる
であるということが
期待できる
けです
今回改善を試みた点はこの
三つなんですけどもまず
キーワードの抽出単位を
これまでは茶筌の一形態素
一形態素単位で抽出していたのですけども
実際のキーワードキーワードというか専門用語などは複合語が
多いということが
想像できますので
複合語にも対応する必要がありました
そこで今回それについて
ちょっと行ってみました
従来は茶筌で
形態素解析をして
名詞だけを
キーワード候補として抽出します
そして各名詞についてＴＦＩＤＦスコアを
計算します
でＩＤＦスコアはＣＳＪの二百十六講演の
ドキュメントより取得しております
で
各名詞についてＴＦＩＤＦスコアを計算しまして
それをスライドごとの平均を求めます
でそのスライドの平均ＴＦＩＤＦスコアを上回る名詞をキーワードとして
抽出していました
で今回は
自前のツールじゃなくて恐縮なんですけどもＴｅａｍＥｘｔｒａｃｔというＰｅｒｌモジュールを使って
複合語を抽出します
で後は同じでそれぞれの複合語について
ＴＦＩＤＦを計算し
スライドのＴＦＩＤＦスコアを上回る複合語をキーワードとして
抽出しています
で抽出したキーワードの例
これは講義一の前半についてですけどもこちらに
示します
今までの単位では細かい単位でぽこぽこ
これは発話に対してキーワードをマッチングさせた例ですけども
細かい単位でぽこぽこキーワードが出て来ていたのが
このように
より大きな単位にまとまることで
不要なものを排除することができました
また今まで隠れマルコフモデルというのを隠れとマルコフとモデルとこの
三つに分割されていたのが
一つの単語として抽出できるようになったと
いうことです
ただこうしてみると
うまくできているような
雰囲気なんですけども
実際にこのキーワードの抽出というのはどのくらい正しいのかということを調査するために
講義の講師の先生の本人に正解
これが本当の
自分の講義のキーワードですという集合を抽出してもらいました
でそれに対するリコールとプレシジョンをもとめたところ
講義一の一ではリコールが十五．五六％プレシジョンが
二十八％
講義三の一では
四十％二十六％と
全体的に低い値となって
しまいました
これは抽出時の閾値など
いろいろ考えるところが
ありそうなんですけれども
とりあえず今回は
このままで実験を進めました
先ほど言ったように抽出したキーワードと
スライド中のキーワードと講義音声の
書き起こしから得られる単語列をＤＰマッチングで対応付け
対応付けはＤＰマッチングで行います
でこれで
スライド中の出現順位を維持しながらこのように
ぽんぽん対応付けていくと
いう
方法です
で
以上が抽出単位を複合語に対応しましたという話で
次にキーワード
の認識率の向上未知語への対応ということで
先ほどお見せしたこの方法では
この書き起こしの単語列に
たとえば
単語単語単位でのマッチングを行うために
書き起こしに表れてこない
ものはそもそも
キーワードとして抽出されても書き起こしに現われなかったらそもそもマッチングできないという
問題が
あります
また
認識
認識システムの辞書にその
キーワードの一部が未知語が含まれていたら
書き起こしにどうやっても認識できないという問題が
ありますそこでまずはキーワード
の
言語モデル中のキーワードの認識率キーワードの
出現確率を恣意的に操作することで
とりあえずキーワードを一杯出すような言語モデル
というものを
作りました
またキーワード中の未知語を
辞書に追加して
とりあえず未知語
追加した未知語に関しては認識できるような
状態にしてどのようにマッチングがうまくいくかということを
確認しました
で言語モデルの確率の
変え方なんですけれども
このようにとても簡単に
元のユニグラムをα倍するだけで
というものです
で
このＦはフロアリング係数として底上げプラス
でやってます
これはユニグラムが〇の
例えば未知語は追加してもユニグラムが〇の場合がありますから
このＦで無理やり確率をつけると
いうことをやってます
でバイグラムトライグラムについてはこれと同じ
倍率で
修正して
います
でこのようにキーワードを無理やり増やした分は他の
単語のユニグラムを下げて
この正規化係数Ｃで下げて
バランスを保っています
未知語の追加ですけども
例えばキーワードウェーブレット変換というのがあって
このウェーブレットの部分が未知語であると
言う場合にはこのウェーブレットだけを
認識辞書
言語モデルの学習の語彙に
追加しますそして言語モデルを再学習させてエントリを作成します
でこの場合このウェーブレットがたとえ学習コーパスに含まれていなくても
とりあえずそれは後の言語モデルの確率を操作しますので
含まれているかいないかということは考慮しません
でこうやって作った言語モデルを
正解文に対してリコールとプレシジョンで評価しました
またこのキーワード言語モデルを使って認識した書き起こし列に対してＤＰマッチングインデキシング処理を行ってうまく
マッチングできるかというのを評価しました
でこちらがその結果
なんですけれども
すいません講義三の一しか
なんか表示されないですけども
おかしいな
αの値を
二と五と十十五二十といろいろ変えて
やったところこちらほうに講義一の一
ったはずなんですけども
表示されていないですけども
まα＝五の時にもっとも大きい値となりました
またこっちの講義三の一ではあまり変化がないですけども
講義一の一ではα＝五のあたりでかなりオリジナルのなにも操作していないモデルと比べると
キーワードのリコールプレシジョンは大幅に向上しました
ただリコールプレシジョンは向上したんですけども実際にそれインデキシングの処理を行っても
元のモデルと変わらないという結果に
なっていますでこのマッチングミスの原因なんですけども
実際は抽出されたキーワードキーワードとして抽出されたうちのほとんど半数以上が
発話されていないということが
しらべ
調べてわかりました
でこちら講義の三の一なんですけどもこちらは
キーワードモデルを使うことで
マッチングできた単語の数が
少し増えたんですけども
こちらの
一番右側が未知語に未知語を追加したモデルなんですけども未知語を追加しても
そもそも
その未知語を含んだキーワードというのは
発話されていなかったということが分かって
あまり効果がないこととなってしまいました
まとめますと講義音声の自動認識では
コンテキスト依存音節モデルの効果
が確認できました
コンテキスト独立音節モデルと比較してコレクトで五．四四％アキュラシーで一．３４％
向上しました
でインデキシングについては複合語のキーワードを抽出可能にしました
でキーワード認識用の言語モデルを使用して
キーワードのリコールとプレシジョンそのものは
向上したんですけれども
向上した書き起こし列を使って
インデキシングの処理を行ったところ
マッチングできるキーワードの数というのは特に増えもせず
変化は見られませんでした
実際にはキーワードとして
スライドから抽出されても
発話されていないものが多かったのが
一番大きな原因だと
思います
今後の課題としては
キーワード抽出の洗練ということで
先ほど
講義の講師の本人
の方から
正解キーワード集合
を抽出してもらってそれとのリコールプレシジョンが低かったということを言いましたけども
これをなんとかしてもうちょっと上げたいと思っています
でより自然なキーワードモデルの構築
今回使ったαとか
Ｆは
恣意的な適当ななんの根拠もない値ですので
その辺をもうちょっと自然に作りたいと
思います
またはマッチングを単語単位ではなくてもっとサブワード単位などで
ワードスポッティングを行うことなどが
考えられます以上で発表を終わります
