はいじゃあ
時間になりましたので
次のセッション始めたいと思います
次のセッション
最初の発表は私
から固有表現抽出を用いた
認識誤りに頑健な
音声ドキュメント質問応答というタイトルで豊橋技科大のが
発表させて頂きたいと思います
はいまず背景ですけれどもこのワークショップの趣旨にありますように音声認識技術が高精度化
実用化してきまして
音声データを文書のように扱うことができるようになってきていると
でそういう技術を音声ドキュメント処理と呼んでるわけですね
で従来テキストに対して行なわれてきたさまざまな技術検索とか要約とか
質問応答とかマイニングとかそのへんの技術を音声
音声データ音声ドキュメントに対して適用してやろうと
いうことそこが鍵となるような技術になると考えています
でこの発表は
いろいろな技術のうち
質問応答というものに焦点を
当てます
で音声ドキュメントを対象とした質問応答というのは
単純に実現しようと思えば
一度
音声データを大語彙連続音声認識で書き起こしを
生成してしまえば後はテキストからの質問応答の問題に帰着されますので
テキストベースの
質問応答システムをそのまま適応すると
いうことが可能になります
だけれどもその時に問題になるのが
認識の時の
認識誤りですね
で書き起こし
に認識誤りが含まれる可能性があると
で認識誤りが含まれる書き起こしに対して
質問応答を
実行するわけで
質問応答の性能が
著しく低下してしまうという問題点があります
でこの問題は非常に
特に質問応答の場合には
大きな問題がありまして
と申しますのは
質問応答の質問というのは
答えとしてですね固有表現を問うという場合が非常に
多い
で
固有表現というのは
多くの場合ですね
認識デコーダの
ＯＵＴ ＯＦ ＶＯＣＡＢＵＬＡＲＹ認識語彙外の語になると
そういう語を含んでいるという可能性が非常に高いものですから
答え自身が正しく認識できないと
いう可能性が高い
でその場合質問応答を適用しますと
答が
正しく認識
されてないと抜け落ちているというテキストから
質問応答をやろうという問題になりますので非常に
困難になってしまうと
いう
問題点があります
でこの問題点に対して
我々ここのこの研究では
従来質問応答で使われています固有表現抽出と
呼ばれる技術これの代わりに
もっと大雑把にですね固有表現検出というものに置き換えてやろうというアプローチを取ります
これは
要はテキストの中から
特定の固有表現
が実現する
位置まで特定して抽出すると
いうのはもう
難しいとそれは
難しいであろうということ
から
それは諦めて
もうちょっと大雑把にですね
あるセグメントある範囲の中に
今注目しているタイプの固有表現が
含まれているか含まれていないか
いうことを擬似判別してやろうと
でこういう手法に置き換えることによって認識
誤りを含んでいるような
テキストに対してもロバストに
質問応答ができるであろうと
いうアプローチをとりました
でまず
固有表現検出をまず実装してみましたでこれは
固有
表現
タイプ毎の二値分類器を使うことで実現をしましたで二値分類器としましては
今非常に性能が高いと
言われておりますＳＶＭを使いました
でこのＳＶＭは
各タイプごとに用意して
二値分類
してやろうとセグメントに
こういう表現は含まれているか含まれていないかというのを判定してやろうと
いうことをやりました
で特徴量としましては
セグメントの
単語Ｎグラムおよび品詞Ｎグラムを使いました今回非常に単純な方法ですね
テキスト情報だけを使って
単語のＮグラムと品詞のＮグラムを使いました
で今回利用した固有表現のタイプとしましてはＩＲＥＸで定義されている七つのタイプに限定しました
これはＰＥＲＳＯＮＬＯＣＡＴＩＯＮＯＲＧＡＮＩＺＡＴＩＯＮ
ＤＡＴＥＴＩＭＥＭＯＮＥＹ
ＲＡＴＥこの七つですね
この七つそれぞれのタイプ毎に
固有表現検出器をＳＶＭでこう
構成して
セグメントにこういう表現は含まれているか含まれていないか
いうのを判別してやろう
でまず固有表現検出の性能を調べてみました
性能を調べるための予備実験を行いました
データとしましては
ＮＨＫのニュース音声データベースこれは百十七番組を含んでおります
でこのうちですね
三十番組
を
使いました
でこのデータベースに対して
人手書き起こしを
行なったテキスト
と
あと大語彙連続音声認識を使って自動的に書き起こした
テキストというものを
用いました
で
三十番組に対して今回
人手で
書き起こしたテキストを調べることで
固有表現のタグ付けを行ないました
で
そしてこのデータを
学習用と評価用の両方に使いました
で残りの八十七番組はその後の質問応答の評価
性能評価のためにとっておきます
でその三十番組に対して
十二点交差検定で性能を評価しました
でこの時ですね
注目している認識誤りの影響を
見積もるために
固有表現が正しく認識されていないというところに注目をしました
どういうことか
と申しますと
三十番組
の
うち
固有表現
が正しく認識されているセグメントは除いて
認識されてないあるいはそもそもその固有表現は含まれていないと
いうセグメント
だけ
各タイプ毎にそういう
発話
だけに注目して
固有表現検出の性能を
調べてみましたでこれを
ルールベースの
利用可能な
テキストベース
テキストを対象とした固有表現抽出器
ＮＥＸＴですねＮＥＸＴと
いう抽出機と性能を比較をしました
でこちらがまずＰＥＲＳＯＮの結果なんですけれども
実はＰＥＲＳＯＮに関してはＮＥＸ
Ｔは
そこそこロバストに動きまして
認識誤りが含まれた場合でも
ある程度
認識ができたとでこれはなぜかというと
人名の場合その直後にですね肩書きのような表現がくるでそこを手がかりに
ＮＥＸＴの場合
比較的
うまく抽出ができている
ただ今回使いました
固有表現検出を使いますとそれより若干良い
結果が得られる
特徴量の選択によって性能がさまざまですけれども
少し良い結果が得られると
あと今回使った固有表現検出の特徴としては
ＲＥＣＡＬＬとグラフの説明しておりませんでしたけどこれ横軸が
再現率で縦軸が
精度です
で
固有表現検出を使いますとＳＶＭの閾値をコントロールすることで
ＲＥＣＡＬＬとＰＲＥＣＩＳＩＯＮのコントロールができると
いう特徴がありますこれこれを
ＱＵＥＳＴＩＯＮＡＮＳＷＥＲＩＮＧ質問応答に
有効できる有効利用できるであろうという風に考えられる
で次
ＯＲＧＡＮＩＺＡＴＩＯＮの場合ですけどもこちらの場合は
ルールベースの通常の固有表現
抽出を使うと
あまり高い性能は得られない
今回の
検出の方を使うと
それなりにロバストに動いているということがわかると思います
でもう一つ
これは今度は数量表現の方ですけれども
ＭＯＮＥＹについてみる
みてみますこれも
検出を
今回使ったものを使うと
より精度が高いと
で特に
こういう
表現抽出は数量表現ですね認識誤りをこうして通常表現に関しては
あまり良い性能が得られてないという
結果が得られていますそれに対して
抽出を
固有表現抽出を使うと
ロバストに検出ができていると
いう結果です
で予備実験の結果をまとめますと
固有表現
検出が固有表現が正しく認識されなかったテキストに対して
総じて高い性能を
示しました
でその時にわかったことは
固有表現のタイプ毎に
効果的な特徴量というのはさまざまである
いうことがわかりました
で例えば
数量表現には単語の特徴量だけを使う方が
効果的であると
いうようなことがわかりました
で
また固有表現抽出の方に関してもタイプ毎にかなり性能が違いまして
先ほど見ましたようにＰＥＲＳＯＮに対してはまあまあ
高い性能を示しますが
数量表現に対してはあまりよくなかった
いう結果がわかりました
そこでこの結果をふまえまして質問応答システムへ固有表現検出を統合
を
して全体の性能を調査を致しました
統合方法ですけれども
従来法ですと
固有表現抽出を使う部分に関して検出を使って
発話単位で
答えを出そうという実装をしましたもう固有表現の
位置を
決めるのはあきらめまして
問題設定として
固有表現あるセグメントが固有表現
注目する答答を含むような
セグメントであるかどうかというのを見つけましょうという問題で
質問応答システムを構築しました
で
従来と違うのは質問解析で
予測された固有表現のタイプを
今回
使った固有表現検出
で利用するタイプ情報として使うと
いうことですね
で
そして最終的な回答というものは
パッセージ検索の
で得られたスコアと
固有表現検出で
得られた時のＳＶＭのスコアですねこれを
シグモイドファンクションで
ノーマラズしまし
少し慣らしまして
線形補完したと
いう形で
スコアを計算してこれを
使って
各
発話をリスコアリングして出力をすると
いうような実装方法をとりました
で先ほどの予備実験の結果を踏まえまして
各固有表現タイプ毎に最も性能の高い
固有表現検出器の設定を選択を致しました
で今回選択をしたのは
特徴量に何を使うかという選択と
その閾値ですね
ＳＶＭスコアのどこからどこまでを
どこまでどこ
から上を正例とするか負例とするかその閾値を
自動的に選択をしました
でその時の
最も高い性能とその性能を測る尺度として
Ｆ（３）—ＭＥＡＳＵＲＥというものを使いましたこれは
Ｆ—ＭＥＡＳＵＲＥの一般化
になっておりまして
その精度再現率をコントロールしたした
式になっております
で今回はＦ（３）
ＴＨＲＥＥ三というものを使いましたけどこれは
意味としましては精度よりも再現率の方を三倍重要であるというふうに考えた
尺度になっています
でこの尺度を使って
先ほどの
予備実験の結果を
使っ
て
最も性能が高くなるような
閾値と特徴量を自動的に選択するということをやりました
で下の表がその選択の結果ですが
各特徴量毎に
ＦＥＡＴＵＲＥとその閾値を決めてやると
でこの結果から
わかることには
ＬＯＣＡＴＩＯＮＯＲＧＡＮＩＺＡＴＩＯＮＤＡＴＥに関しては品詞
も素性に使う方が
良いと
で他に関しては単語だけのＦＥＡＴＵＲＥを使う方が良いというのがわかりました
で閾値に関してもそれぞれ
最適な値というものを求めると
いうことです
評価実験ですけれども
先ほど
予備実験に用いなかった学習データに用いなかった
残りの八十七番組ですね
七百九十二
の記事と六千七百の発話を含んでいます
でこちらを
検索対象としました
質問応答で
評価実験を行いました
で
ちょっと
予稿集に間違いがあるんですけれども
事実型質問は予稿集では五十問になっていますが
四十問で評価を
致しましたでこれは
五十問用意しましたけれども今回対象とした八七十番組に答がそもそも見つからないと
いうものが十問
ありますので
それを除いて四十問
ということになりますで内訳は
二十五問が名称を問うような質問で十五質問が数量を
問うような質問になっております
で評価尺度としましては質問応答の性能評価によく使われますＭＲＲという手法を使いましてこれは
システムが順位付けで
正解を出し回答を出した時に
一番高い順位に
ある正解の順位の
逆数ですねこれをスコアとして
全質問で平均をとったという値になっています
比較した手法としましては二つの手法と比較をしました
でまず
ベースラインの手法として
パッセージ検索だけを使うという手法を用いましたこれは
先ほどの
質問応答システムの中で
要はパッセージ検索だけを行なってそのスコアだけで順位付けをしたということに
等しいわけですね
すなわち
質問から質問解析でわかるような
固有表現タイプの情報を全く用いない場合の性能
ようなシステムになっています
でもう一つＮＥフィルタリングと呼んでいる手法と比較を行いましたこちらは
通常のテキストベースのＱＡと同じようなアプローチを取った方法で
各
パッセージ検索の結果の各候補パッセージに
通常の固有表現抽出を適用してやると
でその時に
質問から予測された固有表現タイプが
タイプを持つような固有表現が抽出されなかった場合にはその候補を棄却してしまうというような
方法です
でその固有表現抽出器としては現在利用可能な二つのものを利用しました
一つはルールベースの
抽出器でＮＥＸＴ
と呼ばれるものです
でもう一つは
機械学習ベースのものでＣａｂｏｃｈａ
ですねＣａｂｏｃｈａを使いました
こちら実験結果ですけれども
縦軸がＭＲＲ
になっていますで
左側からベースラインのパッセージ検索を使った場合
ルールベースの
ＮＥフィルタリングの場合機械学習のＮＥフィルタリングの場合で
一番右が今回の提案手法です
で
ＮＥフィルタリングを使う場合はやはり
過度にですねフィルタリングを
行なってしまいまして
元々のパッセージ検索だけを使うという方法に比べて
性能が悪化してしまうという結果になりました
で提案法は
固有表現の情報を利用して元々のパッセージ検索の
性能を改善すると
いうような結果が得られています
でさらにですね
今回認識誤りの影響を
見たいということで
わざとですね認識誤りを
起こすような
書き起こしを作成してそれに対して性能がどうなるかということを調べました
で
そのためにですね
今回使った手法は
書き起こしを生成する
大語彙連続音声認識レコーダですねこれの認識語彙から
そもそも質問の正解になるような
正解を構成するような単語を
消去してやってこれを使って書き起こしをすると
いう方法を使いました
すなわち
これによって認識されたテキストに
は正解の
単語が必ず含まれ
含まれないと
現れないということになります
で
これを質問中
数量表現はちょっと対象にしませんで
名称
になるよう名称が答になるＰＥＲＳＯＮＬＯＣＡＴＩＯＮＯＲＧＡＮＩＺＡＴＩＯＮに対して
認識辞書辞書から削除をしてそれを使った書き起こしを対象に
質問応答を用いてその性能を調べました
実験結果ですけれども
認識誤り
が含まれるということで全体的に性能は下がるんですけれども
提案手法は
認識誤りが含まれているという状況でも
まだ
多少の改善は行なわれてると
で
ＮＥフィルタリングの場合は
二つのＮＥフィルタリングを
使いましたけどもそれぞれちょっと性能性質が違いまして
ルールベースの
固有表現抽出を使った場合は
そこそこロバストもともとの正しく認識された場合でも
あまり性能は高くないんですけれども
認識誤りに関してはそこそこ
頑健に動いてると
じゃあそれに対して
機械学習を使ったＮＥフィルタリングを使いますと
認識誤りを起こしていない場合には
性能は高いんですけども
誤りを起こした時に性能の低下が激しいと
いう結果が
得られました
で実験結果をまとめますと
提案手法は新しく認識された場合でも誤認識された場合でも
共に良い性能を示しました
でベースラインよりも固有表現の情報を使うことで性能を改善し
また
誤認識された場合でも頑健にもっていくということがわかりました
で
パッセージ検索だけを用いたベースライン手法は
認識誤りが含まれる場合でも頑健には動きますけどもそもそも
固有表現の手がかりを用いてないために
その性能には限界があるであろうという風に考えられます
で
以上ですけども今後の課題としましては今回
ちょっと単純な手法で固有表現
検出を
実装しましたけども
その性能の改善をするということが考えられます
で例えば
特徴量にもう少しいろいろなものを使ってやろうとか
認識の尤度とか信頼度とかデコーダから得られる情報を利用してやろうということが考えられます
あるいは
音声ドキュメントを対象にした質問応答に関しては
認識誤りに対処するようなその他の
様々な手法の適用を考えていきたいと
認識Ｎベスト候補を利用したり例えば今回の
ニュース音声
ですと
それと同内容のテキストテキストの
データというものが
手に入る可能性がありますので
それと併用してやることで
性能を改善すると
いうようなことが考えられると思います
以上で
発表を終わります
ご質問が
ありましたらお願いしますはい
