豊橋技科大のと申します
おはようございます
発表は私が行ないますけれども、本発表は君が
やった仕事の発表になります
で
翻訳モデルを用いた内容、音声ドキュメントの検索というタイトルで前回のワークショップでも
発表させて頂きましたけども、この発表はそれのその後の進展の話でして
文脈情報を使った文書拡張と言語モデリング
検索手法を適用したと
いう内容になっております
はい。それでまず研究の背景ですけれども
このワークショップの目的にもありますように、音声認識技術を
使うことによって、音声データをテキストのような
文書のように扱うことが可能になりつつあります
で
そこで音声ドキュメント処理と
いうことをやりましょうということになります
でその時に鍵となる技術は従来テキストに対して行っていた様々な技術を音声に適用してやろうと
で検索とかですね要約とかマイニングとかいろいろありますけども
その中で検索というのは中心的な
技術になるだろうという風に考えられます
はい。それで
でこの研究も検索を対象と致します
ただですね検索
の中でもこの研究は内容検索
を対象とします
で音声の
対象とした検索では検索といいますとよくキーワード検索ですね。こちらの方
指すことが多いんですけれども
この研究では与えられたクエリに
内容的に一致する、内容が
合致する文書を見つけるタスクと
いうものを対象とします
図で
説明しますと、キーワード検索というのは
クエリとして何かタームを与えて、音声ドキュメントの中からこのターム
が発声されている位置を特定しましょうというタスクです
でこれに対して内容検索の方は
クエリ
に
クエリ文のような形でクエリを与えてそのクエリの内容と一致する
文書を
文書集合から見つけましょうというタスクを指しております
はい。それでこの研究の目的はその音声ドキュメントを対象とした
認識誤りに頑健な内容検索手法を開発するということにあります
で本発表では新し
く
こちらの三つの
研究を行いましたのでこれについて発表したいと思います
はい。発表概要ですけれども
まず最初にこの研究で使います検索
タスクについて
説明を致します。使用しますデータと
タスク設定、そして評価尺度について説明します
でその後に
提案手法
を
説明します
で
評価実験を交えて説明していきたいと思います。まず
検索タスクの方の
説明を致します
で本研究はＣＳＪテストコレクションと
いうものを使用しております
これは日本語話し言葉コーパスＣＳＪの
学会講演と模擬講演
全部で二千七百二講演、これを対象とした
検索用のテストコレクションです
で
このテストコレクションは
講演を検索するタスクではなくて
講演の一部ですね。その講演の中に含まれている情報ですね。これは
発話を単位としてどのぐらいの長さにあるかっていうのはそのクエリごとにまちまちですけれども
その可変長の区間を
探すような検索タスクが設定されています。で三十九の質問が用意されておると
で詳しいところは
第一回目のこのワークショップの発表あるいは
今月
発行になりました音声情報処理学会の音声ドキュメント処理
特集で発表しておりますのでそちらをご覧頂きたいと思います
はい。でどういうタスクが設定されてるかと言いますと、例えば情報検索性能を評価するような
するにはどのような方法があるか知りたいというような
クエリが与えられていると
で
ここに示したのが
ＣＳＪの書き起こしになります。で
一行毎に発話
と呼ばれる単位で書き起こされていると。でこのクエリに対して
こういう区間ですね。
この部分が正解だよと
いうふうにタグ付けがされています。でここを探しましょうと
でこの正解部分ていうのは発話
単位でタグが付いていますが
その長さに関しては
回
答に応じて
長さがまちまちである
いうようなものになっております
でこのデータを使いますが、まず
その可変長の区間を探すというタスクは少し難しいので
まず問題を単純化致しまして検索タスクを再設定致しました
どうしたかといいますと
その音声の講演を
予めですね一定長の固定区間に
分割しておきます
そして
各区間をそれぞれ検索対象の文書と見なして
その文書を探すという内容検索タスクというものを設定致しました
それでどういう区間でどういう長さの区間で区切るかということで
いくつか試しました
で本研究では
十五発話三十発話六十発話で試しましたけれども
この中で、この発表では
こちらですね。十五発話一番難しいケースですね
こちらのでのこちらの十五発話を使った結果を報告致したいと思います。予講集の方には全て載せておりますけれども
この発表では十五発話
時間の関係で十五発話だけを述べたいと思います
過去の研究から
この手の研究だと
短い区間の方が効果があると
いうことはわかっております
はい。それで
再設定した検索タスクですけども
このような書き起こしに対して
先頭からですね、予め十五発話の区間で
自動的に区切って
っておくと
でそれぞれの区間を
検索対象の文書だとみなしてこの文書を見つけましょうと
いうタスクを設定致しました
そして正解タグが付いていますけれども
ここ、こういうもともとのテストコレクションの正解ですね、これが少しでも
被っていると
いう区間
を正解だと見なして
この区間を見つけましょうと
いう設定を行いました
でこのＣＳＪテストコレクションですけれども
この分野でよく知られているＴＲＥＣのＳＤＲタスクコレクションというのがありますけれども
言語とか
対象言語が
対象文書、ＴＲＥＣの場合はニュース音声ですね。ＣＳＪの場合は講演音声と
対象としている音声の分野が違うんですけれども
今のように
予め固定区間で区切ると
で三十発話区間を使った場合にはだいたい
ＴＲＥＣＳＤＲコレクションとコンパラブルな
規模のコレクションになっていると
いうことです
はい。それでこの研究での評価尺度は
十一点平均精度というものを用いました
でこれは
０％から百％までの
十％刻みで再現率を取りまして、その十一点
各点での
精度を出してそれを平均化するというような評価尺度になっています
これを
用います
はい
で以上で検索タスクの説明
は終わりまして、後半の
提案手法の説明に移りたいと
思います
まずベースラインの手法ですね。ベースラインになる手法として
とりあえず認識して書き起こしをしてそれで
テキスト
をそのテキストを使って検索をしましょうという普通の手法を
実装しました
大語彙音声連続認識によって検索対象の音声ドキュメントをテキストに書き起こしてその書き起こしたテキストを
そのまま
通常のテキストだとみなして索引付けをして
検索をしましょうと
いう方法を取りました
でもちろんこの単純な方法だと、認識誤りとかデコーダに含まれない語彙ですね、アウトオブボキャブラリーが存在しますので
検索性能が低下するという問題点がございます
はい。一応ベースラインの検索手法は例えば
こういった
ある区間を見つけたいというタスクを設定して
例えばこの真ん中の区間
に注目しますと
ここの部分ですね。この部分の書き起こしテキストだけを使って
これを使って索引付けしましょうと
いうような方法を取ります
はい。それで今回試した方法の一番目としましては
文脈を利用した文書拡張と
いうことを行いました。でこれは
要は普通の文書検索タスク
と違いまして、このタスクですと
同じ講演から抽出された文書というのはたくさんあるということで、文書間が独立ではなくて
互いに関連していると
それを使いましょうと。で特にある区間に注目すると
その前後の文脈というのは
おそらく非常に内容的に近い
ものが含まれているでしょうということなので
前後の文脈を利用して文書拡張を行なって索引付けをすると
いうことを行ないました
でその時にパラメータとしてどの程度の範囲を文脈とするかという選択があります
で今回はここ前後のＮ発話ですね。これをＮをいろいろ変えて
実験を行なってみたと
であるいは
文書拡張を行ないますけれども、そもそもの検索対象の区間っていうのは
文脈に比べると重視をして
した方が良いであろうということで重み付けの割合ですね、これをどうするかというのを考えました
で
この式のうち
要は元の文書のＴＦと文脈の
タームフリクエンシーを合わせるわけですけども
その時に
元の方の
文書ですね。こちらの元の文書のＴＦに関して
少し重み付けをしてやりましょう。β
倍してやりましょう、ということをやって
索引付けを行なっております
はい。手法としましては
この真ん中の区間に注目しますと
ここ
をだけを使って索引付けをするというのがベースラインですけども
これに加えて前後のＮ発話も索引付けに利用しましょうと
いうことをします
でその時に真ん中部分ですね
真ん中はちょっと重視したいのでβ倍してやると
いうことですね
はい。いきなり結果ですけれども
実験結果です。横軸がですね、先ほどの重み付けのβで、一から十ぐらいまで変えて
実験をしました
で文脈長としては十五発話、三十発話、六十発話
で比較をしてみたと
いうことですね。縦軸が先ほどの十一点平均精度になっております
でこれを見ますとベースラインがこちらの点線になっておりまして、やはり文脈を使うと
検索性能が
かなり改善すると
いうことがわかりました
でその中でも
重みとしては五程度かな
それで
文脈長としては三十発話ぐらい使うと良いのではないかということがわかりました
はい。続きまして
以前提案しました翻訳モデルとの併用ということを行いました
でこれは
今の文脈
を利用した文書拡張と以前の方法と
併用したと
いうことですね
でまず翻訳モデルに基づく音声ドキュメント検索て何だったかというのを
説明したいと思いますが
これは
音声認識による自動書き起こしテキストから
そもそも誤りの無い
書き起こしテキストを予測して索引付けしましょうと
いうことを行ないます
でそのために
統計的翻訳モデルというものを利用します
すなわち
認識された単語が与えられた時に、それが
どういう単語に
本来どういう単語だったのかということを予測するような
単語翻訳モデルというものを使って索引付けしましょうと
いう方法です
で概念的には音声ドキュメントがあった時に自動書き起こしをしますと認識誤りが含まれていると
でこれに対して翻訳モデルでいろんな単語を予測してやって
その中に正しいものも正しくないものもありますけれども
中には正しいものも含まれていると
で翻訳モデルで文書拡張をしてやると
検索
が
性能が上がるであろうという
考え
に基づくものです
でこの手法でまず
単語翻訳モデルというものを推定する必要がありますが
これは
自動書き起こしテキストですね。認識結果と
人手の書き起こす
テキストの対からなる
パラレルテキストから推定を行なっております
説明としてはこのようにですね
自動書き起こしのテキストの単語列と人手書き起こしの単語列があると
でこいつに
この二つを
対応付けするしてやると
でアライメントを取ると正しく認識されたとこはこのように一対一で対応付けができる
で認識誤りが起こったところに関してはどこ
に対応
付けすれば良いかわからない
でここを確率的に
割り当てましょうということですね
でこの確率の推定方法ですけれども
今回はですね、いくつか方法試しましたけど、今回は非常に単純な方法を使っています
要は
正しいところに関してはもう一意に決まっていると
で正しく
認識誤り起こしているところに関しては
可能性のあるところについて
均等に配分してやりましょうと
でこの
断片化したカウント
でアライメントされているというふうに考えて
あとはこの断片的なカウントをパラレルテキスト全体で
集計してやって
モデルを最尤推定してやりましょうと
いう方法を取りました
でこちらの翻訳モデルを用いますとそもそも正しい
語で、どのぐらいの単語単語フリクエンシーがあるかということが推定できます
でそれはこちらの式で行ないますが
こちらですね
そもそも認識されたものを単語フリクエンシー
に
先ほど推定した翻訳モデルを使いますと
正しい語の
単語フリクエンシーの期待値が求まると
でそれ
単独ではなくてそもそも
認識された語の単語フリクエンシー
も線形補完してやると
いうことで
推定された
頻度というものを推定して
それで索引付けしましょうということです
でこの手法をですね、先ほどの文脈を利用した文書拡張手法と
併用
しました
というのが
今回やったことです
でその併用方法ですけれども
先ほどのようにですね
先ほどのコンテキストは元の文書だけではなくてコンテキストも
の単語を使いましょうということをやりましたので
各
それぞれですね、元の文書の
翻訳モデルに
よる推定と文脈
における推定ですね。これを
そのまま使って
索引付けする単語フリクエンシーを
求めてやろうということをやります
はい。でこれが実験結果です
縦軸が検索性能で横軸にそれぞれいろんな手法が載っております
で
ベースライン手法に比べて
先ほど見たように文脈を利用すると
性能が向上すると。で同じようにですね
翻訳モデル単独で使用した場合でも
性能は向上するということが
わかりました
だけれども、今の方法でですね両者を併用すると
性能が下がってしまっていると
いう結果が得られました
でこれはちょっと変な結果なんですけども、よくよく調べてみますと
何で悪くなったかというと
単語のＩＤＦ
ちゅうかですね
総じて小さくなって、なっていると
いうことがわかりました。でこれはそれぞれの手法がですね
ＩＤＦ
適応するとＩＤＦが
低く見積もられてしまうと
いう手法になっていまして、でその両者を組み合わせることで
効果がですね、組み合わされて
合わされてしまって
ＩＤＦ値が
小さくなってしまったと
でこの重要度が正しく推定できないということに起因して
性能が下がってしまったのであろうと
いうふうに
考えます
で提案手法の三と致しまして
今のですねＩＤＦに起因する問題を回避するために
検索モデルを変えて
検索をしてみましょうということをやりました
で先ほどのＴＦＩＤＦ重み付けを行なう
使ったベクトル空間法の代わりに
言語モデリングに基づく検索手法
というものを用いて検索を
行なって、てはどうかということを実験してみました
でまず言語モデリングに基づく検索手法ですけども
こちらの
ような方法になります
こちらの手法は
検索対象文書から検索質問
が得られる
確率ですね
Ｐ（Ｑ｜Ｄ）
これを推定してやると
でこれによって文書Ｄの順序付けを
行なってやりましょうという方法です
でＰ（Ｑ｜Ｄ）ですけれども
各クエリに現れる単語が独立であるという風に仮定するとこちらのように
分解できまして、さらに
この各クエリ単語の
ユニグラム確率ですね、これをですね
こちらの式で推定してやろうと
いうことをやります
でこの式はですね、要は
こちらが
検索対象のＤから推定した単語ユニグラム
に相当すると。でこちらは文書集合全体から推定した単語ユニグラムに相当します
で
この二つを線形補完してやってスムージングを行なって
クエリに現れやすい
単語というものを推定しましょうと
いうことをやります
はい。でこの手法と言語この手法と先ほどの翻訳モデルとの併用ということをやりました
で
式はこちらのように
なりまして
両方とも確率的な手法なので
比較的
ストレートに統合することができます
でこちらが
先ほど求めた言語モデルに基づく
単語ユニグラム
になります
でこれに対して
翻訳モデルですね
こいつを組み合わせて
そもそもの
正しい単語というのを推定して
やると
いうことですね
で
いうことで
Ｐ（Ｑ｜Ｄ）というものを推定しましょうということが
できます
ただしですね今回の実験ではこの推定式をそのまま
使う
わないかのようにちょっと近似を入れました
どこを近似を入れたかというと先ほどですね
翻訳モデルを
用いた検索手法で
ＴＦの推定値ってのを出しました
でそこで求めたＴＦ値をベースに
単語ユニグラムを推定してやろうということを
やりました
だからこいつの近似になってくる
わけですね
で
こちらだとですねＴＦを一回推定してやってそっからまた
Ｐ（Ｑ｜Ｄ）を推定するということで
推定が二回入りますので少し精度は
精度の点では劣るんですけども実装が
単純でしたので今回はこちらの方法
を取ることにしました
はい。それで
実験結
果
ですけれども
まず
言語モデリング今の方法使った結果で赤色のところ
を注目して頂きたいんですが
この検索手法を、検索モデルを用いた場合には
先ほどのベースラインに比べて
翻訳モデルと翻訳を利用した場合で改善すると。で両方を併用した場合に
さらに改善をすると
いうことですね。だから併用することによる効果というのが認められました
でこれ、この点は良かったんですが、ただ
絶対的な性能の点で、ベクトル空間法に比べるとまだ及んでいなくて
ベクトル空間法での最高性能には達していないと
いうことになりました
で
だからまだちょっと実装方法に問題が残っているのかなあというふうに考えております
はい。それでまとめと今後の課題はこちらのようです。
文脈を利用した拡張によって検索
性能が拡張したと
いうことがわかりました。それで
併用した場合には
ＩＤＦの問題があるということがわかりましたので言語モデル
に基づく
検索を行ないますとその併用の効果が認められました
で今後の課題としては
言語モデリングに基づく手法の実装方法を改善するということが考えられるかと思います
はい。以上で
発表を終わります
