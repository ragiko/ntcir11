それでは始めたいと思います
ちょっといつ
発表者のまずいかもしれませんが
では始めたいと思います．講義コンテンツの収集分析および
講義音声の認識手法に関する検討
としまして静岡大学のが報告を行います
まず研究の背景と目的
ですが
授業ですね大学とかで授業をやっているときに
講義内容
復習できる環境というのが最近整いつつあります
これは授業中に
教員が授業をやっている間にコンテンツを収集して
というツールも最近
出始めてきています
今ちょうど使っていますけども日立のＥＺプレゼンテータというソフトがありましてこちらは
授業コンテンツを
授業をしながら
授業終了と同時に
コンテンツの収集が終わりまして
同時にＨＴＭＬ形式の
授業コンテンツが出来るので後はＷＥＢサーバにあげるだけで
学生
が利用可能な授業コンテンツができるというものです
でこちらにあげている
例が
ＥＺプレゼンテータのビュアーの
ほうになるんですけども
このように
今後ろで録画していますけども
そのように授業の風景
あと
その時点でのスライドの状況
あとこちらはスライドの
タイトルですね
タイトルでリンクが張られていましてクリックしますと
その時の説明
と
ビデオですね
ビデオとスライドが動くと例えば
この
こうクリック
するとしますとこんな感じでして動くというツール
になっています
で他に
ＥＺプレゼンテータ以外にこういうことをできるツールとしまして
ＭｉｃｒｏｓｏｆｔのＰｒｏｄｕｃｅｒっていうのもあります
こちらはＰｏｗｅｒＰｏｉｎｔで作成したコンテンツと
事前録画あるいは後で録画した動画っていうのを組み合わせて連携してコンテンツを作ると
というものですけどもこちらのほうは
講義中あるいは講演中に動的に作るものではなくて後でもしくはあらかじめ作るというタイプの
作成ツールとなっています
でこのようなコンテンツを実際に
学生が見ようとした場合ですね内容にアクセスできる
最小単位っていうのはスライド単位となっています
ですので知りたい内容について
実際に学生が見ようとした時に
どのスライドを見ればいいんだろうという悩みが出てきます
という欠点が
あります
そういったところで本研究の大まかな
全体の目標としましては
知りたい内容を学生が直接
アクセスできる環境を作りたい
いう
ところで何が必要かといいますと
まず
今収集しているような講義コンテンツあるいは講演で録画したようなコンテンツというものを
に対して検索に必要となる情報をインデキシングする必要があります
具体的にはまず
講演
講義の音声を認識
しまして
スライド情報などを使いましてキーワードの抽出あるいは
音声と講演の
あるいはビデオ動画の
同期の処理
あるいは学生が短時間に復習をしたい場合などに要求のある要約をする
という
必要が出てきます
あとはですね，こちらで作成した講義コンテンツに対する検索を
出来るような環境
ビュアーのほうの
実装も必要になってくると
でこちらもたとえばですけども検索用の音声対話システムを作るといったことが考えられます
ここでは特にこちらの
インデキシングのほう
についてもう少し詳しく説明を行います
流れとしましては
収録したコンテンツを
音声認識して書き起こしを作り音声認識結果を作って
こちらのほうは人手で音声の書き起こしを
今のところは作っていますけども
そちらに対して
セグメンテーションインデキシングをしてインデキシング情報を作ると
いう流れになるわけなんですけども
いろいろやってまして
この発表では特に
こちらの
収録してから書き起こしを作って音声認識を
するところの部分について紹介をしたいと思います
まず音声認識率を出すために収録した講義の書き起こしを
作らないといけないわけなんですけども
書き起こしを用意する方針としまして
今回はですねＣＳＪ
日本語話し言葉コーパス
の
で付けられている
タグのサブセットをまず用意
しています
具体的にはフィラー
あと自立語断片であるＤというタグと
付属語の間違い言い直しのＤ二
あと英数字
発音の怠け
などを付与
しています
でこちらはＣＳＪ準拠のサブセットとしていますけどもさらに
話し言葉特有
に起こる現象をもうちょっと分類して付与する必要が
あるだろうと考えて
あとＰｏｗｅｒＰｏｉｎｔの情報ですね今発表しているＰｏｗｅｒＰｏｉｎｔの
ＪＰＧとあとスライドの切り替え時間
今使用しているＥＺプレゼンテーターというのはこのスライドの切り替え時間を自動で保存できる
ツールです
とあと要約情報も付与しよう
というところを狙っているんですが
こちらですね話し言葉的現象
具体的にはどんなものがあるのかっていうのをちょっともう少し詳しく説明します
ここにあげられている五つ
になりますけども
この三つの部分っていうのはＣＳＪ
におけるＤとかＤ二というので表現されているんですけども
こちらというのは
こういうような分類がされているわけではなくて自立語の断片があったらＤ
付属語の
いい直しがあったらＤ二
という大まかな
分類しかしていませんので将来的にはこういう
分類をしていく必要が出てくるのではないかと思っている
具体的に
それぞれ例をちょっと見せますけども
言い直し言い換えはこのような
言い淀み
こんな感じで
次の自立語の一部を言ったところでもう一度止まってしまうな感じ
の
発話
で繰り返しっていうのは
同じ
単語あるいは類義語を
発話するような
言い止めはこんな感じで
途中までいったんだけどそこでもうやめて次に良い直ししない状況ですね
あと倒置
えとこんな感じで特に倒置言い直し
言い足しに関しては結構出てくるのではないかと
て
いろいろ説明のほうしましたが現段階ではここに上げられている三種類についてＣＳＪの
ＤおよびＤ二のタグを付け
たところまで
え
やっていまして
将来的に
収録したデータを公開するような状況になりました
た
こちらのような
タグを
きちんと定義してＸＭＬ形式で保存することを予定しています
といったところで書き起こしを実際に
まだ全部は終わっていないんですけども作りました
で書き起こしの例ですけどもだいたいこんな感じで
ＷＡＶファイルの拡張ファイル名に対して
書き起こしを作る
で
Ｆはフィラーですね間投詞
あとこのような感じで自立語の断片や
付属語この場合は二の
のといってからにと言い換えている
ような
こんな感じでタグを付けていきます
で
三大学で後で出てきますが静岡大学と山梨大学と豊橋技科大の三大学で
講義の収録を行っています
いまもピンマイク二つとハンドマイクひ
使ってますけどもこんな感じで
講義中に複数のマイクを
使って
講義のほうの収録を行っている
現時点で二千五年から収集を開始して
いまして現時点でこのような
感じですね
だいたい五千五ひゃ
く
約五千五百分ぐらいの収録を
行いました
で収録したコンテンツで書き起こしが終わっているものに対してまず講義の
フィラーとか言い直し
の分布を見てみました
大体こんな感じで間投詞は大体四％五％六％ぐらい
平均はこうなったんですけども
フィラーは結構話者の分散が大きいということもわかりました
十％を超えるような
教員の方もいれば一．三％しかいない教員もいるという感じで
分散は激しいんですが大体五六％程度にはなる
ということがわかり
あと言語断片
ＣＳＪでいう言語断片のほうは
こんな感じで
多くても零．八％というところで
一％には満たない程度であると
いうことがまず確認できました
でに見てもらえればようにフィラーというのは結構無視できないというのも分かりし
たでこちらについては
明日の
発表
にて
報告があるかと思います
で実際に書き起こしを
行いましたで講義の収録も行っていますので音声の認識のほうを行ってみました
でこちらのほうはマイクの
収録の仕方やコンテンツが違いますので三大学それぞれで説明のほう行っていきたいと思います
まず静岡大学のほうで行いましたのは無線
のピンマイクと有線のヘッドセットマイク
で収録を行っていまして
それぞれで認識率というのを見てみました
デコーダはＪｕｌｉｕｓで音響モデルトライフォンで言語モデルは
トライグラム
ですけども言語モデルは二つ
ありましてこちらのほうはＣＳＪ
で用意されている
講演模擬講演
対話
その他の全データで学習した
二百
二万一千単語
のものと
こちらは
二千五年
の
収録分の講義データで学習した三千八百語彙の言語モデルの二つを用意し
で収録ですが
こちら日立のフローラになってましてあと無線
ですねこちらは
ＰＣに音声が入力されていまして
こちらはＷＭＶで
えと動画が保存されますので
そっから音声を切り出しています
ですので音声のフォーマットとしましてはＷＭＡとなっていまして
だいたいこんな感じで録音がされていまして認識の時には十六
十六ｋＨｚのＷＡＶに落としてから認識を行って
あと有線のヘッドセットマイクはこういうもの
でこれは今現在ここにもあるんですけどもこれを用いています
こちらのほうは
直接十六ｋＨｚの十六ｂｉｔで録音のほう行っています
で先ほど紹介した二つの
言語モデル
そですね二つを作ったんですけども参考としまして
二千六年
これが一応
認識対象としましてこちらで
の書き起こしでも
言語モデルを作りました
で大体こんな感じになっているんですがちょっと
パープレキシティが
低い
気がするんですが後で出てきますけども
こちら
がＣＳＪ
すね
でこちらが二千五年の講義で学習したものＬ三が二千六年
としたものになっています
で実際の認識結果はこんな感じになっていまして
ＷＭＡ一が無線
のワイヤレスマイクで取ったもの
ですねＷ
こちらです
でＰＣＭがヘッドセットで録音したもの
でＷＭＡ二っていうのは
こちらがＷＭＡで保存しててこちらがＷＡＶで保存していますので
ＷＭＡによる影響なのか無線
ワイヤレスによる
なのかというのがわからないということになっています
でだいたいこのような感じになっていてＰＣＭで録音したほうがいいっていうのが
あたりまえですけどもわかりまし
山梨大学のほう
のほうにいきますこちらでは言語モデル
による認識率の差っていうのを調べました
ＣＳＪの講演プラス模擬講演の一万七千の語彙とあと新聞と
講義の書き起こしですこちらのほうは
豊橋技術科学大学
と山梨大学で収録した講義で学習したものとなって
でパープレキシティとしましてはこんな感じになっていまして
認識ですね
こちらではＣＳＪの
の認識率が一番認識率が高い
とですねこちらの講義Ｂなんですけども
パープレキシティは一番低いんですが認識はそんな良くないのでこの辺はたぶん話者性
話者
として認識がしにくかった
という感じだと
で山梨大学のほうではほかに
授業の
授業評価に関しての評価も行っていましてそちらは
この次の発表で
発表があるかと思い
技術科学大学のほうでは
音響モデルとかデコーダによる認識の差あとマイクの差による認識の差っていうのを調べました
でこちらについてはより詳しい説明が
三二件後の発表である
と思いますのでそちらを
参考にしてくだ
で認識率を見ますとこんな感じで
有線
有線の字漢字間違ってますが有線のハンドマイク
がやっぱり一番いいという結果が得られているのと
コレクトだとＪｕｌｉｕｓトライフォンがよくて
アキュラシーだと
音節
がま
のほうが若干
こちらではよくなっ
感じになっています
認識実験のまとめですけどもこんな感じになっていまして有線のほうがいいというのが当たり前ですけどわかりまし
あとは関連した
講義の書き起こしで学習した場合は認識率が
ＣＳＪよりもいいんですけども
いろんな分野の講義で学習した場合っていうのは
ＣＳＪのほうが認識率がいい
ということが分かる
続きまして連続講義の音声認識という内容に行きます
大学の講義っていうのは通常ある
キュラムにそって行われていますので
ある講義を認識しようとした場合その
講義に関連する
例えば前の
学期に行われた講義の内容を知っていれば
より理解が深まる
というところを認識でも
つかえると当たり前ですけども使ってみようと
すね
こちら二千五と書かれているところというのは
えーと大学の静岡大学の一年生の後期に行われている
プログラミングの授業
で二千六と書かれているほうは
大学二年生の前期ですね
この流れですので同じ学生に対して行っている授業となっています
で一年生後期と二年生前期ですので完全に連続した講義となっ
でこちらについて
ＣＳＪの言語モデルに
二千五年の
講義データをそのまま加えたものをＬＭ四としまして
でデータの比率が
えと大体二百倍
文数の比率が二百倍になっていましたので
こちらの二千五の
講義の内容を二百倍して足したもの
で学習したものの二つを用意しまして
みてみま
で結果がこんな感じになっていまして
こうみるとＣＳＪが
これですけどもＣＳＪに比べて
ＰＣＭのほうは
若干良くなっています
ただし
ある程度無線のワイヤレスだと
ＣＳＪのほうが
いい
ただこちらは
こうなっていますのであまり変わらないで
ＷＡＶだと
若干
向上してるような結果が得られまし
でまとめ
としまして当たり前のことですけどもハンドマイクのほうが認識率が高いということが確かめられました
カリキュラム上連続した講義について
事前の講義の内容を
含んだものを
を使うことで認識率の向上が図られました
今後の課題ですけども
今現時点でもそうしてるんですけどもマイクを三つもしくは四つ付けての講義というふうになりますので
ちょっと
講義がしにくい
という状況が
若干見られまし
ですのでまあ将来的には無線ピンマイク一つで講義をする
て収録をするということが望ましいんですけどもそうすると認識率の問題があるので
認識率をどれだけ近付けられるのか
というところが
問題と
でありましてもう一つは
例えば連続
毎週やっているような講義であれば前の週のデータを使えばもっと良くなる
ですけども
一週間で書き起こしを用意するのは面倒なのでそう言ったところも
考えていく必要があるかと考えています
以上で発表を終わります
