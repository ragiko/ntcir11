では整形された書き起こしからの整形非整形部分の自動検出と題しまして
豊橋技術科学大学のが発表させていただきます
まず本研究の背景といたしまして
話し言葉の正確な書き起こしというのは
各種の音声言語処理のアプリケーションにおいて非常に不可欠なものとなっております
例えば音声認識というのを例にとりますと話し言葉を対象とした音声認識を行なう際には
話し言葉の特有の言い回しに対応した言語モデルというのが必要に
なってきます
従来はこうした場合には認識対象と同一ドメイン
でありかつ話し言葉特有の現象を含むような正確な書き起こし
というのを使って言語モデルを学習すると
いうのが一般的な方法でした
従って
話し言葉特有の
このように話し言葉特有の現象を含む書き起こしというのが非常に
不可欠で
あると
いうことなんですが
ただそうした話し言葉音声を正確に書き起こす作業というのは
時間面費用面の両方において非常に高いコストが必要となってきます
具体的に申しますと
正確に書き起こす
書き起こしの作成というのは実時間の十倍から数十倍の時間が必要となっています
これはなぜこんなにかかってしまうかといいますとまずフィラーや言い淀み言い回しといった特有の現象が発生すること
それから話し言葉特有の言いまわしというのが存在すること
が挙げられますこちらは国会答弁の例になりますがこのように話し話し言葉特有のところがですねえという言い回しが
パスへ出現したり
フィラーや言い直しなどが
出現しますのでこれらを正確に書き起こすというのが非常に
コストがかかってしまうと
いう問題があります
それに対して速記録や会議録といったいわゆる正確でない書き起こしというのは幅広いドメインで
存在をしております
例えばこちらは国会会議録の例になりますが
国会答弁の実際の音声でこのように発声されているのに対して国会会議録ではこのようにフィラーや言い直しが削除され話し言葉特有の言い回しも書き言葉調に置換をされ助詞が補完される
などなどといった整形がされております
こうした整形された形の会議録等は
さまざまなドメインで利用が可能となっておりまた最近ではＡｍａｚｏｎ ＭｅｃｈａｎｉｃａｌＴｕｒｋなどを利用して
非専門家によるラフな書き起こしを作るといった動きも
ありますしまた音声動画といったメディアデータデータもますます増加しておりますので
今後このようないわゆる正確でない整形された書き起こしというのは増加していくであろうと考えられます
こうした背景を踏まえまして本研究の目的としましては整形された書き起こしというのを正確な書き起こしに半自動変換する枠組みというのを
開発を目指しております
この手順としましてはまず第一に整形された書き起こしから整形箇所を自動検出し
次にそうして検出された整形箇所を人手で正確に書き起こすことで効率的に正確な書き起こしというのを作り出します
この枠組みに
に関しましては昨年のこのワークショップでも一度発表させていただきましたが
今回この整形された書き起こしから整形箇所を検出するという点において
改良を加えましたのでその部分についてご報告させていただきます
ということで一度整理させていただきますと本研究の目的としては整形された書き起こしを正確な書き起こしに半自動で変換を
して書き言葉と話し言葉のファイルコーパスというのを効率的に
構築を
すると
でこうすることができますと書き言葉から話し言葉への変換ルールというのが抽出可能になり
また言語モデルのスタイル変換等に応用が可能となります
また検出された非整形部分というのを話者的応用の発音ラベルとして利用することも可能と
なります
具体的な目標としましてはパラレルコーパスのこの構築作業というのを三倍以上効率化できればと考えております
ていうことで本提案手法というのは二段階からなりましてまず第一に整形された書き起こしと原音声との間でフォースアラインメントを行ないまして
このフォースアラインメントによって得られた素性に基づく検出キーを使って
整形箇所というのを自動的に検出をするという手順になっております
まず
第一段階として整形された書き起こしと原音声とのフォースアラインメントについて説明をさせていただきます
今回このフォースアラインメントにつきましてはこちらの図のように
バイグラム言語モデルに基づく制約を加えて使って実現を行ないますご覧のようにこの制約では書き起こしの単語列Ｗ一からＷ二に対して
ある単語ＷＩ
にＷＩから
ＷＩ＋一に伸びているアーク
とフィラーに伸びているアークＳＰすなわちショートポーズに伸びているアークの三通りが
ございましてこれはすなわちこの
ＷＩとＷＩ＋一の間にフィラーとポーズの挿入を許した制約と
なっております
ような制約を用いて大語彙連続音声認識用デコーダを駆動しますと任意の単語間にフィラーとショートポーズの挿入を許したアラインメントというのを行なうことができます
このようにしてアラインメントを実現いたしますがただ問題点といたしまして
書き起こしと原音声との間で対応関係が取れていないと
いう問題がありますすなわち書き起こしのどの
どの単語からどの単語までが原音声の音声区間のどこからどこまでかという対応づけが
多くの場合されていない
いう問題があります
これに対して本研究では以下の四つの手順で
対応付けを行ないます
まず
少なくとも先頭部分に関しては書き起こしと原音声で対応しているだろうと
いうことを考慮して原音声の先頭から約十秒間の発話区間を切り出します
この発話区間に対して連続音節認識を行ないましてその音節認識結果の
音節数に基づいて
発話区間に対応する書き起こし区間の長さつまり単語数というのを推定します具体的には
この
音節認識結果の音節数を
単語の平均音節長で割って単語数を推定すると
いうことを
行ないます
そうして発話区間とその
推定した書き起こし区間とで
アラインメントを行なう訳ですが
今申しましたように書き起こし区間の長さは音節認識結果から自動推定したものですので
一定の誤りが含まれてしまいます
従ってこうしてアラインメントを取ったうちの
特に末尾の部分というのは
アラインメントが誤ってくるだろうと
いうことが考えられますので
今回はこのアラインメントを取ったうちの前半約六秒間
のみのアラインメント結果を信頼して採用すると
いうことを
行なってい
そうしてアラインメントを行なった一つの例がこちらになりますが
今回のように整形された書き起こしと原音声では書き起こしと音声の内容が一致していない部分がありますから
そうした不一致部分つまり整形がされている部分では
実際の発声とは異なったモデルが強制的に対応づけられてしまうことになりますその結果
周囲の音節の対応区間が歪められて
また音響スコアも低下してしまうということが起こります
今回のこの図の例ですと音節ｓｉの区間が不自然に
伸びてしまっておりまたモデルｔｅが
音節ｎｅに
強制的に対応付けられて
います
このような現象が起こることから
音節区間が極端に長いあるいは短い部分
それから音響スコアが極端に低い部分というのが整形箇所である可能性が高いといえます
続いて第二段階としてフォースアラインメントによって得られた素性に基づく検出キー
を用いた整形箇所の検出についてご説明をいたします
今回は整形箇所のこの検出というのを書き起こし中の各単語に対する二値分類問題として定式化をします
例えばこちらの例ですと結果として財政的に豊かになっているのているの部分が整形をされている訳でですのでこのてといるの二つの単語が整形部分と
であるとしてラベル一を
それ以外の部分は正確に書き起こされていて
整形されていない非整形部分であるということでラベル〇
をそれぞれ付与をしまして
こうした二値分類問題
をサポートベクターマシーンを用いて検出を
の問題を分類問題を解くと
いう
ことを行なっています
その
さ検出のための素性としましては今回今回は当該単語直前二単語及び直後二単語に関する
音響的素性と言語的素性を組み合わせて用いると
いうことを行なっています
以下詳しくご説明して
参りますが
まず音響的素性のうち単語単位の音響尤度についてご説明いたします
こちらはアラインメントによって得られた
音響スコアつまり対数尤度を使用いたしますが
ただし単語の時間長によってこの対数尤度を正規化を行ないましてさらに連続音節認識によって得られた音響スコアとの差分を使用します
これにより話者間の尤度の差も正規化をされることに
なります
これはすなわちこのこちらの式のような対数事後確率を素性として用いることに相当しています
またこれに加えまして今回は音節単位の素性も使用します
単語単位の音声素性だけでは音節単位での異常さを検出するには不十分な場合というのがありまして例として
国会会議録ではところがと書き起こされているのに対して実際の音声ではところがですねと発声されている場合というのを考えます
この場合最後の音節が
の部分にのみ音響尤度と音節長に異常が現れます
従って単語単位で
考えてしまいますとこの異常さというのが四分の一に薄められて
しまうことに
なります
例えば
昨年の発表では単語に含まれる音節長の平均値などを
の単語単位の素性を使った結果についてご報告させていただきましたが今回はこの問題を考慮しまして
単語中の
音節で最も異常と推測される音節の
音節レベルの音響的素性というのも使用をいたします
でその音響的素性としましてまず一つめに正規化音節長というものを使用します
この正規化音節長というのは具体的にはまず原音声を正確に書き起こした音節列Ｓ一からＮ
というのと原音声というのを
をアラインメントをおこないまして
各音節の音節長ＤＳＩを求めます
次に音節の種類Ｘごとに
音節長の平均ＥＤＸと分散ＶＤＸを
次式のようにそれぞれ求めます
このＥＤＸとＶＤＸを用いまして実際に出現した音節ＳＪに対してその音節長を次式のように平均〇分散一に正規化を行ないますこうして正規化された
音節長Ｄ〜ＳＪを正規化音節長として使用します
この正規化音節長の考え方としましては各音節の種類ごとに正常ないわゆる標準的な音節の長さというものがあるだろうと
仮定しましてその標準的な音節長からどれだけ逸脱しているかという異常さを
示す尺度になっております
続いてもう一つの音響的素性として正規化音響尤度についてご説明いたします
こちらも同様にまず原音声を正確に書き起こした音節列Ｓ一からＮと原音声とでアラインメントを行ないまして各音節の音響尤度ＬＳＩというのを求めます
続いて音節の種類Ｘごとに音響尤度の平均ＥＬＸと
分散ＶＬＸというのを求めまして
これを用いて実際に出現した音節ＳＪの音響尤度というのを次式のように
平均〇分散一に正規化を行ないます
でこうして正規化された正規化音響尤度Ｌ〜ＳＪというのは先ほどの正規化音節長と同様に
その音節の種類ごとにそれぞれ
存在する標準的な音響尤度に対してどれだけ異常であるかという異常さを示した尺度になっております
以上のよような正規化音節長と正規化音響尤度を用いていくわけですが
ここで国会会議録において最も多い整形処理というのはフィラー言い直し言い淀みの削除であると
いうことを考慮
しますと国会会議録
等の書き起こしというのは実際の原音声に比べて
短くなって
いると
いうことが言えます
従って
整形がなされている部分では
国会会議録のほうが短いので不自然に引き伸ばされてアラインメント
がなされている場合が多いだろうと
考えられます従っ
て従いまして正規化音節長が最大であるような音節
または正規化音響尤度が最小であるような音節というのが最も単語中で最も異常な音節であると
いう可能性が高いといえます
というようなことを考慮しまして今回は以下の四つの素性を音節レベルの音響的素性として用いますすなわち当該単語中の正規化音節長の最大値それと当該単語中の正規化音響尤度の最大
最小値ですね
それと当該単語中で正規化音節長が最大である音節の正規化の正規化音響尤度
そして当該単語中で正規化音響尤度が最小な音節の正規化
音節長
をそれぞれ素性として使用します
またこれに加えまして言語的素性として
整形がされやすい単語とされにくい単語というのがあるだろうということを考慮いたしまして単語情報と品詞情報そして
単語に含まれる音節の総数というのをそれぞれ言語的素性として今回使用いたしました
以上御説明しました提案手法を今回国会会議録を用いた評価実験によって評価を行ないました今回は衆議院の実際の国会会議録の一部をデータとして使用しまして学習データには
七人の話者による計四十二分間の会議録
テストデータには十一人の話者による
計六十分間の会議録をそれぞれ使用しました
また整形箇所の検出器としてＳｕｐｐｏｒｔ ＶｅｃｔｏｒＭａｃｈｉｎｅを採用いたしましたがそのＳｕｐｐｏｒｔ ＶｅｃｔｏｒＭａｃｈｉｎｅ の学習としてＴｉｎｙＳＶＭバージョン〇．〇九を使用しました
カーネルは多項式カーネルを使用しております
またアラインメントや連続音節認識のデコーダとしましては本研究室で開発をしておりますＳＰＯＪＵＳ＋＋を使用いたしました
音響モデルはＣＳＪから学習した音節モデルになっております
ということでまず整形箇所の検出の
ＲｅｃａｌｌとＰｒｅｃｉｓｉｏｎで評価をした結果
がこちらになりまして
今回まず音響的素性と言語的素性の両方を使用した場合と言語的素性のみを使用した場合
を比較を行ないました
ご覧のように音響的素性と言語的素性の両方を使用した結果のその実線と比べて言語的素性のみを使用した場合の点線が非常に低い性能となっておりましてこの性能差から今回採用した音響的素性というのが効果的であるということがわかります
また本提案手法をＬＶＣＳＲ
を用いた結果と比較いたしました具体的にはＬＶＣＳＲの認識結果と整形された会議録を比較しまして
一致する部分については非整形部分であると
で一致しない部分については整形部分であると
して判定するような方法
と
本提案手法を比較しましたまた
本提案その
ＬＶＣＳＲ
を用いた方法の結果が
このグラフのこのこちらのプロットのようになりますがこのように提案手法と
ほぼ変わらない結果となりました
またそれに対してＬＶＣＳＲの結果を用いる方法と提案手法を併用した
方法についても評価を行ないましたその併用の方法といたしましては以下のような方法となっておりますまず第一段階に
整形された書き起こしと
ＬＶＣＳＲの認識結果が閾値以上に連続して一致した部分を非整形部分といたします続いてそれ以外の部分を対象として提案法による判定結果を採用をすると
いう二段階の方法
になって
おります
そちらがこの赤い線の
になっておりますがこのように
提案手法と比べてほぼ同様の結果となっております
このようにＬＶＣＳＲを用いた方法とまたその併用の効果が小さかった原因としましては
今回のような
国会答弁
などの場合にはＬＶＣＳＲの認識精度が比較的低くなってしまうためだと考えられます
また本提案手法を逆に適用しまして
整形されて
整形されていない箇所つまり正確に書き起こされている非整形部分の検出というのを行ないました
今回は音節単位のＰｒｅｃｉｓｉｏｎで評価をしておりましてそれぞれＬＶＣＳＲを用いた方法と提案手法とその併用とそれでまた評価を行ないましたが
このように
提案手法によって整形された書き起こしの
六十％を選択すると
Ｐｒｅｃｉｓｉｏｎ検出精度としては八十．一％から八十六．五％に改善がされました
また提案手法とＬＶＣＳＲを併用した場合には
再現率が四十％から六十％の区間においてやや改善するという結果が得られました
またこうして検出された非整形箇所を
話者適応の適応データとして使用した場合の評価も今回行ないました
結果がこちらのグラフになっておりますがまず話者適応なしのベースラインの失礼しました話者適応なしの性能としてはこの程度
となっておりますがこれに対して単純に国会会議録をそのまま適応データとして使用した場合にはこの程度の
性能となっておりますこれに対して
提案法を用いて抽出した非整形部分を
適応データとして使用しますと
この国会会議録を単純に利用した場合よりも高い性能が得られましたＬＶＣＳＲを用いた方法に関しましては
発音ラベルの精度は非常に高いのですがカバー率が
低くなってしまうため
十分な適応の性能は得られませんでした
正確な書き起こしの音節ラベルを使用した場合つまりその性能ののそのアッパーバウンドに対して
本提案手法は
ベースラインよりも
近づいておりますので本提案手法による話者適用は有効なので
はないかと考えられます
まとめます整形された書き起こしから整形箇所を自動検出する手法を改良しました
今後はこれに対して正確な書き起こしの構築作業をどの程度効率化できるかというのを被験者実験によって評価をしていきたいと思いますまた提案法によって取り出された非整形部分を話者適応に利用しました
提案法では発音ラベルの精度とカバー率の間にトレードオフが
ありましたので今後はより大規模なコーパスを用いることでカバー率の低下を補えるかどうかというのを検討していきたいと考えております
以上で発表を終わります
