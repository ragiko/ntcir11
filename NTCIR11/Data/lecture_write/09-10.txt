それではお待たせいたしました
音声状況の同時推定に基づく野球実況中継のメタ情報の付与ということで神戸大学のが発表させていただきます
まず研究の社会的な背景としまして、個人が使うコンテンツ、特に動画のコンテンツが増大してきたという背景があります
そのため、検索を見たいものを直ちに見れるようにするという意味で検索を容易にする技術が
必要とされております
このために音声認識が利用できるだろうということが考えられます
多くの動画コンテンツには音声が含まれますのでこの音声この音声を音声認識を用いることによって
検索のための
データベースの構築に利用しているということが考えられます
で、本研究ではちょっとタスクが限定的なんですけれども野球実況中継をコンテンツの例としまして
メタ情報の付与を行っていきたいと思います
まずタスクの具体例について説明いたします
野球実況中継のメタ情報付与ということで具体的にどんなことがしたいのかということなんですけれども
今からその実況中継の音声をちょっと再生しますので
左の
この左にこの文章がその音声の書き起こしになってますので
ちょっと合わせて見ていただければと思います
というふうな音声でちょっと周りがにぎやかな
音声なんですけれどもこのような音声を音声認識しまして
これに対してその状況この二つ状況というものを考えているんですけれども
一つはこの一つの発話だけが表すこの一つ分だけの瞬間的な
状況ということと
この状況がどんどん積み重なっていく部分の例えばストライクであるとか
ボールであるとかといったこの瞬間的な状況が積み重なっていく
状況ですね。この二つを対象と
しております
でこちらの瞬間的な状況としましては
これは重要なイベントかなというふうに考えているんですけれども
特に重要なものとしては投球であったり、ストライク、ボールなどの投球結果
で、それからアウト、であるとかホームランなどの特に野球のルールに関係する
部分を重要なイベントとしております
それ以外の
隣の解説者との会話であるとか
全員出場といったような
普通の特に
ルールに関係しないものについてはその他と
いうふうにして
ラベルを振っております
で、こちらの継続的な方についてはスコア、ボールカウンターとかあと出塁状況いうことで
このようなラベルを付与しております
でどういう情報を付与するかということについては色々あると思うんですけれども今回は放送局さんの
要望でこのような
イベントと状況のメタ情報を付与するということにいたしました
でちょっと
通常であればメタ情報を付与するという場合にはこのイベントのような形で
一つの発話に対して何かラベルを一つ振るということが大半かなと思うんですけれども今回はそれだけではなくて例えばここでストライクというような
イベントがあった場合にはこちらでも次のところでここちょっと小さいんですけども
ワンストライクからツーストライクにボールカウントが変化するという意味で
その瞬間的な一つの文章に対するメタ情報が
継続的な状況に影響を与えていくという部分がちょっと違うところかなというふうに考えています
でこのような目的のために音声認識を行うんですけれども先ほどお聞きいただいたとおりわりと
この特徴的な音というかかなりにぎやかな音ですので
音響モデルの適用を行うということを行っております
まず
マップによって音響モデル適用を行っています
でこれは同一話者の別の日の音声ということで
話者はクローズで
発話自体はオープンというような形で音響モデル適用を行っております。大体二時間くらいのデータで適用を行っております
でそれから言語モデルについてはこの先ほどの実況中継の書き起こしテキストから構築しておりまして
語彙サイズが大体三千くらいで未知語はないと、なしというようなものを用いております
でこのような感じで大体タスクドメインにマッチしたモデルを利用しているというふうに思うんですけれどもこれで
ワードエラーレートが三十六．二パーセントぐらいちょっと難しい箇所かなというふうに考えております
でここからメタ情報を付与していくんですけれども従来手法といいますか通常考えられる手法としては
音声認識を行った後にその１−ｂｅｓｔの認識結果を用いてそれに対して状況を推定するということが普通の手法かなと考えられます
でこれに対して提案手法では音声認識を行った後に状況を推定するのではなくて
音声と状況を同時に推定すると、音声認識を行いながら状況も同時に認識していこうということを
行っています
従来手法については生成モデルが文章から音声が出てくるとそれを逆に音声を観測して文章を推定すると、でその後推定された文章から状況を推定すると
いうことで普通にいつもどおり普通の音声認識を用いた手法というふうになっています
でこれに対して提案手法では
ちょっと図がややこしいんですけれども
まず一番下に継続的な状況得点、出塁状況、ボールカウントという状況が何かずっと流れていて
でその中から継続的な状況から時々
イベントが
発生してくると
例えばここに依存関係があるのは
三振だとかファールボールフォアボールなんかは
例えばツーストライクだとかスリーボールのときにしか現れないというような条件がついたりしますのでこういう形で状況からイベントが出てくると
それから文章はこのイベントと状況継続的な状況の両方を説明するために発話されますので
でこの両方に
置こうとこの両方に依存していると
いうふうになっています
で音声は
当然文章に依存するんですけれども
このイベントの分については例えばホームランだとかアウトなんかの場合にかなり興奮して
発話されるという特徴がありますので
この音声の部分もちょっとイベントに依存しているというような
ふうな仮定を置いております
でこの提案手法を形式化していくんですけれどもちょっとややこしくて申し訳ないんですけれども
大体単語列がＷ観測特徴量がＯで
イベントがＥですねこれは瞬間的状況の方です
で
これは継続的状況の方を普通の状況というふうにちょっと書いてましてＳと
いうふうにしてます
定式化では観測特徴量Ｏからこの単語列とイベント系列、状況系列
ＷＥＳを全て同時にすると
いうようなふうに定式化を行っております
でこれをちょっと式変形しますとちょっと長いんですけれども、ちょっと順番に説明させていただきます
まず一つ目の項がこれは音響モデルになります。ただしイベントに依存した音響モデルということになっています
これは先ほど述べたとおり
で二番目がこれは状況とイベントに依存した言語モデルということになっています
で三つ目が状況からイベント、どんなイベントが出てくるかと
それから最後が
状況がどんなふうに遷移していくかというモデルですのでこれはちょっとルール、野球のルールをモデル化したような
モデルになっています
でこれがかなり自然な
自然なというか素直な定式化かなと思うんですけれども
ちょっとこれは問題がありますので、もう一つちょっと式変形をしまして
このような定式化も行っております
でちょっとこの二つの式の比較について
述べます
これどこが違うかといいますと、この赤線の部分が違うんですけれども
こちらの上の方は、すいませんこれちょっと、イベントじゃなくてここ状況、んで瞬間的状況継続的状況になってます
すいません。ちょっと間違えてます
で上の方は
その瞬間的、継続的の状況の両方に依存して
で依存した言語も出るというふうになってしまいますので、この両方に依存したという部分で
かなり学習データが少なくなってしまうというのがまず一点問題があります
でそれから推定能力が低いということなんですけれども
このイベントで例えば投球の結果ボールになったという場合のボールという発話と
その発話以外にもあちこちでその
単に玉を意味するボールが
どこにでも出てきますので
その辺でちょっと推定能力がかなり低くなってしまうという問題があります
でこれに対して下の方のモデル定式化なんですけれども下の方の定式化は
言語モデル自体はもう状況のみに依存するというふうにしております
でそれと
右端に
これはイベントを推定するモデルが四つ目に出てくると
これはであるＷから
イベントを直接推定するというようなモデルになっています
でこの上の方はですね
イベントと状況の両方に依存した言語モデルを用いると
いうことでＳＥ言語というふうに呼ばしていただきまして
でこちらの下の方のモデルを提案手法と
いうふうにいたしております
で提案手法の各モデルの学習各モデルをどうやって学習するかということについてなんですけれども
音響モデルはホームランやアウトなどイベント時に興奮して発話することがあるということから
音響モデルはイベントに依存する形にしておりまして
これはベースラインの音響モデルを各イベントの音声で適用しております
例えばアウトであればアウトの音声だけを集めてきてこれで
音響モデル適用を行うといったふうにして学習しております
次の言語モデルなんですけれどもこれはベースラインの言語モデルとそれからこの状況ですね、例えばボールカウントワンストライクツーボールのみの状況を集めてきて、それでＮグラムカウントを混合して適用するという形で学習しております
これはボールカウントや例えばワンストライク、ボール、ツーボールの際にはそれ以外言わないと
いうようなことから状況が正しく推定できていれば結構効果があるんじゃないかなというふうに考えられます
で三つ目がルールモデルになってまして、こんなふうにワンストライクツーボールからツーストライクスリーボールにいきなり遷移しないといったようなことが
モデル化されています
で最後のイベント推定モデルなんですけれどもこれは
認識仮説のＷからイベントを直接推定するということなんですけれどもこれは複数単語が
単語列になっていますので
でその単語列からどうやって
イベントを推定するかという問題になっています
ここではＡｄａｂｏｏｓｔを利用していましてちょっとＡｄａｂｏｏｓｔの詳しい説明は書いてないんですけれども
どういう単語があるかによって
どういうイベントに投票するかということを学習した学習する学習した識別器になっています
でＡｄａｂｏｏｓｔは通常二値の識別木なんですけれどもこれを他クラスに
持っているために
ワンバーサスレスト
によって識別を行っております
でまたＡｄａｂｏｏｓｔの出力
Ａｄａｂｏｏｓｔの出力は
出力スコアですね、出力スコアがですね確率ではないんですけれども
他の三つのモデルが全部確率モデルになってますなってますので
この中に合わせて使うためにシグモイド関数を用いて
シグモイド関数はこの、こういうゼロから一の間に
収めるため収まる関数なんですけれどもシグモイド関数を用いて擬似確率化
利用しております
でこう
で実験なんですけれども実験は最初に説明した
このＳＥ言語この
状況と状況とイベントに依存した言語モデルを用いて状況とイベントを両方推定していくようなモデルと
それから先ほど説明しました状況に依存した言語モデルと
それから
認識仮説
の単語列からイベントを直接推定するモデルを用いて
状況とイベントを推定するモデル
これは提案書なんですけれども
それと一番最初に説明した
音声認識を行った後に１−ｂｅｓｔを用いて状況を推定すると
いう三つの手法を用いて実験を行っております
実験のコーパスはですねまず先最初に聞いていただいたラジオ実況中継なんですけれどもあれは一応接話マイク
から録音した音声になっておりまして
一応その
完成のレベルであるとか、横にいる解説者の音声のレベルはちょっと
ボリュームがおさえめになっているというタスクになっています
でが大体三千単語で
試合が全部で四つありまして、それぞれ大体二時間程度コーパスになっております
でこれを
４ｆｏｌｄの
クロスバリデーションによって評価をおこなっています
で
そうですね。で、発話をどういうふうにして分割しているかという部分なんですけれども
トレーニングの時には
人手で書き起こしてもらった書き起こしテキストがありますので
その書き起こしテキストの句点で区切っていったもの
発話と一つの発話にしています
それからテストの際にはパワーによって区切ったものを一つの発話として
認識を行っております
実験結果なんですけれどもまず従来手法１−ｂｅｓｔを用いた手法なんですけれども
単語正解精度が六十三．八パーセント
それからイベントの検出
これはその他の会話であるとか一般的な実況
の中から重要なイベントがどのくらい検出できたかというイベント検出Ｆ値が
０．８５程度になっております
で、それからそのイベントがどの程度正解してるか正解していたかという点については０．８３
いうふうになっています
で、これに対して提案手法を用いると
少し改善するという結果が得られています
単語正解精度については
０．１パーセントですのでほとんど変わらないということになっています
単語正解精度があまり変わらない理由としては
いくつか単語では改善があるんですけれども、改善している部分っていうのがほとんど
野球のルールに関係している単語だけというふうになっていまして
その関係しない単語がほとんど動かないので
あまり単語正解精度全体としてはあまり良くならないというふうになっています
それから状況正解率についても
提案手法で同時に推定することによってちょっと深いパス
深い認識仮説のパスは利用できたりしますので
それによって少し改善すると
いう結果になっております
ＳＥ言語についてはちょっと悪いというふうになっています
でこのイベント検出のＦ値があるとか状況正解率が良くなっている大体どういうところが良くなっているかという部分なんですけれども
例えば最初に文章の認識の仮説と
仮説として
三振といってるのか阪神といっているのか
ちょっとなかなかよくわからないというときに
尤度が少し高かったので阪神という方を選んだと
いうケースがあったんですけれども、このような場合にはイベントは一般的な発話であるというふうに識別されます
で
この次の発話の部分でボールカウントノーストライクノーボールと
いうような発話があった場合に
これはノーストライクノーボールですのでゼロノーストライクノーボールになるんですけれども
このノーストライクノーボールになるということ
から逆に考えますと
ここの前の発話では三振と言っている方が望ましいと
三振といっていれば三振しますので
次のバッターに代わってノーストライクノーボールに変わるというようなことがありますので
こういう継続的な
状況とそれからイベントというものをが両方相互作用、相互に作用して
認識誤りが改善するという例が見られました
でもう一つ実験としまして四つモデルを利用したんですけれども
イベントに依存した音響モデルと言語モデル、それからイベント推定モデルとルールモデル、この四つのモデルを
使わなかった場合音響モデルについてはイベント依存を使わなかった場合ですね、イベント依存ではない普通の音響モデルを使った場合
にどのくらい精度が変化するかと
いうことを調べました
で音響モデルを抜いた場合にはすいません、一番下がこれは何も抜かなかった場合なんですけれども
音響モデルを通常の音響モデルに変えた場合でもほとんど性能は変化しないと
いう結果になっています
で、これは
イベントに
依存させた場合でもさせなかった場合でも
その
ホームランの時、アウトの時のようにかなり興奮して喋ったような音声はどちらにしてももう全然認識できないと
いうようなことがありましてこの依存を考えた場合でもほとんど変化しないと
いう結果になっています
それから言語モデルについては
イベントのあたりについてはこれは１−ｂｅｓｔとほとんど同じ結果になりますのでこの程度なんですけれども状況正解率については
その例えばボールカウントワンストライクワンボールの時にはボールカウントワンストライクワンボールしか言わないと
いったような依存がちょっと考慮できなくなる分
少し下がってしまうと
いうような結果になっています
イベント推定を用いなかった場合にはもうほとんどイベントの検出はできないという結果になっています
ルールモデルを用いなかった場合にも
ここも少し下がるというような結果になりました
最後まとめなんですけれども、試合状況の
音声と状況同時推定
する
ことによって
メタ情報の付与を行ったんですけれども
試合状況の推定については
同時推定により少しずつ性能改善が得られています
ディクテーション性能の改善、ディクテーション性能については単語正解精度が0.1パーセントくらいということでほとんど変わらないという結果になっています
これは状況に関連する状況ですね、状況であるとか野球のルールに関係する
単語にしか効果がないということで
ここを上げていくためには
もう少しゆるい状況であるとか
曖昧な状況
に対応していく必要があるのかなというふうに考えています
以上です
