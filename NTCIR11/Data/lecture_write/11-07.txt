はい立命館大学のですよろしくお願いします
今回音響情報の話者依存ベクトル量子化を用いた音声検索語検出を
ということで発表させていただきます
本研究の背景となるのですが近年大量の音声データを含んだマルチメディアコンテンツが様々なところに
されるようになりまして
音声データの検索のニーズが高まってきております
これに伴いまして音声データを対象として与えられたキーワードを検索する検索語検出の
研究が活性化してきてきておりまして
近年ですと記号列に対する照合と
いうことで連続音声認識による単語列を用いた手法や
サブワード認識結果を用いた
研究が行われてきています
古くにはですね音響情報に対する照合と
いうことでワードスポッティングの研究なんかも
行われておりました
この従来手法の連続音声認識による単語列を用いた手法に関しましては
音声にですね音響情報が与えられていまして
こちらにですね
単語列
単語単位での
音声認識をかけまして
この結果に対しまして検索語を与えて
検出を行うと
といった手法となっているのですが
はですね
誤認識による検出性能の劣化やですね
認識結果に現れない未知語はですね
検出できないと
いった問題がありまして
近年ですね
サブワードを
認識結果を用いた手法
が検討がされております
こちらはですね同じく音響情報に対しましてサブワードを
サブワード単位での
認識を行いまして
こちらの結果に対しまして
検索語をですね音素系列に直しまして
照合を行うと
いった手法と
なっています
しかしこちらはですね音響情報をサブワードに直すということでですね
音響情報を粗く
近似した
表現形式との照合となっていまして
精度があまり良くないと
いった結果が出ています
と古くにですね音響情報に対する照合と
いうことでワードスポッティングの
研究に関しましては
音響情報
にですねＨＭＭを用いまして
直接照合を行うと
いった手法となっております
こちらはですね精度は良い物が得られているのですが
処理時間が
かかってしまうため
大量の音声ドキュメントには向いていないと
いう結果が得られております
我々の目的としましては大量の音声ドキュメントに対して高精度かつ高速の検索を実現したいと
いうことでですね先程二種類の表現形式の音声ドキュメントの表現形式を
述べたのですが
どのような形式で音声ドキュメントを表現しておくかということが
一つ重要なことと
なっておりまして
未知語の問題にも
対応しておかなければならないと
いうことで我々はですねベクトル量子化によって音響情報を離散化したＶＱコード列を音声ドキュメントの表現形式として用いると
いうことを提案します
我々としましては先ほど述べました記号列と音響情報の中間的な表現形式ではないかなと
考えております
提案手法のイメージとしましては
音声のですね音響情報に対しまして話者ごとにベクトル量子化を行いましてコードブックを
作成しましてそれを基にですね
この音響情報
ＶＱコード列に
直します
このＶＱコード列とですね検索音素系列との照合を行い検出を行うと
いった手法になっております
この照合を行う際にＶＱコードと音素との関連度が必要となってくるのですが
こちらに関しましては後で後ほど述べさせていただきます
フローチャートですが
音声ドキュメントに対しまして話者ごとに
ベクトル量子化を行いコードブック作成しＶＱコード列を生成すると
さらに同時にですね大語彙連続音声認識をかけまして音素列も生成しておく
これをですねデータベースとして保持しときましてこの二つの情報からＶＱコードにおける音素スコア
我々ＶＰスコアと呼んでいるのですが
こちらを算出しておきます
検索語を与えましてこちらを音素列に直しまして
連続ＤＰマッチングＶＱコード音素列の連続ＤＰマッチングを
行いまして
検出結果を出す
いった流れとなっております
先ほど述べました連続ＤＰマッチングの際に用いる局所スコアにですね
ＶＱコードにおける音素関連度ということでＶＰスコアを我々用いております
これはですね
先程
述べましたＶＱコード列と連続音声認識結果
音素列をですね
フレームごとに参照いたしまして各ＶＱコードと
コードに音素の
コード毎に音素の出現頻度
算出して
こちらのスコア求めていきます
この出現頻度を算出したものをこちらの式に当てはめてスコアを求めます
こちらがですね
スコアすいません
こちらのスコアはＶＱコード
Ｖに
Ｖの音素
Ｐに対するスコア
の式となっていまして
括弧内の
上のこのＣＶ括弧Ｐ
はですねＶＱコードＶに量子化された音素のＰのフレーム数
こちらのＮＶはですね
ＶＱコードＶに量子化された総フレーム数となっていましてこの括弧内は必ず
一以下の
一以下の
値となりましてログを取ることによって必ずの負の値になります
これに対しましてプラス二．零をすることによってその音素らしいのであれば
正の値になるような
そんな
スコアを
算出し極小スコアに
用いました
連続ＤＰマッチングに関しましては
パスはこのようなパスを用いまして一つ例を挙げますと
あるフレーム番号Ｉ
におけるですね
累積スコアが五．八七だと
しますと
これはバックトレースかけまして
検出区間のですね始端を決定いたしますスタートアイと
てん
検出区間の総フレーム数を
これを求めまして
平均スコアを
求めると
こちらにこちらに対してこちらの値に対して閾値処理を行うと
いった
形となっております
これをですね式に表しますとこのような式となっていまして
この平均スコアがですね極大値を示したものの内閾値を超える場合に検出
と
するということで検出を行いました
この平均スコアに対する閾値処理だけでも検
索語検出は可能となるのですが予備実験を行った結果
多くの湧き出し誤りが発生してしまいました
この湧き出し誤りの傾向としまして検索語一つの音素に
対応するフレーム数が極端に小さいと
いったものと検索語中の少数の音素が照合不可の大部分を占めると
いった傾向が見られまして例を挙げますと
こちら検索語絶対音感で
検出する際の湧き出し誤りの傾向の例となるのですが
このようにですね
検出区間の大部分をエの音素が
占めていまして
これ絶対音感を検出しているというよりエの音素を検出していると
いったこととなっていまして実際の発話もですねエのところを検出してしまっていると
いった結果が出てしまいました
この下の例では私どもはのモとワの
母音のところのですねオとアに
引っ張られて検索検出されてしまっていると
いった例が出てしまっていましてこれではやはりよろしくないと
いうことでですね我々
三つの条件を新たに加えました
音素フレーム長に関する条件ということでですね
検索語中の一つの音素と照合するフレーム数に関して閾値処理を行うと
いうことを行いました
この閾値に関しましては大語彙連続音声認識結果から得られる各音素の平均フレーム長に基づいて音素毎に設定を行いました
二つ目の条件としまして局所スコアの分散に関する条件と
いうことでですね各フレームのＶＰスコアの分散を求め閾値処理を行いました
これはですねこれは先程の例なのですが
この
エの大部分を占めてるエの音素はですねおそらく
高スコアで
平均スコアを上げているのだろうと
逆に他の音素はですね低スコアにもかかわらず
この
高スコアに引っ張られて
検出がされているのではないかと
いった仮定の基でですね
各フレームのＶＰスコアと平均スコアの差を求めて分散を求めまして
閾値処理を行うと
いうことです
三つ目の条件としまして相対的な音素
時間長に関する条件と
いうことで
相対的な音素時間
長のずれをですねこのような式で表してみました
この左のこちらの式はですね
話者毎話者
その話者の音素ＰＪの
平均的な
音素時間長
こちらがですね検出区間の
音素ＰＪの
音素時間長と
なっていまして
こちらの差を見ることによって
音素時間長のずれを
算出しまして
極端に長い
音素や
短い音素があったりしたら
リジェクトされると
いったような
条件となっております
我々の提案手法は話者毎にＶＱコードブックを作成し各ＶＱコードと音素との関連度を学習し
しておく必要があるということからですね以下の条件が前提となってきます
検索対象の音声ドキュメントにおける話者情報が既知であると
いうことと同じ話者に対してまとまった量の音声ドキュメントが利用可能であると
いうことと大語彙連続音声認識が
ある程度
良い性能で
可能であると
いうことが前提条件となってくるのですが我々としましてはこの条件
ある程度あり得る条件状況だと考えております
評価実験を行いました
ＶＰスコアの学習に関しましては本来であれば
音声認識結果に基づいて行うべきなのですが今回
書き起こしテキストを利用させていただきまし
ベクトル量子化におけるコードブックサイズは四千九十六
音響情報に関しましては十二次元のＭＦＣＣ＋その変化量ですね
計二十四次元
検索対象の音声ドキュメントに関しましてはＣＳＪ日本語話し言葉コーパスのコアデータ百七十七講演
に検出単位としまして発話単位での検出ということで
その検出すべきキーワードが
キーワードを含んだ発話を
検出出来たか出来なかったかで成否を判断し検出を行いました
評価尺度としまして再現率適合率Ｆ値処理時間を
求めました従来手法とのですね性能を比較し評価を行いました
検索語に関しましては音声ドキュメント処理ワーキンググループがＳＴＤ評価用として選択しているセットから二十単語
選出しました選出の基準としましては七モーラ前後のもの
比較的長いモーラ数のものですね
さらにＣＳＪで十回以上発話されているもの
検索キーワード同士類似した単語がないものを選びました
具体的な用いたキーワードに関しましては原稿のほうに載せてあるのでそちらを参照してください
比較に用いた従来手法の説明に入らせていただきます記号列によるキーワードと音声ドキュメントの照合と
いうことで連続音節認識をかけました
未知語にも対応させるため音節単位で認識を行いデコーダーはＪｕｌｉｕｓ
言語モデルはですねパームキットを用いて学習データにＣＳＪのコアデータ以外を用いて
音節トライグラム作成しました
音響モデルとしてましてはモノホンモデル
認識率を参照したところ五十一．五％のものが
得られました
こちらをですね音素列に直しまして連続ＤＰマッチングをかけていきます
音素間の距離としましては福田らが用いている音素弁別特徴を用いました
これはですね
口の中でどのように動かして発声されているかと
いった特徴となっていますこちらを用いまして
連続ＤＰマッチング
を行い検出を行うと
いった形となっております
ともう一つ音響情報を用いた照合ということでＨＭＭに基づいたワードスポッティングを行いました
二つの文法ＡＢこちらのＡＢですね
の
ＨＭＭに基いて発話を
音声認識した際に算出される音韻スコアを用いて検出を行いました
こちらのＡの文法はですね任意の音節の連鎖を許す
文法となっておりましてこちらはその音節の連鎖の中で必ず一度だけ
キーワード音素系列が
出現すると
いった文法となっております
こちらが実際の例なのですが
検索語
カイガラムシを
検出した際の例となります上がキーワードを含む発話の文法ＡＢ
下がキーワードを含まない発話の文法ＡＢとなっておりまして
キーワードを含む発話のほうはスコアの差が二一．七と
キーワードを含まない発話はですね
カイガラムシと
発声されていないのにそこを無理矢理カイガラムシ
置き換えているので
スコア
の差が出てしまって二百一と
なっていまして
このようにですね上のものはキーワードを含む
下は
含まないと
判断し検出を行いました
こちらはですね提案手法における用いる条件を変えたときの結果と
いうことでですね
先程平均スコア以外に三つの閾値処理を行うと
いうことを申したのですが
その組み合わせによる結果の比較ですね
平均スコアだけですと
やはり適合率が
かなり低いものが出てしまってＦ値がかなり低いと
いった結果となっていまして条件を一つずつ加えることによって少しずつ性能が改善されていき
三つ四つを全て組み合わせることによってＦ値零．六一三まで
上げることが出来たと
いった結果になっております
こちらが提案手法と従来手法の比較
なっております
マーカが大きくなっているところがＦ値が最も高くなっている箇所と
なっているのですが
適合率再現率においてですね音響情報に対しても優っていると
といった結果が得られました
こちらがその
Ｆ値が最も高い箇所の再現率適合率Ｆ値処理時間となっております
記号列はですね処理時間は短いのですがやはり性能があまり良くない
音響情報はですね
性能が良いのですが処理時間が大幅にかかってしまうと
我々の提案手法を用いることによってこの記号列のですね処理時間が短いと
いった特徴と音響情報の精度がいいと
いったこの長所二つの長所をですね上手く取り入れた
結果になっているのではないかなと
我々考えております
まとめです
検索対象の音声ドキュメントの表現手法として音響情報をベクトル量子化して得られる
ＶＱコード列を用いることを今回提案しました
これは話者別のベクトル量子化を行うと
いうことです
ＶＱコード列と音素の
関連度に基づいてテキスト入力された
検索語との照合を行うといった手法です
Ｆ値及び処理時間で評価する性能において従来手法よりも優れているということを示しました
今後の課題としましてはＶＰスコアの学習ということで本来であれば音声認識結果に基づいて行うべきなので
この辺りを検討していきたいと思っています現在のところは信頼度の高い音声認識区間だけ選択的に利用すると
いったことを考えております
さらに複数の閾値の設定ということで今回四つの閾値処理を行なっています
このバランスが非常に難しいということで例題を使った自動学習の導入を考えております
更にですねサブワード単位に基づいての検出である程度の候補を出しておき今回の手法で
再評価を行い
結果を出すと
いった併用もですね視野に入れております
あとはですねＶＰスコアの算出方法の再検討やコードブックサイズの検討
考えていきたいと思っています発表としては以上です
ありがとうございました
