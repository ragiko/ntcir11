ＮＴＴのですたびたび質問で長話をして申し訳ありませんでした
わたくしは本日の発表のタイトルなんですけれど音声認識の確信度と
識別モデルを利用した音声からの固有表現抽出というちょっと長いタイトルなんですけれど
でお話します
で初めになんですけどみなさん
昨日と今日の発表で散々おっしゃってきたと思うんですが
音声データを重要な情報源として考えましょうと従来自然言語処理の人達がニュースの記事だとかウェブだとかを使ってきたように
我々は音声のデータを使うんだと
ニュースの放送であるとかボッドキャストであるとか弊社的に申し上げますと通話の記録なんてのもそういうふうになるのかなと
考えておりますけれども
でアメリカのＤＡＲＰＡのＧＡＬＥプログラムという
研究プロジェクトがありまして音声認識して翻訳してそこから情報抽出するぞというふうな
結構大々的なプログラムを実行してまして我々もそういったとこに
興味がある
で
そういったことを考える上で重要なタスクとして固有表現抽出というものをここでは考えます昨日の先生の
御講演でその話がでてきたんですけども非常に重要なもので
でどういうものかというと人名とか地名とか日付
などを同定するようなタスク
でなにか
質問応答とかに使ったときになになにをしたの誰ですかって聞いたときにその答えになるようなものを
ちゃんとピックアップしておきます
これは情報抽出のアプリケーションの基板技術として使われるもので音声ドキュメント処理みなさまご考えのようないろんな人
情報処理の基礎として
考える
ことができるでしょう
てことになります
で研究本研究の目的は音声認識結果
音声データを対象にしてますんで音声認識結果からいかに頑健に固有表現を抽出するかということを目的としています
で具体的な問題としては音声認識を使うことで音声認識誤りがある程度存在することは不可避であるということがいえますのでそれに起因する固有表現抽出の誤り
というのをいかに減らすかということを考える
具体的には
音声認識結果ていうのはなにか音声認識結果というノイズが乗ってると
そういったものを
考慮に入れた上で
固有表現値をどういうふうにするかていうのを考える
従来の研究なんですけれども自然言語処理の分野の方では識別モデルマキシマムエントロピーですとかサポートベクトルマシン
最近ですとＣＲＦなんかを使ってやる方法ていうのが色々でてましてこれは非独立ないろんな素性をごちゃごちゃ使いましょうと
今朝の発表でもあったと思いますけれど例えば
固有表現抽出の例で言いますと単語の表層とか品詞のタイプ
であるとか周辺の単語はなにかとか
あとその単語はどういう文字で書かれるかですねなんか
アルファベット何文字かで書かれるものはなんか略語が多くてそういうものが固有表現になりやすいとかが全部日本語の場合は全部片仮名で書かれるものが固有表現になりやすいとかっていう傾向があったり
しますんで
そういった情報を一緒につかってがちゃがちゃがちゃっと一緒に使ってあげたいと
でここは当然自然言語処理の人達がやってたことなので入力はなんか書き言葉とか書き起こされたものとかで基本的には誤っちゃいないと
ようなことを考えて
それですと今回の話その入力に誤りがあるかも知れないていう話は入れられない
で一方その音声の人達てのは当然そういう話をやってやってきてまして従来の方法ですと生成モデルといってますけれどヒドゥンマルコフモデル
に類したようなものですね
実際完全にヒドゥンマルコフモデルでない場合もあるんですけれどそういったようの
同じ類のモデル
を使っているものです
でこうした方法ですとすでにその音声認識誤りを考慮したモデル化するていう方法が提案されていましてこれもう五年以上まえのＨＬＴの
の話なんですけれど
誤認識のごの字が
なんか平仮名になってますけれど音声認識の確信度を使って
なんかそのある誤認識のある確率で誤認識が
した単語を棄却しながら固有表現抽出をするていう枠組みですね
これを使っています
で音声認識結果を使う
利用して学習することでなんか誤りが入って来た入力が来たときにそれをうまく捨てながら
固有表現抽出するというようなもの
なんですれども
生成モデルの一般的な弱点といわれることとして独立
その
使う情報が独立でないと困ると
言うようなことが言われていますこれは自然言語処理の方で良く言われていることで最近
そういったことに着目
しているから自然言語処理の人達や識別モデルをたくさん使うわけですけれども
そういったふうに言われてましてこういった問題があります
で本研究ではじゃあどうするかというといいとこどりをしましょというふうになります
音声認識誤りを考慮に入れるっていうその音声屋さんの発想を識別モデルを使うという
自然言語処理の人達の方法論に乗っ取って使いましょう
のことを考えますそうするとなにが嬉しいかというと識別モデルを使って強力な分類性能というのを発揮することができます
そしてどうやってやるかというと多様な素性ですねいろんなものをごちゃごちゃごちゃと使うことによって
固有表現抽出の精度を上げることができる
でかたや音声認識の確信度ていう情報を上手に使ってあげることでなんか認識が間違えちゃった
その入力に間違いあるていうような状況でもそれにひっぱれないように
ロバストな固有表現抽出ができると
ことを目指してます
で具体的な話に入って行きますけれどもまず最初に固有表現抽出の問題をちょっとちょっとおさらいしておきます
で
一般的に固有表現抽出の問題ていうのは
単語をある固有表現のクラスに分類する問題として定式化されますクラスというのはなにかというと
固有表現のカテゴリーですね人名だとか地名だとか組織名だとかっていうのを
単語の位置ていってるんですけどその単語はどのある例えば人名の頭の単語例えば名字なんかだったら
頭にきますね日本語だったらそういうふうな情報てのを使うと
具体例を挙げて申し上げますけれど
ここに首相はっていう
文章
ありますけれども
四つあるんですけれどていうのは人名の最初の単語
は人名の最後の単語
あとは固有表現でないのでアザーて付けてるんですけどこういう
ふうにクラス分類する問題として解きます
で
自然言語処理で行われているこの
固有表現抽出を解く方法として
日本語を扱ったものとして一番こう我々にとってファミリアなのは共著者のが
二千二年に発表してますけれどもサポートベクターマシンを使って
固有表現抽出をするという方法を提案してます
これは
サポートベクターマシンの高速化固有表現抽出などの高速化の話なんですけれどもここで使った方法を今回元にしてやることに
で素性としては単語の表層と品詞とあと文字の種類ですね先程申し上げたその片仮名で書かれてるとかアルファベットで書かれてるとかっていう情報を使う
で
当然そのもちろんていうのを判定するのに回りの単語の情報っていうのは役に立ちますんで前後二単語分っていうのを使う
ことになりますで素性の処理が三種類あって
自分と前後二単語づつありますんで一単語あたり十五個の素性を使って分類する
ていう問題として
やってま
ここから提案手法の話にようやく入るんですけれど
じゃあ何が違うか提案手法は
先程ののの
固有表現サポートベクターマシンを使った固有表現抽出法において
素性を一個足します
何を足すかというと音声認識の確信度を素性にします
ということを提案します
でここの確信度の素性ていうのは何かというと
この
単語仮説音声認識した単語仮説が正しいか否かという二値
ゼロか一で与えます
素性値は確信度スコアによって出すものである閾値よりも
確信度スコアが高い
場合は
このこれは一
正しいものとして扱って逆だったら
ゼロ
誤りとして扱うと
つまりあのベクトルの要素が一個増えると素性ベクトルの要素が一個増えるというもんだと思って下さい
でどういうふうにじゃあ今いったような方法をどういうふうに実装するかって話なんですけれどもモデルを学習しなきゃいかん
サポートベクターマシンの学習をどういうふうにするかって話をします
まず最初に音声データがあるんですけれども
学習データを作るためにちょっとあの書き起こしこれ手動の書き起こしを想定しています
でそれに固有表現のラベルこれは人名だとかこれは地名だとかこれは日付だとっていうのをつける
っていう作業がありま
で確信度素性ていうのを付与先程申し上げたその音声認識が正しいか否かて話をするんですけれども
書き起こしの学習データてのは実は後で説明しますけれど一緒に使うことでメリットがあるのでこれも使うんですが
書き起こしってことでつまり音声認識全部正しくできたら百％単語認識精度百％だと思えばいいので
ここでいうところの確信度素性ていうのは全部認識が正しい
ていうようなものです
でかたや音声認識の誤りの傾向を学習しなきゃいかんので音声認識結果も学習に使います
でこれは音声認識した結果
と先程のその固有表現ラベルをつけた状態の書き起こし対応付け
をして
ここは音声認識が間違ってるとかここは固有表現だっていうラベルを写すわけですね
そういうことをします
でこの二種類の学習データ
ができます
で
その二種類の学習データていうのがどういうもんかっていうのをちょっと例を示してお話しますけれども
これ書き起こしで作ったものですこのへんの字面をみるとどういうコーパスかっていうのが一瞬でお分かりだと思うんですけれど
これは全部正しいその新聞とある新聞に書いてあるこの文字列ですねこれがありまして
で固有表現でていうのは人名ですから人名のラベルがついてますし
年頭ていうのはその時間の表現日付の表現なんでこのデートていうのがついています
で書き起こしを使ってますんでこれは音声認識した場合だったら全部正しかったていうふうに仮定をして全部一のラベルがついています
必要な
ことを先に喋っちゃいます
で
ですね次じゃあ音声対応する音声認識結果を使った学習データ
の方でこちらでお見せします
こちらにあるんですけれども
真ん中のところがごっそり音声認識誤り
になってまして
ていうのが氏に位置ってなってて首相は使用に
使用ていうのに誤認識
されてるこういうような状況があったと仮定します
でそんなときにどうするかというと音声認識誤りでさっきのそのていう人名落ちちゃってるんですねで
こりゃ困るなーと
はもうどうあがいてもここからとることは出来ません
一方その年頭ていうのは幸いにしてうまく認識されたんでこっちはちゃんととってくれる
こういうところからどういうふうに学習データを作りゃいいのかなって考えたときに
本手法ではどうするかというと
もうていうその完全な
完成された固有表現がもうとれないと
分かってるのでそこは諦めて下さい
ていうことで部分的に正解しててもそれはもう捨てちゃいましょうと固有表現じゃないんだよていうふうに判定しちゃう
ことにして
こうして
実際実行したときに不完全な固有表現を間違えて持ってきてなんか
部分的にはあってるんだけどそれは俺が欲しいもんじゃないよというようなことを学習させようということにしました
で実験の話にはいりますけれどもちょっとはやいか
コーパスは日本語の新聞記事データで自然言語処理の人達がやってたその固有表現抽出のコンテストがありまして
ＩＲＥＸっていうワークショップでそういうコンテストがあったんですがそれの学習データ
の部分を使いました
テストデータちょっと別にあるんですがちょっと色々権利関係のほうですぐ使えないらしいのでこういうことにしたんですけども千百七十四記事だいたい一万文ちょい
あって一万八千ぐらい固有表現があって二十六万単語ぐらいで品詞は茶筌の一番上のレベルで分けたんだったと思うんですけど六十品詞
あります
で固有表現のカテゴリが八つありまして人工物組織場所人物日付時間金額割合て五つあるんですけ八つあるんですけどこれに分類する
問題
で今回音声からっていう話をしましたんでちゃんと読み上げ音声をとりました
話者百人ぐらいで大体一人百文ちょい読んで頂いたことになります
で我々の音声認識エンジンのＳＯＬＯＮというもので認識したんですけれどちょっと収録環境がいまひとつだったようで
結構頑張ったんですが認識精度が以上ちょっと切ってしまいまして読み上げ音声としてはどうだろうて話はあるんですけれど
この状態で実験しましたで認識エンジンの語彙数が 四十二万語で
未知語率は零．六％しかないんですけど
パープレキシティは七十九位なんでこんなもんかなと
で
この後のプロセスで使うのはワンベストの音声認識結果だけですのでそれの
情報として
ワンベストのなかで八十二％の固有表現は一応人間が手で
ほじくりだせばとれると
ということがわかってます
なのでリコールはだいたい八割ちょっとぐらいで頭打ちどんなに頑張っても八割ちょっとしかいかないていうのを頭にとめといてください
でじゃ実験の話をしますで
提案手法の効果を調べるため先程言いましたけどワンベストの音声認識結果から固有表現を抽出する
問題を解きました
で
比較する手法についてですけれどまずベースラインは
ワンベストの音声認識結果をまるごと信じて
テキストの固有表現抽出のほうをそのまま使うと
いうことをしてますこれがベースライン
これはだから磯崎らの方法をそのまま使った
認識結果に対してってことになります
でもう一つなんですが単語棄却と名付けましたけれども音声認識誤りが含まれているってことを
想定して
じゃあ音声認識誤りがきたらその単語捨てましょうと
いうようなことをちょっと企らんでみましたこれは
認識結果の中で確信度がある閾値より低かった場合
はその単語はなんか未知語みたいなものシンボルに置き換えちゃって
捨てましょうと
そうするとそのまちがった固有表現取らないで済みますよねってことが考えられるのでそういう方法をちょっと試してみます
でもう一つは提案手法です
でもう一つ参考その失礼しましたこっちは違いますね
評価
評価指標はＦ値にしました
適合率と再現率の調和平均ということでおなじみの方法です
で実験の条件なんですけれどデータ一万文ちょいあったんですがファイブフォールド交差検定だいたい二千文ちょいにわけて
クロスバリデーション
をしています
で
提案手法の場合その確信度いくつより上だったらその単語が正解と判定するかっていう閾値決めないといけないんすけどこれあの開発データがいるので
今回はその五等分したデータの中の一
五分の一を
テストデータに使うんですけど
そのテストデータの前半分を使って決めた閾値を使って後ろ半分を評価するその逆をやるていうのをやりました
で確信度はじゃあどうするんだって話すんですけれども今回はちょっと都合によりＳＶＭをまた使いましたいろんな方法ありますんで
それはどれを使っても別に本手法には影響ないんですけれどもちょっと都合によりこういうことに
なってます
でＳＶＭで正しくはこの単語は正しく認識されたのかどうなのかっていうのを判別するような問題
で素性としては表層といけない表層と品詞とあと一般化単語事後確率ていうあの
ＡＴＲにがいたときにやってたやつなんですけどもあの
結構有名なので
最近ＡＴＲの人達がいろいろ使っているから結構有名なので単語事後確率だと思っていただければ結構です
でもう一つ付加情報としまして書き起こし入力時
書き起こし音声認識率が百％だったら
どれぐらいの数字が出るのかっていうのをちょっと先に参考としてお見せしますけれども大体Ｆで八十四％ぐらい
なので八割強ぐらいは
テキストレベルで解ける言い方を換えると一割五分ぐらい間違えるていうようなもの
の
扱っていると思って下さいで実験結果こちらですけれどもベースライン基本単語棄却提案手法の順に並べています
で御覧になって分かる通りＦ値のレベルで二ポイントぐらい提案手法はベースラインより上で単語棄却に対しても一ポイントぐらい勝ってます
で提案手法が固有表現抽出という観点では最高の精度この中では発揮
で細かく見ていきますけれども
まずその単語を音声認識誤りの単語ていう単語棄却をするていうのがどれぐらい効果があるていう話が最初にあるんですが
こちらを見て頂くとその適合率単語を捨てることによって
容易に想像つくとおもいますけれども間違った単語を捨てれば適合率は上がります
そのかわり再現率が下がります
ということがありますで一応これはその
Ｆ値が最大になるように閾値を開発データを使って調整した結果なので
このなかではフェアな結果全てフェアな結果がでてるわけですけれどその状況で
これぐらいの改善がある
ということで単語を棄却するってことでも
前より良くはなる
ことは分かります
で提案手法でやるとさらに稼げると
ということが分かっていまして
これは真ん中のものっていうのは固有表現抽出のモデルはもうテキストが入ってくると信じてるわけなんですけどそうではなくて提案手法の場合は固有
固有表現抽出のモデル自体も音声認識誤りが混じったものがはいってくるんだていうのを知ってるわけですねでそういう
学習がこういう高い精度を発揮するに至った理由であろうというふうに考えられます
ですね
で
誤抽出が減ったということはつまり音声認識誤りによってその間違った固有表現が認識結果中にある固有表現候補が認識結果中にあると
それを取らずに済んだ
いうことですね
でもうちょっと細かくその
提案手法はどこがいいのかっていう話を見るわけなんですけれどまず学習データの違い
による差っていうをみています
ベースラインの結果これなんですけれども
音声二種類ある学習データのうち音声認識結果からくるものだけを使うと
適合率がぐんとあがるんですが再現率ががくっと下がる
ということで
途中で例で挙げて申し上げたその不完全な固有表現は間違ってるからいらないよっていったふうに設定してしまったんで
それがちょっとその適合率偏重の学習を導いちゃってるんだろうなと思います
で最初に申し上げたようなその書き起こしの学習データも使うんだよっていう話をしましたけどそうすると
適合率ちょっと下がりますけれど再現率が三ポイントぐらい回復してます
で
じゃ何が良かったというと書き起こしのデータですとその固有表現のサンプル数が増えるんですね音声認識結果だと
そもそもその認識誤りによってサンプルがいくつか落ちちゃってて学習データが減っちゃってるのでそういうのを補完する役割をはたしてるのかなて思います
でこれあの信頼度素性なしの場合の話をしましたけれども
提案手法においてその
音声認識結果を使った学習データしか使わなかった場合ていうのも同様の傾向が見られました
でその
確信度の閾値は今回クロスバリデーションで決定したんですけれども
そーじゃなくてちょっと固定値でふったらどうなるかなていうのを見てみた結果がこちらでして
外側のカーブが提案手法で単語棄却でいうのがそのさっきの真ん中の列にあったやつなんですけれども
行真ん中の行ですね真ん中の行にあったやつなんですけれどその結果がこれでして
単語棄却の方法ていうのは
閾値上げてくとだんだんこうプレシジョンがあがってリコールが下がっていく方向に行って欲しいんですがなんか結構速い段階でプレシジョンも下がり始めちゃっているものまで捨て始めるということが
おきてます
なので
これはちょっとあんま嬉しくないねと
で
かたやその提案手法ですと確信度素性を使ったことによって
固有表現抽出に影響するようなその
この
固有表現抽出の結果ていうのは合ってるのか間違ってるのかていうのをうまく判定できて
結構高い八十五％適合率で再現率が五割近くていうぐらいの数字が達成できています
でもう一つその確信度これ今回ＳＶＭ確信度を計算したんですけれどこれが
結構精度に影響しそうだていうのは想像に難くないわけです
で
今回その上限値を調べようということで確信度によって音声認識の正誤判別が誤りなくできたと仮定するずるをしてこの認識結果正しい間違いていう正解を
与えた状況でどれだけの数字が提案手法で出せるか
ていうことをみた結果がこちらです
見るとわかるんですがＦ値で四ポイント上がってまして適合率も十ポイント上がってましてかなり
精度が良くなってます
ということで確信度計算を改良すればまだまだ十分改善できそうだってことがありましてこのへんは
足回りの強化っていう意味で
なかなか興味深い結果だと思います
でもう時間が来ちゃいましたんでさっと流しますけれども本発表では識別モデルサポートベクトルマシンを用いて音声認識結果からの頑健な固有表現抽出をするという手法についてお話させていただきました肝は確信度素性というその音声認識が正しいか間違いかっていうことが
わかるっていうのは重要なんですよっていうことで
以上です
