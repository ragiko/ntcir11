はい
では東北大学のです
本日はウェブデータを用いた話し言葉用言語モデルの作成というタイトルで発表させていただきます
まず始めに
日本語話しコーパスにより日本語話し言葉音声認識技術は目覚ましく発展したということはみんな
みなさん知ってる通りなんですが
特に
言語モデルの面から言うとＣＳＪから学習したものが非常に強力であるっていうことがこう全体的に知られていると思います
しかしながら問題点として
ＣＳＪ全体の異なり語彙数は六万語彙程度ということで
様々な話題の話し言葉音声には対応できないといった問題があります
またこのＣＳＪ全体のテキストデータ量総形態素数で言うと約七百万形態素程度ということで
頑健なＮグラム確率を推定するためにはデータ量はやや不十分だと言えます
よって更なる高精度化のためには
もっと学習データ量が必要となるのですがこれ以上音声データを人手で書き起こすということは非現実的となっています
そこで従来一般的に行われるアプローチとしては
新聞などの書き言葉データとの混合により言語モデルを強化補完するといったことが行われます
話し言葉データに加えて新聞などの書き言葉データを使い話し言葉のための言語モデルを強化補完する
この
書き言葉データのみでは
認識しても認識性能は低い
のですが
こちらに語彙がたくさん
入っているので語彙が増え様々な話題に対応できることになることによって
認識性能が上がるといったことが起こります
しかしながらこの書き言葉のデータを加えると書き言葉スタイルのＮグラム確率がどうしても上昇してしまうため
話し言葉スタイルの音声に対しては認識性能が低下してしまう
といった問題が起こります
では従来どうしてこのような方法を行っていったかというと
話し言葉スタイルの音声認識に適した学習データというものは手に入らないと考えられていたからです
一方で我々は
ウェブ上の話し言葉データ
の利用するを利用するアプローチというものを今回模索します
ウェブ上の言語資源は音声認識のために
音声認識のための言語モデルの学習にある程度有用だということが
先行研究
から知られています
また近年
文章スタイルを考慮したウェブ言語モデリングも行われていて例えば音声対話におけるユーザーの検索要求に特化させた言語モデルの作成であったり
文末が疑問文の形式である文章を利用した
疑問文特化型言語モデルなどの作成が行われています
このように
音声対話であったりこの質問であったり様々な
あらゆる種類のデータがウェブ上には存在する
そこで我々はウェブ上の話し言葉のデータを上手く利用すれば大規模な話し言葉用言語モデルを作成できるのではないかと考えます
そこで本研究では
ウェブ上の話し言葉データを利用した大規模な話し言葉用言語モデルの作成ということを目指します
そもそもウェブ
のデータのみから話し言葉用言語モデルを作成するっていうことはまだ作れるかどうかを検証した研究例はありません
そこで我々は既存技術を組み合わせて
ウェブから話し言葉データを大規模に収集して言語モデルを構築するといったことを行います
そして目標としては
ウェブ文書のみからＣＳＪで作る言語モデルと同等の認識性能を持つ
話し言葉用言語モデルを作成する
また
ＣＳＪとその作ったウェブ言語モデルを
使ってＣＳＪ以上の話し言葉用言語モデルを作成するといったことを目指します
ではその上で今回やる枠組みとしては
まずアプローチとしては話し言葉の
データというものを作ります
そのためにウェブから
一つのウェブ文書ずつ次のような流れを適用していきます
まずウェブからダウンロードしたデータに対してフィルタリングを行います
フィルタリングは言語モデルの学習に重要な部分のみを抽出する
つまり文書部分のみを今回はルールベースで抽出します
次に
フィルタリングを行った後のデータに対して
これは話し言葉なのか書き言葉なのかといったことを考えます
最終的には話し言葉データのみを使いたいのでそこで
文書スタイルの分類といったことを行います
ウェブには話し言葉と書き言葉などのデータが混在しているので
今回はナイーブベイズを
分類器を構築して分類を行います
最後に
話し言葉
と判断された後のデータに対して言語現象の補完を行います
これは話し言葉特有の言語現象というものはあくまで今回扱っているのはウェブ上の文章なので
本当に
音声を書き起こしたようなデータに入っているようなものは
入ってないといったことで
今回はまずフィラーがあまり出現しない
といった問題があるのでこれをフィラー挿入
を行います
またウェブの文章
というものは基本的には書き言葉なので
読点の位置っていうものは実際に人間が喋る
場合のショートポーズの位置とは必ずしも一致しないので
ショートポーズ挿入も行います
これによって擬似的にですが話し言葉のデータを構築していきます
このように人手で音声を書き起こすことなく
話し言葉データを準備することができます
ではこの
部分部分
について説明していきます
まずフィルタリングですが
固定ルールと統計ルールを組み合わせてフィルタリングを行う
と先生の行っていた方法を適用します
まず固定ルールとしては
基本的な方法として句点で終了するような部分
また
ウェブ上にはＨＴＭＬタグ
ではなくＵＲＬなどが入っているのでアルファベットや数字記号の多い文章は除く
また文書部分を
対象としているので一行の長さ
がある程度長さがある文章を
考えます
また統計ルールとしては
近年ですと
二チャンネルなどでは二チャンネル用語などがあるわけで
そういうものは言語モデルの学習には使えないので
それをあらかじめ一般的な単語トライグラムを準備しておくことで
単語パープレキシティ基準で
フィルタリングを行います
そうするとこれは東北大学のＷｉｋｉｐｅｄｉａのページ
を
ＨＴＭＬタグを取ってきたものなのですが
これをフィルタリングを行うとこのような部分は
消えて
後はこの括弧などの部分
も
綺麗にするように整形します
これによって言語モデルの学習に有用な文書部分のみを抽出可能となります
次に
フィルタリングを行った後のデータに対して話し言葉データの抽出を行います
今回はナイーブベイズ分類器によりスタイル分類を行うことで
話し言葉データを判断します
そのためにまず
話し言葉スタイルと書き言葉スタイルそれぞれのユニグラム言語モデルを利用します
今回はあらかじめ書き言葉のデータと話し言葉のデータがあることを仮定して
それぞれからユニグラム
を学習して
ある
フィルタリング後のウェブデータが
どちらのモデルから生成してきたのかということをこのように
書き言葉のモデルから生成
ある文章が生成した確立
などを求め
最終的にこのような式のもと
スタイルを判断します
今回このユニグラムには
スタイル分類が目的なので名詞をストップワードにして助詞や助動詞などを重点的にしています
また
スムージングのために品詞の生成確率を利用するといったことの行っています
これによりナイーブベイズを用いて話し言葉風のデータのみを全自動で分類するといったことが可能になります
最後に言語現象の補完を行います
これはで行われているフィラー及び
ショートポーズ挿入モデルを適用します
フィラー挿入モデルは二つのモデルからなっていて
文書中のある位置にフィラーが挿入される確率
をモデル化しさらにもしそこに
フィラーを挿入するならどのフィラーが挿入されるのかといった条件付き確率
としてモデル化します
またショートポーズ挿入モデルは文書中のある位置にショートポーズが挿入されるかどうか
といったことをモデル化します
今回我々はトライグラムで挿入モデルをモデル化します
そうすると
普通の文章に対して
二つのモデルを適用すると
このように挿入することができ例えば一番上の文章だと
パフィーならちょうどいいかもしれませんねといったように
これは音声を書き起こしたようなデータ
に見えます
このように
話し言葉の特徴を持つような本来は書き言葉書き言葉というかウェブ上の文章
で音声を書き起こしたわけではないのですが擬似的に話し言葉データを作成することが可能となります
ではこのような枠組みを利用してウェブから文章を
話し言葉データを集めて実験を行います
まずそのため
最初に
どのような
ウェブデータを相手にするわけですが
理想としてはウェブ全体のデータを今のような方法で行えればいいのですがそれは非現実的なので今回
は
話題に対して網羅的にサンプリング
ウェブからサンプリングした合計約千五百
千五百万ＵＲＬのデータ
を対象としてそれぞれのデータを先ほどまで説明してきた流れを適用することで
擬似話し言葉データを作成していきます
そのために先ほどまで
フィルタリング統計ルール
のモデルまたナイーブベイズで使うモデル
最後はショートポーズ
フィラーやショートポーズの挿入モデル
の説明をしてきたんですがそれぞれを学習するためのデータとしては今回ＣＳＪ二千五百三十六講演を話し言葉のために
毎日新聞二年分をナイーブベイズで使う書き言葉のために利用します
それによって最終的に擬似話し言葉データを作成し
このデータから
音声認識用言語モデルを作成
また
もともとのＣＳＪから学習したモデル
も学習しこれらを比べていきます
そのための音声認識実験ではデコーダはＪｕｌｉｕｓ音響モデルはＣＳＪから学習したトライフォンモデル
で
テストデータとしては
こちらの二千五百三十六講演を含まない四十講演を用います
ではまず
今回作成したデータ量がどの程度の
量なのかといったことを説明します
ここではデータ作成時の各工程後の総形態素数
を示してあります
縦軸が総形態素数学習
データの総形態素数となっています
まずこのＣＳＪというものはＣＳＪ約二千五百講演学習に使ったもので
こちらのデータは約七百万と一般的に知られている量と変わりません
これに対して今回
約千五百万ＵＲＬのデータそれを
フィルタリングを行
うと最終的に
五十億形態素というＣＳＪと比べると
大分オーダーが大きいデータ
データが手元にあるといったことが分かると思います
この手元にこの手元に置いたこの五十億
形態素のデータをナイーブベイズ
分類器で分類すると
こちら
こちらの赤が書き言葉風と判断されたものこちらの青が話し言葉風と判断されたもので
話し言葉と書き言葉の比は約一対七ぐらいで今回
自動で判断されました
さらにこの話し言葉風となったデータに対してフィラー挿入ショートポーズ挿入などを行うと最終的に
約六億形態素
のデータが取得
できました
これはＣＳＪのデータ量
は約七百万でこちらは約六億形態素
なのでＣＳＪの約八十倍の話し言葉データを今回擬似的に集めました
では
次に今集めたデータ
作ったデータを使って言語モデルを作成し認識性能を評価していきます
まず最初に
語彙サイズを一定
今回約四万の語彙サイズで言語モデルを作成し比較を行いました
縦軸は単語正解精度です
まずこの緑色のＣＳＪの部分は
こちらは
認識ドメインテストデータも学習データも同じドメインでありかつ音声を人手で忠実に書き起こしたデータを使って学習して
この場合
六十二．四五％程度でした
これに対してこのマル一マル二マル三と書いてあるのはマル一というものはナイーブベイズ分類器
の後の話し言葉風のデータ
このマル二はさらにフィラー挿入を行った後の
もの
この最後
マル三はさらにショートポーズ挿入を行った場合です
これを見ると
言語現象の補完により認識性能が改善し約六十．
六十．二％程度
でＣＳＪは六十二．四五％なのでまだ二％くらい差があるのですが
さらにこの一二三
を
単純に足し合わせて
それぞれ補完し合って作ると
最大で約六十一．〇四％
と
ＣＳＪと約一％ぐらいの差ですが
ウェブ文書のみでＣＳＪに匹敵するモデルを作成できるといったことが分かると思います
では
今のモデルを使って今度は語彙サイズを変化させて認識性能を見てみました
先程までは四万語彙
を
ウェブから作ったものもＣＳＪも四万語彙を使っていたのですが
ＣＳＪは大体五六万
語彙程度が限界だということが知られているのでそのまま四十万
四万語彙にして
ウェブから作ったものは四万五万十万二十万三十万と
データ量はいっぱいあるのでその分語彙サイズも大きくすることができます
これを見ると
語彙サイズを増やすことで認識性能も改善して二十万語彙
ぐらいでは六十二．三
八％と
ほとんどＣＳＪと大差ない
大差ないというか同等の部分まできていることが分かると思います
またデータ量がいっぱいあるので未知語率も最終的に〇．〇％まで改善可能です
このようにウェブ文書のみで大規模な話し言葉用言語モデルを作成できＣＳＪのみの場合と同等の認識性能を達成できるということが分かりました
また今回作成した言語モデルの考察として学習データ中に出現したトライグラムの総数というものを見てみました
こちらはＣＳＪ
はトライグラム学習データに出てきたトライグラムの種類数
です
ＣＳＪだと約三百万ぐらいなのですが
今回作成したウェブではさらに
その分
約一億とか一．二億とか
多い
数のトライグラムを実際に観測できていました
実際にデータサイズというものは八十倍
ＣＳＪよりこちらが八十倍で
また
トライグラムの数は四十倍ぐらいということで
全然
収束せずに
トライグラムをまだまだ観測できる
つまり頑健なＮグラム確率を推定するためにはＣＳＪのみではまだまだデータ量が不足しているということが示唆すると思います
最後にモデルを混合した場合の認識性能というものを見てみました
今回ＣＳＪのみのモデルとウェブ文書のみのモデルを作ってあるのでこれらを混合します
混合手法はＮグラムカウント混合を用いて
ＣＳＪから作ったモデルは圧倒的にデータ量が小さいのでＣＳＪを五十倍にしてウェブを一
にして
混合しています
こちらが結果となっていて
この緑は先程までに説明してきたＣＳＪ
こちらが
四十万四万語彙のウェブ
です
これらを足し合わせるとこのような認識性能になり
語彙サイズは変わっていないのですがこれらを足し合わせることで
性能が改善していると
いうことが分かります
今回話題の依存性は完全に省いているので
単純に学習データが増大して話し言葉のスタイルがより学習できることによって改善したと言えます
また語彙サイズを増やすとさらに改善しています
一般的な知見としてＣＳＪは話し言葉のスタイル的には十分なデータ量と今まで考えられていたのですが
今回このような結果から
話し言葉はまだまだ強化することができてそれによってＣＳＪのみの言語モデルからさらに性能改善が可能であるといったことが分かりました
ではまとめます
本
稿ではウェブ上の話し言葉データを利用した大規模な話し言葉用言語モデルの作成を検討しました
まず最初にウェブ文書による大規模な擬似話し言葉データを作成し
最終的にＣＳＪの約八十倍の話し言葉データをウェブから獲得しました
そしてこれらのデータを使って大規模な話し言葉用言語モデルを作成し
ウェブから獲得した話し言葉データのみでＣＳＪに匹敵する認識性能を達成することが分かりました
またウェブから獲得した話し言葉データとＣＳＪを組み合わせることで
ＣＳＪのみよりも高い認識性能を達成しました
これらの結果から話し言葉音声認識のさらなる高精度化に向けてウェブ上の話し言葉データの利用は有効であることを示しました
以上です
