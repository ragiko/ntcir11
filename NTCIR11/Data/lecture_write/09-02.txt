です。よろしくお願いします
未知語に頑健な音声ドキュメント検索手法の検討というので一般的な考え方を中心にですね最初
言ってですね、それで我々の実験結果を紹介するという
ですね
特に音声を対象とした検索で
非常に難しい問題というのは認識誤りですね
それにに対してどう検討するかというのとしかも高速にやりたいという
そういうよな考え方でどういうよな考え方があるかという
最初は検討していきます
この研究の背景とか目的というのは
ほとんど常識的な話なんでいいと思いますけど
大量の音声データに対して高速に検索したいということですが
そういうよな意味でこの認識誤りが途中で生じるということでどうするか
あるいは未知語に対してどうするかということですね
テキスト検索の場合は未知語というのはそれほど問題にならないかもしれないですけど、音声認識の場合は
認識システムに単語登録
は二万語とか六万語とか
例え登録してもですね、未知語が
結構多くなると。特に検索したい単語というのは
案外未知語が多いとかそういうような報告もありました
例えば、検索したい単語のうちのですね
三十％とか四十％が未知語であるとか
そういうよなんで
非常にこう固有名詞とかですね
そういうよなんで普通の単語辞書には無いようなものが検索対象になると
いうことで
未知語に対してどうするかとか、認識誤りにどうするかと
いうことになる
で認識誤りは三種類普通ありまして
例えばこのフーリエ変換としたらですねえ
この
挿入誤りとか
ですね
それとか
時間誤りですね
それとか
こういうよな脱落誤りがあると。これは音節列で認識した場合の話なんですが
単語単位の場合には単語間での挿入とか置換とか脱落になるわけですが
未知語に対しては音節列
一つはですね
音節列で認識しようということになるわけです。そういうよな場合にはこういうような三つの誤りを対処する必要がある
で先行研究についてはどういうような対策していたかといいますと、サブワード単位で認識するということですね、一つは、未知語に対してはですね。例えば二万語対とか六万語の大語彙で認識して
それと並列にサブワード単位で認識しておくと
いうことですね
でサブワードの結果に対してはラティス表現
あるいはグラフ表現
あるいはコンフュージョンネットワーク表現、ネットワーク表現等いろんな表現方法あるんですが、そういうよな認識結果に
対して検索を行なうと
いうのが一般的に行なわれているんですが、こういうよな
表現にしてもですね
やはり
認識この
表現の中に認識結果が
正しく入ってなかったらやっぱり検索できないというので
挿入とか脱落を考慮した表現にはなっていないということになるわけです
そういうよな問題に対してどうするかということで大きく分けて二つの方法があるかなあと思うんですね、未知語に対しては
でこの一つの方法としてはまず大語彙音声認識しておくということです
それでクエリが既知語であれば
こちらで検索するということになり
ますが
未知語であれば
この二万語とか六万語の辞書に無い場合は
サブワード単位の認識結果に対してサーチする
ういうことになります
同じような構成ですが少し違うのは
例えばクエリをですね
単語単位でサーチすると
いう、これ見つかればいいんですが、見つからない場合は
この結果を
こう大語彙の単語単位の認識結果ですが、それをサブワードのシーケンスに置き換えて
このサブワードシーケンスに対してサーチすると
いうことも
考えられます
でそれでも見つからなかったら、サブワード単位で認識しておいた結果に対して
サブワード単位のシーケンスで
検索すると
こういうよな考え方もあると思うんですね
我々はどうするかということですが、基本的には
先ほどの
二つの方法とある意味では似てるんですが、大語彙音声認識しておいて
既知語であれば、クエリがですね既知語であればこの結果に対して検索すると
いう基本的な考えは一緒なんですが
未知語であればですね音節認識結果を出してですね
でそれに対して検索、音節列で検索して
でこうです
でそれでですね、
こういうよな音節認識結果はやっぱり精度が曖昧なので、検索結果の候補が沢山出てきますので
系列のマッチング、ＤＰマッチングですね
それによってもう少し精度を上げてこの
多くの候補から絞り込むと
いうように
して最終的な結果を出すという構成にしています
常識的に考えればですねえ
やっぱり既知語に対しては大語彙認識結果
を使う方が良いかなあというのが一般的な考えになっていると思うんです
全ての既知語であろうが未知語であろうが全ての単語をですね
サブワード単位の認識結果で検索しようというのはちょっと無理かなと
そういうような研究もあると思いますけど
そう考えています
でそれで高速に検索するためにはどうかという考え方ですね。ここでちょっと考えて頂きたいんですが、脱落、置換誤り、挿入誤りと
いうような
系列があるものに対して
高速に検索したいと
いうのが音声特有の問題だと思うんですね
でよく使うのがサフィックスアレイなんですが、ここはさくさくさくらとかなっている例でいってんですが、普通はこういうよな
サフィックスを辞書順に
並べるわけですが
ここで考えてんのはトライグラム、三つ組みを検索単位としています
三つ組みを
そういうよな場合は、こうさくさくさくらを、さくさとさくとさくさ
さく
さくらとかそういうよな三つ組み
一音節ずつずらしながら
三つ組みのですね
トライグラムを作って辞書順にソートしておくと
そういうことなんですが
これを認識結果そのまま
正しく
できておれば問題ないんですが、置換
挿入
か、これは
トライグラムをどう表現するか、数値でどう表現するかだけの話なんですが
挿入誤り、脱落誤り、置換誤りの場合どうするかという話になるわけです
で例えば先ほど言ったような挿入誤り、フーリエ変換とかイが入るとかですねえ
こっちフーリエのエがケになるとか、フーリ、リが脱落するとか、そういうよな
時にどうするかと
いう時には挿入誤りに対しては
認識結果をですね、脱落まで考えて
挿入と仮定される仮定というのは
システムにはわからないですが、全ての
音節を挿入誤りと仮定するわけですね
でそれを脱落させてトライグラムを作るというように対処する
ということです
で置換誤りに対しては、認識候補スリーベスト上位三ベストまで併用して対処すると。そこに洩れるとどうするかという問題起こるわけですね
上位三位
候補に入っていなかった場合にも対処はできないと困るわけですが
一応上位三位、三ベスト、これをＮに
Ｎベストと一般化できますけど、一応三ベストまで
ということにしてますが
で脱落誤りに対しては認識結果に音節が脱落してしまった場合は
クエリーの方を脱落させて
検索すると
そういう考えで対処します
そうすっとですねえ
この挿入と脱落を組み合わせれば、これ認識結果で
脱落させる
クエリーで脱落させると
そうですね。認識結果で挿入があるとしてトライグラム作るときに脱落さす
クエリーを脱落させる。これを組み合わせると置換誤りにも対処できます
そういうよなことで
例えばですねえ、具体例と言えば、一つはこうやっていくわけですね
この誤りが無いとした場合はこう一音節ずつこうずらしてトライグラム作っていくわけですが
こう辞書順に
ソートしておけば高速に検索できるということで一般的な手法なんですが、テキスト
検索では
それを挿入誤りに対しては
例えば例、わかりやすいために
これが挿入誤りと
仮定するとですねえ
そこを脱落させた
こういうよな三つ組みも考えるという意味ですね
だからふ、く、うも
ふ、う、りも、そういうよなのも一応登録しておくと
いうことです
で置換誤りに対しては第三候補まで考えていますから、こう
第二候補、第三候補までに入っておれば、この組が登録されると
いうことになる
登録する数は
増えますけどね
これで対策できる
で
もし認識結果に脱落があった場合ですね
例えばフーリ、エが抜けていたとか
フーリが、リが脱落して認識されたとかね、そういうよな場合はここを脱落させ、クエリーを脱落させる
いうことで対処をしよう
いうことでやっているわけ
でそうすると今三つ組みですから、もう少し長い単語の場合どうするか
五音節の単語とかですね
六、七音節の単語とかどうするかと。三つ組みの
組み合わせで考えると
例えば五音節の場合だったら、形態素だったらけいたという三つ組みと、たいそという三つ組み
これで検索して
両方とも引っかかれば良いと
いうことですね
こういうよな
三つ組みの組み合わせで単語を検索すると
いうので対処しようと
してるわけ
でメモリ量としてはですねえ、どの程度要るか
あるいはこれＮグラム、今三グラムですけども、トライグラムですね。で音節ラティスの候補数
三候補まで考えているんですが、それをＮまで
とします
それと認識対象というか検索対象の音節列で表したときの音節数を
スモールＮとしとんですね
で、一つのＮグラムに必要なメモリ量をＴＲと書けばですねえ、これは十六バイト位あれば
一つの登録ができるとしてですね
で、全てのメモリはこの程度になると
いうことなんですが
もう少し具体例で言えば、一時間の講義音声で
必要な容量というのは十四メガバイト
メガバイトぐらいで
音声ファイルよりも少ない
という程度で表現できると。百時間の講義音声であれば一．四ギガ
バイトぐらい
いずれにしても実際音声ファイルと比べて
それ、それよりも少なければ問題ないであろう、メモリ的には問題無いであろう
思うわけです
思うわけです
あとこういうよなんでやるとですね、ちょっとあいまいになるので多くの候補が検索されます
それを絞るということでどのように絞っているかといったら、最後は
この入力系列とクエリーの音節系列
今音節という単位で言っていますけど、サブワード系列ですね
それでＤＰマッチングすると
いうことをやってるわけです。こういうよな傾斜制限でやって
ただ本質的には脱落とか挿入というのはあまり許すと
ですねえ、ちょっと
制約がゆるすぎるので
少しペナルティ与えています
挿入とか脱落
に関してはですね
それともう一つちょっと考慮する必要があるのは、もし入力としてわたと喋った時に、まになってしまったと
これが脱落してしまった場合ですねえ
普通
ＤＰマッチングで距離を計算するにはこれとこれの距離とこれのこれを距離を計算するんですが
やはりちょっとまずくって
このわたの時がまになったというのは、あが
こうあたになったということを解釈すれば
わとまは距離計算して、これとこれを計算するにはこのあ、あとたを計算するというようにしています
した方が良いかなあと思っています
それと挿入誤りですね
こうが、もしぽうとなった場合
これはこうとぽうは距離計算しても良いけども
このうとこを計算するんではなくて、このおが分かれた後いう意味でおと、うと
距離を計算するとそういうよな修正はする必要があると
いうことですね
でその距離の定義ですけど、これはバタチャリア距離を使っています。音声の音響モデルですね。音響モデルは多次元
正規分布で表していますけど
その分布同士の距離
で
音節間の距離を定義しています
これはよく使う方法なんで
省略しますけど
これが一例ですよ。距離音節間の
距離ですね
こういうよなメジャーを使って音節列同士の
距離でですね
求めて
たくさんの候補を絞っているということ
それでこういうよな方法でどれだけの能力があるかというのをちょっと
考えてみようということですが、大雑把なんですけども
ですねえ、例えば認識結果今三音節を考えているんですが
これが全て正しければ、この三つ組みとしては正しく検索されます
それともし三音節がここがここが迷った間違った場合ですねえ、で次が正しかった場合
これは挿入誤りとか
置換誤りとかいろんな誤り方があるわけですね
脱落も考えられますけど、こういうよな誤りとそれ以外が正しい場合
あるいはこのここの場所が間違った場合、ここの場所が間違った場合とかいろんなパターンが考えられます
で今の説明しました対策ですねえ、挿入誤り対策、脱落誤り
対策
置換誤り対策を併用すれば
これに対処できると
いうことですねえ
でそうすとそれのパターン全部足すとこうなってですねえ
でＰをいろいろ変えてみるとですね、これがＰがＡｃｃｕｒａｃｙに対応するんですけど
精度としてね。でＡｃｃｕｒａｃｙが
例えば九十％になれば
正しく九十五％
検索できるとかそういうことなんですが
しかし音節の認識でですねえ
Ａｃｃｕｒａｃｙを
七割とか八割というのは非常に難しくて
ここらへんができててもこの程度であるということなんですね
これが一つの目安かなと思うんですね。我々が提案している誤り対策ね、認識誤り対策を三つ組みでトライグラムで高速に検索すると
いう方法使った時の未知語のですね、特に未知語ですね今
未知語の検索精度
の推定値です
で実際に評価実験やってみたんですが、講義音声に対してですねえ
やってみたんですが、まず音節の認識精度あるいは単語の認識精度はどの程度得られているかというのをちょっと
おさらいしますと、朗読音声、これＪＮＡＳのデータベースなんですが
単語認識率
ですね二万単語の場合ですけど、登録単語は
そういうよな場合でＡｃｃｕｒａｃｙが九十三％とかコレクトでは九十五％ぐらい得られるわけですねえ
丁寧に読んでいるというような音声に対しては
で音節列の認識に対してもＡｃｃｕｒａｃｙ八十三
音節でスリーベストだったら九十三％ぐらいとか得られるわけ
でこれぐらい得られるとですねえ
問題無く検索、Ａｃｃｕｒａｃｙで八十三とかいったんですが
ここら辺ですね
ここら辺ですから、未知語に対してもですね
かなり
検索できるという話になるんですが、実際にはなかなか難しくて、講義音声になるとＣＳＪ
の講演音声になると、これ我々のシステムですけども
単語単位での認識率、大語彙認識音節音声認識で
七割弱ですね
コレクトで七十三％と
音節で三ベストまで考えてもこの程度です
でところが講義音声になるともっと難しいと
いうことですねえ
でこれですねえ、単語ではもう五、六十％の認識率
音節でスリーベストを使ってもＡｃｃｕｒａｃｙで六割ぐらい
Ｃｏｌｌｅｃｔで七割ぐらいですね
そういうよなことで。でちょっと思い出して欲しいんですが、我々これ評価実験やったんはこれで無謀にもこれでやってしまったんですが
もうちょっと本当は
精度の良い結果を使ってやったら良かったんですが、この認識結果に対して未知語の検索しようとしているわけです
そうすとＡｃｃｕｒａｃｙが六割弱なんで
先ほど振り返ってみると、これに対応します
だから未知語に対して半分ぐらい検索できる可能性があると
いう程度なんですね
でそれでやってみました
それがこれが結果なんですわ。これが既知語の場合です
講義音声に対してまず既知語であります
で既知語三十一語、何回も出てきますから延べ四百五十八語ですけど
で既知語に対してですね、大語彙認識結果で単語単位で検索する。それは音節列に変換してからやってんですけど
単語単位で検索しても、音節列に変換してもそんなに変わらなかったですね、結果としては
再現率八十七％、適合率九十一％として
講義音声で
結構
こう認識率悪かったんですが
この
五十六％とかね
そういうよなんでもキーワードは正しく認識されていると
こういうよな
例えばクエリですねえ
こういうよなのは比較的正しく認識されていたということに対応していると思うんですけども
この程度だったということ
でそれに対して未知語に対してはどうかということですねえ
で未知語に対しては、この愛知県とか川口湖と
こういうよなのが辞書に登録されていなかったということですね、二万単語に
でこれの四十五種類
延べ百五十
個に対して検索実験をやったと
いうことです
三名の七十分ですから全部で二百十分
の講義音声に対して
検索したらですねえ、こうなったと。延べ百五十個あったんですが、検索できたのは七十一個というので
だいたい半分弱なんですねえ
四十七。だいたいこれは偶然かもしれないけど、こう予想とだいたい一致してるんです
先ほどの
Ａｃｃｕｒａｃｙが
六割の時四十八％という見積もりなんですけど、だいたい一致してんですよ
その四十七％、偶然過ぎるぐらい一致してる。これはたまたまかもしれないですけど
しかしですねえ
ちょっと検索候補が多すぎるんですね、しかし
検索は正しくリコールは
そこそこできるとしても、Ｐｒｅｃｉｓｉｏｎが悪いと
でそれで今の方法でいろんな対策したんですよ。もともと対策無しと挿入誤り対策、置換誤り対策、脱落誤り対策と
でそういうよなのをやっ
て、組み合わせるとだんだん良くなって全て使ったら
このＲｅｃａｌｌが四十七％になったということです。でＰｒｅｃｉｓｉｏｎが
非常に悪くて三％といって、非常に湧き出しが多いということ
でそれをＤＰマッチングで
減らそうということでやったわけですねえ
だから
だから百五十個に対して
二千個以上検出されているわけで
でこれを減らそうということですね
でこれでやったのがＤＰマッチングで色と閾値変えてやると妥当なぐらいの数に絞ったのが一番右ですね
こうこれぐらいで二百八十六個を検出
したということになって、そのうち正解が四十七
ということで
実際に検索したかった未知語が百五十個だったので、最終的なリコールが
零．三一
Ｐｒｅｃｉｓｉｏｎが零．一六と
こういうよな段階ですね
ちょっと検索対象が非常に認識誤りの多いものでやったので
この程度で終わったということなんですが
基本的に我々の考えでまあまあうまくいくかなと、もうちょっと認識精度の良い
対象であればいくかなと
いうこと
がわかったと
いうことです
以上で
終わります
