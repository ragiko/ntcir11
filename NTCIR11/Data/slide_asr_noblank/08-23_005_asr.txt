てこのシステムのえー全体像なんですけれどもえーまず方法二を
を行なう際にえー音声の音声とビデオおー録画しておきます
でまたその時同時にえーと最後のデーターとして
え勿論その画像とかテキスト数内容に含まれるデーター勿論そうなんですけれども
でスライドがえー
その時間的変えられその対面で鍛えられたかといったえーそのー時代時間も
で保存してきます
でこれはえーとこのワークショップのえー視力にも使われている技術ですデーターでえ二つにして
します
で収録した音声データーに対してえー幾つかの
えー収録した音声データーを幾つか細かいことに分割します
えー例に情報のえー一つの区間をえー一文文とし
でそれぞれの文に対して音声認識を行ないまして書き起こしテキストを
とします
でえーそうしましたら
その書き起こしテキストから得られる言語的情報と音声データーから得られ韻律情報の二頭をして
え重要とすえーその文が重要かどうかといったえー推定を行ないます
体重要であるとえー判断された分だけ
を集めてえーそのこう人の要約と
あります
でＳが移動データーですけれどもこちらはえー
え先程お見せしたようにえー駅は後でそしてそのキーワードと発話を対応付ける
人に二四六という処理を行ないます
で最終的にえー先程のような関連が
できると
いう形になって
