従来の研究なんですけれども自然言語処理の分野の方では識別モデルマキシマムエントロピーですとかサポートベクトルマシン
最近ですとＣＲＦなんかを使ってやる方法ていうのが色々でてましてこれは非独立ないろんな素性をごちゃごちゃ使いましょうと
今朝の発表でもあったと思いますけれど例えば
固有表現抽出の例で言いますと単語の表層とか品詞のタイプ
であるとか周辺の単語はなにかとか
あとその単語はどういう文字で書かれるかですねなんか
アルファベット何文字かで書かれるものはなんか略語が多くてそういうものが固有表現になりやすいとかが全部日本語の場合は全部片仮名で書かれるものが固有表現になりやすいとかっていう傾向があったり
しますんで
そういった情報を一緒につかってがちゃがちゃがちゃっと一緒に使ってあげたいと
でここは当然自然言語処理の人達がやってたことなので入力はなんか書き言葉とか書き起こされたものとかで基本的には誤っちゃいないと
ようなことを考えて
それですと今回の話その入力に誤りがあるかも知れないていう話は入れられない
で一方その音声の人達てのは当然そういう話をやってやってきてまして従来の方法ですと生成モデルといってますけれどヒドゥンマルコフモデル
に類したようなものですね
実際完全にヒドゥンマルコフモデルでない場合もあるんですけれどそういったようの
同じ類のモデル
を使っているものです
でこうした方法ですとすでにその音声認識誤りを考慮したモデル化するていう方法が提案されていましてこれもう五年以上まえのＨＬＴの
の話なんですけれど
誤認識のごの字が
なんか平仮名になってますけれど音声認識の確信度を使って
なんかそのある誤認識のある確率で誤認識が
した単語を棄却しながら固有表現抽出をするていう枠組みですね
これを使っています
で音声認識結果を使う
利用して学習することでなんか誤りが入って来た入力が来たときにそれをうまく捨てながら
固有表現抽出するというようなもの
なんですれども
生成モデルの一般的な弱点といわれることとして独立
その
使う情報が独立でないと困ると
言うようなことが言われていますこれは自然言語処理の方で良く言われていることで最近
そういったことに着目
しているから自然言語処理の人達や識別モデルをたくさん使うわけですけれども
そういったふうに言われてましてこういった問題があります
