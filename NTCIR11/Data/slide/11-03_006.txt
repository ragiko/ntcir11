まずアプローチとしては話し言葉の
データというものを作ります
そのためにウェブから
一つのウェブ文書ずつ次のような流れを適用していきます
まずウェブからダウンロードしたデータに対してフィルタリングを行います
フィルタリングは言語モデルの学習に重要な部分のみを抽出する
つまり文書部分のみを今回はルールベースで抽出します
次に
フィルタリングを行った後のデータに対して
これは話し言葉なのか書き言葉なのかといったことを考えます
最終的には話し言葉データのみを使いたいのでそこで
文書スタイルの分類といったことを行います
ウェブには話し言葉と書き言葉などのデータが混在しているので
今回はナイーブベイズを
分類器を構築して分類を行います
最後に
話し言葉
と判断された後のデータに対して言語現象の補完を行います
これは話し言葉特有の言語現象というものはあくまで今回扱っているのはウェブ上の文章なので
本当に
音声を書き起こしたようなデータに入っているようなものは
入ってないといったことで
今回はまずフィラーがあまり出現しない
といった問題があるのでこれをフィラー挿入
を行います
またウェブの文章
というものは基本的には書き言葉なので
読点の位置っていうものは実際に人間が喋る
場合のショートポーズの位置とは必ずしも一致しないので
ショートポーズ挿入も行います
これによって擬似的にですが話し言葉のデータを構築していきます
このように人手で音声を書き起こすことなく
話し言葉データを準備することができます
ではこの
部分部分
について説明していきます
