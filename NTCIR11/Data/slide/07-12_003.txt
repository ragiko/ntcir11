でそれでですね現在の音声認識技術っていうのは
統計的なモデルに基づくものが主流になっていますから
そういう多様な話し言葉に対する現象を取り扱う場合であっても
やはり
多様な話し言葉の現象さまざまいろいろなものを全て取り扱っているような大規模なコーパスというのがもし
仮に存在するのであれば話は非常に簡単で
そういうコーパスから
話し言葉の多様な現象に
対応した言語モデルというのを作ってやって
でその言語モデルに基づいて
音声認識というのを行なっていけば良いと思われるのですけれども
現実にはそういうことはありませんでして
例えば国内で最大の日本語話し言葉コーパスを持ってしてでも
持ってしてましても
講演音声として二千七百二件
朗読音声として五百二十三件で合計で約七百五十万語と
でそれに対しまして例えばこれまで使われているような新聞記事で見ますと
このぐらい非常にたくさんありまして
で最近ではもうウェブなんかでも収集することができますから
この差というのは
開くことはあってもおそらく今後縮まることはかなり難しいと
でそれは一体どこに大きな原因があるかといいますと
こちらの日本語話し言葉コーパスの方は
非常に
日本語話し言葉コーパスのいわゆる話し言葉コーパスの構築というのは非常に高コストな処理であるっていうところが問題になってきます
でそういったような背景で対象とするドメインのコーパスが十分に得られない
そういう状況でどうしていきましょうかということが今後研究課題になっていくと思います
で
