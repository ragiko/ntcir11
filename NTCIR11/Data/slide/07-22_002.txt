でそういうところ考えますとマルチチャンネルの音声が利用可能なケースが多いと
いうことです
で具体的にいいますとニュースの場合ですと他国語で放送する
放送があったりですね
あとは国際会議とかですと同時通訳ブースなどがありましてそこで同時通訳の音声が
流れてくるというような状況が仮定できる
結構あるというような状態です
ででして
そういう場合はですね
あのチャンネルが複数ありまして
その複数のチャンネルに
異なる言語でおんなじ内容が入ってくると
そういう状況が
仮定できる訳ですね
で従来このようなマルチチャンネルの入力を仮定したような研究っていうのは今日も発表にもございましたけれども
基本的には同一の音声っていうのを仮定してまして何をやるのが目的かというと雑音除去とか
方位推定とかするのが目的
だったりはする訳なんですが本研究ではそうではなくって
全てのチャンネルに入ってくるのは複数の異なる言語
ですが同じ内容の発話
というような状況を仮定する
でこの認識をやってあげようということ
を考えてます
で各チャンネルの音声の認識を情報を補いながら同時に
実行するということをやりたい
ということを考えました
それでですね具体的には機械翻訳翻訳モデルなんですが統計的なモデルを使って音声認識をやってやろうということになります
でユーロスピーチの二千五年のところでも似たような発表があった訳なんですが
これは
両方が音声であったりする場合ではなくって片一方がテキストでというよう状態
を仮定しているようなものも
含まれてます両方が音声の場合もありますが
それは両方ヨーロッパ系の言語でして語順も比較的似てますし近い
ですが日本語英語というようなこういう機械翻訳が困難であるようなタスク
をですね対象とした研究っていうのがまだやられてないということでやってみました
という話です
