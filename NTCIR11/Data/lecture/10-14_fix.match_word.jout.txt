相手それではえー複数の側と言語モデルを用いたえー音声中の検索を検出の構成どこと題しまして
え違和的に最悪の方のドラマ発表いたします
えーまず研究背景ですけれどもえーこれまでのえ発表にありましたように
えー
とマルチメディアデーターのようなえーその音声を含んだデーターが増えてきていてその為のえー検索機能というのを求められており
てえーまそれに対しえー
音声中の検索を検出の注目されて
てえー
いるということですになります
でえーま代表的なえーっと音声長の検査コンテンツ方式についてえー
簡単に述べたいと思います
えー
えとまず検索対象のえー音声ドキュメント
こうえーま汗をベースの音声認識とサーバーとベースの音声認識を用いてえー単語系列とサーバーとモデル系列
にえー認識をしておきます
でえーまこのようなイメージとなります
て検索語はえー一対五の場合は関係ですからえー未知語の場合はサーバーとモデル系列化といったように
てえー検索語のえーこの基地の
地下道化によってえーこの
系列を買って書いてと言うかえーまーその二つの系列を併用するという方式をんまー
えー
歯対照的であるという風に考えます
ってえー既知語の場合になんですがえー検索に統合することで
てえー高速えーとまー父もですのでま高精度に検出が可能であるという風に考えます
えしかしえー未知語の場合なんですが
すえー既知語と比べてえー素性を取るという風にされていいます
でこれって印はえー認識誤りがえー多く起こる為です
って側の人しか山に対するえー完全性がはえー求められます
そこでえー本研究では
でえー砂漠を用いた検索方式における英語認識に頑健な
検出の実現を目的としております
てえーこれまでにえー私達の研究してはえー幾つか
えーサーバー豆腐の方式について幾つか提案をさせていただいておりましてそれこちらについてえー紹介をしたいと思います
で一つ目ですがえ新しいサーバーとの提案ということで
てこの二分の一三分の一音素ごとＳＰＳというものを提案してきておりました
でこちらは〇のスライドでちょっと説明をしたいと思いますでまずにべん勿論そうですが
ふえーこ一ナイフをえー二分割した形で
で捉え方の前半部分と後半部分に分けて別形となっております
で三分の一音素と同様にえートライホンを三分割してえー
でこの中心部分をですねでモデル化した形となります
ってですＰＳなんですがえーこちらはえーっとーお
音素のえー中心部分と音音素間の
あえー遷移弁別のえー話題の部分をえーモデル化しているという形になります
んで更に
えー破裂音ですねのえー直前に行ってるで無音部分
についてもモデル化をしているということになります
定型これらのえーサブはどの検索性能を
でえー示したいと思います実験データーについては後で示したいと思います
てこちらを見ますとえー従来の
でえーこのこのトライホンと比べまして性能が良くなっているということが分かります
えー
で次にえー検索方式
そしてえー千提案しているものとして
え複数の砂漠の検索結果を統合による検索方式
えーというのをえー提案し取りますえこちらはえーそのー先程えー示しました各サブワードもえー検索した結果
その方法二を検索方式でえー
もう統合することによってえ検索結果に含まれているこう検出とを総合的にカバーする
というえー方式となります
でえーこちらの表を見てていきたいんですがえこちらはえー
検索ご喉頭のえー検索性能になります
て先程示し素性の一番下となっております
ってことは平均的な性能となっておりますで平均的にえーの精度で終わりにべん勿論その一番高い
．一つのですがえ検索語によってはえートライホンですとか三分の一です率が高い
そういうようなこともあってえーまこのえー表に示す通りえー検索性能にばらつきが見られます
でまこの結果を見るとまーそういったような結果がえー側と求められているということで
えーっと重することによって検索精度を改善するのではないかということも予想できます
でえー本研究においてもこのサブはその
え複数サーバーが最も方式交差えー用いております
でこの統語方式の概要について述べたいと思います
えーまずえー検索対象の音声ドキュメントのえー発話区間ごとに分割をしておきます
で兄がその区間ごとにえー各側とでサーバーと認識を行ないまして
えーこのえモノホン系列トライホン系列
えー二分の一といったような形で保存をしておきます
あって検索語はえー変換規則入れてテキストで与えて
えー変換規則に従いましてえ同様にモノホントライホンえー二分の一といったように変換を行ないます
既にえー同じたばこ間でえー
で作り比例マッチングを行ないます
てその結果はえーこの発話区間をえーそのＤＰ距離が大人に得られます
えー
てえこのＡってこの図に示すようにま複数のサブはとても検索結果が得られます
えー
えー
それでえー例えばえーっと
ペアは全て統合する場合の二つのこちらの式を用いて
えーまある区間でこの場合はえーですがえモノホンのえ二匹より
にえーαという重みを掛けて
行けるというな形でえー線形結合の形で統合を行ないます
えー
でその結果えーこのように
えーえ
二つ見づらいんですがえーラージＴということでえーともう距離
としていますがえーこの辺に従って再度えー発話区間が順位付けされてユーザーに提示されるということ気になります
えー
て重みえ先程αとしていましたがその設定方法として
えー事前に定めておいた重みを設定して統合する方式ということでえー単純えこの方法を三十先生と思っと呼んでおります
で例えばモノホンとトライホンを統合する場合
デモの方に〇．三トライホンに〇．七といった形で与えます
つえー
この方式ではえー全ての発話区間において
同じ
重いん終わったよでかつ工程の重みを与えるという方式になります
でえーっとまたばこの発話関係全てに対して
でこの重みのえー適切最適であるとはえー限らないというに考えます
そこでえー
今年のえー昨年え音響会で発表して一つせていただきましたが
え信頼度を用いて重みを設定する
という方法をえー提案しております
でこちら先程と同じえー状況で
でこのえー認識のえ信頼度の大きさに従って
でえー重みをえー動的に変えるというやり方となりますでこの場合ですと
えーえーモノホン
のえー信頼度母数トライホンの信頼度を比較して
えートライホンも信頼度は高いのでトライホンにえーこの関係ではえー
んー大きな重みを与える
一有意なことになります
ベビーではその逆で
えモノホン認識の信頼度が高いのでもの方に大きな重みを与えるというやり方となります
ってこんえー区間ごとにえー信頼度に基づいて動的に重みを設定します
でそこでえーっと発話間における信頼度をおえー区間信頼度として定義します
すえーこのようなえー状況をえー仮定しますえ検索語はえーっとＡＢＣとして与えられているとします
でこの検索語とえー発話区間のえサーバーのモデル系列を
えー連続ＤＰでま陳するとおえー今回お母さんとして
えっとーま要は検索本最も類似してる考えられます
て今回八日間のえーっと側とモデル系列はえーＧＢだとします
してこの二つのえーサバとモデル系列汗をえっとＧＰ法でアラインメントを取ります
でその結果えーこのように
えーっとえー
ぴいぴいアラインメント結果が得られましてえー一から検索語で携帯をか状態を区間にそれぞれ
えー
ってこうだから与えられる信頼度が付与されております
でこの結果を
えー
検索本一致するもの正解良い一致しないえー地下誤りですとか
ずっと対応区間のみに現われる挿入誤り後は検索もの見にあるえーえ
脱落誤り
こうおえー決定します
えー
てその決定結果からえーこのような式を用いてえーとその信頼度を計算します
えー
でまずえー分子の第一項が生成回帰モデルの信頼度の総和です
えー
でこちらのえー括弧の中でそのえーと誤りと挿入誤りモデルのえー信頼度の総和えーこちらペナルティーとして
用いていましてえこの地下誤りですとか挿入誤りが高い場合には
でその間にはその検索語以外がある可能性があるのでそれペナルティーとしてえー検査もします
えー
えーって文法化はえー正解置換挿入脱落の数でまーえー平均を取るような形となります
えー
でこちらのデーターはえー傾きの影響を変化させる係数として
え用いております
すえーこちらもえー
このえー菓子などの大きさに応じて英語によって決定をいたします
てここからえー本研究でのえー提案する内容になるんですが
え複数音響言語モデルの検索結果今後の検討ということになります
てえー今までえー複数のサーバーと検索結果と思うということで説明をしてきました
うこれはえー三ワードごとに得られるえー大量な検索結果を統合することによってえ性能改善掛かるという文を知っ
そこで本研究でもえーとの対応の検索結果を受ける為に
えー複数の音響モデル言語モデルとも知ることを考えます
すえーここで
えーその対応も結構いる為にはえーとーそうすればいいかとかそういうことをえー考えますでこちら示してるのがえーサバの検索の枠組みとなります
えー
っていう交差ワード検索結果
えーんんですがえーまこちらはえー音素バードー認識結果
にも依存してこう変わってくる
とえー考えられます
そしてこの認識結果ですがえこちらはえーこちらのえー認識率の歳のえ音響モデルですそこはえー言語モデルに影響受ける
てえー変わってくると考えも
でそこでえーとその学習データーがえーことなれば
えー多様な検索結果とえー得られるのではないかとえー期待できます
あってそこでえーこの図に示すようにえ学習データーをたくさん用意しまして
えーそれらでえーっと音響モデル言語モデルを学習しますでそれぞれえーサバと認識と照合を行ないまして
えーこちらに示すようにえーまたこの
結果は得られるとしますで
こちらのえー
結果を統合することによって
低精度の改善を図るという形
になります
でえーこのこれをえー
この方式をえ複数のたばこの場合に適用しまして
で単一のモデルを用いた場合よりも高い精度を
を目指します
てえー予備実験といたしましてえー言語モデルをえ先行側の検索性能について調査をしました
でえーっとモノホンモデルを用いましてえーＪＮＡＳとＣＳＪそれぞれ言語モデルを学習しております
えー
てこの結果をするで一番下はえ平均的女性の方でもそれ程変わらない結果となっており
生活を結構見ますと
でえーっとその節検索性能にえーばらつきがえー見られまして
父の結果が得られていると
っていうことが分かりますでま統合によって双方効果が期待できるんではないかと
え考えられます
二えーっとここで本研究ではえー言語モデルに着目しまして
え複数サブワードををｘえ言語モデルの検索結果と思っても検討いたします
で用いる言語モデルですが
えーこの三つのデーターを用いてえー構築いたします
でえー一つ目のえーＪＮＡＳ
となりますで二つ目のＣＳＪ
て三つ目がえーっとウェブ事象ということでえ百二十万単語文えーっと辞書も読み系列を用いてます
でこれをウェブから収集された単語からえー構築しております
え評価実験についたいと思います
えー音響モデルをえーとＪＮＡＳでえー学習しまして言語モデルはバイグラムと後ろ向きトライグラムをえーそれぞれ作っております
で検索対象はえーとＣＳＪの約一三時間もデーターでえー検索語は五十件
え専門用語など五十件を用います
評価指標をえ平均適合率の平均値を用いております認識エンジンはＪｕｌｉｕｓを用います
てえー評価実験のえー方法なんですが
えークロスバリデーションにより評価を行ないます
えー単純線形統合におけるえーっと重みの組み合わせと発話から信頼度におけるパラメーターとしてデーターがありまして
えーこちらのえー最適な訳屋台で
評価を行なう為です
んで検索も五十件ありあるんですが
でそこ分割をしてえー起こる
評価を行なっております
てえーまず初めにえーっと言語モデル別の検索性能を示します
歯えこちらを
でえーえそれぞれＪＮＡＳＣＳＪ例文辞書の結果となっております
でくえこちらを見ますと
えー二分の一音素三分の一音素ＳＰＳとライトモノホンの順でえ精度が高くなって
います
えーえ次にえー
私立中の言語モデルを用いてえ複数のサーバーとの検索結果を
放送の側の性能について示します
えー
えっと一番上にあるのがえーサバル単体での
えー最良の性能となります
えー
でこちらを見ますとえ反対の場合と比べて統合することによってえー検索性能が改善しているということが分かります
って更にえーと単純なやり方ではなくえ信頼度も知ることで
えーちょっと変わらない場合もあったんですがえー殆どの場合でえー約一二パーセント程度の性能が改善されております
でこのことからえー三本男か
ですとか後分かん信頼度も知ることの効果というの確認できます
ってまたはえーそう組み合わせの数が多いことをえー検索性能が改善する傾向がありました
というえー三つがはえー二つ統合する場合って
でこちらが三対四テストなんですが
てその組み合わせの数が多くなることをえ性能改善する傾向が
ありまして
えー
ま数が多い程そこの相関が大きくなる
と考えられます
でえ次にえー二箱一つでえーＪＮＡＳと言語モデルとＣＳＪの言語モデルの検索結果を方もした場合の性能
おしめします
てその単体最良とありますのがえー前はそうＣＳＪでの
えー
最良値となり
えー
一〇一二の三回最良値と比べますとえーと音をすることによってえー一から四パーセント程度ですね
補正の方はえー
改善しております
でまこの結果からえー
くその言語モデルを用いいうことで
って性能改善しているということも分かります
で更にえー名物の言語モデルを追加した場合無声の二ですが
増えたんだ開催量は先程と同じでもえーと三つの言語モデルでの最良値となります
五つの白いえーところがえーとＪＮＡＳとしえ先程示した結果になります
昼間ついて述べ文章を追加した場合の性能です
ふえまずえー単純線形統合の場合なんですが
えー半
とさせて二十以上のえー常するのではなくてえーサポートでえー一パーセント前後改善
しております
てまたえー信頼度を用いた場合にはえー全ての砂漠でえ改善ありまして
え最大でえ取らこの場合ですが三パーセント程度改善しております
え次にえー複数の差分を後にえー
ん適用した場合の性能について示します
え言語モデルはえー素性出すとＣＳＪになります
えーえーっとこちらも側の九月なんですが
えーとトライホンの場合えーっと多値がその衛生のちょっと低かったのでえー今回のＣＳＪのみを統合しております
えこちらを見ますと
えー
まず単純線形と面は
え半数以上のクラスが一パーセント程度改善をしております
価値を四十のみの場合と比べて
え一パーセント程度改善しております
あってえ信頼度を用いた場合にはえー全ての組み合わせで一から二パーセント程度改善
となっておりまして
えーうまこの結果からはえ複数の砂漠の場合でもえー複数の言語モデルを用いて
っていうこともえー効果を確認できました
えー
それで次にえー不辞書を追加した場合のえー戦後になります
てこちらの場合も同様にトライホンはえーとＣＳＪのみを用いております
えー
でまずえーＪＮＡＳと表わすんで単純線形と文の場合ですが
えーＪＮＡＳとＣＳＪのみと比べましてあえっとー僕ら比較しますと
えー戦後ほぼ同じとなっておりますてこの原因といたしまして
えー今回えーっと単純線形統語では重み法をえーと〇．一刻みで設定してまして
で更にえーっと重みが〇を含む組み合わせ方はえーと除外してえー実験行なっております
えーでつまりえっとーこのこの場合ですとえー
とー検索結果を一個使っていることになるんですが
えーっと全て〇と一一というえー
近所の重みとなっていってませんのすることを
改善しなかったのではないかという風に考えてえ
持っております
えー
で次に信頼度使った場合
ですがえーまーそう変わらない場合も
て殆ど変わらない場合もあるんですが
テーマ最大．五パーセント程度
改善する結果となりました
てえー元の元といたしましてえー信頼度語で
でその寝台車高いところも三をえー統合していった為であるという風に考えます
てえー最大でえー今回えー八十二．八九パーセントということで性能が得られまして
えサバを単体の最良値よりもえー七．四パーセント改善しまして
で言語モデル単体の最良値よりもえー２．〇パーセント改善する結果となりました
えー
ですで最後にえー検索時間について述べたいと思います
えーでこちらはえーサバ団体の検索時間でえーっとそのクラスは統合処理のみに要する時間となります
て信頼度を用いる場合このアラインメントですとかはえーその
って発話区間ごとに重みを計算するので
定義文をえーあ
性能化と
検索時間掛かるんですがえー
えー
ありますでアラインメントはえ照合時間もえー平均すると約二割程度の増加で
とかですのでまそれ程おーま大きな
えーっと伊藤ではないかなという風に思っております
正解にえー二分の一三分の一音素ＳＴＳについて
言語モデル三つ用いまして結果の信頼度を使って統合する場合へ行っちゃったり読んで
約四秒程度
検索に時間が掛かることになります
テーマこれ一のＡ対策といたしまして
えーうちＢをえーとその用いまして処理を並列化することを考えます
メーカー
て今回仮にえーま三つ前のモデルを用いますので三つのＣＰＵで並列化することで
でま三分の一程度に抑えられるのではないかという風に考えます
えーっとえーまとめます
えー
本研究ではえー複数のサーバーと複数言語モデルの検索結果と面によるえー音声情報検索の検出において
えー高精度化する方式の提案を行ないました
てえー最大でえー八十二．八九パーセントの検索性のえーということができえサーバーを単体と比べ
てえー七パーセント程度
言語モデル単体と比べて二パーセント程度性能改善しまして
え提案す方式の有効性との確認できました
って今後の課題なんですがえーっと検索性能の構成とかということで
えー今回三つ用いましたがえーそれ以上の数のえ言語モデル
思っていることで後音響モデル今回できなかったので複数の音響モデルで特にＣＳＪを用いる
ということをえーこん
進めていきたいと思っても一人も
てまたをえーサバと認識処理のえー区間がえー
夏の数を増やすことにも大きくなってくので
テーマ少数最良での結果が得られてい女はえー
サバ取ってそこは言語モデルの選択方法の検討を行なっていきたいと考えております
え以上で発表終わります
