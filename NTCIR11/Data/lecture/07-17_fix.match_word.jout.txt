えー神戸大学の差これえーっと表記のタイトルで発表させていただきます
えまず研究の背景なんですけれどもえー近年まー地名やコンテンツがえー増大してきています
えその為人手でまー全てのマルチメディアのコンテンツを設定して
えー何を見るか決めるということが非常に難しくなってきていると
言えると思いま
でその為えー検索がま要約を行なう為のえー情報が必要となってきます
でこえー真面目で何件全てを無礼というのはえ少しまー難しいっているとおえー考えられますので
えーま代表としてまスポーツが扱い易くうーま二つも存在するということから
テーマスポーツ実況中継そしてま特にえ九十途中での構造についてまー構造化をえー行ないます
でここでえー音声認識を利用してえ特にえー後で標準型の音声認識を利用して
でまその認識結果を用いてえ構造化をなものとします
えーえシステムの概要なんですけれども
えー
このようにえーまラジオの
中継音声がえーあるものを
え音声認識しましてまその結果から
え構造化を行なうということになってます
で構造化の内容なんですけれどもでまーどうかどうかお前が一回のモデル一回の裏でえ息子がえーばＡの音ではなくて
いったようなまかんこの情報構造としてえ二をしていくということをえー目的のこの今
でここで特に重要度があるのがえーまー男の子のえー境目だったり
えーっとないかもどうもまー境目母音を観との境目もしくはそのバーがえー火を用いなどがえー一項のことをまー
でえー温泉式をえー用い上での問題点なんですけれども
でま当然この板橋区えー認識できればいいんですけれどもえーこのアルコールが
え例えばこうボールといったようにま高認識されてしまうといった問題があります
でここでえー音声から音響モデルえー
ポータル適用するものもしくは言語モデルを
えーきっちりマッチしたも使うということで
えー認識精度を改善するんですけれどもえー改善しても
えー大体六十五パーセントと
えーそれえーその程高い値とはならない
いう問題があります
えその為
えー音声認識性能をまー更に向上させるということや
えータスク持っ
すえーま野球中継というタスクの知識を持ってることによって
えー誤認識へ対応するといったことがえー必要となってきた
えー音楽を知識を用いてえー音質評価するというのは
えとどここでえーアルコールを溢れ今使ってるんですけれども
えー次の発音男でも三線という発話がありますので
えーまこうボールと水のバッターに代わるだろうという知識を用いれば
え次の端に変わった
変わってすぐにもう三四のおかしいといったようの判定ができると考えます
でえーこのようなえー点に注目して
えー従来えー行なってきて提案なんですけれども
えー野球のまー二十代の状況とえー単語をえー同時に推定すると
いうような音声認識をえー
提案してまいりました
えー同時に推定することによって音声認識の中に
えータスクの知識をえー持っていることがえーできるようになります
でまたその状況を推定いたしますので
えー状況と構造というものも対応を取るといいよって
で構造化もえー可能であると
いうことになって
えただしえーと先程の例のように
えー改善が得ない部分というのは
えー状況の変化に関連のある〇かそだけとありますので
えーま単語誤りの改善はえ一はこの三人限定されていると
えー一つはえー問題
かなり
でまたえーっとー
音声認識率をまー報道させる為のえー
提案します懸命いたしまして
えー話題の遷移を考慮した言語モデルというものを提案も行なっています
えーこれえーこれはえー全体的な単語誤り
崩壊え改善というものが得られるんですけれども
でえーま構造というものはえーま考え方にもえーま構造化はできるということになっ今
でそこでまー親の二つの手法のえーとま高校いたしまして
えーまー全体的な単語誤りを改善した上でえー
でまたその知識を用いて構造化を行なうと
って言ったえー提案を行ない
えまずえ従来の二つの手法についてえー解説えー説明さしていただきます
えまずえーこのえーとー京都単語を同時推移する
え音声認識についてえー動作してたと
えー
本手法ではえーま単語系列のＷとえま東京の系列をベースとしましてえ観測音声の系列方から
またと同時に推定するとえデーター形式を行ないます
でえーま通常であればえーここが
てこれがま比較をＷ体系ってこちら側のま一がないと
えーいうような式になるんですけれども
えここではえー音響モデルも言語モデルも
ま状況というものが関係してくるって思いながら
でえーこれを展開いたしますとちょっとえーここなるんですけども
でまーちょっと複雑なのでえー
ポーズでえー簡単に表わしたいと思います
でここでは
えーまた意志的に得られたえーま形式なんですけれども
えー単語がえーま前の単語に依存する
で更にはえーその状況に依存すると言ってたような
モデルになって今
えーま即ちえま状況に依存したバイグラムであると
えー言えると思いを
でここでえー状況の遷移確率というものもえー存在するんですけれども
えーま完全にまＨＭＭのように相当遷移確率が存在するだけという
言語でもまーいいいかと思ったんですけれどもまもう少し積極的に
まず音を推定するという意味で
えー
前のえーまー
認識結果ですね単語認識結果を用いて
えー次の状態を推定するというような
えー少ないモデルになっております
でこれによりまして
例えばストライクという単語があった場合にはえま水でそれ今度は増えるのかなといったような推定を行なうと
いう風になっております
でえーっとこのモデルでまどういうえー効果が得られるかというところなんですけれども
ま例えばここでま先程二十五えー先程の例なんですけれどもまある五六方
思うと
えー誤認識した場合
えー次の増大
後はえー次の状況はま次の祖母に変化すると
ま左右されたえーストライクカウントボールが本父がまー〇に戻るといったような推定が行なわれますもんますねまえー
推定が行なわれます
でここで
えーまー大阪三線というような場合なんですけれども
でここでま二つのえー
場合が考えられまして
でま関心とそのま認識されてしまうと
いうた場合には
えー次のえーっとラティスの状態の
ま遷移確率が
テーマ
それがあの〇んとこ時からえー三支援するという選択とま存在しませんので
ここ〇になるということで全体的な尤度は
え体系化する
でもしくはその頭子音ではなくてま誤認識なんですけれども安心と二つあると
えー
見た場合には
えーま言語尤度音響尤度共にま体が私ますので
えーま全然できない尤度差があると
えーとユーザー結果になると考えられます
でそこでえーまー
えーそもそもこの
終わる頃おーま方法ま一月にえーまーあることを認識していれば
全体的に誘導はまそのこと生活なっても済む
っていったあー結果が得られ
え利点としてはまえー以上のような
えータスクの知識を用いて
え誤認識を化することができるんですけれども
あ回復することができますまたえー
状況をえ推定するとこう備えていますので
てその木構造化
行なうことができるといった利点が挙げられます
えただしえー改善をすることのみに限定されるとえまたえーラベルをもう不要
行った上で学習を行なう必要があるといった欠点があります
で次にえー話題遷移を考慮した言語モデルなんですけれども
えーこちらはえーま野球中継を見た場合にも発話内容がある程度
固定されていて
えーまー
えー表現がえー
偏っていると
でそれから発話全部にもま一定の規則のようなものが
ありますので
でそのようなものをえ表現できれば
で認識精度を改善するのではないかという風に考えます
でそこでえー
えー話題のえークラスタリングを行ないえーそのクラスターごとにえー言語モデルをえー構築いたします
えそしてえークラス間の遷移確率を与えることによって
でまこの第一のような形でえー言語モデル
ま全体の言語モデルを表現しまして
えーこれによって認識精度は八回です
するのではないか
えー
いう
となって
でえーこれに関しましてえー従来手法としてえー中はえー生物によるえー
え生成Ｎグラムというものが提案されて今
えー生成何グラムでは
えー家まアルゴリズムを用いまして
えー
ま単語
おーテーマ一ののように正規化することによって
えー複数の言語モデルをこう
四でその言語モデル間の
えー遷移確率を与える
えっとモデルになって
二つ入れ方もえ生成Ｎグラムでは数件
田んぼをベースにえー
えー言語モデルを学習する為え学習するということなっていますけれども
で本研究では
えーもうそこ潜在的な話題を考慮した
えーモデル
をえー提案いたします
でえー潜在的なモデルを考慮したえまずえー先程から何度も出てきてると思うんですけれども
えＰＳ重過ぎまして
えー文章構成する洗剤と結構学習いたします
でその潜在えーまた訂正では
仙台トピックごとのえー単語Ｎがまー学生ですでまー
えーま例としましては例えばまーワールドカップの経済効果についてのブライダルサイトがあるというでは記事
えーんの
え潜在トピックを分割してはまサッカーがこのくらいの割合を占めて
でま経済あこのくらいの二分全てといったようなえー分析を行ないます
えー実際の英単語文章における単語出現確率は
えー潜在古くからの単語数に庭もする確率と
えー文書におけるえー潜在トピックもまー各えー出現確率のま線形結合で表わされる
で表わされます
えー
このえー形成を利用してえ文そのクラスタリングを行なっていて
えーまずえー学習コーパスがあーまこのようにまた的文章の中三年ですけれども
でこの文章に対してえー系列を行なうことにより
えー各音素における潜在トピック性と音からえーずっと紀元前のえーますえー
分布のえー
確率を
えー計算いたします
でそれがえーまーえー文書の数だけ存在する
といった風になって今
でここで
えーあ五番目の
えー文書におけるえーま特徴ベクトルというものを
でこの
えー
潜在トピックの
えーまずなくてこう含んでいる割合
のおーでえーそのまま
えー
特徴ベクトルとえーいたし
えーこれをえー文章
えー会いにおける
えー
特徴ベクトルＸＹといたしも
んでそこでえー
先程Ｘｉを用いまして
ＨＭＭを構築いたします
で一年はえー一人このＡから思ってえーまー
月一回の面とか一回の裏という単位で
で一つの系列としまして
えー学習を行ないます
えテストはまこの辺があるんですけれども
でまその結果ま普通のＨＭＭになりますので
えーこのえー状態の遷移確率と
えー状態からもえーこのＸにえー
ま紛争における
えー潜在トピックの
あえーと割合ですね
僕その仙台トピック文法のえー出力確率が偉い
えーつまりえーこの過渡状態から
えー各状態から
潜在トピックのまー
えーする確率と
えーその状態間の遷移確率と二つが挙げられ
いうことになり
でえーこの
えここからえー言語モデルにえー点が付いたんですけれども
でまずえー
最初にえーっとこう却って文章をえー攻めて分析した
えーものを
えーまー潜在トピックのえー実行をまこのように取りましてでそれをまベクトルで表現するとおもこのような
えベクトルはえー書きます
でこれを全てもえー場所についてえーま分析を行なう
の行なった結果
えー
似ている話題
によっても構成されている文書というのはま近くに集まってきて
えこのようにまクラスタリングが行なわれる
いうことなりますでここまでは先程のＨＭＭの話なんですけれども
えーここで
えーここからま言語モデル化古代について言語モデルをえー構築したいので
んえー今度は思いくさいとま分布になってるんですけれどもえーもう一つうー話題括弧の五月もう一つだけの言語モデルと
でいるというえ近似を行ないまして
えーこの下降第については平均の分布だけが存在して
ま平均
一階の分布はもう存在しないという風な人で行ってしまい
でこれによって
せっかく話題のクラスターからはえ一つだけの
え仙台で行く分布がする食べると
っていうようなえーモデルになります
でそこでえーまえー言語モデルもえこの二形式お酒なんですけれども
でもう少しえー簡単にえー説明いたしも
でここのえ差異というのはえーっと
トピックＨＭＭにおけるま状態ですえートピック別にあのーえっと文におけるえその各状態の遷移確率という本を
えーそのえ状態からの
えー単語出力確率というものが
えーえー
得られるとまー高校ではこれがえー欲しい訳なんですけれども
えー各状態におけるまバイグラムが欲しいというところにえーいうところなんですけれども
えー各状態における場合はまーえーっとーこれも先程えーできたと思うんですけれども
えーグラフにしていくと
えーいう手法によって
えー
計算生い立ち
二グラムミステリーにはえー通常のまバイグラムやっぱりトライグラムから
えー各状態における議論の出現確率とまーえー各状態を提示しないえー全てのえー状態におけるえー単語の出現確率をあの最近によって
えー得られ
でこのえー各状態における単語のえー人間であるというものを
えー先程の
えー過渡状態における潜在トピックを用いて
えこのように計算いたします
でこれはまー通常のえー形成の計算式とおえ全く同じで
鉄砲
それが形成ここはまー文章になってるんですけれども
えーこの
えー先程の話題のクラスターあー全てを
えー一つの発生する古代のクラスターを
とその星という風に考えまして
でそのー話題のクラスターからえー千でトピックは
であのー分布があると
えその話題のクラスターについてえー
ええー二グラムのえ出現確率を求める
いう風になっ
でこれによって
えー各状態において
えーバイグラムを超えててまー持っバイグラムを使っトライグラムを形成することがえー可能になり
えー
この手法の丸い点なんですけれども
えー多くの単語について認識あまり高い音するという利点
とーまーもえー音はラベルを付与がなくて自動的に
え学習ができると
えーいう点が挙げられます
えーただしえーま知識をえー
付与していない為にえー構造がはえー区間行って
え提案手法ではえー先程述べました二つの手法の統合を行ないます
えこの表しかえーとー後するんですけれどもこれもえーっと
ヘルツで簡単に説明ですが
でまずえーっと両方共一という記号を使ってたんですけれども
えー最初文状況の方はえーそのま五という記号を使いまして
で先程のトピックの方はえーまＫという希望に置き換えます
えー
えー状況の遷移確率がありかつえー状況からえー
ま話題の
えー古代の強い
次に実話題が出現すると
えまつまりはえーと東京ごとにえ先程のトピックＨＭＭが存在すると
いったようなモデルになっております
でえーとす各トピックＳＮからは
えー
単語がえま出力され
出されるんですけれどもこの単語はえーっとー
トピックリズムだけではなくて
えー状況のにもえーまーどうしようとするとえーっとモデルになると
えただし今このまんまモデル化してしまいますとえー状況ごとに書い膨大な数の
えー言語モデルを作らないといけないということになってしまいますので
えーもうえーっとー
トピック別メンバーの状況にあ依存せず
えーと設計者全体一つだけを作ると
えいう風に近似を行ない
えー
これによりましてえーまー全体の認識の手順としましては
えー通常のま音声認識において毎年テストの出力を行ない
えーそのＮベストに対してまーあえー話題ごとに
えー話題止まっていですねを用いましてえー話題語と二グラムミステリーの行なう
え更にえその結果に対してえーもう一度その状況に
かなり強く依存をした単語については
えーリスコアリングを行ない
え最終的な言語モデルを得る
えーいう風になっており
でえーっと実験なんですけれどもま通常の音声認識の結果と
えーそれからえー最初にえー説明いたしましたえー状況単語を同時に推定する音声に
でそれからえー先程説明しました
えー話題遷移を考慮したえーま言語モデルとまそれらを統合した
えー
手法についてえ実験を行ないました
で評価基準としてはえー単語正解精度
えーそれからまキーワード
水は六というのは
えーっとーこの
状況を推定する為にま用いられるようなえ単語
のえー二値を求めております
えそれからえー構造化が
えーどのくらい正しくできたかということでえー一つあのーほっていうことに反映しております
でえー文えー音響分析条件はえーこのようになってま
え音響モデルは生成では別に
えテストセットと同じ音素を用いてえー話者適応を行なっております
えー言語モデルはえー書き起こしえテキストからえ学習しております
えー未知語はえーまー
ないという風に仮定しております
えー音声データーはえー
約一時間半のえー×一と二型音声で
えー異なり単語数はえー大体三千単語という風になっており
でえーっとー仙台トピックするという本て会社の状態数なんですけれども
ええー色々まー実験した結果まこのような値をえー選択しており
え結果なんですけれども
えー通常の音声資料は大体ま際立って足が六十五パーセント程度
んえー得られております
えーそれからえーま状況
を状況方同時についてその語千四十八はもう単語全体であってあえー単語
生活面との向上しないんですけれども
まーキーワードえ二の方は少しでもそうする
でそれからえー大体七割ぐらいの精度で
えー構造を正しく推定できているという風になっております
でこれにえー話題の遷移を考慮した思いを加えることにありまして
えー
約ま〇．七パーセントの改善が得られており
えーそれからキーワードについてもえ改善がえタイトル
でこの二つの手法をえー統合することにありましてえま全体としてえー
この前制度も変わらないんですけれども
えーキーワードをえー二では更にえー少し改善がれまして
えー七十五．五パーセントで
という風になってます
えーキーワード
の正解精度の向上したことにありましてえー構造化もえー正解率も
えま少し違っている
いうような結果になっておりも
でえーとー話題モデルをえー用いた
えー効果なんですけども
えー
まずえー
従来ま通常の音声認識手法ですねこれは際にえどこの村が出ましたという風にまま使ってしまっていたんですけれども
えー話題モデルもそういうございまして恐らくを定型的な表現
がえー学習された結果だと思うんですけれども
皆さんよく心が出ますと
えータスクにすることができております
でまたえーこれはお外に定型的な表現
という部分を
だと思うんですけれども
その話題の遷移確率というものを与えることによる
えー効果も得られております
えー
とーそのー
認識えまー従来ですとまーたまにという風に間違ってしまっていた
そう一つ前の発話
で
ま一秒だけましたと
四十発話が得られてるんですけれども
まこう生まれましたと
いううー発音を次の発話であるということから
また村
という発話よりもえー
まから文の方がまーそうするということで
えー
新しく認識することができていました
えーまとめですけれども
えー受け付けの構造化を行ないましてま総合的に
えー統合することにありましてえー七十二で二十パーセントの各えー生活レートがえ構造化
できていました
えー従来んえー二つの手法をえー統合を行ない
えーっと以上で発表
んー
