えーそれでは京都大学の根本が表記の題目で発表させていただきます
でまず最初に研究の背景についてえー説明します
定期健康にはそのデジタルアーカイブかと取り組みが活発になっており
でそういった中でえ要約テキストやインデックスにより人に利便性を向上することが望まれておりますが
って人手によるこれらの作成は非常にこう子育てを今
でそこでえー音声認識技術の活用によるえーこれらの
半自動化にえー
検討されており半自動化が検討されております
えーそこで本研究ではえー購入音声の認識に取り組んでおります
で本研究で対象とする購入音声の特徴と課題について説明します
えまず本研究ではスライドを持ってる購入を想定します
でここでスライドで申しますのはまこういったパワーポイントの使用のことです
えー
スライド対を用いたさまざまな項目の説明がこういった行為が行なわれるのですが
えーここではあって
スライドにえ専門的な内容が多く含まれる為
抵抗に全体としてえー最適な話題が存在します
え更にえー表示づらいのに関連する発話内容がたくさん現われたり
えースライド前の重要度スコアが反復が起こったりすることから
で局所的な話題の偏りが存在します
えこういったことから
共通の言語モデルのによる認識はＦ０となります
で具体的にどういったことが起こるかと言いますとえー話題に特有な表現の予測能力が低くなってしまう
で更にえ専門用語が未知語になり易い
といった問題が生じます
えそこで本研究ではえーこうに面移動を手掛かりとしてえ言語モデルの適用を行ないます
えこれまでにもこういう音声に対する言語モデルの適用の試みは数多く行なわれております
え代表的なものを御紹介しますとえ関連テキストを利用した方法としてまこういったものが存在するのですが
えーこれらは
影響関数がこうに音声の書き起こしといったテキストデーターを使用しております
ですがすえーこういったテキストデーターがえー電子化されていてかつ利用可能な係数というのは
テーマ限定的であります
でこういったことに対してえースライドするようを用いたえー言語モデルの適応の手法も提案されております
え具体的にはえーつらい顔のＮグラムの他による手法
が提案されているのですが例えばこれは断片的な絆知人となるえーこう二スライドではえー効果が奇麗に出てきたなと今
んー
えまた話者するモデルを用いたえースライド全体のテキストを使用してえ適応を行なってあるという手法も提案されているのですが
でこれはえー行為全体の話題に対する適応のみが行なわれております
でそこで本研究では
効率ライトの特徴を考慮した手法を検討します
えー
で具体的にはえー効率ライブにおいては
キーワードを中心とスター断片的な絆が中心であるといったこと
え更に二系列に沿ってこうに内容が記述されているこういった特徴声を使っ適応を行ない
えそれではえー本研究で行なうスライド映像を利用した適用の概要について説明します
えまず最初に
えー
でえーつらいこう二スライドで使用された面間の全てを用いてえー言えるえー性能持っていることでえー具体的な話題対する適応を行ないます
えー更にえー
学校にスライドからえー一つずつえー検索えー四一つ一えー空を用いてえー検索を行ない
くえー通常されたテキストを用いてえー適用言語モデルを構築する
といった手順で
えーこれまた一的な話題へ対する適応を行ないます
えー更にえー話題の局所的な課題をいへの適用としてま適応としましては
えー
各スライドのテキスト情報を用いてえーその面以外に
えー時間的に対応する発話に対してえーじゃすモデルを持っていることで
え局所的な適応を行ないます
えまたえーこの言えるえー前による大域的な適用
それとえー気圧モデルを用いた局所的な適応えこの二つのえー組み合わせることにより
えーえ帯域的な適用さ局所的な適用映画痩せることを行ない
んー
えそれではまずえー言える性を持っていた最適な適用についてえー説明します
でここでは
えー
五につらいあの単語頻度情報を用いたって言える衛生を用いたえー単語確率の推定
更にえースペインが
といった二つの手順でえ適応を行ないます
えこれまでのＰＬ衛星を用いた研究はえーさまざまなものが行なわれておりますがえーこういった枠組みに基づいております
でここではえー
単語確率をえー部分空間への際に基づきえこちらの好きでモデル化します
えここでえーこの潜在変数の時
というのはえー話題に対応するもの
え突然
え家なアルゴリズムによりえーこちらの日なバブルって言っＰのＴＤを付いてきます
えーコーパスからこれを推定することにより
えー人手によりえー話題を事前に定める必要がないといった特徴が今
え更にえー適応用文章おーまー持ってきてえーそれに対する潜在変数の生起確率の推定
を通じましてえー単語の生起確率を推定することから
で適応用文章の中に出現しない単語の確率の推定可能となり
でそしてえ本研究ではえー次のようにしてつらいと像を用いてえー単語確率の推定を行ないます
えここではえースライド全体をえー先程申しました適応用の文書として
えー単語確率の推定を行ないます
えこういった推定を行なうことで
でまず単語頻度のみに基づきえーこの確率が推定されます
えーその為えーこう二スライドなどでよく現われるえー一番あのキーワードの羅列などからえー確率を推定できま
えー
え更にえーコーパスから学習した潜在変数の生起確率を通じてえ最終的にえー単語の生起確率を推定することから
えーつらいの中に現われない単語の確率も推定されます
えこういった特徴があることからえー総数の間にられた単語によるえー断片的な記述が中心であるえーこうつらいと思っている場合に言える衛星が有効であると言えます
でそしてえーこのようにして求められたえー単語確率を用いてえー家からマスキングを行ないますえこちらの好きならされるのですが
でこれはえートライグラム確率全てに対してえー先程の推定行なうまーえー計算量が膨大なる為えーこういった計算を行なうことにして今
えまたはえー
スライドには主に話題に関連する傷が中心ですのでえー話題の三への適用を行なう為に
えー話題の人の語彙を限定してえーこちらのスペイン語を行ないます
でこのようにしてえー言える衛生による影響が行なわれまして次にえーテキストを用いたえー最適な適応について説明し
えこちらではえーまず
あ失礼しました
まず最初にえーこれの抽出とえーテキストの生成そしてえーそのテキストの収集道具の選択という二段階な手順でえー適応言語モデルの構築を行ないます
でまず最初にえーかつらいとからえー検索色を生成します
でここではえーＴ会とＩＤＦ値除いた名詞をえー各スライドを元にえー選択します
えそしてえーこれは検索をいたしましてえ検索エンジンをもついてえーれるテキストの生成を行ないます
えこの際えーまずえー十分な数のえーテキストを用意したいのでえー
マーカーと移動するとえー
ごみが増えてしまうのでえー二つの町にはえーくえー一つ当たりえー五百件
と定めました
えー
でそして次にえー集められたテキストにはまー
類ＩＴをえーま相手の長さより短い文や
えアルファベットがえー殆ど全て言わない言語モデルの学生にあって汚いと思われる文がまれるので
えーこれらは付いてしまう
えっとですが
えそしてえーベースライン言語モデルに対して
えーパープレキシティーを計算しえー猿がスキー場したまた文をえ学習用のテキストを
として選択します
でそして最後にえーベースライン言語モデル
のえーこの
適応用にえー集めたえテキストの今後行って
でえー適用え言語モデルをこう
え以上の手順で
テレビで傷を用いた言語モデルの方もえー適応が行なわれます
え次にえーじゃそのモデルを用いたえー局所的な話題への適用について説明します
でここではえー
じゃすモデルの枠組みでえーこう二つられたデーターを使用することで
で最終的な音声に
結果を得る
そういった手順になる
でまず最初にえー提案するモデルについて説明します
でじゃすモデルというのはえー直前に現われた単語は再び現われ易いという仮定に基づき
えー各
各単語の直前の単語履歴をえーチャンスとして記憶する
といったモデルになっております
えー突然
えー単語確率をえーこちらのようにえー
履歴の中でのえー単語頻度に基づいてえー推定します
えこの単語履歴はえー最初に自動音声認識を行ないますでえその結果を用いてえー得られ
え次にえーこの二話者モデルにえースライドを情報を利用します
でここではえー自発モデルとえー同様でしてえースライド中の単語はあー現われ易い
という仮定に基づきまして
で先程の式の影響するのを元にえーある発話に対応スライドをえー
スライド中の単語頻度を用いてえーパルスライトの下での単語の生起確率を推定します
て更にですねえー先程のテンスモデルで用いた単語履歴とえースライドを併用する
でこうしてえー総合の中での振動トータルしましてえそれを操作ではある
といったで前によりえーこちらの確率の推定が行なえます
えーこう捨てられたえー単語確率のいずれかをえーベースライン言語モデルのえートライグラム確率とえー
線形補間することによるえー適応単語のえー言語モデル確率が推定されます
でこうして得られたトライグラム確率を用いましてえ最初に行った音声認識結果のえーベスト仮説のリスコアリングを行ないます
で構成財政的なえー適用ものを低認識結果が得られま
でまた
でえー先程ベースライン言語モデルを用いて最初の音声認識を行なうと言いましたけれど
えここでえー最初に説明したえー言える衛生による適応言語モデルを用いた
えー音声認識部を組み込むことにより
え大域的な話題Ａに対する適応度をえーこの局所的な話題
えー
対する適用をえー組み合わせることができます
えそしてえーこれらの機構に対してえー評価実験を行ないました
で対象としたデーターはえー二千四年二千五年にえー京都大学学術情報メディア全体で行なわれた
音声認識音声対話字ずつこう社会におけるえー一二回目の音声となっております
え更にもう一種類のデーターとしてえー京都大学で行なわれたえー通常の後に三回分の音声を用いました
でこれらは全て時間はほぼ全て九十分となっておりますでえー五つの重複は五名のみ
でそしてえー全ての五人においてえー使用された効率ライトと
そのＴがえ時間情報が利用可能となっております
え音声認識は映画の強い検定を行ないました
でデコーダーはＪｕｌｉｕｓ三．五．二を用いましてえ音声モデルはえＣＳＪの学会講演からえー話者適応学習を行なったえー状態共有トライホンＨＭＭモデル
に対してＭＬＬＲ教師なし話者適応を行なったものを使用しました
えー〇づらいん言語モデルはえーＣＳＪの学会も二講演からえー学習したので
で語彙サイズはえー五万語のトライグラムえ言語モデル
でまたえー先程御説明したそうにおけるえーパラメーターはえー一二のように設定しました
えまず入れる前によるえー部分空間の学習ですが
でこれは
えー話題をカバーする為にえーベースライン言語モデルの学習に用いたえー結果赤い講演のえーテキストを使用しました
え潜在変数の数はえーテストセットパープレキシティーが最小となった時の値であるえ百と定めますが
またえーできるとの生成にはえー検索エンジンツバキを用いますが
えー
更にえー国の選択の際にえー用いるＴＦＩＤＦ値の計算ですが
でＴ会としてはえー彼スライドにおけるえー単語頻度
でＩＤＦはえー二つ前のえー学会主に講演の一講演を一文章と見なすか値を使用しました
えそしてえーＮグラムの頻度の今後はえー重み歩いて五つとしますが
で更にえー局所的なクラスモデルにより適応の際のパラメーターですが
でこれはえーこう全体音声に対するえークロスバリデーションにおい決定しまして
えーじゃその長さがえー六十え線形補間の重みはえー気圧の方もあるえー一五
えベースラインモデルの重みがえー〇．九としました
で更にえー適応を行なう際にはえー単語辞書にはえこう二スライド中の未登録語をえー追加しておりました
えまず最初にえーベースライン言語モデルを用いた場合の音声認識結果を示します
でこのようにえー講習会で七十五．六パーセントえー大学を二でござい発展六十パーセント
都営号仙台の方がえー認識精度がえーま大まかに高くなるといった結果が得られます
えこれは
でまー幾つかの要因が考えられるのですがえー
重要なこととしては講習会はまー学会講演に従って一回生の発話スタイルである
でそれに対して大学のこうのというなま教室で学生を相手に行なわれるものなので
で一分くだけたスタイルである
といったことがあります
でまたえー先程えー未登録語単語辞書に追加した場合はえーまーその改善はえー×となりますが
えこの実験ではえーこの三道路が追加された単語辞書を用いてえーすモデルの適応を行ないました
でえー次にえー冷静によるえー具体的な研究を行なった場合の結果を示します
えースライドを用いたところえー改善が得られたのですが
でえー認識結果を用いた一度の三ＬＳＩを用いた場合でこちらの値ですね
でこちらに比べてえー
番号に精度のせえー改善は三割結果となりますが
えこれは認識結果にはつらいのに困らない情報も含まれる為
で七ですがえー
ただえーつらい共付ける場合えー合成音二は一の間で行ないば良いので後続なそれがあの都内
でまだ一単語としてえー
認識結果をえーベースラインのモデルの学習テキスト二言語して
えー
認識を行なった場合をえー上回る結果となりました
え次にえーテキストの生成によるえー適応を行なった結果について説明します
でここではえー
やはりえー単語に精度の改善が見られましたが
でこう社会ではえー一パーセント酒
の改善に止まったのですがえー大学を二ではえーま二パーセント
今日の改善となりまして
部屋の改良になさそう舌を出ました
えこれはこう一回の話題はまー音声認識関係のものが多いのでえ話題がある程度カバーされているのに対して
声帯学校には全く関係のない話題なので
で話題関連のえテキストの収集によりえーこういった
ベースラインのコーパスでカバーされていない話題がえー適切に音になるかと考える
別にえー気圧モデルを用いた場合の
結果について説明します
でこのようにえー
通常のジャズモデル用いた場合えースライドを用いた場合
更にえー
つらい時や調整をした場合
でそれぞれにおいてえー話題の局所的な形に対する
適切な適用が行なわれて
え認識精度が改善されました
でその際表示されているつらいどん底があって急に有効であったと考えられま
で更にえー具体的な適用と局所的な適用の組み合わせを行なった結果を示します
えこちらがその値ですでえーこれはえー二衛生えーじゃすモデルそれぞれ単独で用いた場合の結果となっております
えこのようにえー具体的な適用といっ局所的な適用の組み合わせによりえーほぼ客観的な効果が得られました
えまたえー各
五年ごとのえー単語認識精度を見てみますと
え例えばえこちらの方にではえー例文の説明などの影響によりえーＰＬ衛生の交換はえ非常に小さくなると言うか悪くなっております
え更にえーれるテキストの生成の手法に注目してみますと
えこれらでは
えー
二つ精度の向上がえー低くなっておりますでえーこのようなテキストの青春が起こってしまった
ということが要因として考えられます
でまこのようにえー全体としてこう人内容やスライド後です形式によってえー適応の効果はえーばらつきが大きいという傾向が見られました
え第学校に対してはえーこのようになっております
猫面でのえーこの二つの語にはまず次の文記述が多い為にえー言える衛生による適応の効果はやや小さくなるといった傾向が見られますが
えまたえーこちらの方にではえーテキストを生成によるえー大幅な改善が見られました
でこれは英語の方にはまー画像それに関連する話題がえー話題のページなどで
えー
テキストの収集がえー高価で現在大スターと考えられま
え更にえー話題語の二つ精度による評価を行ないました
えここではえーこれらの語をえー話題ごと定めまして
でこれらは高二の内容理解の為必要でありえー認識結果表だとそれが正解要約をする影響が大きいと考えられます
えこちらはえー再現率適合率による評価を行ないました
えー交通書い音声に対する結果をこちらに示します
で言えるえーせえー年齢えこちらの値って言っなってきをですねそれに対して局所的な適用他にえーその二つを組み合わせた場合
についてえーすっえーを示しますてるとえこのようにえー失礼えー
八．〇．八五から出て二十八
といったようなえー改善が見られました
え大幅にえー再現率が上がっていることが分かります
えまた大学校についてもえー同様な結果を示します
でこちらも同様にえー再現率がえー大幅に
とそうしておりますで
芸術としてえー〇．七から〇七八分の改善が見られました
でこのようにえー
先程えー御
えー先程のえー手法によるえー適応はえー話題の何精度の改善に燃えおいしく固定しました
えそしてえー特に話題もあの認識率でえー特にええ再現率においてえー大きな改善が見られました
で以上まとめますと本研究ではえー後に音声に対する面の情報を用いた言語モデルの適応行ないました
で具体的にはえー具体的な適応とは局所的な適用を行ないそれを組み合わせますと
えーそしてえー
実際の声による評価を行なったところえーこういった改善が得られますが
え以上で発表を終わります
