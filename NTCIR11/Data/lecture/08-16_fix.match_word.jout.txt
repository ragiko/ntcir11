あっあえー入国大学情報メディアが強く情報メディアがあのー母です
えー今回やはりあのー音声条件とまー入る検索の為の音声情報処理の検討について私の側と坂本発表さしていただきます
まず初めに平均でまー地名では本にえーバスの中でも音声ドキュメントは
えーんでとー当時えーネットワークを通してえー通じてえー配置され
えー文開花される傾向にあります
その検索にえー話し言葉の音声認識は必要かつ
重要なニュースを待っています
そこで本研究ではえー国際放送ニュースが台風について
えーっと焦点を当ててみました
でこれにはえー
重要単語などのえーインデキシングなどによるえー基本ベースのえーっと音声認識にはえーいいた全てのテキストする町ないんですが二ページ括弧二のノードに関しては言った全てをテキスト化する必要がある為に
えー音声認識の高精度が必要となってきます
でそこでえ複数の入力をすえーこれはえー二言語なんですけどまあー利用できるっていうことをに着目しえー機械翻訳モデルを用いながら当時一にする方法前半の竿提案さしていただきます
また
音声はネットワークを通じて配置良いきっかけ圧縮月
動かされる場合が多い為多いことに着目し
えー圧縮処理が音声認識に与える影響の調査について
怖さが本は発表さしていただきます
まずえ母言語の同時音声認識について発表します
国際放送ニュースはえーではえー丸三の音声は利用可能なケースが多くなっています
例えば多分の方そのー
つまり複数の異なる言語で同じ内容の発話されることが多いです
そこで
その二つの異なる言語の各チャンネルの音声の認識を情報を時代当時の実行すること
つまり二か国語を同時音声認識を今回提案さしていただきます
えーその枠組みについて説明します
えー国際放送ニュースなどではえー日本語の音声実音声として英語の音声と同一内容の英語の音声が付与されてることがあります
そのえーそれぞれえー音声認識を行ない
えー
翻訳モデルから
ええー英語と日本語の単位のスコアはえー算出し
えーリスコアリングを行なうことによってえー日本語の文字列
する節のそのす認識精度は改善させるというのがえーとにかくこの二音声認識の目的となっています
またのように英語の文字列をするその際も
えーそれぞれの音声認識を行ない日本語と英語の対応スコアを取ってえーその情報を何ことによってえものも一つの二六四
えー
認識精度を高めることを目的目標としています
そこで定式化について説明します
えー
ここでは日本語と英語の同時認識について説明します
えー
四六単語列はえー先程申した通りえー日本語と英語の面でもよろしいのですが
で今回は日本語のえー単語出力するのもえーと定式化します
その日本語音声認識について私は説明しますと
えー日本語の音声Ｘの英語の音声×が与えられた時にそれらを最もよく説明するのか日本語単語列体を求める問題としてしかします
まず
えー日本語の音声とＸというもの音声は五から
えー日本語のえー最大となる日本語の単語列で要するする為にまずこの式となります
次に
ピンＸとＹは事例によるえー最大化と二型である為に的なすることができこの式になります
次に
え全ての可能なえー表一つまりえーと八音声認識の各えー方法
ほいー検討を置き
で一応まー取ってこの式になります
またえーΣは関係ないところ外してこの式になります
次にえー先程の式から対数を取り重みを導入することによってこの式になり
フレーズそこを用いて
楽しく皆変形できます
重みのＫマイナスｂをα
古いお母もあ置いてえー整理する
最終的にはこの式があえー
採集されます
ここで
ただあー語彙部分を
えー日本語音声認識のスコアは
赤い部分を英語の音声認識息子は
八時期以来もう英語の音声認識のスコア配分を翻訳モデルのスコアとえー
することができます
ここで
えー日本語の音声と英語の音声を用意したえー日本語の音声認識のスコアと英語の音声認識のスコアと翻訳モデルのスコアを用いるとにおいて
えー日本語の音声認識が行なえることはこの式で一生できました
次に
えー予備実験を行ないました
入る解析や内容としましては翻訳モデルを用いた音声認識の文を正しく機能するかを調査しました
つまりえー
そもそもえーやり方としましては形態や英語テキストは間日本語の音声認識を行ないました
破裂音用いて説明します
で先程あって
ではえー日本語の音声と英語の音声の一内容の日本語の音声と英語の音声を用意しそれぞれ音声認識をして
えー親子モデルから与えられた翻訳スコアを使ってリスコアリングを行なうことにより日本語の文字とする二というのは
えーうまく説明したえー枠組みなってます
そこで
でえーそのえー音声と英語の音声認識のあのー
えー言語テキスト良いつまり対訳前のテキストでえ普段は今率が〇パーセントの対話例のテキスト二を用いて
えー日本語の音声と
えーっとー
あの音声
認識を行ない
えー日本語の文字列を出力するというのが呼び
い予備実験のえー枠組み若い方なってます
式はこのようになります
この式を用いてより詳しく説明さしていただきます
えー
先程の違ってこの場合日本語の音声認識はえー日本語の音声Ｘと英語のテキスト二が与えられた時にそれらを最もよく説明する日本語の文字列体を求めるプロセスになってます
ここで
えー
先程の式はえーこのような式になり
えー
この式でえー下の式で違うものは
えー
っていうものを音声認識のスコアというものが含まれてないことになります
つまり
えー予備実験ではえー
言語テキストいー一文を用いてる為えー日本語の音声認識のスコア完全に翻訳モデルスコア足し合わせ
その式によって
えーと日本語の音声認識ですがのみの場合
日本語文音声の認識でリファレンスモデル四のスコアを
足し合わせたものを比較することによってえー日本やっモデルスコアが用いを用いいることの有効性を
えー今回はえー予備実験で示すことができると考えました
また
えーテーマ二三式の原音声認識の方が方法二い料理の相手とし為え枠組みとしてはえー認知へ同時音声です
後えーっと同一であると考えました
ではえー評価実験について話します
評価データーにはえー二つ言いたい訳です九十四読み上げえー日本語話者四名から五十文取りました
次にえーと音声認識システムにはデコーダーはＪｕｌｉｕｓを
音響モデルには読み上げ音声から学習した文の方
方言をモデルには新聞記事から学習した
単語トライグラム
翻訳モデルにはＩＰＡモデルツリーを用いた
用いました
またその学習データーに歩いた記事対訳コーパスを使いました
では結果です
まず音声認識のスコアの翻訳モデルスコアの方法もみたいなもの効果について説明します
このえー式にそのえーあ翻訳モデルスコアのえーと重みγの値をえ社会
〇から一まで変えることによって
えー
このγの値がどれくらいならばえー認識率がより向上するのかというのを
で調査しました
横軸がγの値
縦軸が認識率の改善率の絶対値になります
その結果
えーγの値が例で五からあー〇〇〇〇一えー〇．四五程度で平均で認識率の向上が張りがあるということが分かりました
そこでこのγの値をれていようにえー
んえーと定めてえー次の
実験を行ないました
つまり
がもう〇．四四段階でえー翻訳モデルを用いた音声認識というものを行ないました
その結果
えー翻訳モデルを持つえーとー先生えー
話者ごとに行ないました
赤いえー棒グラフがえーの
音声にえー日本語音声認識のスコアのみを用いたえー単語誤り率
いい香りもグラフはえー翻訳モデルを用いたえー日本語音声認識の
えー
方グラフになってます
えー
一番右にあるのはえー平気になってます
その結果
えー翻訳モデルを用いた音声認識は平均の値でえ単語誤り率が一三．一さパーセントから四十二．４０パーセント
で削減され
え誤り削減しそして四．八四パーセント削減となりました
ただえーこの
翻訳モデルを用いた音声認識はえーモノホンモデルを用いており
えー二つ
他のえーＰＴでもトライホンモデルを用いた場合の
えー単語誤り率を調べてみました
その結果平均〇五．３０パーセントから五．五三パーセントの
えー現象がはつえー改善は少なくなりました
これはえー最もこのベースラインの音声認識精度は高過ぎると他は少ないということが
あります
しかし
実際の話し言葉の音声認識精度はこれよりも低い為相手の可能性は×だと考えました
続きまして
えーん音声認識の精度はその程度必要なのかというのを今回えー
発表さしていただきます
え先程の予備実験ではえー
日本語の音声と英語の対訳テキスト一を用いてえー日本語の文字としました結果です元よりも誤り率が五四て八十パーセント意見ということが分かりました
そこで
実際にえー音音声認識を行ないました
その結果英語の認識文がえー
出力されました
その英語の音声英語の音声認識文のえー単語誤り率が一体何パーセントならば先程も正しい対訳テキスト
体をまー二を用いた場合と同等の結果が得られるのかつまり日本語の文字列がえー先程と同じような改善が得られるのかっての
えー調査しました
ここで
えー
上の文音声認識文とえー音声学会ではテキスト文を用いた場合で大きく変わってくるのがこの四角で囲ってある
でなぜえー二の後えー前の二し
つまり
えー
翻訳モデルスコアになります
この翻訳モデルスコアを正しく評価することによって
テーマ
単語誤りえー認識部の単語誤り率が何パーセントならば
早くテキストがえー用いた場合と同等の結果が得られるのかというのを調べてみました
詳しく説明します
先程の翻訳モデルスコアによるえー目的言語の一単語当たりの平均予測する
これを翻訳モデルパープレキシティーと呼びますを利用しました
この翻訳モデルパープレキシティーという名前はえー言語モデルの
評価によく用いられるえーパープレキシティーをえー今回はえー参考にした為その名前にしました
この翻訳の面パープレキシティーの方が下の知識のえ文の部分にあえー
ただしえーおテキスト二四と
えー音声会話音声認識文えい家が与えられた時の
親子モデルパープレキシティーの差は
がえー
対象としました
そのそれが小さい場合には
えー日本語の音声認識の最終そこはまー近くなるということが分かります
また
その結果えー元の音声認識文利益を用いても
えー
あーいうものが対訳テキストの歴史を用いてもえー日本語の音声認識の精度改善がどんどん家があるかと予測が付きます
そういうことでえー
この
翻訳モデルパープレキシティーの寒いとえー単語誤り率の
えー三を調べることでえー
で
あー英語音声認識文の単語誤り率が
んえー
どのぐらい影響を与えるのかというのを調べました
経営の温泉にえ結果です
でこう音声認識の認識率と翻訳モデルパープレキシティーの関係についてえー図にしました
横軸はえー文音声認識の認識率
縦軸は翻訳モデルパープレキシティーの変動になっています
母相関係数は〇．四六三を取り
えーこれはえー建物音声認識の認識率が
んでなれば翻訳モデルパープレキシティーの変動も小さくなるということが分かります
また
えー
この丸で囲った単語誤り率が四十パーセント以下
その場えーのところでは
翻訳モデルパープレキシティーの変動が小さい値を持っています
この四十
パーセント以下の英語の単語音声認識のがえー単語誤り率四十パーセント以下ならば
えー
んー
えー
それをえー組み込んだあえーと二音声認識では
えー
精度の改善が得られるということが示されています
また
この四十パーセントからえー六十パーセントのところなんですけどもえー結構半分ぐらいが小さい値を取っています
これについて言えることはえー半分程度
つまり四十単語誤りさ四十パーセントから六十パーセントの半分程度の誤りを含んでいても
えー翻訳モデルを用いた
えー
文字音声認識というものが有効であるということを示しています
前半のまとめです
国際会議でその音声認識について今回発表さしていただきました
そん中でえー同じ内容の異なる言語
例を用いたマルチチャネル音声の音声認識について今回提案さしていただきました
その結果です音節その中ではえー予備実験として日本語音声認識時にえーのテキストを翻訳モデルを利用したものお予備実験として提案さしていただきました
その結果
翻訳モデルを用いた音声認識の文が機能することを確認しました
また
翻訳モデルパープレキシティーに基づいてえー影響の調査について後
えー
発表さしていただきました
尊敬が翻訳モデルを用いた音声認識が十分に機能する為には
えーえ音声認識の単語誤り率が四十パーセント
程度であることが必要であるということがえーと二から分かりました
以上で発表終わります
えー
えー
えー
えー
んー
えー
えー
んー
えー
はい
で
んー
えー
で
えー
んー
えー
えー
に
んー
えー
えー
えー
えー
父は後半の発表を使うと発表生成いたします
えー前半では国際ニュースえー国際放送ニュースの値を対象とした
音声情報処理の手段として
再翻訳モデルを用いながら同時に処理する方法の差は発表させが来ました
またえー国際放送ニュースあの音声ドキュメントは
いうことはこう通じてはいすいそれ詳しくは報道される場合は多いことから
まーすそれが音声認識与える影響を調査を行ないましたえーそのえー
発表さしていただきます
えーネットワーク上のおーセグメントを警察の為にはえーキーワードなど人でえそしてえー
付与することが重要であります
声にえーインデックスを使用する為にはえー音声認識概要です
これまでの一般的な音声認識の推定量は対象は
四十八キロヘルツサンプリングえー二六ビットを選定量子化のちらし構成が用いられています
しかしえーネットワーク上のセグメントは
元気水やえーえーし逆ＭＬ法して圧縮され方や土が行ない対話を行なっています
こう例としましてえーインターネット上ではえーＢ水
いう自転車もそれはえー詞の形式を持ちあります
小屋形式は最悪らしくである為
この明日の波形は人間の聴覚影響しないようにえー情報が設定されています
またえー圧縮音声からは元の音声は完全には発見できない為
このような気が八日付けである音声を
認識対象とし用いる場合には何かそう対策が必要と考えます
しかし音声圧縮が音声認識与える影響を調査はこれまで十分にお前で行なわれていない為
ポストでき検討としましてさまざまな形式
あそいで圧縮した音声を認識実験を行ないました
え音声認識実験を大きく三形に分けて行ないました
それぞれえー適応音響モデルはと一日二つ目にはベースラインを音声認識システムとしまして
従来のえー自動的られる数字六六と後圧縮音声ではすした音響モデルを用いた認識して
月には音響モデルを入力環境への適用として
いう環境を考慮した音響モデル
三つ目には音響モデルの話者性とを入力音声情報への適用として
いう環境とを性を考慮した音響モデルを用いた認識実験を行ないました
母がえー認識システムです
デコーダーはＪｕｌｉｕｓ
音響モデルは全盛学習者トライホンモデル
言語モデルは語彙サイズ六万語を新聞で開発した単語トライグラム
学習データーにはＩＰＡ九十八テストセットを付けました
それからえーそしてえー後半はえー通常の音声認識とありませんが
で勿論マスクした音声を認識数でえ前半死
えー対象とある音声をまず手法一特徴があります
でこちらはベースライン音響モデルを用いた音声認識実験の結果となります
え横軸は人れと人れた日に程おー一つは気がします
縦軸は標本指標で用いたえー単語誤り率
またえー音声圧縮にはえー減衰えー真であるえー上の三形式を用いました
え初めにえーベースラインとなるし圧縮音声を用い
え対象とした認識では
勝手にさんのワードエラーレートを得ました
次にえー三十日より別のえー音声の
認識結果は
生徒のケースにおいても一パーセント前後のまー出られる早い方から
これをな音声を対象として認識を行なう場合には
従来のシステムでも大きなものでナイフは分かりました
ビットレートが二十四二十三ページの前にえーおいては
え方式よって対話数が誤りはどうすんとは思いました
具体的には
えー鉛筆一九四の場合ですと三〇．五四パーセントえーＣの弟子テストを二十二．五九
多分連盟の
．ですとえー一三．八九のお与えられてはえ分けられました
えーこう事件に
こう実験でえ用いた音声ですが
学習時は自動キロヘルツ一二三度の方向性から
しかし実際にえする場合はま思考量です
で本当あらゆる環境と音響モデル二はそうしたと考えます
こうでえ入力環境にえー入力音声つまりま指向性にマッチした音響モデルを用いた認識実験を行ないます方法えしました
本来的には
えー手伝いを音声モデルをＭＬＬＲ適応を行ないました
でそれにえー適応の対象として用いた手法音声は
で最初の実験においてえー三十四．五四のワードエラーレート得られたえーえー推定式
白い鳥ですよもうこうなります
ただえー適応データーはＪＮＡＳコーパスに加える音声約四十八時間
え先程述べましたがえーらしく
クエスチョンを用いた指向性がいるＰ推定七十九五の一つのもの
まここでは一応はえー第二はいる話者はどうできました
えこちらは入力環境にマッチしたモデルを用いた音声認識の実験絶対
音響モデルをえー圧縮音声に適用す
先輩のえー認識結果は
えー二十三．一〇のワードエラーレートを得ました
これは最初二における音響モデルはベースライン入力音声があり一二
つまりモデルと音声がピッチの場合より
とえー比べるとあんまりお約三十パーセント削減しました
しかしえー入力音声が一圧縮の場合に比べると
誤りは約三バイトを七つ
ここからえー利用環境にマッチしたモデルを用いだけでは
城が非常に別な尽くされた音声
認識女性が不十分だと考えられます
えーそこでえー音声のペットを検索には音声を自動的に行ないにし
えインデックスを付与する早くうーそのような音声認識の場合は
認識結果と認識対象の音声データーでえー繰り返し提示を行なうとで
音声認識の精度向上が得られるとはこれまでの研究で明らかになって
そうでえこの繰り返し音声で適応の効果を確認しました
これは理想的な形成を認識精度を調査誰々
結果四つ二つある与える影響したい適応を用いました
適応データーをＩＰＡ九十八テストセット音声
本当から入力環境とは声道情報についてをすると考えます
え適応の
分析を用いたあ指向性は
えー最初の実験における
別に推定し二六キロの場合とえー二十八の場合の二つを用いました
ＸはＡえーＢ政治の町にですのを整理
を適用した音響モデルを用いたりしてる結果となります
縦軸は先程は実は出られると横軸は使用回数
また適応方法はＭＬＬＲとおーまこの二つの方法を用いました
ベースラインの方分けられとか三時四ていう方五パーセントと思い対して
えー三回繰り返して行なうとでえーメールＭＬＬＲ適応では二十．五八
ま結局は一二点の四の得られるま得られました
ここから繰り返し適応を行なうとで二六五四三え精度な思考セグメントは処理結果を面とありました
しかし一方八十三ベースの人の場合ですと
えー別材料は約九十パーセントの分けられるに対して
適応行ってもＭＬＬＲでは六十五パーセント
なくては約四十二パーセントは取り敢えず加えましてられました
本当はえー
二十四ＢＢＳの場合は繰り返し適用行っても圧縮された音声てるんではインデキシングは困難だと考えられます
え方法のまとめです
音声の決めたり音声認識を行なってえインデキシングを行なうと想定した場合
で一つ目に合宿して保存する際には三十日よりベースの人へとか個性は自分であろうと
二つ目に印より形成は音声認識と音声モデルを適応方法に繰り返すことでえー
そいで系統性型の
えー処理できる可能性が可能性を分かりました
えー全体のまとめです
えー前半では翻訳文翻訳モデルを用いた統計的音声認識の文
方についてのでえーその予備実験と評価を行ないました
えその結果翻訳をモデルを用いたあー言語同情音声名詞の組み合わせを凄く分かりました
また星が十分に使用する為には各言語の音声にせるは四十パーセント程度の音は出られる場所やっと分かりました
が後半ではあ指向性の音声認識についての検討を行ないました
その結果あ三十三四五デシベルと言うと加工すれば十分であること
ただ一．二ケースでは音声認識と音響モデルを適応法に繰り返すことでそいで一つの制約は
分かりました
で発表を加え以上で終わります
