えーまずアプローチとしては話し言葉の
データーというものを作ります
その為にウェブから
で一つのウェブ文書ずつ次のような流れを適用していきます
まずウェブからダウンロードしたデーターに対してフィルタリングを行ないます
えフィルタリングは言語モデルの学習に重要な部分のみを抽出する
つまり文書部分のみを今回はルールベースで抽出します
え次に
えーフィルタリングを行なったデーターに対して
これ話し言葉なのか書き言葉なのかといったことを考えます
え最終的に話し言葉データーのみを使いたいのでそこでで
で文章スタイルの分類といったことを行ないます
えーウェブには話し言葉と書き言葉のデーターが混在しているので
今回はナイーブベイズをこう
分類木を構築して分類を行ないます
え最後に
話し言葉
と判断された後のデーターに対して言語現象の補完を行ないます
えーこれは話し言葉特有の言語現象というものはあくまで今回扱ってるのはウェブ上の文書なので
本当に
えー音声を書き起こしたようなデーターに入ってるようなものは
入っていないといったことで
今回はまずフィラーがあんまり出現しない
といった問題があるのでこれをフィラー挿入
を行ないます
えーまたウェブの文章
っていうものは基本的な書き言葉なんで
えー読点の位置っていうものは実際に人間が比べる
場合のショートポーズの位置は必ずしも一致しないので
ショートポーズを挿入を行ないます
えこれによって疑似的にですが話し言葉のデーターを構築していきます
えーひ
このように人手で音声を書き起こすことなく
話し言葉データーを準備することができます
じゃこの
部分部分で
について説明していきます
