でどんな問題があるかということなんですけど道が扱う時にですね
で一つはま
のテストコーパスというのはまー認識する対象ですから予めこれが分かってないですね
をこうずっとオンラインで認識していかないといけないから
その時に
未知語というのを取ら身に付けるかという問題がある訳ですがまそれらの研究もある訳ですね
例えばあのーテストデーターを結構認識していてまー例えば現われとか八割認識できたとしたら
それでトピックをま推定できて
そのトピックに関係するような単語の
ここですねえーえー
リストと言うかそれがウェブから探していってですね
それでどんどんどんどん広韻ボキャブラリーなかった単語登録していくと
っていうのが一般的ですね
未知語の見つけ形ですねテストデーターに対して未知未知語の見つけ方は
そういうのが一般的でそれでま辞書には登録できると呼ぶことにはあり
なり得るかなと思うんですけれども
我々問題するのは未知語登録したとしてもま自動的に登録するか
あるいはあーユーザーがあーこれは新しい未知語であると思ったら登録すると
いうようなことで何らかの方で登録できると
未知語をですね
でその前提の下でその言語モデルをどうするかと
ゆことをやろうとしている訳
でそれでま未知語のもっとの扱い方の問題としてはボキャブラリーインボキャブラリーを増やすとま一万語にするとか二十万語にするとかまそういうなアプローチがありますね
でウェブ以後のレートを下げると
いうことも勿論
ま現実的だと思うんですがまこれはまー
えーえまメモリー飛ばしているとかまそういうな面もあるかもしれないけども
本質的に地方避けられない
どの新しいタームが出てくる
という問題
を想定しておる訳
そういう波で未知語の言語モデルをどうするかと
うーとまクラス言語モデルを使うか
サブワードモデルでえーそういうな未知語をですね
えサブシークエンスで認識するということもあり得ると思うんですが
まーここでは発表するのはプラス言語モデルをどうするかと
いうような
あーというあのー考えで
えやっている
汚い用法文数が
