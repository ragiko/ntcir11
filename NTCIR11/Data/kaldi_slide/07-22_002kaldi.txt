でまそういうところを考えますとまマルチチャネルの音声が利用可能なケースがま多いと
いうことです
で具体的に言いますとまニュースの場合ですとま他国語で放送する
ま放送があったりですね
後はま国際会議とかですと同時通訳ブースなどがありましてそこで同時通訳の音声が
まー流れてくるというような状況が家庭できる
ま結構あるというような状態です
ででして
まそういう場合はですね
まーあのチャンネルが複数ありまして
その複数のチャンネルに
ま異なる言語で同じ内容が入ってくると
そういう状況が
ま仮定できる訳ですね
で従来このようなまマルチチャンネルの入力を仮定したような研究っていうのはま今日の発表にもございましたけれども
ま基本的には同一の音声っていうのを仮定してましてま何をやるのが目的かと言うとま雑音除去とか
ま方位推定とかするのがま目的
だったりはする訳なんですがま本研究ではそうではなくて
え全てのチャンネルに入ってくるのは複数の異なる言語
ですが同じ内容の発話
いうような状況かと
えこの認識をやってあげようということを
考えています
明確チャンネルの音声の認識をま情報補いながら同時に
実行するということをやりたい
ことを考えます
それでですねえっとー具体的には機械翻訳ま分翻訳モデルなんですがま統計的なモデルを使って音声認識をやってやろうということになります
でまユーロスピーチのまー二千五年のところでもんま似たような発表があった訳なんですが
まこれはえー
両方が音声であったりする場合ではなくて片一方がテキストでというような状態
を仮定してるようなものも
含まれてますま両方が音声の場合もありますが
まそれが両方をえヨーロッパ系の言語でして語順も比較的似ていますしま近い
ですがま日本語英語というようなこういう機械翻訳がまー困難であるようなタスク
後ですね対象とした研究ってのがまだやられていないということでまやってみました
いう話
