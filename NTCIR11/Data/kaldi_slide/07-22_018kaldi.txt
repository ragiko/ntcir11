えっとまとめますとま国際会議とかニュース
とかでマルチチャンネルですね異なる言語で同じ内容の発話があるような
場合の音声認識について検討しました
で予備実験としまして
日本語音声認識時にま英語の方が認識しなくてテキストとま機械翻訳を用いて
実験してみて
そういう枠組みがきちんとうまく動くことを確認しました
え今後の課題は
ま実際の話し言葉での実験および評価することと
ま日本語と英語両方ですね
でまここ英語の方が誤りがなかったので
よくなってる可能性も
ま十分ありますので
両方音声認識してみると
でそれから
ま今は
文の
対応っていうのがはっきり付いてるような状態ですし
ま同時通訳
とかとは少し性質が違いますので一回書き起こしたものですので
ま同時通訳とかを音声認識して見るというようなことも
ま必要だろうなということは
え考えています
でそれから最適な統合重みですね先程の
ま振ってみたんですが
まあんまり分からないんですでこれこれをちょっとどうやって決めるか
いうところを
検討していきたい
思っています
発表は以上です
