えこのシステムのえ全体像なんですけれどもえーまず講義を
行なう際にえー音声の音声とビデオ録画しておきます
えまたその時同時にえーっとスライドのデーターとして
えー勿論その家族とかテキストとかスライドに含まれるデーター勿論そうなんですけれども
えスライドがえー
どの時間で着替えられどのタイミングで切り替えられたかといったえーその切り替え時間も
えー保存しておきます
でこれはえーとこのワークショップのえ収録にも使われている以上触れ前提たでえ実現して
います
え収録した音声データーに対してえー幾つかの
えー収録した音声データーを幾つかの細かい区間に分割します
で便宜上このえー一つの区間をえ一文文とします
でそれぞれの文に対して音声認識を行ないまして書き起こしテキストを
取得します
でえそうしましたら
その書き起こしテキストから得られる言語的情報と音声データーから得られる韻律情報の二つを利用して
え重要度のえその文が重要かどうかといったえ推定を行ないます
でえー重要であるとえー判断された分だけ
を集めてえその講義の要約と
しています
でえスライドデーターですけれどもこちらはえー
えーっと先程お見せしたようにえーキーワードを抽出してそのキーワードと発話を対応付ける
韻律インデキシングという処理を行ないます
え最終的にえー先程のような亀が
できると
いう形になっています
