でえっとーそれでですねあのー現在の音声認識技術っていうのは
まあのー統計的なえっとーモデルに基づくものが主流になってますから
えそういうその多様なえっと話し言葉に対する現象取り扱う場合であっても
やはり
その多様な話し言葉の減少さまざま色々なものを全て取り扱っているような大規模なコーパスというのがもし
仮に存在するのであればまー話は非常に簡単で
えっとそういうそのえっとーコーパスからまーあのー
話し言葉の多様な現象に
えっとー対応したえっと言語モデルというのま作ってやって
でその言語モデルに基づいて
え
音声認識というのを行なっていけば良いと思われるんですけれども
え現実にはそういうことはありませんでして
例えば言ってその国内で最大のその日本語話し言葉コーパスを持ってきているもの
持ってきてましても
えーっと講演音声ですね二千七百二軒
朗読音声五百二十三件で合計約七百五十万語と
えそれに対しまして例えばしあのーこれまでえっとー使われての新聞記事で見ますと
まこのぐらいあのとく非常にたくさんありまして
で最近ではもう上グラフからも収集することができますからま
この差というのはえっとー
開く断わっても恐らく今後待乳もあることはかなり難しいと
えそれが機械どこに大きな原因があるかと言いますと
まこちらの日本語話し言葉コーパスの方は
えっとー非常に
日本語話し言葉コーパスにおけるその話し言葉コーパスの構築というのはま非常にこうコストの処理であるっていうところが問題になってきた
でえーとそういったような背景でま対象とするドメインのコーパスが十分にいられない
まそういう状況でどうしていきましょうかということがえと今後研究課題になっていると思う
で
