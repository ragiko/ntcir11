えーまとめますとえ講義音声の自動認識では
えーまコンテキスト依存音節モデルの効果
がえー確認できました
えコンテキスト独立音節モデルと比較してえコレクトで五．四パーセントアキュラシーで一．三四パーセント
向上しました
えインデキシングについてはえ複合語のキーワードを抽出可能にしました
でえーとキーワード認識用の言語モデルを使用して
えとキーワードのリコールとプリシジョンそのものは
向上したんですけれども
えその
向上した書き起こし列を使って
インデキシングの処理を行なったところ
えーっとマッチングできるキーワードの数というのはえー特にフレームせず
えー変化は見られませんでしたえーっと
実際にはキーワードとして
サイドから抽出されても
発話されていないものが多かったのが
ま一番大きな原因だと
思います
