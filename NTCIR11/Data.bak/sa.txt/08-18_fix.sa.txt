はいでは始めます
スペクトル情報を用いたライフログ映像のシーン検出というテーマで
法政大学情報科学部が発表いたします
まず最初にライフログについての説明を簡単にさせていただきます
ライフログといいますのは
人の体験や生活の記録で
映像位置情報文書メールなどで記録されます
利用例といたしましては
備忘録や日記防犯などが挙げられます
まず備忘録といいますのはライフログというのは生活を常時記録しているので
重要なことも記録されるのでそのような利用の仕方ができます
また日記といいますのは例えば映像で
ライフログを記録した場合に一日を映像で振り返るということができます
そのためには一日の出来事を要約して
普段とは違った行動を検出する必要性があります

三つ目の防犯といいますのは例えば子供のライフログをとることで普段の行動をモデル化し
普段の行動とは異なった行動をしたときに保護者に通知するようなシステムが考えられます
このようなことを考えた場合に
映像が出来事の再現性が最も良いと思われますが
データ量がとても膨大なために
映像へのインデクシングが必要になってきます
そのために
一つの意味を持つ映像の区切りであるシーンを検出する必要性があります
ここで先ほど言いましたインデクシングの例を挙げさせていただきます
これは
自宅から大学に行きまた自宅に帰るというような場合の例です
まず家一番最初は自宅から始まります
大学に行くまでの間に
自宅から駅まで歩く
ところの
歩くようなインデクシングや電車待ち
その車内などが挙げられますまた大学では授業や
研究室などで研究している
時や食堂で
昼食などをとっているような場合が
インデクシングされます
このようにインデクシングはなされます

次にライフログのシーン分類に関する従来研究について説明いたします
まずスペクトルを用いた研究
にはデスクワークとミーティングを分類したものがあります
これはキーボードの打鍵音や紙をめくる音を
平均スペクトルと学習データの二乗誤差の
平均と標準偏差を使って
検出し人の声を
人の声の倍音コードを使って検出しています
この人の声の出現頻度でデスクワークとミーティングを検出しています
また色相を用いたものには

照度を用いて建物内建物外で映像を分類したものや
色エッジ情報を用いて

部屋ごとに映像を分類したものがあります
これはエッジ画素数や色相ヒストグラムを利用して行われています
ここで映像で記録する
ライフログを記録する場合の問題点
として
色相の変化を利用する場合には
妨害物による意味のないシーンを検出
意味のないシーンの検出が起きることがあります
例としまして電車待ちを挙げさせていただきます

人の変化というのはここでいいますと電車の発着通過で起きます

この上の写真がその
例なんですが
まずホームで向かい側の向かいのホームを見て待っている状態
そこに電車が入ってきて
その電車に乗り込むというような感じなのですが
これ一つ一つが色相が変わっていくので
シーンとして分類されてしまいます
ここで電車の発着や通過は
ショットいうシーンを構成するものとして扱われるべきですので

最初の二枚の
ところはショットとして扱われ
これこのようなものが集まって電車待ちというシーンが構成されまた車内は別のシーンになる
というような切れ方が適当だと思われます
本研究では
このように
電車が入ってくる時には
その電車の音がしますので
映像情報に加え
音響情報を用いてシーンの検出を行いました
ここで本研究の本研究でのシーンとショットの定義をいたします
シーンはホームで電車を待ち始めてから乗車までで
ショットは以下の七つになります
この箇条書きの番号と
下の図の
番号が対応しています
この矢印は電車の進行方向です
まず一つ目が
電車前方のホームでの発車時ということで進行方向に対して
前方で
電車が発車する時
二番が
電車後方のホームでの発車時ということで電車の進行方向に対して
後方で電車が発車する時
三番が
同じように
電車前方でのホームでの停車時これは電車が停車してくる時

四番が電車後方のホームでの停車時
五番と六番五六七は前後に関係なく電車通過時
また六番が発車停車通過がないときのホームでの待機時
また車内もショットとして扱っています
この括弧の中の
発車Ｆ発車Ｒなどは以下の
説明のときの略称になります
具体的にどのような音がするかということですが
これが通過音です



これが車内の音です

車内の音はこのようなアナウンスや車内騒音が含まれています
このような音を
識別していきます

具体的に電車待ちのシーンをどのように同定していくかということですが
まず
あるショットの
音が入力された場合にそれを短時間スペクトルにします
その短時間スペクトルというのは具体的には短時間のパワースペクトルにいたします
それの短時間のパワースペクトル一つ一つに対し
フィルタバンク分析を行い

メル周波数上で
一定間隔の帯域の和を算出することで
パワースペクトル包絡を求めます
このパワースペクトル包絡を用いて
今回は二つの方法でショットの識別を行いました
一つがパターン間距離を用いた方法でもう一つが確率モデルを用いた方法です
この
識別によりショットが車内であると
いうふうに
同定されたらこれをシーンとみなします
ショットが車内以外と識別された場合にはショットとみなします

その

ショットの識別は入力音と各ショットのプロトタイプとの比較によってなされますがそのためのプロトタイプの抽出方法について説明いたします
フィルタバンク分析はメル周波数上で三角窓を用いて帯域和を算出しています

このようにすることで帯域ごとに特徴が集約でき特徴がより明確になりパターン後に行う
パターン間距離を用いた方法での差が出やすいと思われます
プロトタイプはこの下の図のように
して求めます
まず学習データを短時間スペクトルにして
フィルタバンク分析をしたものを
平均して平均パワースペクトル包絡を求めます
これがプロトタイプになります
今回は比較のために
パワースペクトルを平均したもので
も後に識別実験を行っています
これがプロトタイプです
左側がパワースペクトル包絡を用いた場合で
右側が
単純にパワースペクトルを平均したものということになります

次にパターン間距離にショット
によるショット識別の方法について説明をしていきます
入力音とプロトタイプとのパターン距離を
このような式で求めます
この式をもと
この式を実行することで上の図にあるようにプロトタイプと
短時間スペクトルとのその入力との
パターン間距離が求まります
この距離が最小になる
ショットを
ショット候補というふうにみなします
これは短時間スペクトル一つの
ショット候補といいますのは短時間スペクトル一つのものですので
入力されたデータに対して
このように時系列で


ショット候補を出していきます
この場合ですと
通過が最も多いので
このショットは通過ということになります
次にもう一つの方法である確率モデル
を用いた方法について説明していきます
フィルタバンク出力の帯域ごとのパワー
パワーの対数をとることでまず
このように短時間スペクトルこれはフィルタバンク分析を行ったものなのですが
そのフィルタバンク分析を行った各帯域の分布を見てみると
このような
対数正規分布になります
これの対数をとることで正規分布として扱いこれの平均共分散を求めることで
確率モデルを推定します
この平均といいますのは学習データ一つ一つから出したものの平均で
共分散は
学習データデータ全体から求めた共分散です
これを元にショットの確率モデルを推定いたしました
今回はフィルタ次数が三十八次元でしたので三十八次元に対する正規分布
ということになります
これを用いまして入力に対する
尤度を求めショット推定を行います

各ショットの入力音に対する尤度は
このような式で求められます
この入力音といいますのは
入力されてきた音
のパワースペクトル短時間スペクトルにしてフィルタバンク分析を行ったものを
平均したものを入力としています
この式を
求めまして
尤度は
最大のものをその時のショットとして推定いたします
このようなプロトタイプの抽出や後に行うテスト
ショット識別実験のためのデータ収録の方法について
説明をいたします
録音条件は
こちらの
図のように

ホーム両端で向かいのホームの方を向きサンプリング周波数四十八ｋＨｚ離散化ビット数二十四ｂｉｔでバイノーラル録音をいたしました
一ヶ所で十五分録音をし乗車をして降車をして
その後また十五分録音して乗車するというような行動を繰り返し
データを録音しました
収録
の時間帯は十六十時から十六時の間で十一時から十三時が中心となっています
総収録時間は十一時間でした

収録場所はＪＲ中央線の三鷹駅吉祥寺駅で
電車の種類は中央線の快速が二種類と特急が三種類
で発着の頻度は昼頃は一時間に十本程度でした
次にショット識別実験を行ったのですが
その方法について説明をしていきます
上の
表が学習データとテストデータ数と
その平均時間になっています
下の表が
短時間スペクトルやフィルタバンク分析にするときの条件です
短時間
スペクトルにするときの条件はデータ長が
二千四十八点で時間シフトが千二十四点
ＦＦＴ長が二千四十八点です
フィルタバンク分析を行うときの条件は三角窓長がメル周波数上で二百
周波数シフトがメル周波数上で百
フィルタ次数が三十八次元になっています
このような条件下で実験を行った結果がこの表のようになります
この識別率といいますのは
正解数をテストデータ数で割ったものをパーセントで表示したものです
ここで
ここに発着という一つショットが増えているのですが
これはこの上の
発車や停車通過に関するショットを
一つとしてまとめたものです
これを用いることでも
シーンの誤検出が防げ
防ぐことができます
下一番下の平均はその発着を除く七つのショットの平均識別率になっています
これが詳しい結果です
この図この図はこの上段が
単位がパーセント
下段がデータ数ということになっています
例えばこれは発車Ｆ
を入力したときの結果で発車Ｆと
結果が出たのがゼロパーセント
で停車Ｆと出たのが
十五．四パーセントでデータ数が二
発車Ｒと出たのが二十三パーセントでデータ数が三というふうに読みます

この
これはパターン間距離の
パワースペクトル包絡を用いたパターン間距離での
結果なのですが
その傾向と誤識別の傾向としましては
まず発車Ｆが停車Ｒに間違われやすい
また発車Ｆが停車Ｆが
発車Ｒや待機に間違われやすい
発車Ｒが待機に間違われやすいということが挙げられます
このパターン間距離を用いた方法についての
考察を行っていきます
今回の実験では全体的に低い識別率でした
これは今回はパワーの平均だけを利用して識別しているがために
電車の速度などによりパワーに違いが出てくると思われるので
プロトタイプが似ているものに誤識別されたものと思われます
また発車Ｆはピークに特徴がありあまりプロトタイプが似ているものがないと思われたのですが
低い識別率でした
これはテストデータを一つ一つ調べてみたところ
ピークがなかったりピークがずれているものがありました
この下の図に示すようにこちらの図は
黒い線
がプロトタイプになっています
赤い線
と青い線がテストデータです
このようにピークがずれたり
ピークがないものがありました

このようにパワーのみでは識別が困難だと思われます
次に確率モデルを用いた場合の
結果ですがこのようになりました
表の見方は先ほどと同じで
誤識別の傾向としましては発車Ｆが
停車Ｒに間違われやすく
停車Ｆが
発車Ｒに間違われやすく発車
発車Ｒが
発車Ｆに間違われやすいというような傾向がありました
特に識別率の低かった
停車Ｆと発車Ｒについて
考察をしていきます
停車Ｆは発車Ｒとしての誤識別が多かったです

この二つの音を聴取してみると異なることがわかります


こちらが停車Ｆの音です
次に発車Ｒの音です





このように
聞くと違うというのがわかるのですが
全体を今回は平均しているので
それで類似してしまったのではないかと思われます
このようなものへの対処としてはスペクトルの
時間変化の利用などが挙げられ挙げられます
また
発車Ｒは発車Ｆとして誤識別されました
これはフィルタバンク出力を調べてみたところこれが
三十次の三十次目のフィルタバンク出力の分布なのですが
発車Ｒと発車Ｆはこのように平均が近く
分布も被っています
全く誤識別がされなかった
通過
互いの誤識別がなかった通過や待機に関しましてはこのように分布も
あまり被ってなく平均も離れています
このように

分布や平均が近いものにはやはり間違われやすいという傾向があるみたいです

次に
今回行った三つの手法について
の比較を行っていきます
平均識別率は発着を除いた場合の
パワースペクトル平均が三十
パワースペクトル平均を用いたものが三十七パーセント
パワースペクトル包絡を用いたものが二十七パーセント
確率モデルが七十一パーセントとなりました
発着を使用した
場合では
発着待機車内の識別平均識別率は
パワースペクトル平均が八十七パーセントパワースペクトル包絡が七十三パーセント
確率モデルが九十六パーセントという識別率でした
このことから確率モデルが最も良くショット識別ができたのではないかと思われます
これは平均だけでなく分散も考慮したためだと思われます
こちら下にこれは停車Ｆが入力で
正解した例なのですが
このこちら側はパワーなのですがパワーだけを見ると
この
赤い線が発車Ｒの
平均パワースペクトル包絡で青い線が
停車Ｆの平均パワースペクトル包絡なのですがどちらかというと
発車Ｒに近いような
印象を受けます
しかし
このように分散が大きく異なっているため
補正が働き
正解である停車Ｆというふうに識別されたのではないかと思われます
この最も識別率の良かった確率モデルを用いましてショット検出実験を行いました
ショット検出実験といいますのは二つ以上のショットから
ショットを検出するというものです
具体的には
今回はこのような待機に挟まれたあるショットを検出
するということを行いました

このテストデータの一例としてこのようなものが挙げられます
最初は待機の状態で始まっています
ここで電車が通過して
またこのように
待機の状態になります
このようなテストデータ
の
時系列で前から一定間隔
一定の時間幅で
ショットを検出いたしました
時間幅は四秒六秒八秒のオーバーラップなしという
まず三種類
これはこのような時間波形から
このように四秒四秒ずつまたは六秒八秒ずつ
黒い矢印の範囲で
ショット識別を行っていきました
またもう一つは四秒六秒八秒でやったのですが
オーバーラップを時間幅の半分としたものです
これはこの黒い矢印と赤い矢印の範囲で
ショット識別を行っていきました
こちらがその結果になります

この図このグラフは
横軸が時間で縦軸がその時に検出されたショットということになります
この
上に書いてあるショットは
正解ショットの変化の正解位置ということになります
この場合ですと黒線部分が正解で赤線部分が誤検出なので
このようにここの部分は正解しているのですが次に
ここは不正解でまたここで正解をして最後は不正解ということになります
全体の傾向といたしましてはショットショットが変化する時に
不要なショットの検出が見られました
これは確率モデルがショット全体でモデル化しているのですが
時系列で前から検出していくというのは

ショット全体が入力されることがないのでそれが原因だと思われます
また時間幅とオーバーラップに関してですが
時間幅
は狭くするほど誤検出が増えました
またオーバーラップは行うことでまた誤検出が増えました
いずれにしても誤検出が避けられないので
何らかの情報が
情報が変化するときを検出
するということを利用することが考えられます
例えば映像や音響情報が
変化する点を検出することで
それを用いてショットの検出を行う区間を推定行う範囲を推定するという方法です
最後にまとめと今後の課題について
ですが
まず今回はショット識別実験を行いました
パワースペクトル包絡を用いたパターン間距離が二十七パーセント
パワースペクトル平均を用いたパターン間距離
での識別が三十七パーセント確率モデルが七十一パーセントという検出率識別率でした
また確率モデルによるショット検出実験では
ショットが変化する時に不要なショットの検出が見られました
今後の課題といたしましては短時間スペクトルの時間変化の利用や
ショット検出実験の
評価手法
発着や通過が重なったときの対処法や
向かいのホームの電車の発着今回はそれを考慮していないので
それも考慮していかなければならないと思われます
また映像のシーン
今回の手法を映像のシーン検出にどのように適用していくか
ということが挙げられます
以上で発表を終わります
