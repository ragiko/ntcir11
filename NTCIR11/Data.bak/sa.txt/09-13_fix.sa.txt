では音声認識用言語モデルにおけるポーズ情報の扱いに関する検討と題しまして豊橋技術科学大学のが発表させていただきます
まず本研究の背景と致しまして音声認識における認識の処理単位
についてまず考えてみたいと思います
音声認識におきましてそもそも最適な処理単位
というのを考えてみますとそれはまず実用的な時間で探索が終了し
かつ単語間の意味内容の結束性が十分に利用できるような単位
であると考えられます
すなわち
あまり長い単位を取ってしまうと
探索空間が膨大になってしまいかといって認識単位を短く取りすぎてしまうと単語間の意味内容の結束性が十分に利用できないという問題がある
いうことです
そうしたことから例えば書き言葉原稿の読み上げ音声を対象とする場合には
その原稿の
こうした文単位が適切な処理単位であると
考えられます
なんですが

話し言葉を対象とする場合では
言えます
またそもそも文という単位を話し言葉に対して認定できるのかどうか
というのがそもそも非常に曖昧な問題と
言えるかと思います
そうしたことから現在の音声認識では入力音声をポーズ情報等の基づいて認識処理単位に区切ると
いうのが一方的な方法となっております
またそうして区切られた認識処理単位はそれぞれ
独立に処理がされます
なんですけれどもこれで本当に良いのかどうか
ということで
こうしたポーズ情報に基づく単位としましては
たとえば日本語話し言葉コーパスＣＳＪで

基本転記単位
として二百ｍｓｅｃ以上の無音区間で発話を
区切っているとこのような単位がございますのでこうしたポーズに基づく単位と
コーパスにおける句点に基づく文単位
とまず比較を行ってみました
結果こちらのグラフになりまして横軸が文の長さすなわち単語数
で縦軸がその頻度になりますがこのように国会会議録や毎日新聞といったコーパスにおける句点に基づいた
文単位と比較しまして
ＣＳＪのポーズに基づく
単位というのは非常に短いものが
大変多いと
いうことがお分かりいただけるかと思います
ですのでこうした文に比べて非常に短い単位を用いてしまうと単語間の意味内容の結束性が
十分に利用できていないのではないかと
考えられま
こうしたことを踏まえまして
本研究では
まず認識処理単位の独立性の検証を行います
まずポーズに基づく単位は先ほど示しましたように非常に短かったと
これらを独立に扱ってしまっても良いのかどうかといったことを検証しまた続いて文単位についてはどうなのか文単位は独立に扱ってしまって良いのかどうかといったことを
検証致します
続いてポーズのモデル化についても検討致します
従来読み上げ音声を対象とした場合では
句読点をポーズに対応させることが出来ました
しかし話し言葉ではこのようなことが出来るのかどうかあるいは適切なのかどうか
ということを検討しまた実際のポーズ句読点ではなく実際のポーズを反映した言語モデルの構築についても検討を致します
ではまず一点目の認識処理単位の独立性の検証と致しまして
まずポーズに基づく単位の独立性を検証するためにすなわちポーズに基づく先ほどの転記基本単位のような
単位ポーズに基づく単位を
独立に扱ってしまっても良いのかどうかを
検証するために今回我々は
ポーズの
ポーズ部分の内一定の閾値よりもそのポーズ長が短い部分に関してはそこは認識処理単位の境界ではなくショートポーズＳＰとして扱うものと致しました
そして
ショートポーズＳＰの前後では単語履歴を引き継ぐものと致しました
具体的な例をこちらに示しますがこのように発話がこのように認識処理単位に
区切られて
いたとします
通常これらのこれらの認識処理単位はそれぞれ独立に
扱われますのでたとえばこの閾値という単語を予測する際
そのコンテキストとしてたとえば直前の発話の単語等は
利用されません
そこで
こうしたある閾値よりも短い部分ポーズ部分を
認識処理単位の境界ではなくショートポーズとして扱うことと
致します
こうすることにより
このショートポーズの前後では単語
言語モデルの単語履歴を
引き引き継がれることに
なりますですので
たとえばこの閾値という単語を予測する際は
その直前のこののＳＰといったコンテキストを
利用すると
いうことになります
このように一部のその認識処理単位境界を
ショートポーズに変換しそのその前後では
の単語を独立ではないものとして
扱うと
このようなことを行った場合にその単語の予測が改善するかどうか
といったことを評価を行います
また同様の検証を
句点に基づく文単位に対しても行いました
ただしこうしたコーパスの句点においては先ほどのポーズ長のような情報は含まれておりませんので
今回はランダムに選ばれた句点をショートポーズとして扱うものとしました
ショートポーズの前後では同様に単語履歴が引き継がれます
たとえばこのように文単位が区切られて
いた場合
たとえば確率〇．五としてこのように


一部の
文境界をショートポーズＳＰとして扱うものに
致します
このように
句点やポーズをＳＰに変換しその前後では単語が独立ではないものとして
扱った場合に
の影響をテストセットパープレキシティでもって
評価を行いました
またＳＰの扱い方として
こちらのような二通りを比較を行いました
まず単純にＳＰをそのまま
後続の単語のコンテキストとして用いる場合
またそれに対して
コンテキストとしては用いないすなわちＳＰを透過させた場合とを比較しました
後者の場合ですと例えばこのような例では
閾値という単語を予測する際には
この直前のＳＰは使用せずにさらにその前のこの二単語を
使用することになります
またこの検証を行うコーパスとしましてはまずポーズに基づく単位の検証については日本語話し日本語話し言葉コーパスＣＳＪの学会講演模擬講演を
使用しました
このＣＳＪにはコーパスにポーズ情報ただし二百ｍｓｅｃ以上のものとして原則なっておりますが
ポーズ情報が含まれておりますのでこれらの内一定長よりも短いものをショートポーズＳＰとして扱うことと致します
また句点に基づく文単位の独立性の検証のためには
国会会議録と毎日新聞の二種類のコーパスを使用します
これらのコーパスにはポーズ情報等が含まれていないのでランダムに選ばれた句点をショートポーズＳＰとして扱うことと
致します
まず結果ですが
こちらがＣＳＪのに対する結果になります
横軸がショートポーズの閾値縦軸がパープレキシティとなっております

まずこちらのグラフの左端のこの
プロットが従来の二百ｍｓｅｃで
転記基本単位を区切りかつそれぞれの単位が独立であると
扱った従来の場合になります
これに対して二百から二百五十ｍｓｅｃ二百から三百ｍｓｅｃ三百五十ｍｓｅｃ
などをショートポーズとして扱っていった場合の結果がこの曲線になっておりますが
このようにＳＰを
履歴に用いなかった場合には
徐々に性能が悪化していきますが履歴に用いた場合には徐々に改善していき最終的にすべてのポーズをＳＰとして扱った場合に最も良い結果が
得られています
これこのことから
まず
失礼しました
各ポーズの単位は独立でないものとして扱うべきであると
すなわちポーズの前後では単語履歴を引き継ぐべきであると
ただしそこにショートポーズがあったというＳＰの情報を

利用する必要があると利用した場合には有効となると
いうことが分かりました
続いて文単位に関しての検証ですがこちらが国会会議録の結果になります
ＣＳＪと同様に文境界をＳＰとして
さらにコンテキストとして利用することで性能が改善しています
ＳＰを透過してしまうとかえって性能は悪くなって
しまいます
このことから
句点すなわち文境界の情報もやはり単語の予測には必要であると
いうことが言えます
ここで先ほどのＣＳＪの場合と比べまして
パープレキシティの増減が非常に小さいものとなっておりますが
これは国会会議録において文境界すなわち句点が四十二単語に一回程度と非常に少ないためで
あると考えられます
続いて毎日新聞の結果がこちらになります毎日新聞でもやはり
ＳＰをコンテキストとして利用しない場合にはパープレキシティが悪化していき利用した場合にはパープレキシティが
改善していきます
こちらも毎日新聞の文境界は二十六単語に一回程度とやはり少ないので
その影響は非常に小さなものとなっております
また
これにより予測が実際に改善した実際のコンテキストの
例に
なりますが
まずＣＳＪではこのようなコンテキストにおいて単語予測の大部分すなわち八割から九割程度が
実際に改善しました具体例をこちらに示しますがまず分かりますしかし何々が現状ですそこで
といったように
文末の助動詞に続いて接続詞や代名詞
が続く
という
いわゆる定型句的な
部分でまず予測が改善しまたこの他
名詞助詞の間にポーズが入ってしまっていたり
助詞同士の間に
ポーズが入ってしまっているといういわゆる

文の途中でポーズが入ってしまっているような場合には


原則前後で
履歴を引き継ぐことで予測が改善致します
続いて国会会議録の場合ですが
国会会議録の場合でも
このように
助動詞感動詞ございますありがとうございました
助詞接尾辞
御異議ありませんか御異議なしと
と
いったように文末の単語が次の文頭の予測に有効な場合というのが
見られます
こちらが毎日新聞の結果ですが毎日新聞でもこのように
文末の単語が次の文頭の予測に有効な場合が
見られます特に助動詞と接続詞
に関してはＣＳＪなどと共通している結果と
なっておりますこのような場合には文末の単語が次の文頭の予測に有効となると
いう結果となりました
以上が認識処理単位の独立性の検証についてですが
次にポーズのモデル化について
ご説明したいと思います
従来読み上げ音声などを対象として音声認識の行う場合にはコーパス中の読点をショートポーズとして扱うのが一般的でした
なんですけども話し言葉を対象とする場合にはこうした読点は必ずしもショートポーズに対応するとは限りません
実際にこちらの国会会議録の例を見ていただきますとこのように国会会議録で挿入されている読点
に対して実際の発話におけるショートポーズがあまり対応していないと

ところがご覧いただけるかと
思います
このように話し言葉では読点は必ずしもショートポーズに対応しないと
いうことから
実際のショートポーズを
読点ではなく実際のショートポーズをモデル化する必要があると言えます
また話し言葉音声においてショートポーズの出現頻度ここではＣＳＪの
二百ｍｓｅｃ以上のポーズの頻度
について調査をしてみましたところ

全単語に対して十％以上ということでショートポーズの出現頻度は非常に高いと
従ってショートポーズのモデル化は非常に重要であると
考えられます

こうしたことから今回我々はポーズを含んでいないコーパスに対してポーズ情報を挿入すると
いう方法を
提案しました
具体的にはまずポーズ情報を含む何らかの話し言葉コーパスからショートポーズの挿入モデルを学習します
こうして構築されたポーズの挿入モデルを用いてポーズのないコーパス
に対してショートポーズの挿入を行います
こうしてポーズつきのコーパスが獲得されればここからポーズに対応ショートポーズの情報を含んだ音声認識用言語モデルを構築することが
出来ます

ここでショートポーズの挿入モデルのモデル化についてですが今回我々はこうしたショートポーズの挿入を
与えられた単語列に
対し
直後にショートポーズが挿入されうる場合にはＰラベルをそうでない場合にはＯラベルを付与するという系列ラベリング問題として
定式化を行いました
そして条件付き確率場ＣＲＦを用いてショートポーズの
挿入モデルを構築しこの系列ラベリング問題に適用を
行いました
ＣＲＦはこちらの
基本式の
通りになっております

ということで本提案手法をＣＳＪからショートポーズの挿入モデルを学習し
国会会議録にショートポーズを挿入すると
いう国会会議録を用いた実験において評価を行いました
ここで
ポーズ挿入モデルのすなわち条件付き確率場の素性情報としましては
直前二形態素
現在の形態素
直後二形態素
さらに直前二モーラ
といった素性情報を使用しました
またこの国会会議録にはポーズを挿入する前に
以前我々が提案しましたフィラーの挿入
モデルを用いてフィラーも
挿入を
しておきますフィラーを挿入したのちポーズの挿入を行います

こうしてポーズが挿入された国会会議録の例を
こちらに
示してありますが
このように元々の国会会議録ではこのように
読点が付いていた文に対し
提案手法によって
ショートポーズを挿入したところ
このようにまた北朝鮮が
これらの問題について
建設的な対応を示すのであれば我が国は滞留と交流を通じまして
北朝鮮との関係改善を図る用意があることは
私が施設方針演説で述べたところでもございます
いうように
定量的な評価は
していませんがこのように
実際の話し言葉音声における
ポーズに対応する部分にほぼ
挿入ができているかと言えるかと
思います

ということで本提案手法を
国会会議録に用いた実験によって評価した結果が
こちらになります横軸が
ＳＰの
頻度単語当たりの
パーセンテージになりますがで縦軸がパープレキシティとなっております
でこのようにＣＲＦによって
ポーズを
挿入した
方が
従来のように
読点を
ショートポーズとして利用した場合ですとか
あるいは単語間にランダムにショートポーズを挿入した場合と比べて高い性能が得られていることが分かります
なおこちらは読点
この赤い線のこちらの右端のプロットは
読点をすべて
ショートポーズとして
利用した場合に
に相当します
のでこちらが従来のよく従来の方法と
言えますがこれよりも提案手法の方が
高い性能が得られている
いうことです
続きまして国会答弁の実際の認識実験において提案手法を評価致しました
具体的には国会答弁二十分分の音声認識実験で評価を行いました
ここで音声認識の際の認識処理単位としましては二百ｍｓｅｃでテストデータを
区切りますただし認識処理単位はそれぞれ独立に扱うのではなくて
直前の処理単位の情報も認識に
利用しましたすなわち単語履歴も引き継いで
認識を行いました
またベースラインとしましてまずこちらは参考までの参考程度のものになりますがＳＰを一切モデル化しなかった場合
またランダムに単語間にＳＰを挿入した場合
またすべての読点をＳＰとして用いた場合
ここでさらに

句点すなわち文境界をＳＰとして
扱った場合についても
評価を行いました
提案手法についても同様です
で
で結果を比較してみますとこのように読点や句読点を
ＳＰとＳＰとして用いた従来の
手法に対して
提案手法の方が

高い認識率が得られていることが分かります
特に

ＣＲＦを用いてＳＰを挿入し
さらに句点をＳＰとして扱うことでさらに性能が
改善致しました
まとめます
ポーズに基づく単位
と文単位すなわち句点に基づく単位
の前後で単語履歴を引き継ぐことで

言語モデルのパープレキシティがすなわち単語の予測が改善することができました
具体的にはＣＳＪを用いた実験すなわちポーズに基づく
単位
に関する実験では三．九％程度の相対的な改善が得られました
また国会会議録では
国会会議録の文単位では〇．四％の改善
また毎日新聞では〇．六％の
改善がそれぞれ得られました
ただし国会会議録と毎日新聞では
文境界すなわち句点の数は非常に小さいものとなっておりますので
この影響は今回はあまり大きくないと
いうことが言えるかと思います
またコーパス中にショートポーズを挿入する手法を提案し
国会会議録を用いた実験によって有効性を示し示しました
具体的には読点を読点や句読点を用いる
従来の手法と比べまして
四％程度の相対的な
認識率の
改善を得ることが出来ました
以上で発表を終わります
