石川高専のと申します
どうぞよろしくお願い致します
本日は
講義音声を利用したサブト
ピック分割と検索についてご報告させていただきます

みなさんご存知のようにネットワーク上に最近特にいろんなビデオ教材が
たくさん増えてきました
しかしながらなかなか学生さんが使いたいという目的に合うものはなかなか少ない
ていうことで
実際に作らないとなかなかうまく教育とかに使えない
でいざ作るとなると
時間とか手間がかかって大変と
いうわけで
私どもは

録画したビデオ素材、これは普通の大学等の講義を録画したもの
とかを話題毎に自動的に分割致しまして

ビデオ教材作成の手間を
減らしたいと
それから更に分割した
シーン毎に

実際に見る時にそれをうまく検索したいというのが目的でござい
ここでシーンと申し上げてるのは

トピックをより細かくしたサブトピックの区間をここではシーンと呼ばして頂いておる
で実際にはこういうふうに
自動的に

シーン境界が求まったとしますと
この中から演習とか不要な部分を削除しますと

最低限のビデオ教材ができると
いうことですが、この
シーン分割位置を決めるのは非常に
大変。何回も
同じところを見直してここだっていう風に決める作業が面倒ということになる
で以前にご報告させていただきましたこういう支援するシステムの概要なんですが
まず最初ビデオ素材から音声の情報取り出しまして
音声認識をしてテキ
スト情報を得て
これを基にして
シーンの分割位置推定を行なって
その中から
不要なシーンを削除すればビデオ教材ができる
このシステムにつきましては
ここのＵＲＬの方で
公開させて頂いております
でこのシステムは
ＳＰＨＩ対応の
音声認識ソフトであればどれでも使えるようになっておりまして

こういう音声認識を使った
やり方と単純にポーズだけを使った素早く
使うことができるバージョンと二種類を用意致しております
で実際の画面はこんなような
感じでして

ビデオを指定して分割っていうふうにしますと
こういうシーンが出てきます
当該のシーンをクリックしますと再生されますので、不要であれば削除ボタンを消すだけで
最低限のものができる
いうのが理想でございます
で本報告では
これまで進めてました素材として使ってました石川高専の授業ビデオと言いますか講義ビデオ
に加えまして

豊橋技術科学大学さんのデータベースを利用させて頂きまして
この二つを素材として
トピックのサブトピックの分割と検索について調査した結果をご報告させて頂きます
まずサブトピック分割につきましては
二つのサブトピック分割手法を比較した結果
それから音声認識性能と講義形態の
影響についてご報告致します
それからサブトピックの検索に関しましては
キーワードと実際に学生さんとかが
キーワードとして
指定する
ものと
実際の発話内容との関係
それから音声認識性能の影響についてご報告致します
まず最初に素材に関してですが
石川高専の講義ビデオにつきましては五名の教員による九十分の
ビデオでございます
これを接話型のヘッドセットを使用してますので雑音等の影響はほとんどあり
で音声認識には二つの音響モデルを使ってまして一つは
新聞記事
による
二千状態十六混合ＴＲＩ—ＰＨＯＮＥモデル
それからもう一つは

ＣＳＪ
の

音響モデルを
使わして頂い
それから
言語モデルにつきましてもＣＳＪの言語モデルを使わして頂きます
でこのビデオはそれぞれ平均しまして各五百分ぐらいです
で

かなり
なんていうんでしょうか、演習等も含まれてまして
少しゆっくりしたペースで進みます
それから
共通正解境界数って書いてありますが、これは最終的にシーンとして
こう
切った正解の数が二十
それから平均して二十
でパープレキシティは四百ってことでっちょっと音声認識としては難しいタスク
未知語率は平均で三．四％
で実際音声認識をしてみますと新聞記事
で学習した音響モデルですと非常に低くて単語正解率で四十三％ぐらい
それからＣＳＪで学習された音響モデルでも
五十三％ぐらい
ということで

なかなか厳しい
認識結果です
で一方

豊橋技科大さんの日本語講義音声コンテンツコーパスＣＪＬＣ
のうち五話者六講義を使わして頂き
で各講義は前半後半に分かれてらっしゃるようで
それぞれ七十五分
が六講義分を使
わして頂きます
で
大学院向けの講義
でこのようなもので次Ｃの
分割位置を推定するわけですが

二つの方法を試しました。一つは
ここではちょっと類似法と呼ばして頂いてますが
隣接しているシーン間が
似ていれば
こう一続きのシーン
似ていなければシーン分割位置が
存在するっていうような単純な方法で
でシーンを比較するためにそれぞれのシーン毎に
指標、インデックスが必要になりますが、通常使われるのはＴＦＩＤＦ
先ほどちょっとお話がありましたけど

ここではＩＣＡ独立成分分析を用いた指標を使いまして、指標のサイズを小さくしております
性能的にはほぼ同等以上
ぐらいの感じ
で簡単に申し上げますと
語と文の
語の頻度行列を

話題と文
話題と語
に分割するような方法に最終的になっておる
これによりましてこの話題数自由に設定できますので
好きな次元
でやることができます
先ほどは一万語だと一万次元になっちゃいますが、ここで百ぐらいにすると百次元で収まる
いうことで計算時間がだいぶ変わってきます
それで
そのシーン間を比較する時には余弦を使い
シーンが似てるってことは余弦が大きくなるんですが似ていなければ小さくなるということなので
この
余弦の総和が最小になるように動的計画法でこの切れ目を決めてやるというのが類似法です
次に統計的手法について
これはさん他がご提案、テキスト分野で使われている
提案されている方法ですが、これをビデオ音声に適応した結果です
でまず
単語の並びが与えられます
でこの単語の並びからシーンの切れ目を決めるという問題で、単語の並びが与えられた時にそのシーンの切れ目
が最大になるような確率
そう、最大になるようにシーンを決めてやる
いうことで
このうちの分子の部分が最大になるような
セグメント位置を決めてやる
で
細々したところは省略させて頂きますけれども、いくつかの仮定
例えば

各シーン
の
単語は他の
シーンには依存しないとかっていう独立性の

仮定っていいますか、本来は成り立たないと思うんですが、簡略化のためにいくつかの
過程を仮定しますと
最終的にはこのような式で
この
確率が計算できます
でこれは一般にラプラス法と
いう
形で知られている
方法で
当該シーンの
単語数＋異なり語彙数分の
その
シーン内での
同じ単語数＋一
これで

この確率を

近似しており
で今の
ちょっと細々とした式はこちらの方ですけど、もう一つの
ＰＲＳの方は
単純に等確率
で
与えている
でこれも同様に
対数化してから動的計画法で

この確率が最大になるような
Ｓを決めてやれば良い
でこのような二つの方法についてシーン分割実験を行いました。まず石川高専のビデオについてですけれども
音響モデル一
で横軸が分割率、で分割数を文の数で
正規化したもので
例えば
一つの講義が百文、簡単のため百文だとしますと
そのうち十分割したら
分割率〇．一っていうような形です
で当然分割率上げますとこれが
再現率なんですが、再現率が上がっていく
でこっちは適合率です
でこの
我々のこの研究では適合率
よりも
この再現率の方を重視致します
これは実際にビデオ編集する時に、シーンの切れ目が無いと非常に
その切れ目を入れなくちゃいけないっていう作業が非常に辛いので
再現率がなるべく高い方が良い。できれば百％になると良いという
これが五十％しかないと
半分は自分でシーンの切れ目を決めないといけないということになる
一方適合率が
ある程度までなら低くても無視すれば良いので、あんまり多すぎるとなかなか見づらくなってしまいますが
ある程度までであれば無視すれば良いのでそれ程気になりませんが、
再現率の方はなるべく高い方が良いということになる
ですからちょっと
再現率の方を中心に見て参りたいと思う
でこの赤色のグラフが
統計的手法による再現率
それから青色が
類似法による
再現率です
で比較して頂くとわかるように統計的手法の方が
少し良い結果です
で音響モデル二についても、これは
ＣＳＪで学会講演で学習したモデルですが同じ傾向が出ている
さらに書き起こしテキストについても同様に統計的手法の方が
良い結果が得られている
以上
のことより
統計的手法の方が類似法よりも
良さそうだということがわかり
次に
音声認識性能の影響について

調べました
同じ結果なんですけれども見方を
グラフを変えまして
横軸が
先ほどの分割率ですが
赤色が音響モデル一
それから
ちょっと
次のやつが青色のものが音響モデル二
それから
紫
のものが
書き起こしテキスト。で
かなり音声認識性能かなり違うにも関わらず書き起こしテキストとほぼ同じようなカーブを描いております
でこの原因と致しましては今回利用した方法っていうのが語彙の情報を使っていない
ことで
同じように誤れば
問題ない
いうようなことが起因してるのと思われる
で
それを確認する意味でいくつかのシミュレーションの実験を行ないます
これは書き起こしテキストをわざと
置換誤りを持たせたものです
当然置換誤りが
あっても
原理的には
性能が一緒ということを
実際に試してみて確認
しました。横軸が
置換誤り
縦軸が
先ほどの分割率〇．一から〇．四までの平均の
再現率です
それからこちらの方は横軸が
挿入誤り
これは書き起こしテキストにわざと挿入誤りを
入れたものです
で挿入誤りについても類似法ではほぼ同じ
統計的手法でも十％くらいまではほぼ同じ
で
それ程大きく変動しない
それから
脱落誤り
についても
二十％程度まで振らしてみましたが
それ程変わらない
でさらに


脱落誤りが十％で挿入誤りが五％と十％
それから
置換誤りを振らした場合、要するに混合した場合
ちょっと音声認識を
真似たような感じですが
についてもどの
条件についてもだいたい
それ程
大きな変動は無い
こういうようなことから
二つの音響モデル、書き起こしテキスト、シミュレーション、いずれの実験を通しても音声認識性能の影響は
少ないということがわかる
次に講義形態の影響なんですけれども

まず
これはＣＪＬＣによるシーン分割結果です
でこの赤色の部分が書き起こしテキスト
それから青色が

音響モデル一による結果です
でどちらも
ほぼ同じようなカーブを描いていまして先ほどの音声認識性能には影響しないというのと
同じ結果が豊橋技術科学大学のデータベースでも同じ傾向が得られています
それから
この図は
赤色がＣＪＬＣ豊橋技術科学大学の講義、それから青色の方が石川高専の講義なんですが
講義形態かなり違うんですけども
ほぼ同じようなカーブを描いておる
以上のことより講義形態の影響も少なそうだということが類推
できます
次に
検索について

これまでご発表いっぱいあるので簡単に
だけ
まず利用する情報としては
音声情報以外にスライド情報等様々な情報を用いる方法がご提案されてますが、本報告では音声情報のみを
使います
これはスライドを用いない講義にも対応したいってこともありまして
音声情報のみを利用します
それから未知語対策につきましても
これまでのご発表がいろいろあったように音素インデックスファイルを
生成し利用される方法であるとか
サブワードを用いられる方法であるとか
先ほどもございましたが
講義音声からウェブページ
を検索して
検索キーワードからウェブページを比較して両方を比較するような方法ですとか
という様々な未知語対策が提案されている
それから最初のご発表にありましたように検索テストコレクションが
そろそろ公開されそうということで非常に楽しみにしております
これができれば
こういういろんな

方法を比較検討し易くなるということで期待させて頂いておる
で今回
行ないましたシーン検索の予備実験は
各シーンについてそれぞれ指標を求めて
それかキーワードについても指標を求めて両者を比較するという単純なもの
指標には一般的なＴＦＩＤＦを用いています
先ほどもチラッと申し上げましたがＩＣＡでもちょっとやったんですが
あまりまだうまくいっていないっていうことで
ここでは出てきます
それから
これはシーン検索実験の結果です。でちょっと縦軸はＭＲＲってことで
平均逆数順位を
使いました
これは一位ですと全て第一位に出てくると
〇．五ですと

逆数なので二ってことで、二、平均的には二ぐらいに
その検索したいものが出てくるというような指標でございます
でキーワードとしては
一つだけ指定した場合とか二つから五つまで
横軸がキーワード数が変化致し
でこの最初のピンク色のものが
豊橋技術科学大学のＣＪＬＣの書き起こしテキストによるものです
で
このブルーの
薄い水色のものが
石川高専の書き起こしテキストほぼ同じカーブを描いておりまして
ＭＲＲがほぼ一位に近いってことで
ぼぼ一位に出てくるというようなことで
非常に
高い結果です
ところがこれに次
音声認識
テキストを使いますと極端に
下がりまして
どちらも
このぐらいダウンしてしまう
ちょっと
見た目ではかなりダウンするんですけどもＭＲＲなので、〇．五でも二位以内には出るよぐらいの感じです
それから次にですねえ実際には学生さんがキーワードを指定するんですけど、学生さんはいろんなキーワードの
指定の仕方をするので
実際に被験者として学生さんに、石川高専の五年生ぐらいの
学生さんに
キーワードを
それぞれのシーン毎に出してもらいます
で出してもらってそのキーワードを使って実際検索してみたのが
まずこのグラフです。これは書き起こしテキストなんで比較としてはこの一番上のものと
このぐらいで
このぐらい下がってし
いうことですね
で音声認識についてはこのカーブから
このカーブに落ちてしまう
でどうして落ちるのかなってことで
ちょっと
調査したのがこの表です
で最初、当然未知語があるとその分は確実に落ちてしまうっていうことでこれが
割合としては平均的に十三．八％ございます
キーワードの総数は
ここに書いてあるとおり
これを百％としまして
十三．八％程度が未知語で落ちてしまう
それからちょっと石川高専の場合にちょっと特徴的だったのが抽象化
ってここでは書かして頂いてるんですが
これは何かと申しますと
直接発話していないんだけれども
発話内容を総括したり
こうイベントを表現したり
するような言葉、例えば演習とか実習とか説明とか
例えばこれからこれこれを説明しますって言う場合もあれば、言わずに説明する
こともある
そういう説明っていう言葉が
講義の中に出て来ないんだけど、キーワードとしては何とかの説明みたいな感じ
何とか演習とか
演習これからしますっていうのは珍しくて
これやってみましょうとかっていう場合が多い。そういうことですね。それをちょっとここでは
抽象化という表現で表さして頂い
で高専の場合にはそういう演習が多いもんですから、そういうこともあって
十一％ぐらい抽象化、あるいは
内容はある程度理解
できると
より

感覚的には
概念的な表現をするのかなあというのも
ちょっと
そういう気も致し
それから表現の揺らぎっていうのは
表しますっていうのと表現っていう言い方
のそういう表現の違い
で
こちらが豊橋技術科学大学の方の

実際にどういう割合であったかと
で未知語は十一％ぐらいでした
で抽象化は非常に少なくて
一．四％でした
これはどうしてかというと演習とかそういうのが少ないということと
それから
多分

学生が五年生なんで、大学院の授業いきなり聞いても
きっとよくわからなかったんだと思います
要するにそのまま
出てきた言葉をそのままキーワードとして書いた割合が多かったのかなあという気が致します
これが抽象化が、ですから
抽象化っていう表現が出てくるのは講義によってかなりこうバラつきがあるのかなあという
気が致し
ちょっとデータとしては
まだ少ないので何とも言えませんけれども、そういう傾向がございます
で以上まとめますと



統計まずＣの分割に関しましては統計的手法の方が類似法より良い結果でした
で音声認識性能や講義形態の影響は少ないということが確認できました
それから検索に関しましては
未知語ばかりではなくて抽象化表現への対処っていうのも場合によっては必要になるかもしれません
それからこれは前から言われていることですが、音声認識性能の影響はやはり大きいと
いう
ことが確認されました
以上でございます
