それでは表記のタイトルで発表させていただきます発表者は東北大学工学研究科のですよろしくお願いします
まず初めに研究背景ですが

話し言葉音声の自動書き起こしを大語彙連続音声認識を用いまして
会議録や
議事録などを自動的に作成するという研究が
広く行われています
そして話し言葉の音声認識が難しい理由として
内容をその場で考えながら話しているという特徴があるために
文がまとまりのないものになりやすいフィラーや言いよどみなどが現れる
といったことが
通常のこれまで用いられていた方法では認識が難しくなるという
はい難しくなるという理由になっている
ここでＰＬＳＡ言語モデルについてまず説明いたしますＰＬＳＡ言語モデルというのは
話題をモデル化するという目的で
考案されたものでして

特定の話題に特化した単語出現確率を複数混合モデルという形態を取っています

言語モデルの内部に
潜在モデルと呼ばれる
特定の話題や話し方の特徴のｕｎｉｇｒａｍのモデル
例えば政治スポーツ経済などの
話題であるとか
あるいは方言の話し方で話している場合丁寧語で話している場合といった
話し方の特徴のｕｎｉｇｒａｍのモデルというのを
複数個内部に持っていますそして
表したい話題や話し方の特徴に対して
それらを複数のモデルの最適な混合比を推定して混合することで
目的の
話題や話し方の特徴を持った言語モデルを得るというものです
このＰＬＳＡ言語モデルを話し言葉
の認識に適応した場合の問題点について説明いたします
まず話し言葉のコーパスというのは
ＣＳＪなどが代表的ですが広い話題性を持っているものではありませんので
それだけを使っても
話題性を十分配したＰＬＳＡを作るということは難しいと考えられます
逆に広い話題性を持ってるコーパスとして新聞記事などがあるのですが
こちらは書き言葉で書かれてますのでそのまま使用することができません
そしてこれを解決するための先行研究として二千三年に秋田らに行われた方法に
ＰＬＳＡを二つ
用いまして話題のＰＬＳＡモデルと
話者性の
ＰＬＳＡモデルという二つのモデルを使う方法が提案されています
その研究では
認識対象を政治に関する討論番組の
音声書き起こしというふうに設定しまして
話題のＰＬＳＡを国会の会議録から
そして話者性のＰＬＳＡを
ＣＳＪからという違ったコーパスから学習する方法が取られています
この方法で問題をある程度解決されるのですがまだ残る問題点として
この話題のＰＬＳＡに
元の学習データの
文型話し方の癖などが残ってしまうまた

話者性のＰＬＳＡの方にはその適応対象となった講演の話題性が残ってしまうであろうという事が考えられます
また話題性と話者性の二つのＰＬＳＡモデルを重みづけ混合してますのでどちらにどれだけ強く適応するかというのが
トレードオフ関係になってしまうという問題があります
そこで本研究では提案手法として語彙分割ＰＬＳＡという違った方法で複数のＰＬＳＡモデルを使う方法を
提案しています
これは
言語モデルの語彙を分けるという考え方をしていまして
話題によって出現頻度が変化する語彙
これ話題語と呼んでいます
それから文型によって出現頻度が変化する語彙
話し方や文体などですねそれを文型語そして
この二つの影響どちらも受けない語彙を汎用語というふうに呼んでこの三つのクラスに語彙を分割するという
方法を取っています

そしてそれぞれ別々にＰＬＳＡの学習と適応を行っています
そうすることで
まず先ほどの先行研究と同じように同じ学習データやコーパスの中にない
話題や文型に対しても適応が容易である
また

言語モデルの語彙を三つに分割して後で一つにまとめるという処理をしますので
話
言葉話し方の特徴と話題の特徴
どちらにどれだけ適応するというトレードオフ関係にならないですむという特徴があります
では具体的な言語モデルの生成方法説明します
ＰＬＳＡ言語モデルは学習データとしてある決まった話題や文型を持つテキスト記事毎の
単語出現頻度のデータから最尤推定を行います
そして
本研究で用いている方法ではまずこの学習データを
話題語
話題に関連する語彙のみの出現頻度
文型語
の出現頻度汎用語の出現頻度というそれぞれの語彙
クラスだけの出現頻度に
学習データを分離しますそして
話題のＰＬＳＡモデル話者性のＰＬＳＡモデル
そして汎用語のモデルこちらは
特徴を受けないという前提考えてますので適応を行わないためにｕｎｉｇｒａｍのモデルを生成しています
このように別々にモデルの学習を行います
そして生成した三つのモデルをまず話題のＰＬＳＡモデルと
文型のＰＬＳＡモデルをそれぞれ
目的の
表したい特徴の単語出現頻度で適応を行います
そして三つのモデルをそれぞれの語彙クラスの
出現確率それぞれの語彙クラスがどれだけの確率で現れるかという
情報で重みづけをして一つの言語モデルに戻すという方法を取っています
ちなみにこの語彙クラスの出現確率というのは適応に用いた単語出現頻度のデータとｔｒｉｇｒａｍ言語モデルを元にして
ある文脈の下で次に
この三つの語彙クラスがそれぞれどれだけの確率で現れるかというのを
推定するクラス出現確率の推定モデルというもので
求めています
式の上ではこのような形になっていまして
先ほど説明しました話題のＰＬＳＡモデルがこの
ＰＴの部分
文型ＰＬＳＡモデルがこの部分そして汎用語の
モデルが
このＰＧの項となっていましてそれぞれの
言語モデルの確率を

ある文脈hと直前二単語の後ろに
それぞれのクラスが現れる確率で重みづけして混合するという計算をしています
ですが実際にはこの三つのモデルというのは
語彙が完全に分かれてますので
この
例えばｗｉ目的単語が
話題語であった場合はこの話題語のＰＬＳＡモデルだけが確率を持っていて他の二つは確率が〇になる
という状態で
三つのモデルどれかを選択的に使っているという状態になります
次にその話題語文型語汎用語の分割基準について説明をいたします
基本的には茶筌の持っている品詞分類九十種類を
この話題文型汎用語のどれかに分類するという方法で作っています
まず
最初に
この九十種類の分類を人の判断で
どれかに分類するという方法で
暫定的にこのような分割基準を考えることができます
話題後は一般名詞や固有名詞など
文型語は助動詞代名詞フィラー感動詞など
そして汎用語には助詞や
文頭文末記号などという
ような考え方で基準を作っていくことができます
ですが人の判断で作った基準というのはやはり間違いを含んでる可能性もありますし
手間もかかるということでこれを
統計的な方法で生成できないかということを
考えました
品詞分類毎にその品詞分類が話題に対してどれだけ関係性があるか
文型に対してどれだけ関係性を持っているかということを統計的に測って
それに基づいて
分割の基準を決めようという事を検討しています
そのための
方法としてＪｅｆｆｅｒｙ情報量に基づいたこういう分割基準の生成ということを
本研究では行っています
ジェフェリー情報量というのは二つの確率分布の間で
Ｋｕｌｂｕｃｋ−ｄｉｖｅｒｇｅｎｃｅを二つ測りましてその

二つの値を足し合わせることで二つの確率分布の間をどちらから見ても
距離が等しい距離尺度となるようにしたものです
式の上ではこのような形になっています
このＪｅｆｆｅｒｙ情報量
をどこにどことどこで求めるかと言いますと
ある決まった品詞ある一つの品詞分類の上での
一つの記事
ある決まった文型を持っている記事の上でのそのクラスの
単語出現確率の分布
一方もう一つに学習データ全体で見た場合のその
クラスの
確率の分布というこの二つの分布の間がどれだけ
距離があるかというのをＪｅｆｆｅｒｙ情報量で計算します
つまり
ある品詞分類の上で
このように全体の平均の分布となっているであろうｕｎｉｇｒａｍの確率分布と
決まった話題や文型の特徴を受けている
一つの記事の上での確率分布これがどれだけ違うかというのを
計算していることになります
これを基本的な特徴量としましてまず

話題語文型語と
汎用語
この二つ
二種類に分離する方法を考えます
先ほどの距離をｕｎｉｇｒａｍを構成している全ての記事について
平均しますそうしますと

もし
その品詞分類が汎用語であった場合というのは
話題の特徴の文型の特徴も受けないつまりどのような記事の上でも
出現パターンが変化しないはずということで
このように
この図でいうとこの×印とかユニグラムで
一つ一つの記事が同じような位置にある距離が近い分布をしているということが考えられます
逆に話題語や文型語であった場合はそれぞれの記事の持っている固有の特徴で出現パターンが変化しますので
距離が遠くなっている
ということが考えられますつまり
その平均値が
高かったものは話題語か文型語である
平均値が低いものが汎用語になっているであろうと考えることができます
そして同じような方法で話題語と文型語の分離ということも行うことができます
今度は事前に文型が異なると分かっている二種類のコーパスを考えます例えば
書き言葉の新聞記事と
話し言葉のＣＳＪといったようにです
そして例として
話し言葉のｕｎｉｇｒａｍでの確率分布と
書き言葉の上での一つの記事の確率分布話し言葉の確率というふうに

この二つの距離を測ること
考えますと
同じ
文型を持っているものは文型語のクラスであればですが
文型語では

同じような
文型の特徴を持っていますので出現パターンも似ているつまり距離が近くなるだろうと
考えられます
一方
書き言葉と話し言葉というように違った文型を持っていた場合は
この距離は遠くなる
と考えられます
そして話題語であった場合はこの同じ二つの距離を測ったらどうなるかとか
いいますと
こちら話題性が一致しない限り単語の出現パターンは変化するであろうと考えられますので

この二つの距離がどちらも遠くなると考えられますつまり
同じ種類のコーパスに対する距離と違う種類のコーパスに対する距離で
距離の傾向が異なってくるものが文型語ではないかと考えられます
全体まとめますとこのような
ことが考えられまして
話し言葉の
記事と
書き言葉の記事
書き言葉のユニグラムと話し言葉のユニグラムで
四つの確率分布を考えることができますが
その間で測る四つの
距離が
どれも大きくなるものが話題語
どれも小さくなるものが汎用語そして
話し言葉の記事と話し言葉のユニグラム話し言葉と書き言葉というように違ったもので測った場合で傾向が異なるものが文型語であると
ということで

計算の仕方としましては
この四つの距離尺度の相和の逆数を取りましてつまり距離がどれだけ小さいかが汎用語らしさを表していると
そして違う記事で測った
二つの距離の差分の二乗和
つまりこの普通で言うとこの話し言葉同士と話し言葉と書き言葉の距離の差分を計算しまして
それが大きければ大きいほど文型語らしさが高い
というようにして汎用語らしさ文型語らしさという尺度を定義して
実際に
各品詞分類について
実験を行っていました
その結果が
こちらになっていましてグラフの横軸が汎用語らしさ縦軸が文型語らしさになってる
そして
この赤い点一つ一つが茶筌の品詞分類九十種類の
一つ一つに対応しています
具体的にどのような
分類が現れていたかと言いますとまず汎用語らしさが非常に高かったものが
助詞の連体化
何々のののですね
それから格助詞などが非常に高い値を示しました
そして文型語らしさが高かったものが
名詞の非自立助動詞互換これは何々のようにです
それからなども高い値を示しました
そして二つとも低い
値となる傾向だったのが名詞のサ変接続や
固有名詞など話題性を強く
反映してると思われるものは
どちらの値も小さくなるという傾向でした
そこで
この汎用語らしさ文型語らしさに閾値を
このグラフの
青と緑の線ですが閾値を設定しまして
グラフの上で
右下に出ているものを
汎用語のクラス
左上に出ているものを文型語のクラス左下を話題語のクラスと
このように考えて語彙分割の基準を生成いたしました
その結果得られるのがこちらの表です
最初に示しました人の判断で暫定的に決めたものに非常に近い
ものが得られています
多少変化したものもありましてこのフォントが斜めになっているものが
人の判断の基準から分割される
クラスが変わったものなのですが
話題語に接頭詞や接尾語が
分類されたこと
それから文型語に動詞が全て文型語となったことなどで若干の違いは
生まれています
では以上説明しました語彙分割ＰＬＳＡ言語モデルの評価実験の説明に移ります

言語モデルの語彙サイズは三万語彙のものを生成しました学習データに用いたのは
話題性をカバーしてるコーパスとして毎日新聞の二千年度版話者性をカバーしてるものとしてＣＳＪの学術講演模擬講演
対話を使っています
そして
語彙分割ＰＬＳＡの三つのモデルそれぞれの
0287; 語彙数形態素数はご覧のようになっていますちなみにこれは
情報量基準で

こういう分割基準を決定した場合の

条件となっています
そして評価尺度にはテストセットパープレキシティを用いまして
テストセットには
ＣＳＪの模擬講演の中にある現在から過去数年の間に新聞雑誌などで扱われたニュース
というものを百五十二講演用いています
そしてｔｒｉｇｒａｍ従来のＰＬＳＡモデル
そして語彙分割ＰＬＳＡの二種類これは
最初に示した人の判断で基準を生成した場合と
情報量基準で分割基準を決めた場合の二種類でこの四つのモデルについて
比較を行いました
実験結果です
左から順にトライグラム従来のＰＬＳＡ
語彙分割ＰＬＳＡで基準は人の判断で決めたものそして情報量基準で決めたものと
このような結果になりまして
情報量基準で語彙分割を決めたものが最も
良い結果を示しました
従来のＰＬＳＡと比べますと四．五六％
パープレキシティの改善を得られています
次にこの言語モデルを認識実験に適応した場合の実験について説明いたします

この言語モデルをＪｕｌｉｕｓに直接使用するというのが
難しかったのでまずは
Ｎベストリスコアリングによる認識実験を行いました
認識エンジンとしてはＪｕｌｉｕｓを用いまして音響モデルにはＣＳＪ付属の
学術模擬講演ＧＩＤモデルを使っています
そしてｔｒｉｇｒａｍ言語モデルを使ってまず仮認識を行いまして
五百ベストの
認識結果候補文を出力させますそれを
語彙分割ＰＬＳＡの
言語スコアで
リスコアリングするという方法取っています
なおリスコアリングの際にはこの
言語モデルの効果が強く表れるように
言語重みと挿入ペナルティを通常のＪｕｌｉｕｓのデフォルトの値の二倍に大きめに設定してやります
認識対象としたのは
先ほどの
パープレキシティの評価に使ったテストセットから十個の講演を選択して使っています
実験結果ですがこのようになりました
それぞれ十本のテストセットの
黄色がトライグラム
の仮認識結果の時点でのワンベストの
認識精度そして青がリスコアリングを行った後の
認識精度となっています
そして順番にそれぞれのテストセットの十本のテストセットそれぞれの結果となってまして一番右が平均値です
結果としては
六十四.四一％からリスコアリングを行って六十四.四五％
改善したのが〇.〇三三％ということで
ほとんど結果としては変化が得られないというものになってしまいました
テストセット毎に見ていきますと
良いもので〇.七％程度
改善
してまして逆に悪化してしまうものもの
ものもありましてそちらでは
〇.七％
悪化すると
そのような結果になってまして
全体を平均するとあまり変化が無かったという結果です
なぜこのようなあまり目立った結果が得られなかったかという所なんですが
まず
この
五百ベスト分のリスコアリングという方法があまり適切ではなかったのではないかと考えています
というのはこの五百ベスト分というのがトライグラムの
制約で選ばれてますので
その
一文よりも
より文単位で見て認識精度の高いものが
二位から五百以内になければならない訳ですが
実際に

認識精度が悪化してしまったテストセットを見ますと
この一位文より良い文というのが二位以下に無い
という
傾向が見られました
またそれ以外にも
この右側のグラフというのは
横軸に

テストセットの正解文
を使って仮認識に用いたｔｒｉｇｒａｍ言語モデルのパープレキシティを計算した値を取りまして
縦軸には各テストセットのリスコアリング前後での認識精度の変化を取ったものなんですがこのように
元々パープレキシティが高かったものが悪化してしまっていて
良かったものについては改善が得られているという傾向が見られました
このことからもこの仮認識時の
ｔｒｉｇｒａｍにリスコアリングの結果まで
大きく左右されてしまっていたのではないかという
ことを考えていますそのため認識の適応方法を見直す必要があるのではないかと
現在考えていまして
分単位のリスコアリングではなくて単語グラフの上でリスコアリングを行うという方法や或いは
リスコアリングではなくて文脈適応したＰＬＳＡをｂｉｇｒａｍやｔｒｉｇｒａｍに変換して
Ｊｕｌｉｕｓに直接与えて
使用するといった方法が必要なのではないかと
いう風に考えています
まとめます
本研究では話し言葉認識のために話題と文型の特徴をそれぞれ
独立して適応できる言語モデルというものを研究しております
方法として語彙分割ＰＬＳＡ言語モデルというものを提案していまして
語彙を話題語文型語汎用語の三クラスに
分ける
そうすることでそれぞれ独立な適応が可能になるというものを提案しています
またその語彙の分割基準の生成方法に
統計的な特徴に基づいて文型語らしさ汎用語らしさというものを
数値化して求めましてそれに基づいた基準を作るということを行っています
その結果パープレキシティの評価では従来のものと比べ四.五六％
パープレキシティの削減効果がありました
また五百ベストリスコアリングで認識に適応した場合
〇.〇三三％認識精度の改善を得ました
今後の課題としてはこの二式の適応方法がやや不適切であったと考えられるのでそれについて検討していきたいと考えている
以上です
