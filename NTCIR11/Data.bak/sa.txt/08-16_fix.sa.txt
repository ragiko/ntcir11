龍谷大学情報メディア理工学部情報メディア学科のです
今回多言語音声ドキュメントのアーカイブ検索の為の音声情報処理の検討について私とが発表させて頂きます
まず始めに近年マルチメディアコンテンツその中でも音声ドキュメントは
ネットを通じネットワークを通じて通じて配信され
アーカイブ化される傾向にあります
その検索に話しことばの音声認識は必要かつ
重要な技術となっています
そこで本研究では国際放送ニュースのアーカイブについて
焦点をあててみました
これには
重要単語などのインデキシングなどによるキーワードベースの音声認識には一旦全てをテキスト化する必要は無いんですが字幕付与などに関しては一旦全てをテキスト化する必要があるために
音声認識の高精度化が必要となってきます
そこで複数の入力音声これは多言語なんですけど利用できる事を着目し機械翻訳モデルを用いながら同時に処理する方法を前半が提案させて頂きます
また
音声がネットワークを通じて配信非可逆圧縮がす
施される場合が多いため多いことを着目し
圧縮処理が音声認識に与える影響の調査について
後半が発表させて頂きます
まず前半多言語の同時音声認識について発表します
国際放送ニュースはではマルチチャンネル音声が利用可能なケースが多くなっています
例えば多国語放送
つまり複数の異なる言語で同じ内容の発話がされることが多いです
そこで
その複数の異なる言語の各チャンネルの音声の認識を情報を補い同時に実行すること
つまり二ヵ国語同時音声認識を今回提案させて頂きます
その枠組みについて説明します
国際放送ニュースなどでは日本語の音声に副音声として英語の音声同一内容の英語の音声が付与されていることがあります
(W それらをそれぞれ音声認識を行い

翻訳モデルから
英語と日本語の対応スコアを算出し
リスコアリングを行うことによって日本語の文字列
(W 出力しその認識精度を改善させるというのが二ヵ国語同時音声認識の目的となっています
また同様に英語の文字列を出力する際も
それぞれの音声認識を行い日本語と英語の対応スコアをとってその情報を補う事によって英語の文字列を出力し

認識精度を高める事を目標としています
そこで定式化について説明します

ここでは日本語と英語の同時認識について説明します

出力単語列は先程申した通り日本語と英語どちらでもよろしいのですが
今回は日本語の単語を出力するのをを定式化します
その日本語音声認識について詳しく説明しますと
日本語の音声Ｘと英語の音声Ｙが与えられたときにそれらを最もよく説明する日本語単語列Ｊを求める問題として定式化します
まず
日本語の音声とＸと英語の音声Ｙから
日本語の最大となる日本語の単語列Ｊを出力するためにまずこの式になります
次に
ＰのＸとＹはＪによる最大化と無関係であるために掛け合わせることができこの式になります
次に
全ての可能な英語文字列つまり 英語音声認識の各候補
をＥＭと置き
シグマをとってこの式になります
またシグマを関係ないところを外すとこの式になります
次に先程の式から対数をとり重みを導入することによってこの式になり
ベイズ則を用いて
この式に変形できます
重みのＡ−Ｂをα
Ｂをγと置いて整理する
最終的にはこの式が
算出されます
ここで
この青い部分を
日本語音声認識のスコア
赤い部分を英語の音声認識のスコア
あっすいません黄色い部分を英語の音声認識のスコア赤い部分を翻訳モデルのスコアと
することができます
ここで
日本語の音声と英語の音声を用意したら日本語の音声認識のスコアと英語の音声認識のスコアと翻訳モデルのスコアを用いることによって
日本語の音声認識が行えることがこの式で立証できました
次に
予備実験を行いました
具体的な内容としましては翻訳モデルを用いた音声認識の枠組みを正しく機能するかを調査しました
つまり
そのやり方としましては対訳英語テキストを与えた日本語の音声認識を行いました
図を用いて説明します
先程
では日本語の音声と英語音声同一内容の日本語の音声と英語の音声を用意しそれぞれを音声認識をして
翻訳モデルから与えられた翻訳スコアを使ってリスコアリングを行うことにより日本語の文字列を出力するというのが
今まで説明した枠組みになってます
そこで
この英語の音声と英語の音声認識の部分を
英語テキストＥつまり対訳の英語テキストで単語誤り率が零％の対訳英語テキストＥを用いて
日本語の音声と

の音声
認識を行い
日本語の文字列を出力するというのが予備で
予備実験の枠組みの概観となってます
式はこのようになります
この式を用いてより詳しく説明させて頂きます

先程の違ってこの場合の日本語の音声認識は日本語の音声Ｘと英語のテキストＥが与えられたときにそれらを最もよく説明する日本語の文字列Ｊを求めるプロセスになってます
ここで

先程の式はこのような式になり

この式と下の式と違うところは

英語の音声認識のスコアというものが含まれていないことになります
つまり
予備実験では
英語テキストＥ一文を用いているため日本語の音声認識のスコアに単純に翻訳モデルスコアを足し合わせる
その式によって
この日本語の音声認識のスコアみの場合と
日本語の音声認識に翻訳モデルのスコアを
足し合わせるものを比較することによってに翻訳モデルスコア用いを用いることの有効性を
今回予備実験で示すことができると考えました
また
の下の式の英語の音声認識の各候補が一通りの場合と等しいため枠組みとしては日英同時認識
と同一であると考えました
では評価実験についてお話します
評価データには日英対訳ニュース記事日本語文読み上げ日本語母語話者五名から五十文とりました
次に音声認識システムにはデコーダにＪｕｌｉｕｓを
音響モデルには読み上げ音声から学習したＭＯＮＯＰＨＯＮＥ
言語モデルには新聞記事から学習した
単語トライグラム
翻訳モデルにはＩＢＭモデルスリーを用いた
用いました
またその学習データにはロイター記事対訳コーパスを使いました
では結果です
まず音声認識のスコアと翻訳モデルスコアの統合重みγの効果について説明します
この式の翻訳モデルスコアの重みγの値を
零から一まで変えることによって

このγの値がどれくらいならば認識率がより向上するのかというのを
調査しました
横軸がγの値
縦軸が認識率の改善率の絶対値になります
その結果
γの値が零点零五から零点零零点四五程度で平均で認識率の向上が得られるということがわかりました
そこでこのγの値を零点四に
定めて次の
実験を行いました
つまり
γを零点四にした値で翻訳モデルを用いた音声認識というものを行いました
その結果
翻訳モデルをすみません
話者ごとに行いました
赤い棒グラフが
音声日本語音声認識のスコアのみを用いた単語誤り率
青い棒グラフが翻訳モデルを用いた日本語音声認識の

棒グラフになっています

一番右にあるのが平均になってます
その結果
翻訳モデルを用いた音声認識は平均の値で単語誤り率が十三点一三％から十二点四零％に
削減され
誤り削減率としては四点八一％削減となりました
ただこの
翻訳モデルを用いた音声認識はＭＯＮＯＰＨＯＮＥモデルを用いており

他にＰＴＭトライフォンモデルを用いた場合の
単語誤り率を調べてみました
その結果平均で五点三零％から五点一三％と
減少幅が改善幅が少なくなりました
これはもともとのベースラインの音声認識精度が高過ぎると効果が少ないということが
いえます
しかし
実際の話し言葉の音声認識精度はこれよりも低いため改善の可能性は大だと考えました
続きまして
英語の音声認識の精度はどの程度必要なのかというのを今回
発表させて頂きます
先程の予備実験では
日本語の音声と英語の対訳テキストＥを用いて日本語の文字列を出力した結果ベースラインよりも誤り率が四点八一％減ということがわかりました
そこで
実際に英語の音声認識を行いました
その結果英語の認識文が
出力されました
その英語の英語の音声認識文の単語誤り率が一体何％ならば先程の正しい対訳テキスト
をＥを用いた場合と同等の結果が得られるのかつまり日本語の文字列が先程と同じ様な改善が得られるのかというのを
調査しました
ここで

英語の音声認識文と英語の対訳テキスト文を用いた場合で大きく変わってくるのがこの四角で囲ってある
ＰのＪＥのＲとＰのＪのＥＣ
つまり

翻訳モデルスコアになります
この翻訳モデルスコアを正しく評価することによって

単語誤り英語認識文の単語誤り率が何％ならば
対訳テキストと用いた場合と同等の結果が得られるのかというのを調べてみました
詳しく説明します
先程の翻訳モデルスコアによる目的言語の一単語当たりの平均予測数
これを翻訳モデルパープレキシティーと呼びますを利用しました
この翻訳モデルパープレキシティーという名前は言語モデルの
評価によく用いられるパープレキシティーを今回参考にしたためこの名前にしました
この翻訳モデルパープレキシティーのこの下の式の英語文の部分に
正しい英語テキストＥＣと
英語正解音声認識文ＥＲが与えられたときの
翻訳モデルパープレキシティーの差を

調査しました
そのそれが小さい場合には
日本語の音声認識の最終スコアが近くなるということがわかります
また
その結果英語の音声認識文ＥＲを用いても

英語の対訳テキスト文ＥＣを用いても日本語の音声認識の精度改善が同等に得られると予測がつきます
そういうこで
この
翻訳モデルパープレキシティーの差Ｖと単語誤り率の
差を調べることで
この
英語音声認識文の単語誤り率が

どのぐらい影響を与えるのかというのを調べました
結果です
英語音声認識の認識率と翻訳モデルパープレキシティーの関係について図にしました
横軸が英語音声認識の認識率
縦軸は翻訳モデルパープレキシティーの変動になっています
相関係数は零点四六三をとり
これは英語音声認識の認識率が
低くなれば翻訳モデルパープレキシティーの変動も小さくなるということがわかります
また

この丸で囲った単語誤り率が四十％以下
のところでは
翻訳モデルパープレキシティーの変動は小さい値をとっています
この四十
％以下の英語の単独音声認識が単語誤り率四十％以下ならば



それを組み込んだ同時音声認識では

精度の改善が得られるということが示されています
また
この四十％から六十％のところなんですけども結構半分ぐらいが小さい値をとっています
これについていえる事は半分程度
つまり単語誤り率が四十％から六十％の半分程度の誤りを含んでいても
翻訳モデルを用いた

同時音声認識というものが有効であるということを示しています
前半のまとめです
国際会議ニュースの音声認識について今回発表させて頂きました
その中で同じ内容の異なる言語
を用いたマルチチャンネル音声の音声認識について今回提案させて頂きました
その結果その中で予備実験として日本語音声認識時に英語テキストと翻訳モデル利用したものを予備実験として提案させて頂きました
その結果
翻訳モデルを用いた音声認識の枠組みが機能することを確認しました
また
翻訳モデルパープレキシティーに基づく影響の調査についても

発表させて頂きました
その結果翻訳モデルを用いた音声認識が十分に機能する為には
英語音声認識部の単語誤り率がの四十％
程度であることが必要であるということが今回わかりました
以上で僕の発表は終わります
























では後半の発表をが発表させて頂きます
前半では国際ニュース国際放送ニュースのアーカイブを対象とした
音声情報処理の手段として
機械翻訳モデルを用いながら同時に処理する方法をが発表させて頂きました
また国際放送ニュースなどの音声ドキュメントは
ネットワークを通じて配信非可逆圧縮が施される場合が多いことから
圧縮処理が音声認識に与える影響の調査も行いましたのでその
発表をさせて頂きます
ネットワーク上の音声ドキュメントの検索のためにはキーワードなどをインデックスとして
付与することが重要となります
このインデックスを付与する為には音声認識が有望です
これまでの一般的な音声認識の研究の主な対象は
十六 ｋＨｚサンプリング十六ｂｉｔ線形量子化の非圧縮音声が用いられています
しかしネットワーク上の音声ドキュメントは
ＭＰ３やＡＡＣＷＭＡの方式で圧縮され保存や通信が行われる機会が多くなっています
この例としましてインターネットラジオではＭＰ３
ＢＳデジタル放送ではＡＡＣの形式が用いられています
これらの形式は非可逆圧縮であるため
この圧縮の過程では人間の聴覚に影響しないように情報が削減されています
また圧縮後の音声からは元の音声は完全には復元できないため
このような非可逆圧縮である音声を
認識対象として用いる場合は何かしらの対策が必要だと考えられます
しかし音声圧縮が音声認識に与える影響の調査はこれまで十分に行われていないため
この基礎的検討としまして様々な形式
圧縮率で圧縮した音声の認識実験を行いました
音声の認識実験は大きく三パターンに分けて行いました
それぞれ具体的には音響モデルが異なるのですが一つ目にはベースライン音声認識システムとしまして
従来の十六 ｋＨｚ十六ｂｉｔの非圧縮音声で学習した音響モデルを用いた認識実験
二つ目には音響モデルの入力環境への適応として
入力環境を考慮した音響モデル
三つ目には音響モデルの話者性と入力環境の両方への適応として
入力環境と話者性を考慮した音響モデルを用いた認識実験を行いました
認識システムです
デコーダ−はＪｕｌｉｕｓ
音響モデルはＪＮＡＳで学習したトライフォンモデル
言語モデルは語彙サイズ六万の新聞データで学習した単語トライグラム
学習データにはＩＰＡ９８テストセットを用いました
処理の流れとしまして後半部は通常の音声認識と変わりませんが
勿論圧縮した音声を認識するので前半時に
対象となる音声を圧縮しているところに特徴があります
こちらがベースライン音響モデルを用いた音声認識実験の結果となります
横軸がビットレートビットレートは右に行く程音質が低下します
縦軸は評価の指標に用いた単語誤り率
また音声圧縮にはＭＰ３ＡＡＣＷＭＡの三形式を用いました
始めにベースラインとなる非圧縮音声を
対象とした認識では
八点二三のＷＥＲを得ました
次に三十二ｋｂｐｓの音声の
認識結果は
どの形式においても十％前後のＷＥＲが得られたことから
このような音声を対象として認識を行う場合には
従来のシステムでも大きな問題が無いことがわかりました
ビットレートが二十四ｋｂｐｓの場合においては
方式よって異なりますが誤りが増加することがわかりました
具体的には
ＭＰ３形式の場合ですと三十四点五一％ＡＡＣの形式ですと二十二点五九
ＷＭＡの
ですと十三点八九のＷＥＲが得られました
この実験に
この実験で用いた音響モデルですが
学習時は十六 ｋＨｚ十六ｂｉｔの音声から
しかし実際認識している場合は圧縮オーディオです
このことから入力環境と音響モデルの不一致が生じたと考えられます
そこで入力環境入力環境つまり圧縮音声にマッチした音響モデルを用いた認識実験を行いその効果を確認しました
具体的には
ベースライン音響モデルのＭＬＬＲ適用を行いました
ちなみに適用の対象として用いた圧縮音声は
最初の実験において三十四点五一のＷＥＲを得られたＭＰ３形式
十六ｋｂｐｓのものとなります
また適用データはＪＮＡＳコーパスに含まれる音声約四十七時間
先程も述べましたが圧縮
適用に用いた圧縮音声はＭＰ３形式十六ｋｂｐｓのも
またここでは評価データに含まれる話者は除きました
こちらが入力環境にマッチしたモデルを用いた音声認識の実験結果です
音響モデルを圧縮音声に適用す
した場合の認識結果は
二十三点九零のＷＥＲを得ました
これは最初の実験における音響モデルがベースライン入力音声がＭＰ３
つまりモデルと音声が不一致の
と比べると誤りを約三十％削減しました
しかし入力音声が非圧縮の場合に比べると
誤りは約三倍となります
このことから入力環境にマッチしたモデルを用いるだけでは
十六ｋｂｐｓに圧縮された音声
認識の精度は不十分だと考えられます
そこで音声ドキュメントの検索には音声を事後的にオフラインで認識し
インデックスを付与すればよくそのような音声認識の場合は
認識結果と認識対象の音声データで繰り返し適用を行うことで
音声認識の精度向上が得られることがこれまでの研究で明らかになっています
そこでこの繰り返し音響モデル適用の効果を確認しました
ここでは理想的なケースでの認識精度の調査であるため
正しいテキストラベルを与える教師あり適用を用いました
適用データはＩＰＡ９８テストセットの音声
このことから入力環境と話者性の両方に適用すると考えられます
適用の
適用に用いた圧縮音声は
最初の実験における
ＭＰ３形式十六キロの場合と八キロの場合の二つを用いました
こちらはＭＰ３十六ｋｂｐｓの音声で
を適用した音響モデルを用いた音声認識実験の結果となります
縦軸は先程と同じくＷＥＲ横軸が適用回数
また適用方法はＭＬＬＲとＭＡＰの二つの方法を用いました
ベースラインのＷＥＲが三十四点五一％のものに対して
三回繰り返し適用を行うことでＭＬＬＲ適用では二十点五八
ＭＡＰ適用では十二点七四のＷＥＲが得られました
このことから繰り返し適用を行うことで十六ｋｂｐｓ程度の圧縮音声ドキュメントは処理できる可能性があることがわかりました
しかし一方八ｋｂｐｓの適用の場合ですと
ベースラインでは約九十％のＷＥＲに対して
適用を行ってもＭＬＬＲでは六十一％
ＭＡＰでは約四十二％のＷＥＲが得られました
このことから
八ｋｂｐｓの場合は繰り返し適用を行っても圧縮された音声ドキュメントはインデキシングは困難だと考えられます
後半のまとめです
音声ドキュメントに音声認識を行ってインデキシングを行うことを想定した場合
一つ目に圧縮して保存する際には三十二ｋｂｐｓのビットレートを確保すれば十分であること
二つ目に十六ｋｂｐｓでは音声認識と音響モデルの適用を交互に繰り返すことで
処理できる可能性になる
処理できる可能性になる可能性があることがわかりました
全体のまとめです
前半では翻訳モデルを用いた統計的音声認識の枠組み
について述べその予備実験と評価を行いました
その結果翻訳モデルを用いた多言語同時音声認識の枠組みが機能することがわかりました
またそれが十分に機能するためには各言語の音声認識精度は四十％程度のＷＥＲが必要であることがわかりました
また後半では圧縮音声の音声認識についての検討を行いました
その結果三十二ｋｂｐｓのビットレートを確保すれば十分であること
また十六ｋｂｐｓでは音声認識と音響モデルの適用を交互に繰り返すことで処理できる可能性にあることが
わかりました
発表は以上で終わります
