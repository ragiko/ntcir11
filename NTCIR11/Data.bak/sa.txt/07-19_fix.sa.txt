はいすいませんちょっとトラブルがましたもので少し遅くなって申し訳ありませんでしたそれでは
会議記録システムのための音声ドキュメントやメタデータ化と題しまして岐阜大学のが発表いたします
まず本発表の流れについて簡単にご説明いたします
はじめに研究の背景などをご紹介いたします
そのあと
本研究のメタデータの生成について説明をいたします
次に会議記録システムについて本研究で構築したものについて説明をいたします
以上をもちまして実験評価行いましたのでこれらについてご報告をいたします最後にまとめと今後の課題について述べたいと思います
まずはじめに皆さんご存じのことと思いますが二十一世紀はスピードの時代ということで会議においても迅速な決断や情報共有が必要不可欠となっております
でこれらを実現するためとして会議記録システムというものが提案されております
この会議記録システムでは音声をマイクロフォンアレイやピンマイクなどでまた画像については複数であるカメラで会議の風景を
録画しこれらをまとめてアーカイブ化するということを行っております
アーカイブ化したコンテンツに関しましては再生停止などにより後から閲覧できるようになっております
またオンラインでウェブから利用できるようなものも近年報告されております
従来会議内容記録するものとしては議事録というものがありました
議事録ではおおよその概要をつかむことはできますがしかし例えば不参加者にとっては詳細まで会議の詳細までを知ることができないまた会議の雰囲気
までは知ることができないといったような問題がありました
これに対しまして音声や画像を利用いたしますと不参加者にとっても検索することによってより詳細な情報を知ることができるようになります
また会議の様子を
これらの音声画像を再生することで知ることができるようになります
先ほど申しましたように会議の音声や映像をアーカイブ化するということが行われるわけですがこれを効率よく利用するにはどのようにしたらいいのかということで

この収録したデータに対してメタデータというものを付与することが重要になります
メタデータとは皆さんご存じのことと思いますがデータについて記述したデータのことでインデックスやキーワードなどが
挙げられます
このメタデータですけれども人手で全てを付与することには非常に膨大なコストがかかってしまいます
そこで画像認識や音声認識を用いてメタデータ付与を自動化するといった試みがなされております
本研究では
マイクロフォンアレイと複数カメラ用いて会議内容の収録を行いました
またビームフォーミングや音声認識によってメタデータを生成し

これらを用いた会議記録け
検索閲覧システムについて構築を行いました
次にメタデータの生成の部分についてそれぞれの技術について説明していきたいと思います
メタデータの生成の図を簡単に示します
入力はカメラで取得した映像とマイクロフォンアレイで取得した音声データになります
この二つを統合して一つの映像音声データを生成します
また音声データに関しましては
ビームフォーミングや音声切り出し音声認識を行います
これらからメタデータを生成します

次に本研究のマイクロフォンアレイについて説明したいと思います
本研究ではこの図にありますように正二十面体型のマイクロフォンアレイを
構築いたしました
このような形にしたのは
同じく本学の別の研究室で研究されております全方向性用カメラSOSというものと将来的な統合を考慮してこのような形状となっております
この
マイクロフォンアレイですけれどもこの正二十面体の各頂点にそれぞれ十二個
マイクが配置されております
なお本研究ではこのうち五個のマイクを使用しております
このマイクロフォンアレイ各頂点の距離は十．五ｃｍです
またアレイの中心から床の面までの高さは三十八ｃｍとなっています
このマイクロフォンアレイで収録した音声はこの後さんの発表があると思うんですけれどもそのさんが開発された
さんの
産業技術総合研究所で開発されたＲＡＳＰ多チャンネルリアルタイム音響処理装置といったものを利用してビームフォーミングや音源方向の推定を行っております
マイクロフォンアレイですけれども本研究では会議室円卓や格子状のテーブルの中央に置くことを想定しています
それ故マイクロフォンアレイから離れている話者の音声のＳＮＲが低下してしまうという問題があります
そこで
遅延和アレイによるビームフォーミングによってこの
音声の強調を試みました
この遅延和アレイですけれども学習時には各マイクの
相関を求め
各方向ごとにその遅延量を予め求めておきます
そして音声強調を行う際には
各マイクに対して目的方向に合った遅延量を付加します
そして
このマイクの総和をとることで
目的方向の音声を強調することができるという仕組みになっております

続いて音声切り出しについて説明いたします
会議全体の音声から発話ごとに音声の切り出しを行っております
この切り出しについてはいくつか方法がありますが本研究では各話者ごとにビームフォーミングして得られた音声を利用いたしました
例としてこちら側に
二話者音声話者Ａと話者Ｂの
波形を示しております
具体的な計算方法としてはこの話者Ａと話者Ｂに対してそれぞれこのフレームの時間の中でパワーを計算します
そしてパワーが最大となっている話者をその
フレームにおいて発声している話者というふうに推定しております
またこの時パワーの閾値による無発声区間の検出や時間方向のスムージングやエラー処理なども併せて行っております
例えば
この次のフレームこの部分では閾値以下ということで無発声区間というふうに判断をする
というような処理を行っております
この場合ではこちらが話者という形になります
先ほどの図でもう一度示します
以上のようにして得られた切り出した音声
を使って音声認識を行いメタデータを生成します
本研究ではメタデータとしてこちらにあります会議メタデータ
と今回呼びますがこのデータと議事メタデータという二種類の
メタデータを生成いたしました
このうち
会議メタデータについては手動で作成するもので具体的には
会議名や開催日時場所また参加者や会議の概要などを
人間が手動で与えます
こちらの議事メタデータについては自動に生成するもので具体的には
発話者情報や各話者の開始終了時間また発話内容
などが含まれます

この議事メタデータについても少々説明いたしますと発話者情報としては

の抽出についてはまず話者は
会議中には移動しないという仮定を本研究では設けております
その上でマイクロフォンアレイで音源方向推定した結果と予め設定した
話者方向の角度と話者名との対応から話者名を推定しております
発話の開始時間終了時間については音声切り出し処理で求められたものをそのまま利用しております
また発話の内容については
先ほど音声切り出しで切り出した音声に対して音声認識を実行し
得られた音声認識結果をメタデータとして使用しております
続いて会議記録検索システムについて説明したいと思います
こちらがシステムの流れ図になり
本研究で構築した会議記録検索システムはウェブブラウザを用いたオンラインシステムとなっております
キーワードによる会議シーンの検索が可能となっております具体的にはウェブブラウザを通してキーワードを入力いたしますと
先ほど求めたメタデータと照合検索を行い
その結果を元にＨＴＭＬＸＭＬですけどもこちらを
生成します
そして議事失礼しました
映像音声データと合わせて会議シーンコンテンツとしてクライアントに返します
ユーザはこのコンテンツを再生したり
閲覧したりすることが可能になります
それではデモをお見せしたいんですけども動画のファイルを持ってきたんですがちょっと動画のファイルのコーデックが
合わなくてこちらでちょっと再生できないようなので
代わりに静止画のスライドになってしまうんですけれどもこちらで説明したいと思い
このような画面が初期画面になります
Ｇｏｏｇｌｅのような検索画面
に似たような画面になります
そしてここにキーワードを入力して検索をしますと
図が出ないんですが

このような画面が
表示されます
この文が会議のタイトルになります
そしてこの部分に
それぞれの先ほどの議事メタデータに相当する各会議のシーンの
ヒットしたシーンがここに表示されます

発話者はここに表示されており
また認識結果がこのように
表示されるようになっております
またこの各リンクについては詳細画面のリンクとなっておりここに時間
発話時間なども表示されております
そしてこのリンクをクリックしますと
このような画面に

移動することができます
この画面において一番上に表示されているのが会議メタデータ
人間が手動で付けたデータが表示されます
またここに映像が表示されますこの部分ちょっとキャプチャの関係で映像が落ちてしまっているんですけどもこの
この場合四画面ですがこの四画面のうちどれか一画面選択された一画面がここに大きく表示されます
このこの表示される画面は切り替えることが可能でこの
四つのボタンにより
ここに表示される画面を切り替えることが可能となっています
また
こちらの部分ですけれども
ここに再生制御
が組み込まれております
このスライダーを操作することで任意の場所からの再生や停止が可能となっておりますまたここに再生停止ボタンここに時間インデックスの表示機能も付いております
最後のこちらの部分ですけれども
この部分に

リンクが貼られておりましてこのリンクをクリックすることでそれぞれの場所からの再生が可能となっております
具体的にはこの部分が一番会議が最初からの再生になり
またこの

この部分が先ほどの
この検索結果にそれぞれ対応してるわけですけれども
ここをクリックしますとこの場合ですと零分十三秒この場合ですと三分十六秒という形で
別の
同じキーワードな別のシーンを
このクリックによって再生することができるようになっております


以上で構築いたしましたメタデータの生成と会議記録検索システムを用いて評価実験を行いましたのでこちらについてご報告したいと思います
まずこの実験の目的ですけれども会議の参加者または不参加者が
会議記録検索システムを利用して効率よく会議内容の検索閲覧ができるかを調査いたしました
実験の種類は二種類で音声認識の性能評価及び
システムの主観評価となっております
データベースですけれどもＲＷＣＴ会議用音声データベースに収録されておりました西鉄旅行キャンペーンというシナリオがあるんですけれどもこちらを本研究にあたり再収録したものを利用しております
会議の参加者は男性四名で会議時間は約二十五分となっております
具体的な収録風景ですけれども

ちょっと小さいのでお
おきくします


このような格子状のテーブルを用意いたしましてここにマイクロフォンアレイが置いてあります
そしてここに話者一人二人三人居てもう一人ここに四人居るんですけれども
この四人の話者がここで会議をしていると
いうような光景になっております

もう一度この会議室の配置について説明いたしますと

まず中央にマイクロフォンアレイがあります
そして部屋の四隅に
カメラがありましてこのカメラで会議の風景を撮影しております
またマイクロフォンアレイと各話者の距離は約一．五ｍであり各話者はこのように九十度づつ離れて配置しております
まず音声認識実験について説明します
音声認識実験ではＪｕｌｉｕｓによる音声認識の評価を行っております
使用した音響モデルはＣＳＪコーパスによる話者性別非依存のトライフォンモデルです
また言語モデルは二種類用意いたしましてＣＳＪコーパスの書き起こし文章からのトライグラム
オープンと
西鉄旅行キャンペーンの書き起こし文章から作成したトライグラムクローズの二種類です
実験条件はビームフォーミングのありとなしまた言語モデルのオープンとクローズでこの三種類を
用意いたしました
それでは実験結果になりますこちらの結果は言語モデルの違いによる認識率の変化を示しております
こちらが言語モデルがオープンのものＣＳＪを用いたもの
こちらがクローズのもの書き起こし文章を用いたものです
赤い方がＣｏｒｒｅｃｔｎｅｓｓで緑側がＡｃｃｕｒａｃｙになります
縦軸がパーセンテージをそれぞれ示しています
グラフを見ますと分かるように

言語モデルによる差が非常に大きいことが分かります
こちら側右側のグラフは

クローズ
の言語モデルを用いていることでｕｐｐｅｒ ｌｉｍｉｔ上限というふうに考えられます
そこで今後はこのオープンの結果の
認識率をいかにこの
クローズの結果に
近づけるかが課題となっていることが分かると思います
続いてビームフォーミングの有無による認識率の変化を見てみました
この場合言語モデルはクローズを利用しております
こちら側が
ビームフォーミングなしの場合のもの
こちらがビームフォーミングを行った場合の結果になります
このようにビームフォーミングによって認識率が大幅に改善しており
ビームフォーミングの効果が確認できましたＣｏｒｒｅｃｔｎｅｓｓでは九．六％Ａｃｃｕｒａｃｙでは七．七％の改善となっております
なお通常音声認識の評価はこちらのＡｃｃｕｒａｃｙの方で
行いますが
今回検索システムとしてはキーワードより正確に検出するという
ことを考えますとＣｏｒｒｅｃｔｎｅｓｓの評価も重要になりますいずれにしても音声認識の改善の余地があるということがお分かりいただけるかと思います
もう一つ
実験を行いました
先ほどの結果ですけれども音声切り出しの
切り出し誤りが含まれておりますがこの音声切り出しでは短い発話を棄却するというようなものになっております
そのため
音声認識では脱落誤りとしてこの部分がカウントされますのでこの切り出し誤りによる認識精度の評価を調べてみました
こちら側先ほどのグラフ右側に相当します

言語モデルがクローズドビームフォーミングありの結果になります
これは切り出し誤りを含んでいます
そしてこちら側の右側のグラフは条件同じでただし
切り出し誤りを含まない
切り出し誤りを除去したものがこちらになります
これを見てみますと
おおよそ五％程度
差があることがわかります
つまり音声切り出しによって認識率が五％低下しているというふうにも言い換えることができます
ただし棄却された発話は相槌やフィラー例えばはいとかそうですねといった発音でありますとか発話の最後の不明瞭な部分
何何何だと思いますのような非常に不明瞭な部分
といったようなものがあり
あまり重要なキーワードが含まれていないということが分かりました
このことからこの
低下による検索システムそのものへの影響はほとんどないものと考えられます
続いて二つ目の評価ですけれどもシステムの主観評価を行いました
これは被験者によるアンケートで評価しております
二つの対象を用意いたしまして実験を行いました
対象一といたしましては
先ほど収録に参加した会議の参加者四名
によるアンケートです
この四名に関しましては後日会議の内容を確認することを目的としてシステムを利用してもらいました
このような六段階の失礼しました六種類の質問に対して一から五の五段階評価を行っております
また対象二といたしましてはこの会議に参加しなかった六名に対して
後日続きの会議二回目の会議に参加してもらうという仮定のもと
一回目の会議内容を理解してもらうという
ことを目的としてシステムを利用してもらいました
質問は
対象一と同じになります
この質問はそれぞれメタデータ認識結果システム全体についての評価に相当します
こちら結果になります
質問が六種類で一番下の一が悪いという評価五が良いという評価になります
青色が参加者
紫色が不参加者
赤色が全体になります
この
真ん中の部分が平均でありこの部分が標準偏差に相当します
これを見てみますと
質問ＡＢこれはメタデータに関する質問ですけれども
これにより時間情報や話者情報はユーザにとって必要であることがお分かりいただけるかと思います
このことから
このこれらの情報を提供するメタデータの有効性が示されたと思います
続いて認識結果こちらの質問は認識結果に対して質問ですけれども非常にばらつきがあることがお分かりいただけるかと思います
特に不参加者こちらの紫の部分ですけれども
こちらの不参加者は実際に検索システムを利用する際に一般的な単語で検索する傾向がみられこれらの単語は認識の頻度が高いということで
あまりユーザに対して
ユーザが
満足できるような結果にということがわかりました
逆に会議の参加者は
会議中で出たより専門的な単語で検索する傾向があり
認識精度は低く誤認識によりそもそもこのキーワード自身が存在しないといったこともあるため
ユーザが満足できなかったものと考えられます
最後にシステム全体については
効率的な会議内容の検索閲覧が可能となったことが示されました
最後にまとめと今後の課題を述べたいと思います
本研究ではマイクロフォンアレイとビームフォーミングにより会議の音声をまた複数カメラにより会議風景の収録を行いました
音声については音声切り出しや音声認識によってメタデータを抽出いたしました
そして
以上で得られたメタデータと
アーカイブを用いて会議記録検索システムの構築を行いました
評価二種類を行いまして音声認識の結果は約六十％となりまだシステムの改善のためには
今後さらなる認識精度の向上が必要であると考えられます
また
主観評価では
会議参加者や不参加者の人であっても
効率よく会議の内容を検索できることが分かりました
また会議情報のメタデータは必要というようなアンケートも得られましたこのことから音声ドキュメントのメタデータ化の有効性がしめ
されたかと思います
今後の課題はこのようになっております認識率の向上や会議記録システムの向上
またシステムの機能追加などが挙げられます
以上で発表を終わりにいたしますご静聴ありがとうございました
