えーつ声の高さ
えーっとスペクトルは多分外国人と言って表現を残し
いうタイトルでえー
はえー
んー
えー
えー
えっとまずですねあのー本研究の内容について進めする前に
入るなりましたスペクトルクラスタリングいう
えー
ものについてま簡単に説明したいま文書のあの
出るとん時間も一度説明しますけども
えー言葉の説明ってことで最初
娘し
えー
あースペクトルクラスタリングっていうのはまこのスペクトルですけれども
えーいわゆるえー
て比べまして部分がえー固有値分解
という意味ではスペクトル
ということですで
えーんーまー実際には対象データー間類似度行列に対してえー固有ベクトルを用いて
クラスタリングをするという手法なんですが
えー元々はそれぞれ四の最小カット問題というもので
えーま適応されたもんでして
えーまかなり
えー取り扱いが容易である簡潔な
えーんます
完結編
ということから
え近年えーこういった
す文書分類であるとかえー画像認識という毎日ね形と色々な分野で用いられています
でえーま関連仕事しましては
えー
ま線形のま一でした成分分析ってあるとか
二つがえーま同じ考えでえー民族を
いったものとまー
ほぼ等価なものであるということが報告されている
でまた
えー生まれてしまって
これですね
でもまー関連性があるってことでえー馬琴に注目を二ん
えー
えー元につきましては後程えー
また
娘じ
えまず研究背景ですけれども
えーま企業とですねま今日の発表と
まー
んーなぜか来るとまー一つとかと思うんですけども
えー我々研究してま行ってもそこに製造検索システム
いうものをま作ろうということで
現在関してこう
で
えーま人手で行なわ大変え索引を付けたいんだけれども一例を
数量化の困難であることから
ま音声認識率自動的に二四つということでまー多くの研究比較で
えー行なわれてると思うんですけれども
まー
これだけに
えー
二万二千の対象としているということから
そのニュース記事と全く同じものがゲーム上にまー話者ＢＣＤ中のものが要集にもあるということで
えー二つに削除ウェブから生成して
えーっとにくいと書いてるもの構築するいうことでえーまこの青年行ってきます
でえー
で実際にあのー関連研究としてこういうゲーム上のテキスト利用するというもの
ま研究は数を行なってましてま先程の研究もありましたしま昨日の
五分でまとめますけども
えー
まこのようなものが関連研究としてあります
でえー実はあのー昨年度の強くえーですねえー
音声言語シンポジウムのいいますけども一昨年えー
ま同様のですねえー矛盾えニュース記事を対象としてから検索式を用いるという
えー発表水があるんですけれども
えーま基本的にあーの同じようなあのー
えー
で
えー
このあのセッションでもえーっと
立川
えー
訳だったもんですけども
えーま劇団テキスト利用する場合にはえー
ま大きく二つのパターンが
んーであるということでまー予めえこういったテキスト集めてほしいという風に指定する場合とえー
まず
認識結果直接集めてきたりという場合とが
いうことで
えー我々のえー後はえーこのこちらの方と同じ
んーとです
ねで考えて長いお勧めしますけども
えー最初にえーニュース音声のえー範囲を言語モデル認識します
で
でえー認識結果が索引語を抽出してえ索引語を選び出すえー
えー六畳か生地を
えー関連した二十．二以上はえー検索し収集してきてえー
それを用いて元モデルを更新するえー
で
この処理がえーとま音声認識
最初の音声認識の時点では
えーま誤認識と含まれてるんですけどもうまく類似記事を集めてくることができれば
えーまー
交通の認識ができるえー誤認識を少なくなってことで
でそれをまた繰り返しなんかすることでえー
精度が癌でないということでえーっとこの
あーこれについては昨年のですねえー聴覚
これで
発表したんですけれども
えこういうやり方を
という
で
ま結論としましてはま
正直に運動をえー
うまく行く時はもう
でまー当たり前の結果はですねえーうまく行くとつまり
えー認識がうまく集められて言語モデルの中
いい付ければ
えーどんどん更新
分かりませ分かるんだけども
もしくはレベルにえー音です
え以上から四十一記事がまノイズがあった位置がトピックの地であったりすると悪くなっゆまー
当然の結果になっていく
でえー
えーと問題点としてそれにまーお話しましたけども
そのというじょ適切なものをただ連れられているのか
いうことしてから
えーまー
ま適切で各重要な量の文書収集できているか
いう二つの問題が
えー問題です
点として考え
で
えー
ま先程もお話しましたけども
えー誤認識がどう違うトピックを拾ってしまう可能性があります
まーそのそのー
えーそのニューストピックそのニュースの内容はですねえー
例えばあの町議会形でよく男女ニュースで報道されてるものと非常にたくさんの記事が存在する訳ですし
えー
七十なり分けて二できるんですが
で一時的なニュースであったりもしくはまローカルな記事だったりする入学すると
えーまー
想像の類似した木自体が見つからないという問題が
なります
でえー本研究では
何まこの問題を解決する為に
えー
友情となってきた
えー
文章の中から
適切な文章先のおー選択してそれを用いて
えー言語モデルを作ろう
えー
でそれからえー二点目としては
えー
えー昨年度のえーえー発表では
風にそのおー予め切り出しておいて
えーま全体にえー検索全体の認識結果が検索をすること行ったんですが実際にはそのニュースの中では
えー他の回答インタビューと中に含まれていたりってから
社会県であったりとか
えーもしくは背景雑音だったりとかで
発話ごとにえー
海の認識精度が異なるということが
えーありますので
えー発話単位の処理をする
いうことを考えます
で実際に行なわ楽しむ非常に明瞭な
二十なりますので
えー
検索とか
非常に認識精度なんですけども
まこちら生まれたその旅であるとか
えー記者会見音のものと全く認識実験今日とか後まー
そういう問題
では
相手からえーとですねんー
これまであのまた続けまし手法ではえーニュース記事であるということから
に回答限定せずにサイトから記事を詰めてくれることを行なっていたんですけども
えー
まー
その場合
まローカルな記事やっぱりえー一次元二者ってずっと十分な共通語化できないということでま今回は二三入札への対処して検索を行なって
んー
で
ここで基本的な考え方なんですが
ま繰り返しになりますけども
えー明瞭な発音でえーま発声されたアナウンサーの音声
まそういう
発話区間であれば
認識精度もなかなか一
でずそういう認識結果から抜き出した索引語を用いた場合には
えー
ま関連した後類似した
大量の文書収集することができる
まこういう前提でやっていたんですけども
で実際には
誤認識多く組まれていることから
実際その誤認識が含まれているような
えー認識結果から索引語を抽出して検索しますと
まー微妙に異なるとＢだとかもしたまた関係猫であるとかまばらばらとですね色々な文章がしゅ抽出されてしまうんじゃないか
いうことで
で
えー
あーまこういうえー想定から
集めてきた記事をクラスタリングすることで
えーそのー
分布状況部分のえ上映会を調べて
えー
最も多く集まっている
えー
いうものを用いたというのがあー基本的な考え多分
んー
でえーそのクラスタリングにま最新御説明しましたスペクトルえースペクトルクラスタリングを利用するんですけれども
えー
二十一文書に対してえー各文書間の類似度をま三十計算します
で
えーこの時に
えー
基本的にはそのー
ま単語ベクトル空間上での類似度計算するんですけども
えーま非常に
益々ね
で下降次元の空間なってしまっいうことから
んー
まー
そのまま
通常のクラスタリングを行ないますとま計算量の問題であるとかま精度の問題等で
えーま若干
えー
クラスタリングます
ま望ましい重られないということで
えー今回このスペクトルクラスタリングを用いるとします
で
えーま特徴としましてえーこういったあー単語ベクトル空間でのえーま特色化数の低次元化を行なうこと
そいから
えー特徴空間流れており環境構造と書いてますけども
一近いものは
保険は何っていう
えー
えー提示喧嘩特色化を提示喧嘩した的に
えー
文章が文章として二言語学近くにいけないが特にという
形でえー距離が共存したままでえーこの事件なしかできますので
えーま非常にこういった文章
二クラス二とＶ形
いうことでえー今回構築するクラスを用い
えー
でま簡単に原理を説明しますとま最初にお話しましたえさえあの子供大学の最小化と問題として
いう提案されていたものですけれども
下手でもこういったグラフが
存在していてまどこで
えー分割するとえー最も
えー最初の異なるいうことを考え
いう問題
で
でこの仮にえー
各ノードとお
えー
まそれがえー
繋がってるかどうかいうことでえー
大勢か二日ぐらい前に言った重みをま設定してて
で
更に
えー二つのクラスの二つのおー逆に分割するという場合には
えー考えますと
もしあの
上の方のえーグラフであーグラフに含まれてるのはえー生き甲斐を一と四
えーＢの方逆の方ではマイナス一とするというように
気が四百ということをしますと
別のえーこの対象をかと問題はえーこういった式をえー最小化する問題としてえしかし二で
まこれは簡単ですねの弟ノードと
形を取ってえーその間繋がってんのというでまー
えー全部足してしまった時にえー最初何々ということなんですが
でこれをま展開していきますとまいわゆるこういった二十形式という形に置き換えることができまして
えー
で更にこれを
んー
えーところがですねえーこれが生成計画問題なりますのでまー
えーっとま父が難しいということで
えー連続値に緩和することになって
えー
この式からえー
ことをし加えることができます
で
原点ですねこの形に
変換しえー変形した時点で
えー
ま今えー固有値問題という風に置き換えることができますので
えーこれのえー固有ベクトル高いと
いうことになっ
でえーと先程のえーこちらのえーと書くんですけども
えーんー
まこれは最初講演者〇．という性質があることが分かってで〇での要するに固有ベクトルが全部一もしくはマイナス一対の直流成分なる訳なんですが
ま経験ての頃医学全体を表わして一分割でプラセンタ表わしているのもいうことで
えーま一般的な語に関連この固有値に対応したという距離を自分
なります
で
えーんー
で更にえーっと先程グラフの分割の問題だったんですけどもま一般のクラスタリングに応用する場合には
えーっとまー学の接続関係を表わした頭が主というものを
の中の類似度まー
文書クラスタリングのまだ文章間の類似度ですけどもに置き換えることでえー
そういうの問題
とことでえークラスタリングを行なうことができます
で本研究ではえー
ま簡単な為にえー第二こういうですね二番目の講演賃貸でしたこういう風だけを用いてま近似的なクラスに行なうとします
え更に
えー
ま元々の
元々のえー
このクラスタリング額の最初核問題っていうのが
要するにこの
一番
縦のグラフの間でま一番生徒が少ないと思っ小さいところっていうの求める問題になっていますので
えー
クラスタリングを行なう時の境界口語としてはえー疑似的類似度の総和が小さい体の境界で候補として
えーまクラスタリング行って孤独まこの後えーっと
んで
んー
えー時代の
スペクトルクラスタリングどういうことができるかということなんですが
でこちらがですねえーと縦横
がえー
文書集合なんですけれども
えー
まこういうようなあ文書がんー九十三つとして
えー
勝手にですねこの観点はえ暗い方がま似ているということを表わしています
で大学でも当然自分年ですねまーうまくなんですけども
こういったものを先程の式でえースペクトルクラスタリングを行ないます
まして
えー
得られた値にこういう風にもちょっと気にしますとえこのようにですねえー
非常に
まギャップが存在するようなこういった結果が
大体
という
でこの想定した結果に基づいて元々の方の類似度行列を並べ替えてみますとこのように
えーま奇麗ですねえー
似てる文が似ているところに対角線上に集まるような形でえクラスタリングされ
いうこと
でえー
えー
結局この前ですねえーと元々三つのトピックを混合してえまーだんだん辞めたんですけども
えー
クラスタリング境界点としてはまこういったとこですねこの集まった集合のこことここという形で求めたいので
えー
二点においおけるえ
えー
二以上の総和
いうものを求めた時に
え最も小さくなるというのが
教会っていうことになり
えー
んー
でで以上のようなえー方法を用います
でんー
実際にメルから収集した記事に対して
えー
クラスタリング行って
えー実験を行ないます
で
ね二次元一としては
んー
えー二やつですね用いてますで汎用言語モデルは今回は
えー新聞記事から学習した文一文単語バイグラム
モデルを用いて
で
えー
先程の
処理の流れでえーですね
と決定ニュースと経験的おー言語モデル言語的行なうという風にお話してたんですけども
今回のえー
実験では
九十五記事から作成したバイグラムモデルに対してえー汎用言語モデルの語彙を追加する
いう形で
まーニュースと低いよう言語モデル
ま同化してるん〇
ん作ってまそれ実験行ないます
で音響モデルはえー九十二月机の分布ですけども
評価尺度として
音声認識単語正解率と
えー索引語の方となる名詞のみを対象とした再現率適合
んでえー評価を行ないます
んー
でえー実験で用いた二つトピックなんですが
えーと今回ですね用いたのはえこのようだと
はい
で
えー
まこれ縦軸を用いたまこれあのー
わりと最近のものを用いるという文字だけがあるんですけれども
で一つはあのこの理由の一つとしてはえこれまでにですねえーまー
幾つかのトピックで
千実験行なっていて
えーま音楽家をま聞くことが分かっている
いうことで
えー
ま比較的
一時的かつまローカルな
まあまりこう話題になってないような気し
いうのでこう四つの基準にそれがあのー
でえーま平均
各肉の平均を当時からまー三分ということ
で
この中のえー平均発話文数は
大体六文型ということで
各発話
形には言えずまー三十八単語
平均三．三六単語
えー含まれているんですが
ま中には小さなものや大きなものまゆ
でえー索引語をこう
発話内の平均を削減法としては
んー待ってるし
いうことになりますえー
でえーっとー×です載せてますけれども
えー
今回の実験では
えーっとー結婚後に
予めトピックが気に分けられているものとして各トピックごとに実験行なっ
でそれからこの発話切り出しに関しては
えー
え発話切り出しに関しては二つですね
まＪｕｌｉｕｓを用い方と同様の処理でえー
えーまあ接続をし程度で
えー
言って
自動的には
ここと
でえーっと性が索引語母語に関しては喧嘩したら
えー一般名詞二三四五分
でまずはや言語モデルに
用いてえ各発話をえー認識した結果をえー
御覧いただきたいと思います
でえーっとピンク一から四までありましてえーまそれぞれ大体六二十分と入ってですけれども
えーん御覧のえーとですね
緑が
単語正解率で真ん中の赤いのがえー
適合率でえー黄色い方がんー再現率になります
で御覧いただいて分かる
んー他の体系と思いますが
え例えばこれですねえー
非常に
発話によっては非常に精度が高いものが
いうこと
で
ただえーっと逆にですねこのように
まつまりいーえー発話によっては
殆どえー
認識されてないもの
いうものもあると
えっとー予稿ですね背景な雑音で学習者は上がっていってるんところ
なんですけども
えー認識
世界一はあーＡます
四十五十パーセントですけども
空から名詞はもう殆ど間違い
でえー最後のこの六
えーと決定の六番目の文に関しては
えーこれはですねえーふアナウンサーの
発話が終わった後で
んー
社会気になってまーからこういううー
んよく見ながらお話
いうこと
えー
でえーと実際の例を御覧いただきますけどもま正解文の中ができました名詞がこういうものなんですけども認識結果としては
父の発達とか影響ぴったりの数というのも変わってるんですけどもえー誤認識でえー
全く関係名そのものが詰まったりもできる
えこのような
これを用いて検索しまうと当然ま関係ないようなトピックも集まってくるということ
でえー先程の
スペクトルえークラスタリングを用いたクラスに結果なんですけども
えー実はこういうな
んんー
えっと上の文ですねそう金融低下が一形で行なった後類似度行列になっ
でえーっとー
ん波形に対して累積類似度を求めて
えークラスター
あのー歳の
教会高校出しているんですが
毎回この一例が下の方にできるものではクラスター教会の九
で
えー
ってクラスタリングを行なった結果あートピック一に対しては
えーまー
ま関数は大体同じようなとこに集まっていてま最大のクラスターを形成している
で
えーサイン音というように
えー
若干違う基づいてえートピックを集めてしまってきます
違うと離れどこにあるという
でえーと結果三四に関してもんーまーほぼ同様なんですけれどもえこのように
認識率が低かったものをそこにを弾き方れるようになって
えーっと
こちらもしますけどもで最終的に
えー認識結果Ａを見ますと
えーこれは結果なりましたえトピック一二三四とありまして
太陽言語モデルと
えー正確に言うとえ今回提案手法
の結果が分かっ
でえー
収集したり全部で集めたま広くなっ
えー
まー
でえーっと
ま若いところで今回提案した手法でえーまか改善が
えーとまー
ほぼ同じが改善が見られ
いうことが
はい以上まとめですけれども
えーま今回はあー
えー
彼女の類似文書の中に一結局のモデル構築するという際に
できたらクラスタリングを用いて
よりえ明示したあ文書集合の形をする手法を提案します
でえクラスタリング結果から
信頼性の低い音声認識話そこは使わないという
えー方法取ります
ま今後の課題としたら分
んー
