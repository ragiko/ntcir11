はい
であ東北大学のまずはえー
本日は上データーを用いた話し言葉調言語モデルの作成というタイトルで発表さしていただきは
えーまず初めに
えー日本語話すコーパスによりえー日本語話し言葉音声認識鮫がまず仮定したってことはみんな
実は三つてる通りなんですが
ま特に
言語モデルの面からえーと四時から四つがものが非常に協力であれっていうことがこう全体的に知られてると思いまー
えしかしながら問題点として
ＣＳＪ全体の異なり語彙数はあ六万個一程度ということで
さまざまな話題の話し言葉音声に挙げたようできないといった問題がある
またこのお話い全然ない訳テキストデーター量を形態素という訳ななかったなっていうな形容ってことで
ま頑健なＮグラム確率を推定する為にやってないよう割合二十一だと言えば
えーよって参考と言うかな為にあのー
元学習データー量が必要となるのですがこれ以上音声データーを人手書き起こすってのがあ非現実的だなって今
でそこで従来一般的に行なわれが四つとしては
新聞七の書き言葉データーとの混合により言語モデルを評価関数でできることが行なわれます
で話し言葉データーに加えてえー一年中の言葉データーを使い話し言葉の為の言語モデルを強化する
でこの
書き言葉データーのみではまー
認識性能認識性の低い
ノイズが
まー
こちらに恋がたくさん
ん入ってんので語彙合併えーさまざまな話題内容的に異なることによって
えー認識性能が上がるといったことが起こります
えしかしながらこの書き言葉のデーターを加えると書き言葉スタイルのＮグラム確率劣化動作の上昇してしまう為
話し言葉対話音声に大体二世の低下してしまう
といった問題起こります
部屋従来どうしてこのような方法を行なっていったあー程度
話し言葉への音声認識に生きた学習データー点も何か手に入らないと考えられていたら
て一方でえー我々は
メル以上の話し言葉でいや
論理要するえーっと利用するアプローチというものを今回私も
えー
えーレベル以上の言語資源の葉を手にする為に
音声認識の為の言語モデルの学習に背景というようたということが
え先行点
一から知られています
えーま人間
文章スタイルを考慮したで言語モデルにでもかなりえー例えば音声対話におけるえーユーザーの検索要求にえっと発話した言語モデルの作成であったり
え文末第九の文の形式である文章を利用した
疑問文と違った言語モデルながら作成例が多くなり
でこのように
でえー音声対話であったりえーこの質問でやはりさまざまな
あれすれのデーター食べる上には存在する
でそこで我々はゲーム上の話し言葉のデーターをうまく利用すれば大規模な話し言葉用言語モデルを作成できるのではないかと考えは
でそこで本研究では
え以上の話し言葉データーを利用した対象が話し言葉用言語モデルの作成ということを目指します
えとまたもう別でえー
のデーターのみから話し言葉用言語モデルを作成っていうことはまだてるかどうかを検証した研究ではありません
そこで我々はストーンに水を組み合わせて
ペルーから話し言葉データーを体験を二十一つで言語モデルを構築するといったことを行ないます
そして目標としては
ペルージャの面からＣＳＪ付ける言語モデルＡと同等の人数制の問題
話し言葉用言語モデルを作成する
まだす
ＣＳＪではその疲れが別に言語モデルを作る
買って四次以上の話し言葉用言語モデルを作成するっていったことを目指します
じゃその上でえー今回やる枠組みとしては
えーまだプロセスでは話し言葉の
景気があっというものを作ります
その為に縁から
で別に認め文節でえー次のような流れを適応していけば
まずベルからダウンロードした結果に対してフィルタリングを行ないます
えぴったりとあ言語モデルの学習に重要な部分のみを抽出で
つまり電車で便のみを今回はルールベースで抽出します
で次に
えフィルタリングを行なったデーターに対して
これ話し言葉なのでき言葉なんだっていうことを考えます
で最終的に話し言葉データーのみを使いたいのでそこでで
で二番目の分類といったことを行ないます
テレビや話し言葉と書き言葉のデーターが存在せんので
今回はないいる人をこう
分類木を構築して分類を行ないます
で最後に
話し言葉
と判断された後に大体すえー言語現象の補完を行ないます
えーこれは話し言葉特有な言語現象ようなあくまで今回扱って言われている以上の文書なので
本当に
でえーと音声を書き起こしたようなデーターに入るようなものは
入っていないっていったことで
今回はなぜ日はあまり実現しない
といった問題がなぜこれを日は父にいー
行ないます
えーまあー米の文章を
っていうのは基本的に表わす言葉なんで
でえーっと元の位置っていうものは実際に人間が食べる
場合ですとどうも音の一一は必ずしも一致しないで
ちょうど方というの行ないます
でこれによって疑似的にですがあー話し言葉のデーターを構築してきます
で
このようにしか出て音声を書き起こしたお店で
話し言葉データーを準備することができます
であのー
部分部分の日
について説明していきます
えー
えまず聞いたりですが
固定れた統計量組み合わせて聞いたりんどうかな
後は二つ目え性能を行なっていた方法を適用します
えまず固定いたしてはまー
基本的な方法としてえ百点に整理をするような部分
また
で上にはＨＴＭＬであって
ではえーいＵＲＬなどが書いてるのである為八ページ記号のお五ページのあのて
全くえー二年前を
対象としてので一ような長さ
金まで色んな形がある以上方
考えます
また統計例としては
平均年齢層はえー
二チャンネルなんかではまー二チャンネル四などがあればて
そういうものをまー言語モデルの学生には使えないので
それを予め一般的な単語をトライグラムを準備しておくことで
単語パープレキシティー基準でえー
っていう形を行ないます
でそうするとこのこれはあー東北大学への人ピアノページ
この
ＨＴＭＬタグを取ってきたものなんですが
でこれをフィルタリングを行なうとこういうこのような部分まあー
えー
ま後はこの括弧の中で言う
もう
奇麗にするように設定します
でこれによって言語モデルの学習に言うような文章で文のみを充実化を行ない
えー次に
というやり方がな何て何だか話し言葉データーの抽出を行ないます
で今回はないので分類器によりスタイル分類を行なうことで
で話し言葉データーを話します
その為にまで
話し言葉大量書き言葉書いてそれぞれにグラム言語モデルを利用します
で今回は予め書き言葉のデーターと話し言葉のデーターがあることを仮定して
それぞれから二グラム
母音がステージで
である
フィルタリング後の例で言えばが
どちらのモデルから生成素敵だなってことをこのように
書き言葉のモデルから生成
ある事情が提示さが類似性
などを求め
最終的にこのような好きなものを
第例と判断します
で今回この家に比べには
大分類が目的なので名詞弟僕は金してえー助詞や助動詞などを重点的にしています
まー
スムージングが何一つの生成確率も利用するといったことを行なって
でこれによりナイーブベイズを用いて話し言葉と言うのであの実は全自動で分類するといったことが可能になり
で最後に言語現象の効果はないまー
えこれはあー周波時代という二十二課題をかなり八百屋です
ちょうど喉頭ニューモデルを適応します
でえ後にえモデルＡは二つのモデルからなっていて
えー文章中のある一に水が挿入される確率えー
本モデル易い更にそこの文字そこに
フィラー購入するならこの日は購入され向かっていった条件付き確率
としてモデル化します
ま多少本当にモデルは文節エラー率にショートポーズが挿入されるかどうか
という訳語をモデル化します
で今回我々はまートライグラムえーでそういうモデルをモデル化します
えーっとずっとまー
普通の文書に対して
次二つのモデルを適用すると
このように挿入することができ例えば一番上文章だと
かなりならえーとちょうどいいか忘れます年齢といったように
まー
高齢は音声を書き起こしたような定義が
には
このように
話し言葉の特徴を持つようなま本来あれば書き言葉書き言葉ではべき乗のページを
でえー音声を書き起こした訳ではないですが疑似的に話し言葉データーを達成することが可能となり
部屋このような枠組みを利用して〇から文章
話し言葉データーを集めて実験を行ないます
えまずその他
相手に
どのような
で結果を相手にする訳ですが
まー編
いいリソースが出て全体データーを今のような方法で行なえればいいのですがこれはまー一技術的なので今回
まー
ま大体千網羅的にサンプリング率
えＡからサンプリングしたあー合計八えー戦後百ゆ
千五百万いＵＲＬの的な
妨害想定してそれからデーターを先程まで説明した流れを適用することで
っていう記事話し言葉データーを作成していてまー
でその為に先程までえー
フィルタリングを経る
の面でえーまたナイフ一つえーデーターも出て
才能がショートポーズえ
えー嫌い外ＰＯＣの挿入モデル
その説明してきたんですがそれでそれぞれを仮説が明瞭おーデーターとしては今回ＣＳＪ二千五百三〇六講演話し言葉の為に
えー毎日分にね年五枚上でえー使う書き言葉の為に利用します
で前にはえー体制的に生地話し言葉データーを作成し
このでいながら
音声認識用言語モデルを作成
また
元々の四時でから学習者モデル
文を学習しこれらを比べていけば
で三番目のおテニス実験ではレコーダーはＪｕｌｉｕｓで音響モデルは四二五から水さトライホンモデル
で
テストデーターとして
でえーこちらの二千五百三〇公演を含まない四十一講演を用い
えー山で
今回作成したデーター量がどのっていうのは
ようなのかということを説明します
えーここであり八ページのまー格好で後おー統計学ふえー
道を示してあります
で各事例が多くていた私
家が残っているとすると何か
でまこの二次会というものはえー四え制約に前後百五円学生に書かもので
こちらのデーターうはまー約七百万と一般的に調べてみようと変わりません
でこれに対してえー今回
えー約千五百万いう悪い例のデーターあーそれを
できればいいのかな
二度最終的に
五十四境界と言えますＣＳＪに比べると
第一講座が大きいデーター
えー映画が手元にある出来事が分かると思います
この手元にえーんこの手元においてこの五十億円
形態素のデーターを内部でいいです
分類器で分類すると
んえーこちら
こちらなかなか聞くことばかりを判断されたものこちらの方が話し言葉という判断されたもので
えー話し言葉と書き言葉の比は約一たいなないぐらいで今回判断
んでえー自動で判断されました
で更にこの話し言葉増えた中で単位解析が挿入ショートポーズを挿入などを行なうと最終的に
逆六億てないと
のデーターが強く
って言いました
でえーこれは事前のデーター量
割り当て七百万えーこちらは逆六億しないと
なのでえーまＣＳＪの約八十前の話し言葉データー今回は疑似的に集めました
で
次に今詰めた例が
付けたデーターから定型のモデルを達成し認識性能を評価していては
えまず最初に
えーボイス動いたりえーっぽいって
今回やえー四番の娘以外でで言語モデルを作成し比較を行ないました
えー縦軸えーまーあの世界性で
まずこのす緑色のＣＳＪの部分が
まこちらは
で認識ドメインでそれがあの学習データーも同じドメインでありかつえー音声を人手で忠実に書き起こしたデーターを使ってが付いて
まこの場合
六十二四五パーセント程度でした
で
これが一個の丸一丸二丸三回であのあんまりじ読まないので一えー分類器
などの話し言葉二のデーター
この形は更に日学校に行った後の本を
もの
でこの最後の
丸三は更にショートポーズ導入を行なった場合えー
でこれを見るとまー
えー
言語現象の他により認識性能が改善し約六十円
六十．二パーセント程度
テーマ二十一二えーお婆六十二四五パーセントまでまだ二パーセントぐらい差があるのですが
更にこの一二三
後
まー単純に足し合わせて
それで補間し文ですけれど
最大でえー約六十五．〇四パーセント
その
ま四事例とい約一パーセントぐらいの差ですが
ペルージャのみで実現に匹敵するモデルを作成できるといったことが分かると思います
部屋
今のモデルを使ってえーこの語彙サイズを変化さして認識性能を見ていました
え先程早い四万語い
んー
データー果物もお四つえー文読ま語彙を使っていたのですが
祭りでは大体五六万
後一程度が限界であって後出してありますのがま四じゅまー
あー四万語一にして
生活程度の内容まー後まー後えま二十万三十万と
えーえーデーター量はいっぱいあるのでその分語彙サイズも大きくすることができ
でこれを見るとまー
語彙サイズを増やすことで認識性の問題でして毎日一万個一型
ぐらいであ六十二年三
八パーセントとまー
殆どＣＳＪ返さない
書いてないということをどの部分ができているってことが分かると思います
まあーデーター量がいっぱいあり未知語率の解析ん〇．〇パーセントまで改善が可能です
これに別々涙一つは話し言葉用言語モデルを作成歴史以前のみの場合と同等の二世のえーすることができるってことが分かりました
えまた今回作成した言語モデルの考察として各四例が手に出現したぐらいであのソースＡというものを見ていました
でこちらが付いえ二次会
の
はあートライグラムうー学生がん出てきたトライグラムの種類えー
えー
明治時代約三百万ぐらいなんですが
ま今回作成されるでは更に
その辺
で約一億円とか言ってい二億とか
多い
家庭のトライグラムを実際に観測できていました
で実際にえ課題Ａというのは二十一場合
えＣＳでよりこちらが二十一倍で
また
でトライグラムうーの数は四十倍ぐらいということで
えー
全然
生徒が生徒に
えートライグラムをまだまだ観測できる
えつまり頑健なＮグラム確率を推定する為に一つ前の日にはまだまーデーター量が不足して入れてくださってると思います
えー最後にこのモデルを混合した場合の認識性能というものを見ていました
え今回ＣＳＪの皆モデルと別々の三のモデルを作る際のえーこれら混合します
えー混合手法は要ら監督を用いて
チーズ出掛けたモデル後的にデーター量が小さいので四つでもう一倍にしてベルを一
にして
混合しています
でこちらが結果となっていて
この緑は先程まなどはえー説明したＣＳＪで
こちらが
四十何個か四万語い述べ
で
でこれ私はえーとこのような認識性能になり
娘以外ではないんですがこれらをアジアっていうことで
えー
性能が改善しているとは
いうことが分かります
え今回話題の依存性は完全に食べてるので
完全に学習データーがどう対して話し言葉のスタイルがより学習できることによってえー改善したと言えまー
ま娘以外で親と更に改善しています
えー一般的な知見として四つ言えば話し言葉あの体系的には十分なデーター量を今まで考えられていたのですが
今回このような結果から
話し言葉アークはまだまだあー評価することができでそれによってＣＳＪの実の言語モデルから更に二の改善が可能であるといったことが分かりました
えー山と今
えー本
こうでは出る以上の話し言葉データーを利用した内容な話し言葉用言語モデルの作成を検討しました
電話回線レベル文章による体系の七二二話し言葉データーを作成し
え最終的にＣＳＪの約八十代の話し言葉データー欧米から六しました
でそしてこれあのデーターを使ってないけど話し言葉用言語モデルを作成し
えー例から獲得した話し言葉データーのみでＣＳＪに匹敵するえー認識性能を達成することが分かりました
学べるからあ即した話し言葉データーとＣＧ絵を組み合わせることで
ＣＳＪの三よりも高い認識性能を達成しました
でこれらの力話し言葉音声認識の更なる高精度化に後えー劇場の話し言葉データーの内容は有効であることを示しました
以上です
