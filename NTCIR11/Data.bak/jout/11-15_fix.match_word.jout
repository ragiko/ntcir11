えーでは
後現存ネットワークを用いたしあれによる音声認識誤り訂正えー題目で神戸大学×研究室の中には発表させていただきます
えまず研究背景といたしまして
えー
えー音声認識精度
はえーニュースなどの正しい書き言葉で後画像九十五パーセント程の精度があるのですが
えー学会講演などのえ自由な話し言葉になると
後八十パーセントまで下がってしまいます
えーよってえー話し言葉でストレスのないえー音声認識を行なう為に
更なるえー音声認識精度の向上が期待されます
えー
えー従来の音声についてま簡単に説明しますとえ従来音声認識では
で言語モデルとして自然なえバイグラム
やっトライグラムの動画としています
えしかし
えーこのＮグラムの問題点といたしまして
えースムージングなどによりえー不自然なＮグラムが発生してしまうえーことがあります
えまた問題点が二つ目として
えＮグラムが自然だとしても
文章として自然な場合があります
でこの例文を見てもらったら分かると思うんですけど
別データー冷たいものが食べたくなかったっていうのは
えー自然な
で二グラムから生成されたえ文になっています
えー次に
えーこのえー冷蔵庫の中に面積をえ〇であるというのもえー自然がＮグラムからえー生成された自然な日本語です
えしかし
先程の分布並べますと
えー冷蔵庫の中に面積を入れてある冷たいものがあー食べただからだとなりましてえ冷たいものやえー食べるでうちはだから
え面積という部分に不自然さを感じるようになります
で現在のＮがものでではえーこのような不自然さにえー採用することができません
えーよって問題点が解決法といたしまして
えー問題でえー一つ目の
自然のＮグラム
自然のＮグラムの発声に対しましては
予めえーま識別的言語モデルといたしまして
自然のＮグラムを学習しておくことで解決したいと思います
で問題点の二つねでえーＮグラムでは分からない不自然さに対しましては
えーバイグラム
トライグラムよりもおー範囲の文脈情報
をえー取り入れることで解決します
猫でえーこの
後半えー文脈情報場所でえ文脈情報ということにします
で後え提案手法ですがえ条件文脈情報を用いた四あええ音声認識誤りをえ曖昧性性をえー提案しまー
えーまずえー自然
あー自然あるいはえ自然のＮグラムをしアレーを用いて学習します
えーこの為には予め
えー学習単語にえ最後ラベリングを行なっていく必要があります
えまたえ四八例によって学習する素性の一つとして
ちょっぴり文脈情報を追加することで
音声だけの二つの話題を考慮します
えーえ構造ここまででえー知られえ誤り検出モデルが
えー作成されますので
えーそれによって曖昧性識別された母音計算ネットワークを用いてえー説明
えーまずあのー平叙ネットワークについて簡単に説明しますと
えー
これはえーまークラスとクラスタリング圧縮することであります
えまたその過程でえーこのように
確率に信頼度が付与されます
えーこの
あ多い
点線の部分で
えー
点線で囲まれた部分はこの閉鎖音セットと言われていまして
上から順に第一候補
第二個おー第三方向という風に表現されています
えー
本研究ではえー四アレーによる誤り検出を用いてえこの
九ながら正解を探すことであんまり
えー誤り訂正を実現します
えまたえこのえー見にくいですけど水色で囲まれている
えー
入るんで表わされている単語はＮ付いて張りまして
でこの七歳を選択することで
えーこのヘッドセットスキップすることができます
えつまりこの
第一方法列を選択しますと
私価値はえー単語列が生成されることになります
えーこの音でサインを選択することでえ挿入誤りを決定することが可能になります
えー
知られによる誤り検出モデルについてまー簡単に説明いたします
えー私は頭から来た
っていう入力に対しましてえー誤り検出モデルをえー適用しますと
えー例えばこのようにラベリングを行ないます
でＣというのは背が得られ
いいっていうのが曖昧な縁になっているのでえここ
えーこの誤り検出モデルにおいて
えーこの私
っていう単語がえー誤りであると識別されたことになります
えこのえモデルの学習にはえー単語単語列に成功ラベリングが発生後ラベリング
されたものが必要となりますので
え音声データーを
音声認識器に通しまして
えー書き起こしデーターと比較することでえー先行ラベリングを行ないえー学習を行なって今
えーまたえー整合それぞれの学習えーそれぞれの特徴を学習するので
えー自然なＮグラムと共にえこのように
誤りを含んだ自然のＮグラムについても学習可能になり
えーこれはま知られうー
えーせえー二終わらせまー条件付き確率分布になってるのですが
えー
あー入力Ｘについて得られる場合が付与される条件付き確率で表わされています
えー後えーラベル場合っていうのは
えー本研究では生後ラベリングに用いますのでえーし
正解ラベルと誤りあるのに一位になって
えー試合二のえー学習はえーこの
素性に関して関するえその素性が重要であるλ
うーこう学習するのがえー学習型となっていまして
でこの条件付きか
条件付き確率
あのー対数尤度を最大にするように計算されます
えー
もっと具体的に説明いたしますとえー
頭別のように明らかにえー誤りだと分かるバイグラムは
えー誤り部分音のみよく出現しますので
えー
誤りに対する重みが大きくなるように先程のλが学習されます
で逆にこれは
のようにおだけでは正解誤りかを識別できないえーバイグラムに対しましては
えー
えー
重みがえー小さくなるように計算されますえー例えばえーこれは犬
えーこれは犬のようにえー犬です
のようにえーたちますと
えー
それはえー自然な
えーＮグラムになりますのでえー
正解傾向を示すＮグラムになるのですがえーこれは食べるようにえー指しますとでそれは誤り傾向を示すＮグラムになってしまうので
えここでえではえー正解誤りを識別できないということになります
えーこれはえー例としてえーバイグラムをさ既にえー説明いたしましたが
えーとこの音響尤度やえー品詞の連鎖など
でさまざまな素性を柔軟に設計できるのが特徴となって
によって
えっとそれの一つとして
名所けえ文脈情報もえー取り入れることにします
で条件文脈情報ってのはこれはえー周辺のえー認識結果単語を参照した時に識別対象単語が不自然でないかという情報のことになります
えー例えば音声
であえー会話
話者
対話っていう単語が現われる場合の中に突然大根
っていう単語は現われるのは不自然だと感じられます
えこのように出現単語の水データーをい三つとして大切な
えーこれによってえーバイグラム
トライグラムよりもえー後輩の文脈情報を考慮できるようになります
えそしてここではえ動詞形容詞名詞のみにスコアが今
えー
え次に意味スコアの算出ですが
えー
これはえー単語ｗについての水を求めるとします
えーそのその場合えー
その単語Ｗとえー周辺の単語集合
調べデーターのえー類似度をまず求めます
えそしてえーその周辺の単語ｗｉの各ｗｉにつきましても
えー類似度を求めましてえその平均分かります
熱でえその二つの値
からえー正規化を行ないえそれを意味スコアとして今
えーこのＬへ児童の計算にはえー星を用いていますがあまり形成について説明は割愛させていただきます
んえー提案手法の流れになりますが
えーっと以上のようにえー説明したあ手法を用いて提案手法をえ実現します
えまず
えー音声認識器により音声ネットワークを出力しま
えーこの音声データーは
私達は
という発話に対して出力されたコンピューターネットワークです
えーこのこのえーとネットワークに対しましてえーちょっとえ文脈情報としての
水を増やします
えー先程申しました通りえー形容詞と
名詞と動詞のみにえー三つかを与えるので
えここでは
えーまー名詞しか登場していないのでえー現われた名詞二に都合が付与されます
えそしてえー
この今日のネットワークと
私達はえー書き起こしデーターを用いましてってせいもラベリングを行ないます
えーそしてこの
このデーターを用いまして
知られずによって誤り検出モデルを学習します
えー
えーそしてえーその
流れ学習した誤り検出モデルを用いましてえコンピューターネットワーク上で
音声認識の誤り生成を行ないます
えーその生成手順について簡単に説明させていただきます
えまずえーま何らかの
えー音声データーを入力しまして
えこのような
ごみのネットワークが出力されたとします
えーこのエコーロケーションネットワークの
最尤法これ
えー第一次以降これとえー抜き出しましてえそれは私達は
というえー単語列になります
その単語列に対しましてあんまり現実を行なうと
えこのようにえー示されまして
えーかつて単語は誤りであると識別されました
あよってこの第二候補である
×と置き換えることにおいてえ性を行ないます
えーそしてえー活動着替え私達はっていう単語列ができますので
えーその単語列に対してえーもう一度
えー四アレーによる音声認識の曖昧で検査を行ないますと
でこのようにえー全ての単語がえー
正解であると識別されました
えこれには別訂正があり四といたします
えー評価実験といたしまして
えベースラインはえーＣＭですと書いてあるんですが
えこの併存ネットワークのえ最尤法これ
えこの単語列を
えベースラインとしての
えまたえー飲んセマンティックというのはえー提案手法の素性としてい水を用いない場合
えつまり
で知られてるによって学習パス
学習する素性がＮグラムだけの場合となります
そしてえープロポーズメソッドっていうのはえーそれにリスクを
えー
付与しえーい水を
祖先の一つとしてえー追加した場合
で更にオラクルというのは
えこの併存ネットワーク上の正解単語を全て得られた場合の単語列となりまして
え本研究のえー既存の値となります
で評価しようとしましては単語誤り率
まーデーターベースを用います
えー我々とはえーこの
えー置換誤り
削除誤りって挿入誤りをの葉をえ全単語数で割ることによってえー算出されます
えーコーパスといたしましてえー日本語話し言葉コーパスＣＳＪを用いました
音声認識はＪｕｌｉｕｓえー音響モデル言語モデル共にえＣＳＪから学習しています
でそして誤り検出モデルのえー学習には
えＣＳＪの百五十講演
で評価にはＣＳＪの一三講演を用いています
えー最後にえー知られの
えー誤り検出モデル
のえー学習に用いた素性といたしまして
え表層単語の意味であのーバイグラムトライグラム
えーそしてコンフュージョンネットワーク上の信頼度
で更に意味スコアそして今
んえー実験結果ですがえーまず単語誤り率についてえー評価したいと思います
えー
でこれがベースラインであるＣＭでさんがあるんですけどえー韻律句を用いない
家のセマンティック
でもえーベースラインに比べましてえー三．五三ポイント
えーま与えられたが改善しているのが分かります
え更に意味スコアを追加することで
えーベースラインに比べまして三．七五ポイントを改善しました
えしかしえーこの二そんな体であるオラクルと比べると
また
僕の誤りがえー残されているのが分かると思います
えー次に誤り種類別の評価をします
えーここではえー
意味スコアのない場合とある場合についてえー評価をしたいんですが
え削除誤りと
挿入誤りにつきましてはえーこの
えー
あえー誤りの数が殆ど変わっていませんが
えー
一番多く変わっていたのはえー
この置換誤りでしてえー置換誤りがえー
水を用いない場合とを用いた場合ではえー
曖昧が百個程
減ってる
という結果になりました
えーよってえー韻律語はまちょっとえ文脈情報は置換誤りに思い出に有効でありました
えしかし
えーっと
置換誤りにおいてえこのオラクルとの差が
えー大きいのもえー現状でして
えーもっと
流行な韻律句を見つけることでえーこれが改善できるのではないかと考え
えーまとめといたしまして
本研究ではえーこんえーとネットワークを用いて
四アレーによる音声認識誤り生成を行ないました
えーまたあー素性としてえーちょっとえー文脈情報である水を
導入しました
でえー提案手法において単語誤り率でえー三．七一ポイントを改善しました
えー今後の課題といたしまして
誤り検出精度の改善が挙げられます
えーこれはあの品詞情報の追加や
パラメーター推定法の変更などが挙げられます
また
本研究では
え今回あのー
えー
家のグラムを用いて
のえーＮグラム法を用いてえー月でした
えーの音声もあると
えー
家のグラムを水をえーえ素性として用いたえープロポーズメソッド
の比較をしたんですが
えーこの意味スコアはどれだけ
聞いたのかっていうのがあーこれだと分からないので
えーちょっとえ文脈情報のみをえ素性として用いた場合の評価っていうのもおー
今後の課題となり
えー以上で発表終わります
御清聴ありがとうございました
