でえっとー
まその
既存の
会話の流れをむすえーっとあまり考慮されてないという
言ってたんですけど
まーあのー
係数ラベリングもえーもうえー使ってえー推定しますと
で後から来率ラベルのモデルですと
まーあのー代表的な隠れマルコフモデルです
心の状態ついに単純マルコフ立場でしたマルコフモデルなんですけど
えーん
ま家族兄弟Ｘのこれがあの発話の系列に当たるんですけど会話に当たるんですけど
二状態系列え×
まず発話音声えー発話検証といったするとこの系列を求め問題になります
でえーっとー
ま本来はえーと系列全部を見経営歳
えーっと一最もらしい系列を選んでくるんですけどその
築地ついでになるのでその先の会話っていうのは予想できないので続い推定することになるので
まこういう形で
推定することになりますその前のおー推定した結果を利用してす推定することにあります
てこれだとあのー決定的に
えーうー推定していかないといけない
んですけども
保存前向き確率を利用したら
そのー
直前の状態を使うえ実例をえー与えて
えーある程度頑健になるのかなということで
まーこの普通でえーとー情報の推定を
がえー
えー比較してみますと
でえーとーＨＭＭの特徴としてはそのまー
提示られるのも全部で四枚の状態起こる可能っていうのと後
後はまー生成モデル
というまこれ二三
とおーかなと思いどうんーまその日
ＰＸ次元の場合はなってい付いていけないと
えーいけないといけないという生成モデル
脳特有のまー
欠点があります
後まー一独立な素性を
そして四独立な素性を扱わできないというような
まデメリットもありま
テーマ私はえーまー単純に
最尤推定で
取れるんですけど
えー
の
〇二の問題
えーと二つ
えー学習データーに現われて内での大割れない単語が
えー
テストデーターに現われえっとーえー頭ではないちゃうのでえあのー今回は新たスムージングをしますと
