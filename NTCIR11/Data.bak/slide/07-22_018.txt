まとめますと国際会議とかニュース
とかでマルチチャンネルですね異なる言語で同じ内容の発話があるような
場合の音声認識について検討しました
で予備実験としまして
日本語音声認識時に英語のほうは認識しなくてテキストと機械翻訳を用いて
実験してみて
そういう枠組みがきちんとうまく動くことを確認しました
で今後の課題は
実際の話し言葉での実験及び評価することと
日本語と英語両方ですね
英語のほうが誤りがなかったので
良くなってる可能性も
十分ありますので
両方音声認識してみる
でそれから
今は
文の
対応っていうのがはっきり付いてるような状態ですし
同時通訳
とかとは少し性質が違いますので一回書き起こしたものですので
同時通訳とかを音声認識してみるというようなことも
必要だろうなということは
考えてます
でそれから最適な統合重みですね先ほどの
振ってみたんですが
あんまり分からないですでこれこれをちょっとどうやって決めるか
というところを
検討していきたい
思っています
発表は以上です
