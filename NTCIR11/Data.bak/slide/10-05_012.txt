で
先ほどのちょっと出てきたのとまた
復習も兼ねまして今のような音響ベクトルＡというのが出て千二十四
に
してたんですがそれとあと文書ベクトルＤのほう
これも特異値分解で
実際には単語数とかエヌグラムまあバイグラムぐらいですと何万となるわけですがそれを
ＬＳＡで千二十四にする
ゆうようなことをします
で
そこの間の関連付けですけれども基本的にはどの文書とこの音楽っていうのが結びついているっていうのがもう分かっているそういう条件のもとで学習が可能
なものっていうのは入手できますのででそれらを使えばある文書ベクトルと音響ベクトルの組っていうのがあってでそれの間をこう関連付けたときの誤差これですね
この誤差が
最小化されるような
形でＷを学習します
このＷっていうのは
このように解析的に解けるっていうことが分かってますのでこの形これを
この式をそのまま解けば良い
これでＷが推定できると
二乗誤差最小化の条件のもとで解けと
いうことになるわけです
ということが
