で実験なんですが
音響モデルの方についてモノフォンとトライフォン使ってみたんですが
結果は三名ずつなんで
六個あり
で縦軸が認識率でして赤色が
普通に音声認識行った場合です
で青色が翻訳モデルを使った場合です
で見てみますと
翻訳モデルを用いた場合に
認識率が
この辺除いて向上してるということが分かります
で特にこの辺ですね元々認識率が低いようなところで
精度の向上が
見られたというようなことがわかりました
で実際の話し言葉の音声認識っていうのはもっともっともっと認識率低いところに
あるんじゃないかと思われますので
何かこういうことやってやると良くなる可能性があるんじゃないかという感触を得ています
でその次に
今はこの
ここの統合重みのγって係ってるんですがこれを
事後的に良くなるように決定してたんですがこれを振ってみたらどうなるかと
いうのを
やってみました
