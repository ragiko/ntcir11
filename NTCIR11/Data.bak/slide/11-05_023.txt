であと
系列ラベリングで前向き確率を用いる
っていう話をしたんですけど
そうですねオープンデータだと前向き確率を用いた方が全体的に良い結果が
若干良い結果になってました
でこれがそのＳＶＭと
ＳＶＭのマルコフモデル
を比較し
の結果の例なんですけど
これが正解ラベルをＧっていうのが発話
権の譲渡を意図した
発話
としてラベル付けされているもので
これが各モデルの推定結果と発話権譲渡の
確率を表しているもので〇．五を超えたら
Ｇってラベルが振られるんですけど
注目して欲しいのは三番目なんですけど
ＳＶＭでは〇．八三四
ていう結構
高い確率で発話権の譲渡
を意図してますよって推定しているんですけど
前向き確率用いない場合は
〇．四ぐらいで
誤識別誤判別しちゃってると
あるんですけど
前向き確率を用いると
そうですねもう片方の
状態からの
影響があってなんとか
正しい正しく推定できてますというような
結果です
でクローズドデータだと
前向き確率が
を用いた方が
全体的に
悪
くなる傾向があったんで
本来
モデルの信頼性が低い場合に
有効なのかなと
考えられます
